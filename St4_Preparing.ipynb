{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Ссылки \n",
    "  * [Разведочный анализ данных](https://www.kaggle.com/emstrakhov/eda-with-pandas).<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-03T06:36:14.331316Z",
     "start_time": "2021-02-03T06:36:12.672756Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import warnings\n",
    "from functools import reduce\n",
    "import seaborn as sns\n",
    "import os\n",
    "import csv\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "matplotlib.style.use('ggplot')\n",
    "%matplotlib inline\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "\n",
    "pd.options.display.float_format = '{:,.2f}'.format\n",
    "pd.options.display.max_rows = 200\n",
    "pd.options.display.max_columns = 100\n",
    "\n",
    "sns.set_style(style='white')\n",
    "sns.set(rc={\n",
    "    'figure.figsize': (12, 7),\n",
    "    'axes.facecolor': 'white',\n",
    "    'axes.grid': True, 'grid.color': '.9',\n",
    "    'axes.linewidth': 1.0,\n",
    "    'grid.linestyle': u'-'}, font_scale=1.5)\n",
    "custom_colors = [\"#3498db\", \"#95a5a6\", \"#34495e\", \"#2ecc71\", \"#e74c3c\"]\n",
    "sns.set_palette(custom_colors)\n",
    "\n",
    "os.chdir(r'C:\\Users\\Mr Alex\\Documents\\GitHub\\FlightPreparence')\n",
    "\n",
    "# Рабочие фреймы\n",
    "df = pd.read_csv('train.csv')\n",
    "tsd = pd.read_csv('test.csv')\n",
    "# Объединенный список из фреймов\n",
    "comb = pd.concat([df, tsd], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Преобразуем объектные столбцы в числовые \n",
    "df['date'] = df['date'].map({'S': 0, 'C': 1, 'Q': 2})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Преобразуем объектные значения в колонке в числовые автоматически\n",
    "df['date'] = LabelEncoder().fit_transform(df['date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Преобразуем Dtype колонки в числовые, если нужна внутренняя редактура\n",
    "df['data'] = df['data'].str.replace(r'\\D+', '') #Удаляем все НЕцифры\n",
    "df['data'] = pd.to_numeric(df['data'], errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Извлекаем определенные фразы из объектных строк\n",
    "for dataset in df:\n",
    "    dataset['data_new'] = dataset['data'].str.extract(' ([A-Za-z]+)\\.') #В данном случае слова, в конце которых стоит точка"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Преобразуем float в int\n",
    "df['data'] = pd.to_numeric(df['data'], downcast='integer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Разбиваем колонки на новые, в каждой из которых только свои уникальные значения из прежней колонки\n",
    "pd.get_dummies(df.Data, prefix=\"Emb\", drop_first = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Выделяем числовые колонки в отдельную группу, получаем список заголовков колонок\n",
    "num_feat = [x for x in comb.columns if comb[x].dtype !=\"object\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Выделяем номинальные колонки в отдельную группу\n",
    "cat_feat = [x for x in comb.columns if comb[x].dtype == \"object\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Выделяем упорядоченные колонки в отдельную группу (из номинальных, самостоятельно)\n",
    "ord_feat = ['data','data1','data2']\n",
    "cat_feat.remove(ord_feat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Создаем список колонок, которые будут после обработки удалены из индекса. И добавляем в индекс новые\n",
    "to_remove = []\n",
    "to_remove.append('data')\n",
    "num_feat.append('new_data')\n",
    "ord_feat.append('new_data')\n",
    "cat_feat.append('new_data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Проверка на корреляцию всех числовых колонок\n",
    "corr_matrix = comb[num_feat].corr()\n",
    "plt.figure(figsize=(16,12))\n",
    "sns.heatmap(corr_matrix.T, annot=True, cbar=False, cmap='coolwarm');\n",
    "\n",
    "# Отдельно выделяем все, что выше 0.8\n",
    "corr_matrix = comb[num_feat].corr()\n",
    "plt.figure(figsize=(12,12))\n",
    "sns.heatmap(corr_matrix.T, annot=True, mask= corr_matrix < 0.8 ,cbar=False, cmap='coolwarm');\n",
    "\n",
    "# Ищем колонки с наибольшей корреляцией предикторов к отклику, удаляем отклик\n",
    "corr_ser = comb[num_feat].corr()['y'].sort_values(ascending=False).drop(\"y\")\n",
    "fig, ax = plt.subplots(figsize=(10,12))\n",
    "sns.barplot(x=corr_ser.values, y=corr_ser.index, palette=\"rocket_r\")\n",
    "plt.title(\"Корреляция числовых предикторов с откликом\");\n",
    "\n",
    "# Удаление топ-корреляций из фреймов и из списка числовых колонок\n",
    "high_correlated_var = [\"data\",'data1','data2']\n",
    "comb = comb.drop(high_correlated_var, axis=1)\n",
    "\n",
    "for c in high_correlated_var:\n",
    "    num_feat.remove(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Замена пропущенных значений одной из переменных из колонки\n",
    "df.Data.fillna(df.Data.mode()[0], inplace = True)\n",
    "\n",
    "# Вариант 2, для категориальных колонок\n",
    "for col in cat_feat:\n",
    "    if comb[col].isna().sum() > 0:\n",
    "        comb[col] = comb[col].fillna(value=\"NA\") #Заменяем пробелы объектом 'NA'\n",
    "    else:\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Обработка категориальных колонок\n",
    "new_data = comb['data'].apply(lambda x: 1 if x != \"NA\" else 0).astype(\"object\") #Заменить все NA\n",
    "new_data = comb['data'].apply(lambda x: x if x == \"Predict\" else \"Other\") #Разделить на доминирующий предикт и всех остальных\n",
    "\n",
    "# Plot обновляемых данных\n",
    "fig, axes = plt.subplots(nrows=1, ncols=2, figsize=(12,4))\n",
    "\n",
    "sns.countplot(new_data, ax=axes[0])\n",
    "sns.boxplot(x=new_data.values, y='y', data=comb, ax=axes[1])\n",
    "axes[0].set_xlabel(\"New Data\")\n",
    "axes[0].set_ylabel(\"Y\")\n",
    "axes[1].set_xlabel(\"New Data\")\n",
    "axes[1].set_ylabel(\"Y\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Создание новой колонки на основе других (математические действия)\n",
    "new_data = (comb['data1'].astype(int) - comb['data'].astype(int))\n",
    "comb['new_data'] = pd.Series(new_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Обработка номинальных колонок\n",
    "\n",
    "for col in ord_feat:  \n",
    "    print(f\" Column '{col}' has unique values {comb[col].unique()}\")\n",
    "    \n",
    "ord_map = {\"NA\":0, \"Po\":1, \"Fa\":2, \"TA\":3, \"Gd\":4,\"Ex\":5}\n",
    "for col in ord_feat:        \n",
    "    if len(comb[col].unique()) <= 6 and col !=\"data\":\n",
    "        comb[col] = comb[col].map(ord_map)\n",
    "        comb[col] = comb[col].astype(int)        \n",
    "    elif col in ['data1', 'data2']:\n",
    "        comb[col] = comb[col].astype(int)\n",
    "    else:\n",
    "        print('Dat all')\n",
    "\n",
    "#Включаем обработанные упорядоченные в числовые\n",
    "for col in ord_feat:\n",
    "    num_feat.append(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Фильтр фрейма, оставить только строки с опредленным значением в одной из колонок\n",
    "print( 'Before:', len(df) )\n",
    "gwa_codes = [code for code in df.Code.unique() if 'GWA_' in code]\n",
    "df = df[df.Code.isin(gwa_codes)]\n",
    "print( 'After:', len(df) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Заполнить пустые значения средним по колонке\n",
    "df['data'] = df.groupby(['data1']).Data.apply(lambda x: x.fillna(x.median()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cоздание новой колонки, аггрегирующей данные из нескольких\n",
    "new_col = ['data','data1', 'data2', 'data3']\n",
    "comb['new_data'] = np.zeros(len(comb)).reshape(len(comb),1) #Создаем новую пустую колонку длинной в список\n",
    "\n",
    "#Переносим в новую колонку все значения из старых\n",
    "for col in new_col:\n",
    "    comb['new_data'] += comb[col] \n",
    "    \n",
    "# Удаляем старые колонки из фрейма и из списка числовых колонок\n",
    "to_remove = ['data','data1', 'data2', 'data3']\n",
    "for c in to_remove:\n",
    "    comb.drop(c, axis=1, inplace=True)\n",
    "    num_feat.remove(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-03T14:17:09.733936Z",
     "start_time": "2021-02-03T14:17:09.105935Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'to_remove' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-60b7fbff006d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#Удаляем лишние колонки\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mto_remove\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'to_remove' is not defined"
     ]
    }
   ],
   "source": [
    "#Удаляем лишние колонки\n",
    "df.drop(to_remove, inplace=True, axis=1)\n",
    "\n",
    "#Или\n",
    "for col in to_remove:\n",
    "    comb.drop(col, axis=1, inplace=True)\n",
    "    cat_feat.remove(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Удалим первые 10 строк\n",
    "df = df.drop(np.arange(10), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Удалим всех пассажиров с переменной меньше 10 и больше 50 \n",
    "df1 = df.drop(df[(df['data'] < 10) | (df['data'] > 50)].index)\n",
    "df1.shape[0] / df.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Категориальные колонки не имеют естественного порядка, поэтому преобразуем (еще методы: OneHotEncode и Label Encoding)\n",
    "dummy_comb = pd.get_dummies(comb[cat_feat], drop_first=True)\n",
    "\n",
    "for col in cat_feat:\n",
    "    comb.drop(col, axis=1, inplace=True)\n",
    "    \n",
    "comb_with_dummies = pd.concat([comb, dummy_df], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Преобразуем бинарные столбцы в численные. Колонку y тоже\n",
    "df['data'] = df['data'].map({'predict1': 0, 'predict2': 1, 'predict3': 2})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Приводим множество названий колонок к типу set, находим разность двух множеств: \n",
    "print(set(X_train.columns) - set(X_test.columns))\n",
    "print(set(X_test.columns) - set(X_train.columns))\n",
    "\n",
    "#Добавляем недостающую колонку. Смотрим, стоит ли склеивать отдельные переменные в более крупные классы\n",
    "columns = set(X_train.columns) | set(X_test.columns)\n",
    "X_train = X_train.reindex(columns=columns).fillna(0)\n",
    "X_test = X_test.reindex(columns=columns).fillna(0)\n",
    "\n",
    "#Проверяем совпадение колонок (если да, то True)\n",
    "all(X_train.columns == X_test.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Группировка колонки по двум другим переменным. Медиана группы подставлена в пропущенные строки \n",
    "grp = df.groupby(['data1', 'data2'])  \n",
    "df.Data = grp.Data.apply(lambda x: x.fillna(x.median()))\n",
    "df.Data.fillna(df.Data.median, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Абсорбируем и удаляем лишние знаки из объектов во всех строках колонки во фрейме и записываем их в новую колонку\n",
    "for dataset in comb:\n",
    "    dataset['data_new'] = df['data'].str.extract(' ([A-Za-z]+)\\.', expand=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Построение облачного графика из объектов, где размер коррелирует с частотой\n",
    "wc = WordCloud(width = 1000,height = 450,background_color = 'white').generate(str(df.Data_new.values))\n",
    "plt.imshow(wc, interpolation = 'bilinear')\n",
    "plt.axis('off')\n",
    "plt.tight_layout(pad=0)\n",
    "plt.show()\n",
    "\n",
    "df.Data_new.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Если в БД нет единой метрики, то стандартизируем данные\n",
    "import math\n",
    "from sklearn import preprocessing\n",
    "from sklearn.decomposition import FactorAnalysis\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "norm = preprocessing.StandardScaler()\n",
    "norm.fit(df)\n",
    "X = norm.transform(df)\n",
    "\n",
    "#Cтандартизируем переменные 2\n",
    "df_scaled = preprocessing.scale(df)\n",
    "\n",
    "#Методом поиска главных компонентов проецируем данные на двумерную плоскость и получаем ранжирование компонентов по важности \n",
    "pca = PCA(n_components=5).fit(df_scaled) #Уточняем число компонент и источник данных \n",
    "\n",
    "#Доля разброса в данных, объясняемая главными компонентами\n",
    "print('Влияние компонентов на общий разброс данных: ', pca.explained_variance_ratio_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Возвращаем разделение данных на train/test\n",
    "clean_train_df = comb_with_dummies[comb_with_dummies[\"Y\"] > 0].copy()\n",
    "clean_test_df = comb_with_dummies[comb_with_dummies[\"Y\"].isna()].copy().drop(\"Y\", axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "nbTranslate": {
   "displayLangs": [
    "*"
   ],
   "hotkey": "alt-t",
   "langInMainMenu": true,
   "sourceLang": "en",
   "targetLang": "fr",
   "useGoogleTranslate": true
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
