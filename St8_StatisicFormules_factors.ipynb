{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib \n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "from pylab import plot,show,hist\n",
    "from scipy.stats.kde import gaussian_kde\n",
    "from scipy.stats import norm, chi2_contingency\n",
    "import statsmodels.api as sm\n",
    "from numpy import linspace,hstack\n",
    "from pylab import plot,show,hist\n",
    "import pydot\n",
    "#%config InlineBackend.figure_format = 'svg' для большей четкости графиков\n",
    "matplotlib.style.use('ggplot')\n",
    "%matplotlib inline\n",
    "\n",
    "#Стандартизация данных\n",
    "from sklearn import preprocessing\n",
    "\n",
    "#Для построения диаграмм рассеивания\n",
    "from pandas.plotting import scatter_matrix\n",
    "\n",
    "#Графика для интерпретации моделей\n",
    "from IPython.display import Image\n",
    "from sklearn.tree import export_graphviz\n",
    "from subprocess import call\n",
    "\n",
    "#Факторный анализ\n",
    "import math\n",
    "from sklearn import preprocessing\n",
    "from sklearn.decomposition import FactorAnalysis\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "#SVD - Singular Value decomposition\n",
    "from surprise import SVD\n",
    "from surprise import Dataset\n",
    "from surprise.model_selection import cross_validate\n",
    "\n",
    "\n",
    "os.chdir(r'C:\\Users\\Mr Alex\\Documents\\GitHub\\FlightPreparence')\n",
    "columns = ['age', 'workclass', 'fnlwgt', 'education', 'education-num',\n",
    "           'marital-status', 'occupation', 'relationship', 'race', 'sex',\n",
    "           'capital-gain', 'capital-loss', 'hours-per-week', 'native-country', 'income']\n",
    "\n",
    "\n",
    "#df = pd.read_csv('AmesHousing.txt', sep=\"\\t\", header = 0, index_col=False)\n",
    "#df = pd.read_csv('town_1959_2.csv', header = 0,)\n",
    "#df = pd.read_csv('swiss_bank_notes.csv', index_col=0)\n",
    "#df = pd.read_csv('beverage_r.csv', sep=\";\", index_col='numb.obs')\n",
    "#df = pd.read_csv('Protein Consumption in Europe.csv', sep=';', decimal=',', index_col='Country')\n",
    "#df = pd.read_csv('assess.dat', sep='\\t', index_col='NAME')\n",
    "#df = pd.read_csv('Albuquerque Home Prices_data.txt', sep='\\t')\n",
    "#df = pd.read_csv('agedeath.dat.txt', sep='\\s+', header=None, names=['group', 'age', 'index'])\n",
    "#df = pd.read_csv('interference.csv')\n",
    "#df = pd.read_csv('diamond.dat', header=None, sep='\\s+', names=['weight', 'price'])\n",
    "#df = pd.read_csv('Credit.csv', sep=';', encoding='cp1251')\n",
    "#df = pd.read_csv('adult.test', header=None, names=columns, na_values=' ?', skiprows=1)\n",
    "#df = pd.read_csv('Wine.txt', sep='\\t', header=0)\n",
    "#df = pd.read_csv('monthly-car-sales-in-quebec-1960.csv', sep=';', header=0, parse_dates=[0])\n",
    "#df = pd.read_csv('stickleback.csv', sep=';', decimal=',')\n",
    "df = pd.read_csv('Swiss Fertility.csv', sep=';', decimal=',', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scale_features(df):\n",
    "    \"\"\"\n",
    "    Функция для стандартизации переменных в датафрейме\n",
    "    \"\"\"\n",
    "    scaled = preprocessing.StandardScaler().fit_transform(df)\n",
    "    scaled = pd.DataFrame(scaled, columns=df.columns)\n",
    "    return scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Факторный анализ \n",
    "#Сокращение переменных через введение новых, искусственных переменных (факторов), которые их заменяют\n",
    "#Способы поиска наилучших проекций: projection persuit, многомерное шкалирование,карты Sommer\n",
    "#Выявление структур взаимозависимости данных, матриц корреляции\n",
    "#Преодоление мультиколинеарности переменных в регрессионом анализе\n",
    "#R - матрица корелляции=k*k, где k - число столбцов исходной матрицы. Она же дисперсия вектора \n",
    "#U - (уникальности) особенности в данных, которые не удается объеснить факторами. Определяет качество модели \n",
    "\n",
    "#Удаляем столбцы, где данные непрочитались\n",
    "df = df.filter(regex='^(?!.*Unnamed).*$')\n",
    "\n",
    "#Смотрим коэффициенты корелляций. Мало больших значений - плохо для факторного анализа\n",
    "df.corr()\n",
    "\n",
    "#Строим R матрицу корелляций. Много выбросов, есть бимодальности. Но сильной корелляции увы нет\n",
    "scatter_matrix(df); #Добавление \";\" позволяет показать только график, без цифр\n",
    "\n",
    "#Cтандартизируем переменные\n",
    "df_scaled = preprocessing.scale(df)\n",
    "\n",
    "#Методом поиска главных компонентов проецируем данные на двумерную плоскость и получаем ранжирование компонентов по важности \n",
    "pca = PCA(n_components=5).fit(df_scaled) #Уточняем число компонент и источник данных \n",
    "\n",
    "#Доля разброса в данных, объясняемая главными компонентами\n",
    "print('Влияние компонентов на общий разброс данных: ', pca.explained_variance_ratio_)\n",
    "#Чистые значения главных компонент\n",
    "meanings = pca.singular_values_\n",
    "\n",
    "#Массив, в котором посчитаны значения факторов, заменяющие исходный набор данных\n",
    "pca_factor = pca.transform(df_scaled)\n",
    "\n",
    "#Запускаем факторный анализ. Сравним влияние факторов\n",
    "fa = FactorAnalysis(n_components=2).fit(df_scaled) #Факторов задаем много, сокращаем пока не получим адекватную группировку\n",
    "\n",
    "#Таблица коэффициентов корреляции - что именно измерили факторы. Семь параметров превращаются в два новых фактора\n",
    "pd.DataFrame(fa.components_, columns=df.columns) #Обновление данных, где те же колонки, но переменные в них - факториалы\n",
    "\n",
    "#Дисперсия остатков U. Видно, что хотя новые факторы очевидны, остатки огромные, то есть переменные объяснены плохо\n",
    "#Если некоторые переменные объясняются очень плохо, то они уникальны и преображать их в факторы не надо\n",
    "pd.Series(fa.noise_variance_, df.columns) \n",
    "\n",
    "#Значения факторов можно применить к конкретным объектам\n",
    "scores = pd.DataFrame(fa.transform(df_scaled), columns=['factor1', 'factor2'])\n",
    "scores['factor1'].sort_values() #Сортируем по значению фактора"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SVD-разложение Simon Funk'a для рекомендательных систем. Позволяет работать с данными, где много пропусков \n",
    "#Двойной факторный анализ, проведенный одновременно. Матрица триплетов получается из: номер стр, номер стлб., элемент.\n",
    "#Работает с субъективными оценками, поэтому проверяет ее с помощью средних по матрице, по строке, по столбцу\n",
    "#Не стоит минимизировать MSE - потому что нужны рекомендации только с большими значениями\n",
    "\n",
    "data = Dataset.load_builtin('ml-100k')\n",
    "\n",
    "#Создаем модель\n",
    "algo = SVD(n_factors=160, \n",
    "           n_epochs=100, \n",
    "           lr_all=0.005, #скорость обучения, шаг модификации\n",
    "           reg_all=0.1, #гамма регулирующая\n",
    "           biased=True, \n",
    "           random_state=42 \n",
    "          )\n",
    "#Обучаем модель\n",
    "cross_validate(algo, \n",
    "               data, \n",
    "               measures=['RMSE', 'MAE'], \n",
    "               cv=5, \n",
    "               verbose=True\n",
    "              )\n",
    "\n",
    "#проверяем модель на случайном пользователе\n",
    "userid = str(196)\n",
    "itemid = str(302)\n",
    "actual_rating = 4\n",
    "print(algo.predict(userid, 302, 4))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
