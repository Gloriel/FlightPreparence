{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Полезные ссылки<br>\n",
    "  * [Web Scraping](https://coderlessons.com/tutorials/python-technologies/izuchite-python-web-scraping/python-web-scraping-kratkoe-rukovodstvo)<br>\n",
    "  * [Python - Regular Expressions](https://www.tutorialspoint.com/python/python_reg_expressions.htm)<br>\n",
    "  * [Beautiful Soup Documentation](https://www.crummy.com/software/BeautifulSoup/bs4/doc/)<br>\n",
    "  * [AWS Amazon](https://aws.amazon.com/ru/getting-started/)<br> \n",
    "  * [Список парсеров](https://habr.com/ru/company/click/blog/494020/)<br> \n",
    "  * [Конкурентный анализ](https://blog.click.ru/semantics/kak-besplatno-sobrat-klyuchevye-slova-i-obyavleniya-konkurentov/)\n",
    "  * [ВКшка](https://vc.ru/marketing/138412-instrukciya-kak-ispolzovat-parsing-vkontakte)\n",
    "  * [Soup](https://pythonru.com/biblioteki/parsing-na-python-s-beautiful-soup)\n",
    "  * [Scrapy](https://pythonru.com/biblioteki/sozdanie-parserov-s-pomoshhju-scrapy-i-python)\n",
    "  * [Библиотека Супа](https://www.crummy.com/software/BeautifulSoup/bs4/doc.ru/)\n",
    "  * [Парсинг Хабр](https://habr.com/ru/post/504900/)\n",
    "  \n",
    "«Inspect» (CTRL+SHIFT+I)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-04T13:25:02.931809Z",
     "start_time": "2021-03-04T13:25:02.313732Z"
    }
   },
   "outputs": [],
   "source": [
    "import requests as r\n",
    "import lxml\n",
    "from lxml import html \n",
    "import urllib3\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from selenium import webdriver\n",
    "from bs4 import BeautifulSoup\n",
    "import csv\n",
    "import boto3\n",
    "from urllib.request import urlopen\n",
    "import datetime\n",
    "import random\n",
    "import sqlite3\n",
    "import pymysql\n",
    "import os\n",
    "import webbrowser\n",
    "import json\n",
    "from urllib.request import urlopen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-04T13:25:06.133100Z",
     "start_time": "2021-03-04T13:25:04.653853Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "“The world as we have created it is a process of our thinking. It cannot be changed without changing our thinking.”\n",
      "--Albert Einstein\n",
      "change\n",
      "deep-thoughts\n",
      "thinking\n",
      "world\n",
      "\n",
      "\n",
      "“It is our choices, Harry, that show what we truly are, far more than our abilities.”\n",
      "--J.K. Rowling\n",
      "abilities\n",
      "choices\n",
      "\n",
      "\n",
      "“There are only two ways to live your life. One is as though nothing is a miracle. The other is as though everything is a miracle.”\n",
      "--Albert Einstein\n",
      "inspirational\n",
      "life\n",
      "live\n",
      "miracle\n",
      "miracles\n",
      "\n",
      "\n",
      "“The person, be it gentleman or lady, who has not pleasure in a good novel, must be intolerably stupid.”\n",
      "--Jane Austen\n",
      "aliteracy\n",
      "books\n",
      "classic\n",
      "humor\n",
      "\n",
      "\n",
      "“Imperfection is beauty, madness is genius and it's better to be absolutely ridiculous than absolutely boring.”\n",
      "--Marilyn Monroe\n",
      "be-yourself\n",
      "inspirational\n",
      "\n",
      "\n",
      "“Try not to become a man of success. Rather become a man of value.”\n",
      "--Albert Einstein\n",
      "adulthood\n",
      "success\n",
      "value\n",
      "\n",
      "\n",
      "“It is better to be hated for what you are than to be loved for what you are not.”\n",
      "--André Gide\n",
      "life\n",
      "love\n",
      "\n",
      "\n",
      "“I have not failed. I've just found 10,000 ways that won't work.”\n",
      "--Thomas A. Edison\n",
      "edison\n",
      "failure\n",
      "inspirational\n",
      "paraphrased\n",
      "\n",
      "\n",
      "“A woman is like a tea bag; you never know how strong it is until it's in hot water.”\n",
      "--Eleanor Roosevelt\n",
      "misattributed-eleanor-roosevelt\n",
      "\n",
      "\n",
      "“A day without sunshine is like, you know, night.”\n",
      "--Steve Martin\n",
      "humor\n",
      "obvious\n",
      "simile\n",
      "\n",
      "\n",
      "1:  $24.99 за Short Dress\n",
      "2:  $29.99 за Patterned Slacks\n",
      "3:  $49.99 за Short Chiffon Dress\n",
      "4:  $59.99 за Off-the-shoulder Dress\n",
      "5:  $24.99 за V-neck Top\n",
      "6:  $49.99 за Short Chiffon Dress\n",
      "7:  $24.99 за V-neck Top\n",
      "8:  $24.99 за V-neck Top\n",
      "9:  $59.99 за Short Lace Dress\n"
     ]
    }
   ],
   "source": [
    "# Скарпинг элементов с одной страницы\n",
    "    \n",
    "url = 'https://quotes.toscrape.com/'\n",
    "response = r.get(url)\n",
    "soup = BeautifulSoup(response.text, 'lxml')\n",
    "quotes = soup.find_all('span', class_='text')\n",
    "authors = soup.find_all('small', class_='author')\n",
    "tags = soup.find_all('div', class_='tags')\n",
    "\n",
    "for i in range(0, len(quotes)):\n",
    "    print(quotes[i].text)\n",
    "    print('--' + authors[i].text)\n",
    "    tagsforquote = tags[i].find_all('a', class_='tag')\n",
    "    for tagforquote in tagsforquote:\n",
    "        print(tagforquote.text)\n",
    "    print('\\n')\n",
    "    \n",
    "url = 'https://scrapingclub.com/exercise/list_basic/?page=1'\n",
    "response = r.get(url)\n",
    "soup = BeautifulSoup(response.text, 'lxml')\n",
    "items = soup.find_all('div', class_='col-lg-4 col-md-6 mb-4')\n",
    "\n",
    "for n, i in enumerate(items, start=1):\n",
    "    itemName = i.find('h4', class_='card-title').text.strip()\n",
    "    itemPrice = i.find('h5').text\n",
    "    print(f'{n}:  {itemPrice} за {itemName}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-04T13:25:14.123467Z",
     "start_time": "2021-03-04T13:25:10.498756Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1:  $24.99 за Short Dress\n",
      "2:  $29.99 за Patterned Slacks\n",
      "3:  $49.99 за Short Chiffon Dress\n",
      "4:  $59.99 за Off-the-shoulder Dress\n",
      "5:  $24.99 за V-neck Top\n",
      "6:  $49.99 за Short Chiffon Dress\n",
      "7:  $24.99 за V-neck Top\n",
      "8:  $24.99 за V-neck Top\n",
      "9:  $59.99 за Short Lace Dress\n",
      "9:  $34.99 за Fitted Dress\n",
      "10:  $69.99 за V-neck Jumpsuit\n",
      "11:  $54.99 за Chiffon Dress\n",
      "12:  $39.99 за Skinny High Waist Jeans\n",
      "13:  $19.99 за Super Skinny High Jeans\n",
      "14:  $19.99 за Oversized Denim Jacket\n",
      "15:  $24.99 за Short Sweatshirt\n",
      "16:  $12.99 за Long-sleeved Jersey Top\n",
      "17:  $39.99 за Skinny High Waist Jeans\n",
      "17:  $24.99 за Short Sweatshirt\n",
      "18:  $12.99 за Long-sleeved Jersey Top\n",
      "19:  $12.99 за Long-sleeved Jersey Top\n",
      "20:  $19.99 за Jersey Dress\n",
      "21:  $24.99 за Short Sweatshirt\n",
      "22:  $24.99 за Crinkled Flounced Blouse\n",
      "23:  $29.99 за Bib Overall Dress\n",
      "24:  $17.99 за Loose-knit Sweater\n",
      "25:  $29.99 за Skinny Regular Jeans\n",
      "25:  $12.99 за Henley-style Top\n",
      "26:  $17.99 за Joggers\n",
      "27:  $34.99 за Skirt with Lacing\n",
      "28:  $17.99 за Top with Tie\n",
      "29:  $34.99 за Joggers\n",
      "30:  $49.99 за Chiffon Dress with Flounce\n",
      "31:  $34.99 за Skirt with Lacing\n",
      "32:  $9.99 за V-neck Top\n",
      "33:  $29.99 за Hooded Jacket\n",
      "33:  $29.99 за Hooded Top\n",
      "34:  $34.99 за Lyocell-blend Blouse\n",
      "35:  $29.99 за Bib Overall Dress\n",
      "36:  $34.99 за Wide-leg Pants\n",
      "37:  $24.99 за Ankle-length Slim-fit Pants\n",
      "38:  $9.99 за Short Sweatshirt\n",
      "39:  $17.99 за V-neck Blouse\n",
      "40:  $24.99 за Short Skirt\n",
      "41:  $17.99 за Mesh T-shirt\n",
      "41:  $59.99 за Blouse with Embroidery\n",
      "42:  $34.99 за Wide-cut Cotton Top\n",
      "43:  $54.99 за Pleated Skirt\n",
      "44:  $69.99 за Coat\n",
      "45:  $49.99 за Wide-leg Pants\n",
      "46:  $29.99 за Top\n",
      "47:  $69.99 за Knit Mohair-blend Sweater\n",
      "48:  $69.99 за Dress\n",
      "49:  $29.99 за T-shirt with Embroidery\n",
      "49:  $49.99 за Blouse with Ruffled Collar\n",
      "50:  $49.99 за Pants\n",
      "51:  $19.99 за Jersey Dress\n",
      "52:  $6.99 за T-shirt\n",
      "53:  $6.99 за T-shirt\n",
      "54:  $49.99 за Blazer\n"
     ]
    }
   ],
   "source": [
    "# Скарпинг элементов с нескольких страниц\n",
    "url = 'https://scrapingclub.com/exercise/list_basic/?page=1'\n",
    "response = r.get(url)\n",
    "soup = BeautifulSoup(response.text, 'lxml')\n",
    "items = soup.find_all('div', class_='col-lg-4 col-md-6 mb-4')\n",
    "\n",
    "for n, i in enumerate(items, start=1):\n",
    "    itemName = i.find('h4', class_='card-title').text.strip()\n",
    "    itemPrice = i.find('h5').text\n",
    "    print(f'{n}:  {itemPrice} за {itemName}')\n",
    "\n",
    "# Ищем адреса страниц и собираем их в список. UL - галвный, LI - указатели на список    \n",
    "pages = soup.find('ul', class_='pagination')\n",
    "urls = []\n",
    "links = pages.find_all('a', class_='page-link')\n",
    "\n",
    "# Проверяем валидность полученных адресов\n",
    "for link in links:\n",
    "    pageNum = int(link.text) if link.text.isdigit() else None\n",
    "    if pageNum != None:\n",
    "        hrefval = link.get('href')\n",
    "        urls.append(hrefval)\n",
    "\n",
    "# Проходим по списку адресов и забираем по каждому из них нужные элементы        \n",
    "for slug in urls:\n",
    "    newUrl = url.replace('?page=1', slug)\n",
    "    response = r.get(newUrl)\n",
    "    soup = BeautifulSoup(response.text, 'lxml')\n",
    "    items = soup.find_all('div', class_='col-lg-4 col-md-6 mb-4')\n",
    "    for n, i in enumerate(items, start=n):\n",
    "        itemName = i.find('h4', class_='card-title').text.strip()\n",
    "        itemPrice = i.find('h5').text\n",
    "        print(f'{n}:  {itemPrice} за {itemName}')\n",
    "        \n",
    "# Оптимизированный аналог\n",
    "\n",
    "url = 'https://scrapingclub.com/exercise/list_basic/'\n",
    "params = {'page': 1}\n",
    "# задаем число больше номера первой страницы, для старта цикла\n",
    "pages = 2\n",
    "n = 1\n",
    "\n",
    "while params['page'] <= pages:\n",
    "    response = r.get(url, params=params)\n",
    "    soup = BeautifulSoup(response.text, 'lxml')\n",
    "    items = soup.find_all('div', class_='col-lg-4 col-md-6 mb-4')\n",
    "\n",
    "    for n, i in enumerate(items, start=n):\n",
    "        itemName = i.find('h4', class_='card-title').text.strip()\n",
    "        itemPrice = i.find('h5').text\n",
    "        print(f'{n}:  {itemPrice} за {itemName}')\n",
    "\n",
    "    # [-2] предпоследнее значение, потому что последнее \"Next\"\n",
    "    last_page_num = int(soup.find_all('a', class_='page-link')[-2].text)\n",
    "    pages = last_page_num if pages < last_page_num else pages\n",
    "    params['page'] += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-04T13:28:06.911156Z",
     "start_time": "2021-03-04T13:28:06.889150Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<a class=\"page-link\" href=\"?page=2\">2</a>,\n",
       " <a class=\"page-link\" href=\"?page=3\">3</a>,\n",
       " <a class=\"page-link\" href=\"?page=4\">4</a>,\n",
       " <a class=\"page-link\" href=\"?page=5\">5</a>,\n",
       " <a class=\"page-link\" href=\"?page=6\">6</a>,\n",
       " <a class=\"page-link\" href=\"?page=7\">7</a>,\n",
       " <a class=\"page-link\" href=\"?page=2\">Next</a>]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "links\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-03T06:24:14.536799Z",
     "start_time": "2021-03-03T06:24:14.202339Z"
    }
   },
   "outputs": [],
   "source": [
    "last_update_id = 0\n",
    "\n",
    "result = r.get(\n",
    "        'https://api.telegram.org/bot1407505601:AAEbW_Ylkz5R0s2XN6LPSimh3-fAByQoBQw/getUpdates',\n",
    "        params={'offset': last_update_id + 1})\n",
    "data = result.json()\n",
    "for update in data['result']:\n",
    "    last_update_id = update['update_id']\n",
    "    chat_id = update['message']['chat']['id']\n",
    "\n",
    "    send_result = r.get(\n",
    "        'https://api.telegram.org/bot1407505601:AAEbW_Ylkz5R0s2XN6LPSimh3-fAByQoBQw/sendMessage',\n",
    "        params={'chat_id': chat_id, 'text': 'Привет от LETPY'}\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-03T06:24:51.986610Z",
     "start_time": "2021-03-03T06:24:42.208835Z"
    }
   },
   "outputs": [],
   "source": [
    "#Объект ответа в HTTP. Получаем инфу о контенте \n",
    "url = \"https://authoraditiagarwal.com/wpcontent/uploads/2018/05/MetaSlider_ThinkBig-1080x180.jpg\"\n",
    "\n",
    "r = r.get(url, allow_redirects=True) #запрос для выполнения HTTP-запросов GET для URL\n",
    "for headers in r.headers: \n",
    "    print(headers)\n",
    "    \n",
    "#загружаем контент\n",
    "\n",
    "r = r.get(url) \n",
    "with open(\"ThinkBig.png\",'wb') as f:\n",
    "   f.write(r.content)\n",
    "\n",
    "print (r.headers.get('content-type'))\n",
    "print (r.headers.get('Server'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-03T06:25:17.644337Z",
     "start_time": "2021-03-03T06:25:17.547385Z"
    }
   },
   "outputs": [],
   "source": [
    "#создаем объект Soup \n",
    "soup = BeautifulSoup(r.text, 'lxml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-03T06:25:30.315319Z",
     "start_time": "2021-03-03T06:25:30.284377Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#запишем захваченные данные в файл CSV с именем dataprocessing.csv в этой папке\n",
    "f = csv.writer(open(' dataprocessing.csv ','w'))\n",
    "f.writerow(['Title'])\n",
    "f.writerow([soup.title.text])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-03T07:07:57.828142Z",
     "start_time": "2021-03-03T07:07:57.381392Z"
    }
   },
   "outputs": [],
   "source": [
    "#scraping Wikipedia to find out all the countries in Asia.\n",
    "\n",
    "\n",
    "website_url = r.get('https://en.wikipedia.org/wiki/List_of_Asian_countries_by_area').text\n",
    "soup = BeautifulSoup(website_url, 'lxml')\n",
    "My_table = soup.find('table',{'class': 'wikitable sortable'})\n",
    "links = My_table.find_all(\"a\")\n",
    "Countries = []\n",
    "for link in links:\n",
    "    Countries.append(link.get('title'))\n",
    "\n",
    "df = pd.DataFrame()\n",
    "df[\"Country\"] = Countries\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://aws.amazon.com/ru/getting-started/ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-03T07:08:17.367914Z",
     "start_time": "2021-03-03T07:08:17.044538Z"
    }
   },
   "outputs": [],
   "source": [
    "# для хранения данных в корзину S3 нам нужно создать клиент S3 \n",
    "s3 = boto3.client('s3')\n",
    "bucket_name = \"our-content\"\n",
    "#Созбдаем сегмент S3\n",
    "s3.create_bucket(Bucket = bucket_name, ACL = 'public-read')\n",
    "s3.put_object(Bucket = bucket_name, Key = '', Body = data, ACL = \"public-read\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-03T07:08:37.066129Z",
     "start_time": "2021-03-03T07:08:34.931961Z"
    }
   },
   "outputs": [],
   "source": [
    "#Подключаемся к SQL серверу\n",
    "\n",
    "conn = pymysql.connect(host='127.0.0.1',user='root', passwd = None, db = 'mysql',\n",
    "charset = 'utf8', port=None)\n",
    "cur = conn.cursor()\n",
    "cur.execute(\"USE scrap\")\n",
    "random.seed(datetime.datetime.now())\n",
    "def store(title, content):\n",
    "   cur.execute('INSERT INTO scrap_pages (title, content) VALUES ''(\"%s\",\"%s\")', (title, content))\n",
    "   cur.connection.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Запускаем ХромДрайвер\n",
    "driver = webdriver.Chrome()  # Optional argument, if not specified will search path.\n",
    "driver.get('http://www.google.com/');\n",
    "search_box = driver.find_element_by_name('q')\n",
    "search_box.send_keys('ChromeDriver')\n",
    "search_box.submit()\n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Извлечение веб данных о системе пользователя\n",
    "import user_agents\n",
    "ua = user_agents.parse(ua)\n",
    "ua.is_bot\n",
    "ua.is_mobile\n",
    "ua.os.family\n",
    "ua.browser.family"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#robots.txt — это файл, используемый для идентификации частей сайта, которые сканерам разрешено просматривать \n",
    "#Sitemap - карты сайта, которые помогают сканерам находить контент без необходимости сканировать каждую страницу"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "nbTranslate": {
   "displayLangs": [
    "*"
   ],
   "hotkey": "alt-t",
   "langInMainMenu": true,
   "sourceLang": "en",
   "targetLang": "fr",
   "useGoogleTranslate": true
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
