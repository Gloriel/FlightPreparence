{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib \n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "from pylab import plot,show,hist\n",
    "from scipy.stats.kde import gaussian_kde\n",
    "from scipy.stats import norm, chi2_contingency\n",
    "import statsmodels.api as sm\n",
    "from numpy import linspace,hstack\n",
    "from pylab import plot,show,hist\n",
    "import pydot\n",
    "#%config InlineBackend.figure_format = 'svg' –¥–ª—è –±–æ–ª—å—à–µ–π —á–µ—Ç–∫–æ—Å—Ç–∏ –≥—Ä–∞—Ñ–∏–∫–æ–≤\n",
    "matplotlib.style.use('ggplot')\n",
    "%matplotlib inline\n",
    "\n",
    "#–°—Ç–∞–Ω–¥–∞—Ä—Ç–∏–∑–∞—Ü–∏—è –¥–∞–Ω–Ω—ã—Ö\n",
    "from sklearn import preprocessing\n",
    "\n",
    "#–î–ª—è –ø–æ—Å—Ç—Ä–æ–µ–Ω–∏—è –¥–∏–∞–≥—Ä–∞–º–º —Ä–∞—Å—Å–µ–∏–≤–∞–Ω–∏—è\n",
    "from pandas.plotting import scatter_matrix\n",
    "\n",
    "#–ò–µ—Ä–∞—Ä—Ö–∏—á–µ—Å–∫–∏–π –∫–ª–∞—Å—Ç–µ—Ä–Ω—ã–π –∞–Ω–∞–ª–∏–∑\n",
    "from scipy.cluster.hierarchy import dendrogram, linkage, fcluster\n",
    "\n",
    "#–ö–ª–∞—Å—Ç–µ—Ä–Ω—ã–π –∞–Ω–∞–ª–∏–∑ –º–µ—Ç–æ–¥–æ–º –ö-—Å—Ä–µ–¥–Ω–∏—Ö\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "#–õ–∏–Ω–µ–π–Ω–∞—è —Ä–µ–≥—Ä–µ—Å—Å–∏—è\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "#–†–∞—Å—â–µ–ø–ª–µ–Ω–∏–µ –Ω–∞ –æ–±—É—á–∞—é—â—É—é –∏ —Ç–µ—Å—Ç–æ–≤—É—é –≤—ã–±–æ—Ä–∫–∏\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#–î–µ—Ä–µ–≤—å—è —Ä–µ—à–µ–Ω–∏–π –¥–ª—è –∑–∞–¥–∞—á–∏ –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "#–î–µ—Ä–µ–≤—å—è —Ä–µ—à–µ–Ω–∏–π –¥–ª—è –∑–∞–¥–∞—á —Ä–µ–≥—Ä–µ—Å—Å–∏–∏ \n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "#XGBoost\n",
    "from sklearn import metrics\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "\n",
    "#–ù–µ–π—Ä–æ–Ω–Ω—ã–µ —Å–µ—Ç–∏\n",
    "from keras.models import Sequential #—Ç–∏–ø —Å–µ—Ç–∏\n",
    "from keras.layers import Dense #–º–µ—Ç–æ–¥ —Å–æ–µ–¥–∏–Ω–µ–Ω–∏—è —Å–ª–æ–µ–≤\n",
    "from keras.utils import np_utils #–æ–±—Ä–∞–±–æ—Ç–∫–∞ –¥–∞–Ω–Ω—ã—Ö –ø–æ–¥ –ö–µ—Ä–∞—Å\n",
    "from keras import optimizers\n",
    "from keras import initializers\n",
    "\n",
    "\n",
    "columns = ['age', 'workclass', 'fnlwgt', 'education', 'education-num',\n",
    "           'marital-status', 'occupation', 'relationship', 'race', 'sex',\n",
    "           'capital-gain', 'capital-loss', 'hours-per-week', 'native-country', 'income']\n",
    "\n",
    "os.chdir(r'C:\\Users\\Mr Alex\\Documents\\GitHub\\FlightPreparence')\n",
    "data = pd.read_csv('AmesHousing.txt', sep=\"\\t\", header = 0, index_col=False)\n",
    "town = pd.read_csv('town_1959_2.csv', header = 0,)\n",
    "df = pd.read_csv('swiss_bank_notes.csv', index_col=0)\n",
    "beer = pd.read_csv('beverage_r.csv', sep=\";\", index_col='numb.obs')\n",
    "food = pd.read_csv('Protein Consumption in Europe.csv', sep=';', decimal=',', index_col='Country')\n",
    "ass = pd.read_csv('assess.dat', sep='\\t', index_col='NAME')\n",
    "albi = pd.read_csv('Albuquerque Home Prices_data.txt', sep='\\t')\n",
    "noble = pd.read_csv('agedeath.dat.txt', sep='\\s+', header=None, names=['group', 'age', 'index'])\n",
    "inter = pd.read_csv('interference.csv')\n",
    "diamond = pd.read_csv('diamond.dat', header=None, sep='\\s+', names=['weight', 'price'])\n",
    "cred = pd.read_csv('Credit.csv', sep=';', encoding='cp1251')\n",
    "test = pd.read_csv('adult.test', header=None, names=columns, na_values=' ?', skiprows=1)\n",
    "wine = pd.read_csv('Wine.txt', sep='\\t', header=0)\n",
    "sales = pd.read_csv('monthly-car-sales-in-quebec-1960.csv', sep=';', header=0, parse_dates=[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def two_histograms(x, y):\n",
    "    \"\"\"\n",
    "    –§—É–Ω–∫—Ü–∏—è, –∫–æ—Ç–æ—Ä–∞—è –ø–æ—Å—Ç—Ä–æ–∏—Ç –¥–≤–µ –≥–∏—Å—Ç–æ–≥—Ä–∞–º–º—ã –Ω–∞ –æ–¥–Ω–æ–π –∫–∞—Ä—Ç–∏–Ω–∫–µ.\n",
    "    –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–æ –ø—É–Ω–∫—Ç–∏—Ä–Ω—ã–º–∏ –ª–∏–Ω–∏—è–º–∏ —É–∫–∞–∑—ã–≤–∞—é—Ç—Å—è —Å—Ä–µ–¥–Ω–∏–µ –∑–Ω–∞—á–µ–Ω–∏—è –≤—ã–±–æ—Ä–æ–∫.\n",
    "    x: –≤–µ–∫—Ç–æ—Ä pd.Series,\n",
    "    y: –≤–µ–∫—Ç–æ—Ä pd.Series\n",
    "    \"\"\"\n",
    "    x.hist(alpha=0.5, weights=[1./len(x)]*len(x))\n",
    "    y.hist(alpha=0.5, weights=[1./len(y)]*len(y))\n",
    "    plt.axvline(x.mean(), color='red', alpha=0.8, linestyle='dashed')\n",
    "    plt.axvline(y.mean(), color='blue', alpha=0.8, linestyle='dashed')\n",
    "    plt.legend([x.name, y.name])\n",
    "    \n",
    "def regression_coef(model, X, y):\n",
    "    \"\"\"\n",
    "    –§—É–Ω–∫—Ü–∏—è –¥–ª—è –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è —Å—Ç–∞—Ç–∏—Å—Ç–∏—á–µ—Å–∫–æ–π –∑–Ω–∞—á–∏–º–æ—Å—Ç–∏ —Ä–µ–≥—Ä–µ—Å—Å–∏–æ–Ω–Ω—ã—Ö –∫–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç–æ–≤\n",
    "    \"\"\"\n",
    "    coef = pd.DataFrame(zip(['intercept'] + X.columns.tolist(), [model.intercept_] + model.coef_.tolist()),\n",
    "                    columns=['predictor', 'coef'])\n",
    "    X1 = np.append(np.ones((len(X),1)), X, axis=1)\n",
    "    b = np.append(model.intercept_, model.coef_)\n",
    "    MSE = np.sum((model.predict(X) - y) ** 2, axis=0) / float(X.shape[0] - X.shape[1])\n",
    "    var_b = MSE * (np.linalg.inv(np.dot(X1.T, X1)).diagonal())\n",
    "    sd_b = np.sqrt(var_b)\n",
    "    t = b / sd_b\n",
    "    coef['pvalue'] = [2 * (1 - stats.t.cdf(np.abs(i), (len(X1) - 1))) for i in t]\n",
    "    return coef"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#–ö–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è - –ø—Ä–∏–ø–∏—Å–∞–Ω–∏–µ –æ–±—ä–µ–∫—Ç–∞ –∫ –∫–ª–∞—Å—Å—É –Ω–∞ –æ—Å–Ω–æ–≤–∞–Ω–∏–∏ –∫–ª—é—á–µ–≤–æ–π (–≥—Ä—É–ø–ø–∏—Ä—É—é—â–µ–π) –ø–µ—Ä–µ–º–µ–Ω–Ω–æ–π –∏–ª–∏ —Å–æ–≤–æ–∫—É–ø–Ω–æ—Å—Ç–∏ –µ–≥–æ —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫\n",
    "#–¢–∏–ø—ã –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö. –ö–æ–ª–∏—á–µ—Å—Ç–≤–µ–Ω–Ω—ã–µ(–Ω–µ–ø—Ä–µ—Ä—ã–≤–Ω—ã–µ, –¥–∏—Å–∫—Ä–µ—Ç–Ω—ã–µ). –ù–æ–º–∏–Ω–∞–ª—å–Ω—ã–µ (–Ω–µ—Å—Ä–∞–≤–Ω–∏–≤–∞–µ–º—ã–µ). –†–∞–Ω–≥–æ–≤—ã–µ (–ø–æ—Ä—è–¥–∫–æ–≤—ã–µ)\n",
    "#–ì–∏—Å—Ç–æ–≥—Ä–∞–º–º–∞ —á–∞—Å—Ç–æ—Ç - —Ñ–æ—Ä–º–∞ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è –∫–æ–ª–∏—á–µ—Å—Ç–≤–µ–Ω–Ω–æ–≥–æ –ø—Ä–∏–∑–Ω–∞–∫–∞\n",
    "#–û–ø–∏—Å–∞—Ç–µ–ª—å–Ω–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞. –ú–µ—Ä—ã —Ü–µ–Ω—Ç—Ä–∞–ª—å–Ω–æ–π —Ç–µ–Ω–¥–µ–Ω—Ü–∏–∏. –ú–µ—Ä—ã –∏–∑–º–µ–Ω—á–∏–≤–æ—Å—Ç–∏ (–†–∞–∑–º–∞—Ö - Xmax-Xmin)\n",
    "#–ú–¶–¢. –ú–æ–¥–∞ - —Å–∞–º—ã–π —á–∞—Å—Ç—ã–π –ø—Ä–∏–∑–Ω–∞–∫. –ú–µ–¥–∏–∞–Ω–∞ - –¥–µ–ª–∏—Ç —É–ø–æ—Ä—è–¥–æ—á–µ–Ω–Ω–æ–µ –º–Ω–æ–∂–µ—Å—Ç–≤–æ –ø–æ–ø–æ–ª–∞–º. –°—Ä–µ–¥–Ω–µ–µ (–ú–∞—Ç–µ–º–∞—Ç–∏—á–µ—Å–∫–æ–µ –æ–∂–∏–¥–∞–Ω–∏–µ, EX)\n",
    "#–î–∏—Å–ø–µ—Ä—Å–∏—è D - —Å—Ä–µ–¥–Ω–∏–π –∫–≤–∞–¥—Ä–∞—Ç –æ—Ç–∫–ª–æ–Ω–µ–Ω–∏–π –∏–Ω–¥–∏–≤–∏–¥—É–∞–ª—å–Ω—ã—Ö –∑–Ω–∞—á–µ–Ω–∏–π –æ—Ç —Å—Ä–µ–¥–Ω–µ–π –≤–µ–ª–∏—á–∏–Ω—ã. –° —Ä–æ—Å—Ç–æ–º n, –¥–∏—Å–ø–µ—Ä—Å–∏—è —Å–æ–∫—Ä–∞—â–∞–µ—Ç—Å—è\n",
    "#D = —Å—É–º–º–∞(X–∏–Ω–¥ - X—Å—Ä–µ–¥)**2/n-1. –•—Å—Ä–µ–¥ –≥–µ–Ω–µ—Ä–∞–ª—å–Ω–æ–π —Å–æ–≤–æ–∫—É–ø–Ω–æ—Å—Ç–∏ –æ–±–æ–∑–Ω–∞—á–∞–µ—Ç—Å—è –∫–∞–∫ –º—é, –ú\n",
    "#–°—Ç–∞–Ω–¥–∞—Ä—Ç–Ω–æ–µ –æ—Ç–∫–ª–æ–Ω–µ–Ω–∏–µ, \"—Å–∏–≥–º–∞\", sd = D**0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#–ù–æ—Ä–º–∞–ª—å–Ω–æ–µ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ. –£–Ω–∏–º–æ–¥–∞–ª—å–Ω–æ –∏ —Å–∏–º–º–µ—Ç—Ä–∏—á–Ω–æ \n",
    "#–¶–µ–Ω—Ç—Ä–∞–ª—å–Ω–∞—è –ø—Ä–µ–¥–µ–ª—å–Ω–∞—è —Ç–µ–æ—Ä–µ–º–∞. –î–ª—è –≤—ã–±–æ—Ä–æ–∫ —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω–∞—è –æ—à–∏–±–∫–∞ —Å—Ä–µ–¥–Ω–µ–≥–æ se=SD–∏–Ω–¥/n**0.5, –≥–¥–µ n - —á–∏—Å–ª–æ —ç–ª–µ–º–µ–Ω—Ç–æ–≤ –≤—ã–±–æ—Ä–∫–∏\n",
    "#–ï—Å–ª–∏ n –≤—ã–±–æ—Ä–∫–∞ —Ä–µ–ø—Ä–µ–∑–µ–Ω—Ç–∞—Ç–∏–≤–Ω–∞—è –∏ —á–∏—Å–ª–æ —ç–ª–µ–º–µ–Ω—Ç–æ–≤ > 30, —Ç–æ se=0.5\n",
    "#–ò–Ω—Ç–µ—Ä–≤–∞–ª –¥–ª—è –ø–æ–∏—Å–∫–∞ –ú –≥–µ–Ω–µ—Ä–∞–ª—å–Ω–æ–π —Å–æ–≤–æ–∫—É–ø–Ω–æ—Å—Ç–∏(–¥–æ–≤–µ—Ä–∏—Ç–µ–ª—å–Ω—ã–π –∏–Ω—Ç–µ—Ä–≤–∞–ª): –¥–ª—è 95% –≤—ã–±–æ—Ä–æ–∫ –•—Å—Ä–µ–¥ ¬± 1.96*se –≤–∫–ª—é—á–∞—Ç –≤ —Å–µ–±—è –ú"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#–ß–∏—Å–ª–æ –Ω–∞–±–ª—é–¥–µ–Ω–∏–π(N1), –ø–æ–ø–∞–≤—à–∏—Ö –≤ —Å—Ç–æ–ª–±–µ—Ü. H = C*N1 \n",
    "#H = N1/(N*–¥–ª–∏–Ω–∞ –∏–Ω—Ç–µ—Ä–≤–∞–ª–∞) - –≤ —Ç–∞–∫–æ–º —Å–ª—É—á–∞–µ –≥–∏—Å—Ç–æ–≥—Ä–∞–º–º–∞ –±—É–¥–µ—Ç –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–Ω–æ–π, —Ç–æ –µ—Å—Ç—å –≤ –ø—Ä–µ–¥–µ–ª–∞—Ö –µ–¥–∏–Ω–∏—Ü—ã\n",
    "#–ü–ª–æ—Ç–Ω–æ—Å—Ç—å —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è f(x) –ø–æ–∑–≤–æ–ª—è–µ—Ç —Ä–∞—Å—Å—á–∏—Ç–∞—Ç—å –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å P(A) –ø–æ–ø–∞–¥–∞–Ω–∏–π –≤ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–Ω—ã–π –∏–Ω—Ç–µ—Ä–≤–∞–ª\n",
    "#–í –≥–∏—Å—Ç–æ–≥—Ä–∞–º–º–µ –Ω–∞–∏–±–æ–ª—å—à–∏–π –≤–µ—Å –∏–º–µ–µ—Ç –ø–ª–æ—â–∞–¥—å —Å—Ç–æ–ª–±—Ü–∞\n",
    "data['SalePrice'].hist(bins=60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#–ì–∏—Å—Ç–æ–≥—Ä–∞–º–º–∞ –Ω—É–∂–Ω–∞ —á—Ç–æ–±—ã –æ—Ü–µ–Ω–∏—Ç—å –æ–¥–Ω—É –≥—Ä—É–ø–ø—É\n",
    "#–í–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–Ω–∞—è –≥–∏—Å—Ç–æ–≥—Ä–∞–º–º–∞ \n",
    "data['SalePrice'].hist(density=True, bins=60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#–Ø–¥–µ—Ä–Ω–∞—è –æ—Ü–µ–Ω–∫–∞ –ø–ª–æ—Ç–Ω–æ—Å—Ç–∏ –°–∫–æ—Ç—Ç–∞-–°–∏–ª—å–≤–µ—Ä–º–∞–Ω–∞ - –æ–±–æ–±—â–µ–Ω–∏–µ –≥–∏—Å—Ç–æ–≥—Ä–∞–º–º—ã F(t) = (1/n*h)*—Å—É–º–º–∞ –≤—Å–µ—Ö –Ω–∞–±–ª—é–¥–µ–Ω–∏–π K(t-Xi/h)\n",
    "#–†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –Ø–ø–æ–Ω–µ—á–Ω–∏–∫–æ–≤–∞ –æ–ø—Ä–µ–¥–µ–ª—è–µ—Ç –ø–ª–æ—Ç–Ω–æ—Å—Ç—å –ö - —Å–∏–º–º–µ—Ç—Ä–∏—á–Ω–∞—è, –Ω–µ–æ—Ç—Ä–∏—Ü–∞—Ç–µ–ª—å–Ω–∞—è, —Å –∏–Ω—Ç–µ–≥—Ä–∞–ª–æ–º=1\n",
    "my_density = gaussian_kde(data['SalePrice'], bw_method = 1) #–ú–µ—Ç–æ–¥ –æ–ø—Ä–µ–¥–µ–ª—è–µ—Ç –º–µ—Ä—É —Å–≥–ª–∞–∂–∏–≤–∞–Ω–∏—è\n",
    "x = linspace(min(data['SalePrice']), max(data['SalePrice']),1000)\n",
    "plot(x, my_density(x),'g') #—Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —Ñ—É–Ω–∫—Ü–∏–∏\n",
    "hist(data['SalePrice'], density=True, alpha=.3) \n",
    "show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#–î–ª—è —Å—Ä–∞–≤–Ω–µ–Ω–∏—è –Ω–µ—Å–∫–æ–ª—å–∫–∏—Ö –≥—Ä—É–ø–ø –º–æ–∂–Ω–æ —Å–ª–æ–∂–∏—Ç—å –≥–∏—Å—Ç–æ–≥—Ä–∞–º–º—ã \n",
    "df.groupby('Status')['Length'].plot.hist(alpha=.6)\n",
    "plt.legend()\n",
    "#–ù–æ –ª—É—á—à–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å box-plot. –£—Å—ã - 1,5 –º–µ–∂–∫–≤–∞—Ä—Ç–∏–ª—è. Outlies - 3. Extremes - –¥–∞–ª—å—à–µ.\n",
    "#–í–Ω–∏–º–∞—Ç–µ–ª—å–Ω–æ —Å–º–æ—Ç—Ä–∏–º –Ω–∞ —á–∏—Å–ª–æ –Ω–∞–±–ª—é–¥–µ–Ω–∏–π –≤ –∫–∞–∂–¥–æ–π –∏–∑ –≤—ã–±–æ—Ä–æ–∫, —á—Ç–æ–±—ã –ø—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å boxplot\n",
    "data['MS Zoning'].value_counts()\n",
    "ax=data.boxplot(column='SalePrice', by='MS Zoning')\n",
    "ax.get_figure().suptitle('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#–î–ª—è –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è \"—Ç–∏–ø–∏—á–Ω–æ–≥–æ\" –æ–±—ä–µ–∫—Ç–∞ —Å–æ–≤–æ–∫—É–ø–Ω–æ—Å—Ç–∏ –º–æ–∂–Ω–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å —Å—Ä–µ–¥–Ω–µ–µ(–µ—Å–ª–∏ –Ω–µ—Ç –≤—ã–±—Ä–æ—Å–æ–≤) –∏–ª–∏ –º–µ–¥–∏–∞–Ω—É(–µ—Å–ª–∏ –µ—Å—Ç—å)\n",
    "#–ü—Ä–∏ –Ω–µ—Ä–∞–≤–Ω–æ–º–µ—Ä–Ω–æ–º —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–∏ –º–æ–∂–Ω–æ —É–±—Ä–∞—Ç—å –≤—ã–±—Ä–æ—Å—ã\n",
    "town_2 = town.iloc[2:1004]\n",
    "#–ò–ª–∏ –ª–æ–≥–∞—Ä–∏—Ñ–º–∏—Ä–æ–≤–∞—Ç—å –ø–µ—Ä–µ–º–µ–Ω–Ω—É—é (–¥–ª—è –ª–æ–≥-–Ω–æ—Ä–º–∞–ª—å–Ω–æ–≥–æ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è)\n",
    "x = np.log10(town[u'–Ω–∞—Å–µ–ª–µ–Ω–∏–µ'])\n",
    "pd.Series(x).hist(bins=45)\n",
    "#–£—Å–µ—á–µ–Ω–Ω–æ–µ —Å—Ä–µ–¥–Ω–µ–µ. –í—ã–±—Ä–∞—Å—ã–≤–∞–µ—Ç—Å—è 2,5% —Å–∞–º—ã—Ö –º–∞–ª—ã—Ö –∏ 2,5% –Ω–∞–∏–±–æ–ª—å—à–∏—Ö –∑–Ω–∞—á–µ–Ω–∏–π –ø–µ—Ä–µ–º–µ–Ω–Ω–æ–π. –î–ª—è –Ω–æ–≤–æ–π –ë–î —Å—á–∏—Ç–∞–µ—Ç—Å—è —Å—Ä–µ–¥–Ω–µ–µ\n",
    "exclude = int(len(town)/100*2.5)\n",
    "redacted_town = town[exclude:len(town)-exclude]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#–î–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è –∫–æ–º–ø–ª–µ–∫—Å–Ω–æ–≥–æ —Å—Ä–∞–≤–Ω–µ–Ω–∏—è –æ–±—ä–µ–∫—Ç–æ–≤ –ø–æ –Ω–µ—Å–∫–æ–ª—å–∫–∏–º –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–º\n",
    "#–î–∏–∞–≥–æ–Ω–∞–ª—å –ø–æ–∫–∞–∑—ã–≤–∞–µ—Ç —è–¥–µ—Ä–Ω—É—é –æ—Ü–µ–Ω–∫—É –ø–ª–æ—Ç–Ω–æ—Å—Ç–∏\n",
    "#–ú–∞—Ç—Ä–∏—Ü–∞ —Å–æ—Å—Ç–æ–∏—Ç –∏–∑ –¥–∏–∞–≥—Ä–∞–º–º —Ä–∞—Å—Å–µ–∏–≤–∞–Ω–∏—è\n",
    "colors = {'genuine': 'green', 'counterfeit': 'red'}\n",
    "scatter_matrix(df,\n",
    "               # —Ä–∞–∑–º–µ—Ä –∫–∞—Ä—Ç–∏–Ω–∫–∏\n",
    "               figsize=(6, 6),\n",
    "               # –ø–ª–æ—Ç–Ω–æ—Å—Ç—å –≤–º–µ—Å—Ç–æ –≥–∏—Å—Ç–æ–≥—Ä–∞–º–º—ã –Ω–∞ –¥–∏–∞–≥–æ–Ω–∞–ª–∏\n",
    "               diagonal='kde',\n",
    "               # —Ü–≤–µ—Ç–∞ –∫–ª–∞—Å—Å–æ–≤\n",
    "               c=df['Status'].replace(colors),\n",
    "               # —Å—Ç–µ–ø–µ–Ω—å –ø—Ä–æ–∑—Ä–∞—á–Ω–æ—Å—Ç–∏ —Ç–æ—á–µ–∫\n",
    "               alpha=0.2,\n",
    "              )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#–í —Å–ª—É—á–∞–µ –æ—á–µ–≤–∏–¥–Ω–æ–≥–æ —Å–º–µ—à–µ–Ω–∏—è –¥–≤—É—Ö –Ω–æ—Ä–º–∞–ª—å–Ω—ã—Ö —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–π, –º–æ–∂–Ω–æ –æ—Ü–µ–Ω–∏—Ç—å –∏—Ö –±–æ–ª–µ–µ –ø–æ–¥—Ä–æ–±–Ω–æ\n",
    "df.groupby('Status')['Diagonal'].plot.hist(alpha=0.6)\n",
    "plt.legend(loc='upper left')\n",
    "\n",
    "#–î–ª—è —Å—Ä–∞–≤–Ω–µ–Ω–∏—è –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ –≤–∞–∂–Ω–æ –∏—Ö –Ω–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞—Ç—å\n",
    "data.groupby('MS Zoning')['SalePrice'].plot.hist(density=True)\n",
    "plt.legend()\n",
    "\n",
    "#–ï—Å–ª–∏ —Ä–∞—Å—Å–µ–≤–∞–Ω–∏–µ –Ω–µ–ª—å–∑—è —Ä–∞–∑–¥–µ–ª–∏—Ç—å –ª–∏–Ω–µ–π–Ω–æ, —Ç–æ –º–µ–Ω—è–µ–º —Ç–æ—á–∫—É –Ω–∞—á–∞–ª–∞ –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç –∏ –≤—ã–±–∏—Ä–∞–µ–º –Ω–æ–≤—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –¥–ª—è —Ä–∞–∑–¥–µ–ª–µ–Ω–∏—è"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#–ò–µ—Ä–∞—Ä—Ö–∏—á–µ—Å–∫–∏–π –∫–ª–∞—Å—Ç–µ—Ä–Ω—ã–π –∞–Ω–∞–ª–∏–∑ —Ä–∞–∑–¥–µ–ª—è–µ—Ç –æ–±—ä–µ–∫—Ç—ã –Ω–∞ –≥—Ä—É–ø–ø—ã (—Å—Ç—Ä–∞—Ç–∏—Ñ–∏–∫–∞—Ü–∏—è). –ß–∏—Å–ª–æ –≥—Ä—É–ø–ø –∑–∞—Ä–∞–Ω–µ–µ –Ω–µ–∏–∑–≤–µ—Å—Ç–Ω–æ\n",
    "#–ö–ª–∞—Å—Ç–µ—Ä–Ω—ã–π –∞–Ω–∞–ª–∏–∑ –ø–æ–∑–≤–æ–ª—è–µ—Ç —Å–æ–∫—Ä–∞—Ç–∏—Ç—å —á–∏—Å–ª–æ –Ω–∞–±–ª—é–¥–µ–Ω–∏–π –∏ –ø—Ä–æ–∏–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∏—Ä–æ–≤–∞—Ç—å –∏—Ö\n",
    "#–°—Ö–æ–∂–µ—Å—Ç—å –≤–Ω—É—Ç—Ä–∏ –∫–ª–∞—Å—Ç–µ—Ä–∞ –æ—Ç–æ–±—Ä–∞–∂–∞–µ—Ç—Å—è –∫–∞–∫ —Ä–∞—Å—Å—Ç–æ—è–Ω–∏–µ–º –º–µ–∂–¥—É –±–ª–∏–∑–∫–∏–º–∏ –æ–±—ä–µ–∫—Ç–∞–º–∏ –Ω–∞ –¥–∏–∞–≥—Ä–∞–º–º–µ –∫–ª–∞—Å—Ç–µ—Ä–æ–≤\n",
    "#–†–∞—Å—Å—Ç–æ—è–Ω–∏–µ –º–æ–∂–Ω–æ —Ä–∞—Å—Å—á–∏—Ç–∞—Ç—å –º–µ—Ç–æ–¥–∞–º–∏: –ï–≤–∫–ª–∏–¥–∞(–∏–ª–∏ –∫–≤–∞–¥—Ä–∞—Ç–∞ –ï–≤–∫–ª–∏–¥–∞), –ë–ª–æ–∫(–ú–∞–Ω—Ö–µ—Ç—Ç–µ–Ω), –•—ç–º–º–∏–Ω–≥–∞(–¥–ª—è —Å–ª–æ–≤) –∏ —Ç–¥.\n",
    "#–ú–∞–Ω—Ö–µ—Ç—Ç–µ–Ω –ø—Ä–µ–¥–ø–æ—á—Ç–∏—Ç–µ–ª—å–Ω–µ–µ, –∫–æ–≥–¥–∞ –Ω–µ—Ç –±–æ–ª—å—à–∏—Ö —Ä–∞–∑–ª–∏—á–∏–π –≤ —Ä–∞–Ω–¥–æ–º–Ω—ã—Ö –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö, –ø–æ—Ç–æ–º—É —á—Ç–æ –≤–µ—Å –∞–Ω–æ–º–∞–ª–∏–π —Ç–æ–≥–¥–∞ –º–µ–Ω—å—à–µ\n",
    "#–†–∞—Å—Å—Ç–æ—è–Ω–∏–µ –º–µ–∂–¥—É –∫–ª–∞—Å—Ç–µ—Ä–∞–º–∏ —Ä–∞—Å—Å—á–∏—Ç—ã–≤–∞–µ—Ç—Å—è:\n",
    "#–ú–µ—Ç–æ–¥ –í–∞—Ä–¥–∞ (WARD) - –ø–æ–∑–≤–æ–ª—è–µ—Ç —Ä–∞–±–æ—Ç–∞—Ç—å —Å —à–∞—Ä–æ–≤—ã–º–∏ —Å–∫–æ–ø–ª–µ–Ω–∏—è–º–∏\n",
    "#–ú–µ—Ç–æ–¥ –±–ª–∏–∂–∞–π—à–∏—Ö —Å–æ—Å–µ–¥–µ–π (–ø–æ–∑–≤–æ–ª—è–µ—Ç –æ–ø—Ä–µ–¥–µ–ª—è—Ç—å –ª–µ–Ω—Ç–æ—á–Ω—ã–µ –∫–ª–∞—Å—Ç–µ—Ä—ã)\n",
    "#–°—Ä–µ–¥–Ω–µ–≤–∑–≤–µ—à–µ–Ω–Ω–æ–µ —Ä–∞—Å—Å—Ç–æ—è–Ω–∏–µ: —Å—Ä–µ–¥–Ω–µ–µ –¥–ª—è —Å—É–º–º—ã –≤—Å–µ—Ö —Ä–∞—Å—Å—Ç–æ—è–Ω–∏–π (—Ç–∞–∫–∂–µ –¥–ª—è –ª–µ–Ω—Ç–æ—á–Ω—ã—Ö)\n",
    "#–¶–µ–Ω—Ç—Ä–æ–∏–¥: —Ä–∞—Å—Å—Ç–æ—è–Ω–∏–µ –º–µ–∂–¥—É –∫–ª–∞—Å—Ç–µ—Ä–∞–º–∏ —Ä–∞–≤–Ω–æ —Ä–∞—Å—Å—Ç–æ—è–Ω–∏—é –º–µ–∂–¥—É –∏—Ö —Ü–µ–Ω—Ç—Ä–∞–º–∏ —Ç—è–∂–µ—Å—Ç–∏\n",
    "#–ú–µ—Ç–æ–¥—ã –¥–∞–ª—å–Ω–µ–≥–æ –∏ –±–ª–∏–∂–∞–π—à–µ–≥–æ —Å–æ—Å–µ–¥–∞: —Ä–∞—Å—Å—Ç–æ—è–Ω–∏–µ –º–µ–∂–¥—É —Å–∞–º—ã–º–∏ –¥–∞–ª—å–Ω–∏–º–∏\\–±–ª–∏–∑–∫–∏–º–∏ –æ–±—ä–µ–∫—Ç–∞–º–∏ –µ—Å—Ç—å –º–µ–∂–∫–ª–∞—Å—Ç–µ—Ä\n",
    "#–ú–µ—Ç–æ–¥ —Ä–∞—Å—Å—Ç–æ—è–Ω–∏—è Sorencen-Dice Q = 2*|A^B|/|A|+|B|. –ù–µ —Ä–∞–±–æ—Ç–∞–µ—Ç –µ—Å–ª–∏ –º–Ω–æ–∂–µ—Å—Ç–≤–∞ —Å–ª–∞–±–æ –ø–µ—Ä–µ—Å–µ–∫–∞—é—Ç—Å—è"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#–ê–ª–≥–æ—Ä–∏—Ç–º—ã –∫–ª–∞—Å—Ç–µ—Ä–Ω–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞. –û–±—ä–µ–∫—Ç—ã –≥—Ä—É–ø–ø–∏—Ä—É—é—Ç—Å—è —Å –±–ª–∏–∂–∞–π—à–∏–º–∏, –ø–æ–∫–∞ –Ω–µ—Ç —Å–∫–∞—á–∫–∞ –≤ —Ä–∞—Å—Å—Ç–æ—è–Ω–∏—è—Ö –¥–ª—è —Å–ª–µ–¥—É—é—â–µ–≥–æ —Å–ª–∏—è–Ω–∏—è\n",
    "#–ú–æ–º–µ–Ω—Ç –¥–ª—è –ø—Ä–µ–∫—Ä–∞—â–µ–Ω–∏—è —Å–ª–∏—è–Ω–∏—è –æ–ø—Ä–µ–¥–µ–ª—è–µ—Ç—Å—è –¥–µ–Ω–¥—Ä–æ–≥—Ä–∞–º–º–æ–π (–¥–ª—è —É–º–µ—Ä–µ–Ω–Ω–æ–≥–æ —á–∏—Å–ª–∞ –æ–±—ä–µ–∫—Ç–æ–≤)\n",
    "#–ö–∞–º–µ–Ω–∏—Å—Ç–∞—è –æ—Å—ã–ø—å/–ª–æ–∫–æ—Ç—å –ø–æ–∫–∞–∑—ã–≤–∞—é—Ç —Å–∫–∞—á–æ–∫ (—Ä–µ–∑–∫–∏–π –≤–∑–ª–µ—Ç –≥—Ä–∞—Ñ–∏–∫–∞) —à–∞–≥–æ–≤ –æ–±—ä–µ–¥–∏–Ω–µ–Ω–∏–π, –∫–æ–≥–¥–∞ –∫–ª–∞—Å—Ç–µ—Ä–∏–∑—É—é—Ç—Å—è —Ç—ã—Å—è—á–∏ –æ–±—ä–µ–∫—Ç–æ–≤\n",
    "#–ó–∞–¥–∞—á–∞ –∞–Ω–∞–ª–∏—Ç–∏–∫–∞: –æ—Ç–æ–±—Ä–∞—Ç—å –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ, –≤—ã–±—Ä–∞—Ç—å –º–µ—Ç–æ–¥ —Å—Ç–∞–Ω–¥–∞—Ä—Ç–∏–∑–∞—Ü–∏–∏, —É—Å—Ç–∞–Ω–æ–≤–∏—Ç—å —Ä–∞—Å—Å—Ç–æ—è–Ω–∏–µ –º–µ–∂–¥—É –∫–ª–∞—Å—Ç–µ—Ä–∞–º–∏ –∏ –º–µ–∂–¥—É –æ–±—ä–µ–∫—Ç–∞–º–∏ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#–û–±—ä–µ–∫—Ç, –≤ –∫–æ—Ç–æ—Ä–æ–º –±—É–¥–µ—Ç —Ö—Ä–∞–Ω–∏—Ç—Å—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ–º —Å–ª–∏—è–Ω–∏–∏ –∫–ª–∞—Å—Ç–µ—Ä–æ–≤\n",
    "#–î–ª—è —Ñ—É–Ω–∫—Ü–∏–∏ –Ω—É–∂–µ–Ω —Ñ—Ä–µ–π–º, –º–µ—Ç–æ–¥ –º–µ–∂–∫–ª–∞—Å—Ç–µ—Ä–∞ –∏ –º–µ—Ç–æ–¥ –º–µ–∂–æ–±—ä–µ–∫—Ç–æ–≤\n",
    "link = linkage(beer, 'ward', 'euclidean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#link - –º–∞—Ç—Ä–∏—Ü–∞ (n-1) x 4, –≥–¥–µ n - —á–∏—Å–ª–æ –Ω–∞–±–ª—é–¥–µ–Ω–∏–π. \n",
    "#–ö–∞–∂–¥–∞—è —Å—Ç—Ä–æ–∫–∞ - —Ä–µ–∑—É–ª—å—Ç–∞—Ç —Å–ª–∏—è–Ω–∏—è –æ—á–µ—Ä–µ–¥–Ω–æ–π –ø–∞—Ä—ã –∫–ª–∞—Å—Ç–µ—Ä–æ–≤ —Å –Ω–æ–º–µ—Ä–∞–º–∏ link[i, 0] –∏ link[i, 1]. \n",
    "#–ù–æ–≤–æ–º—É –∫–ª–∞—Å—Ç–µ—Ä—É –ø—Ä–∏—Å–≤–∞–∏–≤–∞–µ—Ç—Å—è –Ω–æ–º–µ—Ä n + i \n",
    "#link[i, 2] –æ–∑–Ω–∞—á–∞–µ—Ç —Ä–∞—Å—Å—Ç–æ—è–Ω–∏–µ –º–µ–∂–¥—É —Å–ª–∏—Ç—ã–º–∏ –∫–ª–∞—Å—Ç–µ—Ä–∞–º–∏, –∞ link[i, 3] - —Ä–∞–∑–º–µ—Ä –Ω–æ–≤–æ–≥–æ –∫–ª–∞—Å—Ç–µ—Ä–∞.\n",
    "link[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#–ü–æ—Å—Ç—Ä–æ–µ–Ω–∏–µ –¥–µ–Ω–¥—Ä–æ–≥—Ä–∞–º–º—ã\n",
    "dn = dendrogram(link, orientation='right')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#–ö–ª—é—á–µ–≤—ã–µ —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫–∏ –∫–ª–∞—Å—Ç–µ—Ä–æ–≤\n",
    "#–í –∫–æ–ª–æ–Ω–∫—É cluster –∑–∞–ø–∏—à–µ–º –Ω–æ–º–µ—Ä –∫–ª–∞—Å—Ç–µ—Ä–∞ –æ–±—ä–µ–∫—Ç–∞ —Å –ø–æ–º–æ—â—å—é —Ñ—É–Ω–∫—Ü–∏–∏ fcluster. \n",
    "#–ê—Ä–≥—É–º–µ–Ω—Ç—ã: linkage, –ø–æ—Ä–æ–≥–æ–≤–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ –¥–ª—è –º–µ–∂–∫–ª–∞—Å—Ç–µ—Ä–∞ (–ª–∏–±–æ —á–∏—Å–ª–æ –∫–ª–∞—Å—Ç–µ—Ä–æ–≤), criterion: distance –¥–ª—è –æ—Å—Ç–∞–Ω–æ–≤–∫–∏ —Ä–∞–∑–±–∏–µ–Ω–∏—è \n",
    "# –û—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º –æ–±—ä–µ–¥–∏–Ω–µ–Ω–∏–µ, –µ—Å–ª–∏ —Ä–∞—Å—Å—Ç–æ—è–Ω–∏–µ –º–µ–∂–¥—É –∫–ª–∞—Å—Ç–µ—Ä–∞–º–∏ –ø—Ä–µ–≤—ã—à–∞–µ—Ç 3\n",
    "beer['cluster'] = fcluster(link, 3, criterion='distance')\n",
    "#–î–æ–ª—è –æ–±—ä–µ–∫—Ç–æ–≤ –≤ –∫–ª–∞—Å—Ç–µ—Ä–µ, –∫–æ—Ç–æ—Ä—ã–µ –∏–º–µ—é—Ç —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—â–∏–µ —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫–∏\n",
    "beer.groupby(\"cluster\").mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#–ö–ª–∞—Å—Ç–µ—Ä–Ω—ã–π –∞–Ω–∞–ª–∏–∑ –º–µ—Ç–æ–¥–æ–º –ö-—Å—Ä–µ–¥–Ω–∏—Ö\n",
    "#–∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –º–æ–¥–µ–ª–∏\n",
    "model = KMeans(n_clusters=2, random_state=42) #random_state - –∑–µ—Ä–Ω–æ –¥–∞—Ç—á–∏–∫–∞ —Å–ª—É—á–∞–π–Ω—ã—Ö —á–∏—Å–µ–ª. –î–ª—è –≤–æ—Å–ø—Ä–æ–∏–∑–≤–æ–¥–∏–º–æ—Å—Ç–∏ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞ \n",
    "#–ü—Ä–∏ –∫–∞–∂–¥–æ–º –Ω–æ–≤–æ–º –≤—ã–∑–æ–≤–µ —Å –æ–¥–∏–Ω–∞–∫–æ–≤—ã–º–∏ random_state –º–æ–¥–µ–ª—å –±—É–¥–µ—Ç –¥–∞–≤–∞—Ç—å –æ–¥–∏–Ω–∞–∫–æ–≤—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#–ø–æ–¥–≥–æ–Ω–∫–∞ –º–æ–¥–µ–ª–∏ –ø–æ –¥–∞–Ω–Ω—ã–º –∏–∑ –ë–î\n",
    "model.fit(beer)\n",
    "\n",
    "#–†–µ–∑—É–ª—å—Ç–∞—Ç –∫–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü–∏–∏ –Ω–∞ –¥–∞–Ω–Ω—ã—Ö –∏–∑ –ë–î\n",
    "model.labels_\n",
    "\n",
    "#–∫–æ–æ—Ä–¥–∏–Ω–∞—Ç—ã —Ü–µ–Ω—Ç—Ä–æ–≤ –∫–ª–∞—Å—Ç–µ—Ä–æ–≤\n",
    "model.cluster_centers_\n",
    "\n",
    "#–î–æ–±–∞–≤–ª–µ–Ω–∏–µ –≤ –∫–ª–∞—Å—Ç–µ—Ä –¥–∞–Ω–Ω—ã—Ö. –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ –¥–ª—è –Ω–æ–≤—ã—Ö –Ω–∞–±–ª—é–¥–µ–Ω–∏–π. –ú–µ—Ç–æ–¥ predict\n",
    "new_items = [\n",
    "    [1, 1, 1, 1, 1, 1, 1, 1],\n",
    "    [0, 0, 0, 0, 0, 0, 0, 0]\n",
    "]\n",
    "model.predict(new_items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#–ß–∏—Å–ª–æ –∫–ª–∞—Å—Ç–µ—Ä–æ–≤ –º–æ–∂–Ω–æ –æ–ø—Ä–µ–¥–µ–ª–∏—Ç—å —á–µ—Ä–µ–∑ –≥—Ä–∞—Ñ–∏–∫ –ª–æ–∫—Ç—è –¥–ª—è –¥–ª—è —Ä–∞–∑–Ω–æ–≥–æ —á–∏—Å–ª–∞ –∫–ª–∞—Å—Ç–µ—Ä–æ–≤\n",
    "#–ú–µ—Ç–æ–¥ inertia_ –≤–µ—Ä–Ω—ë—Ç —Å—É–º–º—É —Ä–∞—Å—Å—Ç–æ—è–Ω–∏–π –æ—Ç –∫–∞–∂–¥–æ–π —Ç–æ—á–∫–∏ –¥–∞–Ω–Ω—ã—Ö –¥–æ —Ü–µ–Ω—Ç—Ä–∞ –±–ª–∏–∂–∞–π—à–µ–≥–æ —É –Ω–µ–π –∫–ª–∞—Å—Ç–µ—Ä–∞ \n",
    "#–ö–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü–∏—é –º–æ–∂–Ω–æ —Å—á–∏—Ç–∞—Ç—å —É—Å–ª–æ–≤–Ω–æ —Ö–æ—Ä–æ—à–µ–π, –∫–æ–≥–¥–∞ –∏–Ω–µ—Ä—Ü–∏—è –ø–µ—Ä–µ—Å—Ç–∞—ë—Ç —Å–∏–ª—å–Ω–æ —É–º–µ–Ω—å—à–∞—Ç—å—Å—è –ø—Ä–∏ —É–≤–µ–ª–∏—á–µ–Ω–∏–∏ —á–∏—Å–ª–∞ –∫–ª–∞—Å—Ç–µ—Ä–æ–≤\n",
    "K = range(1, 11)\n",
    "models = [KMeans(n_clusters=k, random_state=42).fit(beer) for k in K]\n",
    "dist = [model.inertia_ for model in models]\n",
    "\n",
    "#–ì—Ä–∞—Ñ–∏–∫ –ª–æ–∫—Ç—è\n",
    "plt.plot(K, dist, marker='o')\n",
    "plt.xlabel('k')\n",
    "plt.ylabel('Sum of distances')\n",
    "plt.title('The Elbow Method showing the optimal k')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# –í –∫–æ–ª–æ–Ω–∫–µ NR –Ω–∞—Ö–æ–¥–∏—Ç—Å—è –Ω–æ–º–µ—Ä –æ–±—ä–µ–∫—Ç–∞, –µ–≥–æ –Ω—É–∂–Ω–æ –∏—Å–∫–ª—é—á–∏—Ç—å –∏–∑ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –∫–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü–∏–∏\n",
    "del ass['NR']\n",
    "\n",
    "#–û–ø—Ç–∏–º–∏–∑–∏—Ä—É–µ–º –º–æ–¥–µ–ª—å, –º–µ–Ω—è—è —á–∏—Å–ª–æ –∑–∞–¥–∞–≤–∞–µ–º—ã—Ö –∫–ª–∞—Å—Ç–µ—Ä–æ–≤ –Ω–∞ –æ—Å–Ω–æ–≤–∞–Ω–∏–∏ –≥—Ä–∞—Ñ–∏–∫–∞ –ª–æ–∫—Ç—è\n",
    "model = KMeans(n_clusters=4, random_state=42)\n",
    "model.fit(ass)\n",
    "ass['cluster'] = model.labels_\n",
    "ass.groupby('cluster').mean()\n",
    "\n",
    "#–°–º–æ—Ç—Ä–∏–º –∫ –∫–∞–∫–æ–º—É –∫–ª–∞—Å—Ç–µ—Ä—É –∫–∞–∫–∏–µ –æ–±—ä–µ–∫—Ç—ã –æ—Ç–Ω–æ—Å—è—Ç—Å—è\n",
    "ass['cluster'].sort_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#–ü—Ä–æ–≤–µ—Ä–∫–∞ —Å—Ç–∞—Ç–∏—Å—Ç–∏—á–µ—Å–∫–∏—Ö –≥–∏–ø–æ—Ç–µ–∑:\n",
    "#–ì–∏–ø–æ—Ç–µ–∑–∞ —Å–æ–≥–ª–∞—Å–∏—è. –°–æ–≤–ø–∞–¥–∞–µ—Ç —Ä–∞–Ω–¥–æ–º–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è —Å –Ω–æ—Ä–º–∞–ª—å–Ω—ã–º —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ–º? –°–∞–º—ã–π –¥–µ—à–µ–≤—ã–π –∏ –ø—Ä–æ—Å—Ç–æ–π –≤–∞—Ä–∏–∞–Ω—Ç\n",
    "#–ì–∏–ø–æ—Ç–µ–∑–∞ —Å–æ–≥–ª–∞—Å–∏—è2. –ì–∏–ø–æ—Ç–µ–∑–∞ –æ–± —ç–∫—Å–ø–æ–Ω–µ–Ω—Ü–∏–∞–ª—å–Ω–æ—Å—Ç–∏ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è. –ù—É–∂–Ω–∞, –∫–æ–≥–¥–∞ –µ—Å—Ç—å –ø–µ—Ä–µ–º–µ–Ω–Ω–∞—è –≤—Ä–µ–º–µ–Ω–∏ –æ–∂–∏–¥–∞–Ω–∏—è\n",
    "#–ì–∏–ø–æ—Ç–µ–∑–∞ –æ–¥–Ω–æ—Ä–æ–¥–Ω–æ—Å—Ç–∏. –°–æ–≤–ø–∞–¥–∞—é—Ç –¥–≤–µ —Ä–∞–Ω–¥–æ–º–Ω—ã–µ —Ñ—É–Ω–∫—Ü–∏–∏ —Ä–∞—Å–ø—Ä–µ–¥–ª–µ–Ω–∏—è? –ù–∞–ø—Ä–∏–º–µ—Ä, —á—Ç–æ–±—ã —Å—Ä–∞–≤–Ω–∏—Ç—å –¥–∞–Ω–Ω—ã–µ –¥–æ –∏ –ø–æ—Å–ª–µ —Å–æ–±—ã—Ç–∏—è\n",
    "#–ì–∏–ø–æ—Ç–µ–∑–∞ –Ω–µ–∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏. –ù—É–ª–µ–≤–∞—è –≥–∏–ø–æ—Ç–µ–∑–∞ –¥–ª—è —Ä–∞–Ω–¥–æ–º–Ω—ã—Ö –æ–±—ä–µ–∫—Ç–æ–≤. –ü—Ä–æ–≤–µ—Ä—è–µ—Ç—Å—è —á–µ—Ä–µ–∑ –∫–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç –∫–æ—Ä—Ä–µ–ª—è—Ü–∏–∏ (—Å–∫–∞–ª—è—Ä—ã) \n",
    "#–ì–∏–ø–æ—Ç–µ–∑–∞ –æ –ø–∞—Ä–∞–º–µ—Ç—Ä–µ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è. –û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –∫–ª—é—á–µ–≤—ã—Ö –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤. –ù–∞–ø—Ä–∏–º–µ—Ä –æ–¥–∏–Ω–∞–∫–æ–≤—ã–µ —Å—Ä–µ–¥–Ω–∏–µ –∏–ª–∏ –º–µ–¥–∏–∞–Ω—ã."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#–ê–ª—å—Ñ–∞-—ç—Ç–æ —É—Ä–æ–≤–µ–Ω—å –∑–Ω–∞—á–∏–º–æ—Å—Ç–∏(0.05, 0.01. 0.005). –û–ø—Ä–µ–¥–µ–ª–µ—è–µ—Ç —á–∏—Å–ª–æ –æ—à–∏–±–æ–∫ –ø–µ—Ä–≤–æ–≥–æ —Ä–æ–¥–∞. –ù–∞ –≤—Ç–æ—Ä–æ–≥–æ —Ä–æ–¥–∞ –≤–ª–∏—è–µ—Ç —Ä–∞–∑–º–µ—Ä –≤—ã–±–æ—Ä–∫–∏\n",
    "#–¢- —ç—Ç–æ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –∫—Ä–∏—Ç–µ—Ä–∏—è. –ï—Å–ª–∏ T<C–∞–ª—å—Ñ–∞, —Ç–æ –≤–µ—Ä–Ω–∞ –Ω—É–ª–µ–≤–∞—è –≥–∏–ø–æ—Ç–µ–∑–∞\n",
    "#C–∞–ª—å—Ñ–∞- —ç—Ç–æ –∫—Ä–∏—Ç–∏—á–µ—Å–∫–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ. –í–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å –æ—Ç–≤–µ—Ä–≥–Ω—É—Ç—å –ø—Ä–∞–≤–∏–ª—å–Ω—É—é –≥–∏–ø–æ—Ç–µ–∑—É(T>C) –Ω–µ –¥–æ–ª–∂–Ω–∞ –ø—Ä–µ–≤—ã—à–∞—Ç—å –ê(–∞–ª—å—Ñ–∞)\n",
    "#p-value –ø–æ–∫–∞–∑—ã–≤–∞–µ—Ç –Ω–∞—Å–∫–æ–ª—å–∫–æ —á–∞—Å—Ç–æ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –∫—Ä–∏—Ç–µ—Ä–∏—è –≤ –≤–µ—Ä–Ω–æ–π –≥–∏–ø–æ—Ç–µ–∑–µ –±—É–¥–µ—Ç –ø—Ä–µ–≤—ã—à–∞—Ç—å —Ä–µ–∞–ª—å–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è p=P{T>T—ç–∫—Å–ø}\n",
    "#–ï—Å–ª–∏ p<A, –≥–∏–ø–æ—Ç–µ–∑—É –æ—Ç–≤–µ—Ä–≥–∞–µ–º. –ï—Å–ª–∏ p>A, –≥–∏–ø–æ—Ç–µ–∑—É –Ω–µ –æ—Ç–≤–µ—Ä–≥–∞–µ–º. –ü—Ä–æ–≤–µ—Ä—è—é—Ç—Å—è –≤—Å–µ —É—Å–ª–æ–≤–∏—è, –ø—Ä–∏ –∫–æ—Ç–æ—Ä—ã—Ö –∫—Ä–∏—Ç–µ—Ä–∏–π –±—É–¥–µ—Ç —Ä–∞–±–æ—Ç–∞—Ç—å"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#–¢–µ—Å—Ç—ã –ö–æ–ª–º–æ–≥–æ—Ä–æ–≤–∞-–°–º–∏—Ä–Ω–æ–≤–∞ –∏ Shapiro-Wilk –ø–æ–∑–≤–æ–ª—è—é—Ç –ø—Ä–æ–≤–µ—Ä–∏—Ç—å –≤—ã–±–æ—Ä–∫—É –Ω–∞ –ø—Ä–∏–Ω–∞–¥–ª–µ–∂–Ω–æ—Å—Ç—å –∫ –ì–° –∏ –Ω–æ—Ä–º–∞–ª—å–Ω–æ—Å—Ç—å —Ä–∞—Å–ø—Ä–µ–¥–µ–µ–ª–Ω–∏—è\n",
    "\n",
    "#–ü—Ä–∏–º–µ–Ω—è–µ–º –∫—Ä–∏—Ç–µ—Ä–∏–π –®–∞–ø–∏—Ä–æ-–í–∏–ª–∫–∞ –ø–æ—Å–ª–µ –ª–æ–≥–∞—Ä–∏—Ñ–º–∏—Ä–æ–≤–∞–Ω–∏—è. \n",
    "town = town.set_index(u'–Ω–æ–º–µ—Ä')\n",
    "plt.hist(np.log10(town[u'–Ω–∞—Å–µ–ª–µ–Ω–∏–µ']), bins=50)\n",
    "res = stats.shapiro(np.log10(town[u'–Ω–∞—Å–µ–ª–µ–Ω–∏–µ']))\n",
    "print('p-value: ', res[1])\n",
    "#P –æ—á–µ–Ω—å –º–∞–ª–µ–Ω—å–∫–æ–µ, –ø–æ—ç—Ç–æ–º—É –≥–∏–ø–æ—Ç–µ–∑—É –æ –Ω–æ—Ä–º–∞–ª—å–Ω–æ—Å—Ç–∏ –æ—Ç–≤–µ—Ä–≥–∞–µ–º. \n",
    "#–û—Ç–∫–ª–æ–Ω–µ–Ω–∏—è –æ—Ç –Ω–æ—Ä–º–∞–ª—å–Ω–æ—Å—Ç–∏ –±—É–¥—É—Ç –Ω–µ—Å—É—â–µ—Å—Ç–≤–µ–Ω–Ω—ã, –µ—Å–ª–∏ —É–±—Ä–∞—Ç—å –≤—ã–±—Ä–æ—Å—ã"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#–¢–µ—Å—Ç –Ω–∞ –≥–∏–ø–æ—Ç–µ–∑—É –æ–¥–Ω–æ—Ä–æ–¥–Ω–æ—Å—Ç–∏\n",
    "#–ó–∞ –æ–¥–∏–Ω –≤–∞—Ä–∏–∞–Ω—Ç –¥–∏–∑–∞–π–Ω–∞ –≤—ã–∫–∞–∑–∞–ª–æ—Å—å 28 –∏–∑ 100 –æ–ø—Ä–æ—à–µ–Ω–Ω—ã—Ö, –∑–∞ –≤—Ç–æ—Ä–æ–π 20 –∏–∑ 100 –æ–ø—Ä–æ—à–µ–Ω–Ω—ã—Ö. \n",
    "#–ü—Ä–æ–≤–µ—Ä—è–µ–º, —è–≤–ª—è–µ—Ç—Å—è –ª–∏ —ç—Ç–∞ —Ä–∞–∑–Ω–∏—Ü–∞ —Å—Ç–∞—Ç–∏—Å—Ç–∏—á–µ—Å–∫–∏ –∑–Ω–∞—á–∏–º–æ–π —Å –ø–æ–º–æ—â—å—é –∫—Ä–∏—Ç–µ—Ä–∏—è —Ö–∏-–∫–≤–∞–¥—Ä–∞—Ç. \n",
    "\n",
    "#C—Ç—Ä–æ–∏–º —Ç–∞–±–ª–∏—Ü—É —Å–æ–ø—Ä—è–∂—ë–Ω–Ω–æ—Å—Ç–∏.\n",
    "contingency_table = pd.DataFrame([[28, 72], [20, 80]],\n",
    "                                 index=['first', 'second'],\n",
    "                                 columns=['for', 'against'])\n",
    "\n",
    "res = stats.chi2_contingency(contingency_table) #AB-—Ç–µ—Å—Ç. –ü—Ä–æ–≤–µ—Ä–∫–∞ —Ä–∞–∑–Ω—ã—Ö –≤–∞—Ä–∏–∞–Ω—Ç–∞—Ö –Ω–∞ —Å—Ö–æ–∂–∏—Ö –≤—ã–±–æ—Ä–∫–∞—Ö\n",
    "print('p-value: {0}'.format(res[1]))\n",
    "\n",
    "#p-value –ø–æ–ª—É—á–∏–ª—Å—è –¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –±–æ–ª—å—à–∏–º, –ø–æ—ç—Ç–æ–º—É –æ—Å–Ω–æ–≤–∞–Ω–∏–π –æ—Ç–≤–µ—Ä–≥–Ω—É—Ç—å –≥–∏–ø–æ—Ç–µ–∑—É –æ —Ä–∞–≤–µ–Ω—Å—Ç–≤–µ –¥–æ–ª–µ–π –Ω–µ—Ç"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Z-–º–µ—Ç–∫–∞ (–æ—Ä–≥–∞–Ω–∏–∑–∞—Ü–∏—è –≤—ã–±–æ—Ä–æ–∫ —Ç–∞–∫, —á—Ç–æ–±—ã –æ–Ω–∏ –º–∞–ª–æ –æ—Ç–ª–∏—á–∞–ª–∏—Å—å –æ—Ç –Ω–æ—Ä–º–∞–ª—å–Ω–æ–≥–æ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è)\n",
    "\n",
    "s1 = 135       # —É—Å–ø–µ—Ö –≤ –≤—ã–±–æ—Ä–∫–µ –ê\n",
    "n1 = 1781      # –≤—ã–±–æ—Ä–∫–∞ –ê\n",
    "s2 = 47        # —É—Å–ø–µ—Ö –≤ –≤—ã–±–æ—Ä–∫–µ –ë\n",
    "n2 = 1443      # –≤—ã–±–æ—Ä–∫–∞ –ë\n",
    "p1 = s1/n1               #  –æ—Ü–µ–Ω–∫–∞ –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–∏ —É—Å–ø–µ—Ö–∞ –≤—ã–±–æ—Ä–∫–∞ –ê\n",
    "p2 = s2/n2               #  –æ—Ü–µ–Ω–∫–∞ –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–∏ —É—Å–ø–µ—Ö–∞ –≤—ã–±–æ—Ä–∫–∞ –ë\n",
    "p = (s1 + s2)/(n1+n2)    #  –æ—Ü–µ–Ω–∫–∞ –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–∏ —É—Å–ø–µ—Ö–∞ –≤—ã–±–æ—Ä–∫–∏ –ê+–ë\n",
    "z = (p2-p1)/ ((p*(1-p)*((1/n1)+(1/n2)))**0.5) #Z-–º–µ—Ç–∫–∞ \n",
    "\n",
    "p_value = norm.cdf(z) #–§—É–Ω–∫—Ü–∏—è —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è –Ω–æ—Ä–º–∞–ª—å–Ω–æ–≥–æ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è\n",
    "\n",
    "#  z-–º–µ—Ç–∫–∞ –∏ p-–∑–Ω–∞—á–µ–Ω–∏–µ\n",
    "print(['{:.12f}'.format(a) for a in (abs(z), p_value * 2)])\n",
    "#–ù—É–ª–µ–≤–∞—è –≥–∏–ø–æ—Ç–µ–∑–∞ –æ—Ç–≤–µ—Ä–≥–Ω—É—Ç–∞, —Å—Ç–∞—Ç–∏—Å—Ç–∏—á–µ—Å–∫–∏–µ –¥–æ–ª–∏ –æ—Ç–ª–∏—á–∞—é—Ç—Å—è\n",
    "\n",
    "#–¢–æ –∂–µ —Å–∞–º–æ–µ, –Ω–æ —Å–æ –≤—Å—Ç—Ä–æ–µ–Ω–Ω—ã–º –º–µ—Ç–æ–¥–æ–º –±–∏–±–ª–∏–æ—Ç–µ–∫–∏ statsmodels\n",
    "z1, p_value1 = sm.stats.proportions_ztest([s1, s2], [n1, n2])\n",
    "print(['{:.12f}'.format(b) for b in (z1, p_value1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#–¢–µ—Å—Ç –°—Ç—å—é–¥–µ–Ω—Ç–∞ –Ω–∞ –Ω–µ–∑–∞–≤–∏—Å–∏–º–æ—Å—Ç—å –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö\n",
    "x = noble[noble['group'] == 'sovr']['age']\n",
    "y = noble[noble['group'] == 'aris']['age']\n",
    "x.name, y.name = 'sovr', 'aris'\n",
    "two_histograms(x, y) #–î–∞–Ω–Ω—ã–µ —É—Å–ª–æ–≤–Ω–æ –Ω–æ—Ä–º–∞–ª—å–Ω—ã. \n",
    "\n",
    "#–ü—Ä–æ–≤–µ—Ä–∏–º c –ø–æ–º–æ—â—å—é –∫—Ä–∏—Ç–µ—Ä–∏—è –§–ª–∏–≥–Ω–µ—Ä–∞-–ö–∏–ª–∏–Ω–∞, —Ä–∞–≤–Ω—ã –ª–∏ –¥–∏—Å–ø–µ—Ä—Å–∏–∏.\n",
    "res = stats.fligner(x, y)\n",
    "print('p-value: ', res[1]) #p-value –Ω–∏–∑–∫–æ–µ, –≥–∏–ø–æ—Ç–µ–∑—É –æ —Ä–∞–≤–µ–Ω—Å—Ç–≤–µ –¥–∏—Å–ø–µ—Ä—Å–∏–π –æ—Ç–≤–µ—Ä–≥–∞–µ–º, –Ω–∞–±–ª—é–¥–∞–µ–º—ã–µ –æ–±—ä–µ–∫—Ç—ã –Ω–µ—Å–≤—è–∑–Ω—ã–µ \n",
    "\n",
    "#–ì–∏–ø–æ—Ç–µ–∑—É –æ —Ä–∞–≤–µ–Ω—Å—Ç–≤–µ —Å—Ä–µ–¥–Ω–∏—Ö –∑–Ω–∞—á–µ–Ω–∏–π –±—É–¥–µ–º –ø—Ä–æ–≤–µ—Ä—è—Ç—å —Å –ø–æ–º–æ—â—å—é —Ç–µ—Å—Ç–∞ –°—Ç—å—é–¥–µ–Ω—Ç–∞ –ø—Ä–∏ –Ω–µ—Ä–∞–≤–Ω—ã—Ö –¥–∏—Å–ø–µ—Ä—Å–∏—è—Ö\n",
    "res = stats.ttest_ind(x, y, equal_var=False) #–û–ø—Ü–∏—è equal_var=False –≥–æ–≤–æ—Ä–∏—Ç, —á—Ç–æ —Ä–∞–≤–µ–Ω—Å—Ç–≤–æ –¥–∏—Å–ø–µ—Ä—Å–∏–∏ –Ω–µ –ø—Ä–µ–¥–ø–æ–ª–∞–≥–∞—Ç—å\n",
    "print('p-value: ', res[1]) #P-–∑–Ω–∞—á–µ–Ω–∏–µ –∑–Ω–∞—á–∏—Ç–µ–ª—å–Ω–æ –º–µ–Ω—å—à–µ –∞–ª—å—Ñ—ã, –≥–∏–ø–æ—Ç–µ–∑–∞ –æ —Ä–∞–≤–µ–Ω—Å—Ç–≤–µ –æ—Ç–≤–µ—Ä–≥–∞–µ—Ç—Å—è\n",
    "\n",
    "#–ò—â–µ–º –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç—å —Ü–µ–Ω—ã –æ—Ç –ø–µ—Ä–µ–º–µ–Ω–Ω–æ–π COR=1 –∏ 0. –ß—Ç–æ–±—ã –ø—Ä–∏–º–µ–Ω–∏—Ç—å –°—Ç—å—é–¥–µ–Ω—Ç–∞, –ø—Ä–æ–≤–µ—Ä–∏–º –Ω–æ—Ä–º–∞–ª—å–Ω–æ—Å—Ç—å –¥–∞–Ω–Ω—ã—Ö –∏ —Ä–∞–≤–µ–Ω—Å—Ç–≤–æ –¥–∏—Å–ø–µ—Ä—Å–∏–π\n",
    "#–ó–∞–º–µ–Ω—è–µ–º -9999 (–∑–¥–µ—Å—å=–ø—É—Å—Ç–æ–µ) –Ω–∞ –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ–µ –ø—É—Å—Ç–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ.\n",
    "albi = albi.replace(-9999, np.nan)\n",
    "#–°–æ—Ö—Ä–∞–Ω–∏–º –≤ –æ—Ç–¥–µ–ª—å–Ω—ã–µ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –≤—ã–±–æ—Ä–∫–∏, –∫–æ—Ç–æ—Ä—ã–µ —Å–æ–±–∏—Ä–∞–µ–º—Å—è —Å—Ä–∞–≤–Ω–∏–≤–∞—Ç—å.\n",
    "x = albi[albi['COR'] == 1]['PRICE']\n",
    "y = albi[albi['COR'] == 0]['PRICE']\n",
    "x.name, y.name = 'corner', 'not corner'    \n",
    "\n",
    "two_histograms(x, y)  #–í–∏–¥–Ω–æ, —á—Ç–æ –≤—ã–±—Ä–æ—Å—ã –Ω–µ –¥–∞—é—Ç –ø—Ä–∏–º–µ–Ω–∏—Ç—å –°—Ç—é–¥–µ–Ω—Ç–∞ –∏ –Ω—É–∂–Ω–æ –ø—Ä–æ–±–æ–≤–∞—Ç—å –ú–∞–Ω–Ω–∞-–í–∏—Ç–Ω–∏"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#–†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –°—Ç—å—é–¥–µ–Ω—Ç–∞ (t-distribution) –¥–ª—è n<30 - –±–æ–ª–µ–µ –≤—ã—Å–æ–∫–∏–µ —Ö–≤–æ—Å—Ç—ã —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–π.–ß–∏—Å–ª–æ —Å—Ç–µ–ø–µ–Ω–µ–π —Å–≤–æ–±–æ–¥—ã df=n-1\n",
    "#t –∑–∞–º–µ–Ω—è–µ—Ç Z –≤ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–∏ –°—Ç—å—é–¥–µ–Ω—Ç–∞. t=(X–∏–Ω–¥-M)/(sd/n**0.5)\n",
    "#–ü–æ–º–∏–º–æ —Å—Ä–µ–¥–Ω–∏—Ö —Ç–∞–∫–∂–µ –Ω—É–∂–Ω–æ —Å—Ä–∞–≤–Ω–∏—Ç—å –¥–∏—Å–ø–µ—Ä—Å–∏–∏ D (—Ç–µ—Å—Ç –§–ª–∏–≥–Ω–µ—Ä–∞-–ö–∏–ª–∏–Ω–∞) –∏ –º–µ–¥–∏–∞–Ω—ã (–º–Ω–æ–≥–æ n - —Ç–µ—Å—Ç –ú—É–¥–∞, –º–∞–ª–æ n - –ú–∞–Ω–Ω-–í–∏—Ç–Ω–∏) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#–ü–∞—Ä–Ω—ã–π t-–∫—Ä–∏—Ç–µ—Ä–∏–π –°—Ç—å—é–¥–µ–Ω—Ç–∞.  X1—Å—Ä–µ–¥ - –•2—Å—Ä–µ–¥ = –ê , se=((sd1**2/n1)+(sd2**2/n2))**0.5 , df=n1+n2-2\n",
    "#–ü—Ä–∏ t = A/se –∏ df –º–æ–∂–Ω–æ —Ä–∞—Å—Å—á–∏—Ç–∞—Ç—å p –ø—Ä–∏ –∫–æ—Ç–æ—Ä–æ–º M1-M2=0. –¢–æ –µ—Å—Ç—å —Ä–∞–∑–Ω–∏—Ü—ã –º–µ–∂–¥—É –≤—ã–±–æ—Ä–∫–∞–º–∏ –ø–æ—á—Ç–∏ –Ω–µ—Ç\n",
    "#Q-Q Plot –ø–æ–∫–∞–∑—ã–≤–∞–µ—Ç –Ω–∞—Å–∫–æ–ª—å–∫–æ –≤—ã–±–æ—Ä–æ—á–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—Ç –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–Ω—ã–º(–∏–∑ –Ω–æ—Ä–º–∞–ª—å–Ω–æ–≥–æ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω—è)\n",
    "x = inter['DiffCol']\n",
    "y = inter['Black']\n",
    "x.name, y.name = 'DiffCol', 'Black'\n",
    "two_histograms(x, y)\n",
    "\n",
    "#–†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è —É—Å–ª–æ–≤–Ω–æ –Ω–æ—Ä–º–∞–ª—å–Ω—ã. –ü–æ—Å–∫–æ–ª—å–∫—É –≤ –Ω–∞–±–ª—é–¥–µ–Ω–∏—è—Ö —Å–æ–¥–µ—Ä–∂–∞—Ç—Å—è –æ–¥–Ω–∏ –∏ —Ç–µ –∂–µ –ª—é–¥–∏, –≤—ã–±–æ—Ä–∫–∏ —Å–≤—è–∑–Ω—ã–µ (–ø–∞—Ä–Ω—ã–µ)\n",
    "res = stats.ttest_rel(x, y) #–ú–µ—Ç–æ–¥ –¥–ª—è –ø–∞—Ä–Ω—ã—Ö –≤—ã–±–æ—Ä–æ–∫\n",
    "print('p-value: ', res[1])\n",
    "p-value: 0.0162416779538\n",
    "#p-value –Ω–∏–∑–∫–∏–π, –≥–∏–ø–æ—Ç–µ–∑–∞ –Ω–∞ —É—Ä–æ–≤–Ω–µ –∑–Ω–∞—á–∏–º–æ—Å—Ç–∏ 0.05 –±—É–¥–µ—Ç –æ—Ç–≤–µ—Ä–≥–Ω—É—Ç–∞, –Ω–æ –Ω–∞ —É—Ä–æ–≤–Ω–µ 0.01 —É–∂–µ –Ω–µ—Ç. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#U-–∫—Ä–∏—Ç–µ—Ä–∏–π –ú–∞–Ω–Ω–∞-–í–∏—Ç–Ω–∏ –ø–µ—Ä–µ–≤–æ–¥–∏—Ç –∑–Ω–∞—á–µ–Ω–∏—è –≤ —Ä–∞–Ω–≥–æ–≤—É—é (–Ω–µ–ø–∞—Ä–∞–º–µ—Ç—Ä–∏—á–µ—Å–∫—É—é) —à–∫–∞–ª—É –∏ –ø—Ä–æ–≤–µ—Ä—è–µ—Ç –ù–ï —Ä–∞–≤–µ–Ω—Å—Ç–≤–æ –º–µ–¥–∏–∞–Ω. P{X>Y}=P{X<Y}\n",
    "\n",
    "res = stats.mannwhitneyu(x, y)\n",
    "print('p-value:', res[1])\n",
    "#p-value –ø–æ–ª—É—á–∏–ª–æ—Å—å –¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –±–æ–ª—å—à–∏–º, –ø–æ—ç—Ç–æ–º—É —É –Ω–∞—Å –Ω–µ—Ç –æ—Å–Ω–æ–≤–∞–Ω–∏–π –æ—Ç–≤–µ—Ä–≥–Ω—É—Ç—å –≥–∏–ø–æ—Ç–µ–∑—É. –†–∞–∑–Ω–∏—Ü–∞ –º–µ–¥–∏–∞–Ω –≤ –≤—ã–±–æ—Ä–∫–∞—Ö —Å–ª—É—á–∞–π–Ω–∞."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#–ö–æ—Ä—Ä–µ–ª—è—Ü–∏—è. Scatter-plot –∏–ª–∏ –¥–∏–∞–≥—Ä–∞—Ç—Ç–∞ —Ä–∞—Å—Å–µ–∏–≤–∞–Ω–∏—è\n",
    "#–°–∏–ª–∞ –∏ –Ω–∞–ø—Ä–∞–≤–ª–µ–Ω–∏–µ –≤–∑–∞–∏–º–æ—Å–≤—è–∑–∏ –æ–ø—Ä–µ–¥–µ–ª—è–µ—Ç—Å—è –∫–æ–≤–∞—Ä–∏–∞—Ü–∏–µ–π. cov=–°—É–º–º–∞((Xi-X—Å—Ä–µ–¥)*(Yi-Y—Å—Ä–µ–¥))/N-1\n",
    "#–ö–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç –∫–æ—Ä—Ä–µ–ª—è—Ü–∏–∏ –ü–∏—Ä—Å–æ–Ω–∞ –Ω–∞—Ö–æ–¥–∏—Ç—Å—è –≤ –ø—Ä–æ–º–µ–∂—É—Ç–∫–µ [-1; 1] –∏ —Å—á–∏—Ç–∞–µ—Ç—Å—è –∫–∞–∫ Rxy=cov/SDx*SDy\n",
    "#–ö–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç –¥–µ—Ç–µ—Ä–º–∏–Ω–∞—Ü–∏–∏ r**2 –ø–æ–∫–∞–∑—ã–≤–∞–µ—Ç –≤–ª–∏—è–Ω–∏–µ –¥–∏—Å–ø–µ—Ä—Å–∏–∏ –æ–¥–Ω–æ–π –ø–µ—Ä–µ–º–µ–Ω–Ω–æ–π –Ω–∞ –¥—Ä—É–≥—É—é –≤ –ø—Ä–æ–º–µ–∂—É—Ç–∫–µ [0; 1]\n",
    "#–ö–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç –°–ø–∏—Ä–º–µ–Ω–∞ –ø–æ–∑–≤–æ–ª—è–µ—Ç –±–ª–æ–∫–∏—Ä–æ–≤–∞—Ç—å –≤—ã–±—Ä–æ—Å—ã —á–µ—Ä–µ–∑ —Ä–∞–Ω–≥–∏. d=X-Y. Rs=1-6*—Å—É–º–º–∞ d**2/N(N**2-1)\n",
    "#–ß–∞—Å—Ç–æ –∫–æ—Ä—Ä–µ–ª—è—Ü–∏—è –æ–±—É—Å–ª–æ–≤–ª–µ–Ω–∞ —Å–∫—Ä—ã—Ç–æ–π –ø–µ—Ä–µ–º–µ–Ω–Ω–æ–π\n",
    "\n",
    "#–ö–æ—Ä—Ä–µ–ª—è—Ü–∏—è —Ü–µ–Ω—ã –∏ —Ä–∞–∑–º–µ—Ä–∞\n",
    "plt.scatter(albi['PRICE'], albi['SQFT'])\n",
    "\n",
    "res = stats.pearsonr(albi['PRICE'], albi['SQFT']) #–î–æ–ø—É—Å–∫–∞–µ–º —á—Ç–æ –∫–æ—ç—Ñ—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç –∫–æ—Ä—Ä–µ–ª—è—Ü–∏–∏=0, –Ω–æ –≥–∏–ø–æ—Ç–µ–∑–∞ –æ—Ç–≤–µ—Ä–≥–Ω—É—Ç–∞\n",
    "\n",
    "print('Pearson rho: ', res[0])\n",
    "print('p-value: ', res[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#–°—Ç–∞–Ω–¥–∞—Ä—Ç–∏–∑–∞—Ü–∏—è –ø–æ–∑–≤–æ–ª—è–µ—Ç —Å–¥–µ–ª–∞—Ç—å –≤–µ—Å –≤–∞–∂–Ω—ã—Ö –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö —Å–æ–∏–∑–º–µ—Ä–∏–º—ã–º. Min=0(-1), max=1. –ò–õ–ò Z\n",
    "#Z-–°—Ç–∞–Ω–¥–∞—Ä—Ç–∏–∑–∞—Ü–∏—è: –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ –≤ —Ç–∏–ø, –≥–¥–µ –ú=0, sd = 1. –ü—Ä–∞–≤–∏–ª–æ –æ–¥–Ω–æ–π, –¥–≤—É—Ö –∏ —Ç—Ä–µ—Ö \"—Å–∏–≥–º\"\n",
    "#Z=(X–∏–Ω–¥-–ú)/sd –ü—Ä–∏–º–µ—Ä: –ø–æ —Ç–∞–±–ª–∏—Ü–µ Z, –≥–¥–µ –•—Å—Ä–µ–¥=150, sd=8, –ø—Ä–µ–≤—ã—à–∞—Ç—å X–∏–Ω–¥ –±—É–¥–µ—Ç 0.5z –∏–ª–∏ 30%\n",
    "#Z=(X—Å—Ä–µ–¥-M)/se =(18,5-20)/0.5 = -3. –í–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å –ø–æ–ª—É—á–∏—Ç—å —Ç–∞–∫–æ–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç p = 0.0027\n",
    "\n",
    "#–ï—Å–ª–∏ –≤ –ë–î –Ω–µ—Ç –µ–¥–∏–Ω–æ–π –º–µ—Ç—Ä–∏–∫–∏, —Ç–æ —Å—Ç–∞–Ω–¥–∞—Ä—Ç–∏–∑–∏—Ä—É–µ–º –¥–∞–Ω–Ω—ã–µ\n",
    "norm = preprocessing.StandardScaler()\n",
    "norm.fit(df)\n",
    "X = norm.transform(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#–î–∏—Å–ø–µ—Ä—Å–∏–æ–Ω–Ω—ã–π –ê–Ω–∞–ª–∏–∑. –ï—Å–ª–∏ –º–µ–∂–≥—Ä—É–ø–ø–æ–≤–æ–π –ø–æ–∫–∞–∑–∞—Ç–µ–ª—å –∏–∑–º–µ–Ω—á–∏–≤–æ—Å—Ç–∏ —Å–∏–ª—å–Ω–æ –ø—Ä–µ–≤—ã—à–∞–µ—Ç –≤–Ω—É—Ç—Ä–∏–≥—Ä—É–ø–ø–æ–≤–æ–π, —Ç–æ —Å—Ä–µ–¥–Ω–∏–µ —Ä–∞–∑–Ω—è—Ç—Å—è\n",
    "#SST - –æ–±—â–∞—è —Å—É–º–º–∞ –∫–≤–∞–¥—Ä–∞—Ç–æ–≤ –ø–æ–∫–∞–∑—ã–≤–∞–µ—Ç –æ–±—â—É—é –∏–∑–º–µ–Ω—á–∏–≤–æ—Å—Ç—å –¥–∞–Ω–Ω—ã—Ö. –°—É–º–º–∞(X–∏–Ω–¥-X—Å—Ä–µ–¥)**2  SST = SSW+SSB\n",
    "#SSW - —Å—É–º–º–∞ –∫–≤–∞–¥—Ä–∞—Ç–æ–≤ –≤–Ω—É—Ç—Ä–∏–≥—Ä—É–ø–ø–æ–≤–∞—è. –°—É–º–º–∞(X1–∏–Ω–¥-–•1—Å—Ä–µ–¥)**2 + ...(XN–∏–Ω–¥-–•N—Å—Ä–µ–¥)**2\n",
    "#SSB - —Å—É–º–º–∞ –∫–≤–∞–¥—Ä–∞—Ç–æ–≤ –º–µ–∂–≥—Ä—É–ø–ø–æ–≤–∞—è. SSB= n(X1—Å—Ä–µ–¥ - –•—Å—Ä–µ–¥)**2 + ...n(XN—Å—Ä–µ–¥-–•—Å—Ä–µ–¥)**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#–†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –§–∏—à–µ—Ä–∞, F-–∑–Ω–∞—á–µ–Ω–∏–µ. F=(ssb/n-1)/(ssw/N-n). –ü—Ä–∏ –≤–µ—Ä–Ω–æ—Å—Ç–∏ –Ω—É–ª–µ–≤–æ–π –≥–∏–ø–æ—Ç–µ–∑—ã –∑–Ω–∞—á–µ–Ω–∏—è F –æ—á–µ–Ω—å –º–∞–ª–µ–Ω—å–∫–∏–µ\n",
    "#–ü–æ–ø—Ä–∞–≤–∫–∞ –ë–æ–Ω—Ñ–µ—Ä—Ä–æ–Ω–∏ –Ω–∞ –º–Ω–æ–∂–µ—Å—Ç–≤–µ–Ω–Ω—É—é –ø—Ä–æ–≤–µ—Ä–∫—É –≥–∏–ø–æ—Ç–µ–∑. a = ai/n  –ù–û: –º–µ—à–∞–µ—Ç –ø–æ–ª—É—á–∏—Ç—å –∑–Ω–∞—á–∏–º—ã–µ —É—Ä–æ–≤–Ω–∏ —Ä–∞–∑–ª–∏—á–∏—è\n",
    "#FDR –∏–ª–∏ –∫—Ä–∏—Ç–µ—Ä–∏–π –¢—å—é–∫–∏ —Å—á–∏—Ç–∞–µ—Ç p-—É—Ä–æ–≤–µ–Ω—å –¥–ª—è —Å—Ä–∞–≤–Ω–∏–≤–∞–µ–º—ã—Ö –ø–∞—Ä X—Ç—ç=Xa-X–±\n",
    "#–î–≤—É—Ö–∞–∫—Ç–æ—Ä–Ω—ã–π –¥–∏—Å–ø–µ—Ä—Å–∏–æ–Ω–Ω—ã–π –∞–Ω–∞–ª–∏–∑ SStotal=SSW+SSBa +SSBb + SSBa*SSBb\n",
    "#–í–∑–∞–∏–º–æ–¥–µ–π—Å—Ç–≤–∏–µ —Ñ–∞–∫—Ç–æ—Ä–æ–≤ –≤ ANOVA\n",
    "#–î–∏—Å–ø–µ—Ä—Å–∏–æ–Ω–Ω—ã–π –∞–Ω–∞–ª–∏–∑ —Ç—Ä–µ–±—É–µ—Ç –Ω–æ—Ä–º–∞–ª—å–Ω–æ—Å—Ç–∏ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è –∑–∞–≤–∏—Å–∏–º–æ–π –ø–µ—Ä–µ–º–µ–Ω–Ω–æ–π –∏ –≥–æ–º–æ–≥–µ–Ω–Ω–æ—Å—Ç–∏ –¥–∏—Å–ø–µ—Ä—Å–∏–∏(—Ç–µ—Å—Ç –õ–µ–≤–µ–Ω–∞)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#–†–µ–≥—Ä–µ—Å—Å–∏–æ–Ω–Ω–Ω—ã–π –ê–Ω–∞–ª–∏–∑ –ø–æ–∑–≤–æ–ª—è–µ—Ç –∏—Å—Å–ª–µ–¥–æ–≤–∞—Ç—å –≤–∑–∞–∏–º–æ—Å–≤—è–∑–∏ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö –∏ –¥–µ–ª–∞—Ç—å –ª–∏–Ω–∏—é —Ç—Ä–µ–Ω–¥–∞\n",
    "#–ü—Ä–æ—Å—Ç–∞—è –õ–∏–Ω–µ–π–Ω–∞—è –†–µ–≥—Ä–µ—Å—Å–∏—è. –í–∑–∞–∏–º–æ—Å–≤—è–∑—å 2-—Ö –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö. Y-–∑–∞–≤–∏—Å–∏–º–∞—è(–æ—Ç–∫–ª–∏–∫) –•-–Ω–µ–∑–∞–≤–∏—Å–∏–º–∞—è(–ø—Ä–µ–¥–∏–∫—Ç–æ—Ä) \n",
    "#Y=B0(intercept)+B1(slope). –ó–∞—á–µ–Ω–∏–µ Y, –≥–¥–µ –ª–∏–Ω–∏—è –ø–µ—Ä–µ—Å–µ–∫–∞–µ—Ç –æ—Å—å, —É–≥–æ–ª –Ω–∞–∫–ª–æ–Ω–∞ –ª–∏–Ω–∏–∏ –∫ –æ—Å–∏ X\n",
    "#–ú–µ—Ç–æ–¥ –Ω–∞–∏–º–µ–Ω—å—à–∏—Ö –∫–≤–∞–¥—Ä–∞—Ç–æ–≤(–ú–ù–ö) –Ω–∞—Ö–æ–¥–∏—Ç –æ–ø—Ç–∏–º–∞–ª—å–Ω—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã B0 –∏ B1, —á—Ç–æ–±—ã —Å—É–º–º–∞ –∫–≤–∞–¥—Ä–∞—Ç–æ–≤ –æ—Å—Ç–∞—Ç–∫–æ–≤ (SE) –±—ã–ª–∞ –º–∏–Ω–∏–º–∞–ª—å–Ω–∞ MSE\n",
    "#–£—Ä–∞–≤–Ω–µ–Ω–∏–µ —Ä–µ–≥—Ä–µ—Å—Å–∏–∏ Y=B0+B1*X1\n",
    "#B1 = SDy/SDx*Rxy, B0 = (Y—Å—Ä–µ–¥-B1*X—Å—Ä–µ–¥), t = B1/se, df=N-2 –ï—Å–ª–∏ B1 –±–ª–∏–∑–∫–∞ –∫ –Ω—É–ª—é, —Ç–æ –≤–∑–∞–∏–º–æ—Å–≤—è–∑–∏ –ø–æ—á—Ç–∏ –Ω–µ—Ç\n",
    "#–ö–æ—ç—Ñ—Ñ—Ç—Ü—Ç–µ–Ω—Ç –î–µ—Ç–µ—Ä–º–∏–Ω–∞—Ü–∏–∏ (–≤—ã–±–æ—Ä–æ—á–Ω–∞—è –¥–∏—Å–ø–µ—Ä—Å–∏—è) R —É–∫–∞–∑—ã–≤–∞–µ—Ç –∫–∞–∫–æ–π –ø—Ä–æ—Ü–µ–Ω—Ç –≤–∞—Ä–∏–∞—Ü–∏–∏ –æ—Ç–∫–ª–∏–∫–∞ –æ–ø—Ä–µ–¥–µ–ª—è–µ—Ç—Å—è –≤–ª–∏—è–Ω–∏–µ–º –ø—Ä–µ–¥–∏–∫—Ç–æ—Ä–∞\n",
    "#R**2 = 1-(SSres/SStotal) –¥–æ–ª—è –¥–∏—Å–ø–µ—Ä—Å–∏–∏ Y, –æ–±—ä—è—Å–Ω—è–µ–º–∞—è —Ä–µ–≥—Ä–µ—Å—Å–∏–æ–Ω–Ω–æ–π –º–æ–¥–µ–ª—å—é. –ß–µ–º –±–æ–ª—å—à–µ R , —Ç–µ–º –ª—É—á—à–µ\n",
    "#–¢—Ä–µ–±–æ–≤–∞–Ω–∏—è: –ª–∏–Ω–µ–π–Ω–∞—è –≤—Ö–∞–∏–º–æ—Å–≤—è–∑—å X Y, –Ω–æ—Ä–º–∞–ª—å–Ω–æ–µ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –æ—Å—Ç–∞—Ç–∫–æ–≤, –≥–æ–º–æ—Å–∫–µ–¥–∞—Ç–∏—á–Ω–æ—Å—Ç—å(–∏–∑–º–µ–Ω—á–∏–≤–æ—Å—Ç—å) –æ—Å—Ç–∞—Ç–∫–æ–≤\n",
    "#–ò–∑–±–µ–∂–∞—Ç—å –æ—à–∏–±–æ–∫ —Å–ø–µ—Ü–∏—Ñ–∏–∫–∞—Ü–∏–∏ –ø—Ä–∏ –ª–∏–Ω–µ–π–Ω–æ–π —Ä–µ–≥—Ä–µ—Å—Å–∏–∏ –ø–æ–º–æ–≥–∞–µ—Ç –ê–Ω–∞–ª–∏–∑ –û—Å—Ç–∞—Ç–∫–æ–≤. –í—ã—è–≤–ª—è—Ç—å –∫–æ–ª–∏–Ω–µ–∞—Ä–Ω–æ—Å—Ç—å"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "albi = albi.replace(-9999, np.nan)\n",
    "print('Rows in the data frame: {0}'.format(len(albi)))\n",
    "print('Rows without NAN: {0}'.format(len(albi.dropna(how='any'))))\n",
    "\n",
    "#–°–ª–∏—à–∫–æ–º –º–Ω–æ–≥–æ –¥–∞–Ω–Ω—ã—Ö —Å–æ–¥–µ—Ä–∂–∞—Ç —Ö–æ—Ç—è –±—ã –æ–¥–Ω–æ –ø—Ä–æ–ø—É—â–µ–Ω–Ω–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ, —á—Ç–æ–±—ã —É–¥–∞–ª–∏—Ç—å –∏—Ö –≤—Å–µ. –°–º–æ—Ç—Ä–∏–º –∏—Ö —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –ø–æ –∫–æ–ª–æ–Ω–∫–∞–º\n",
    "#–§—É–Ω–∫—Ü–∏—è .apply –¥–ª—è –≤—Å–µ–π –º–∞—Ç—Ä–∏—Ü—ã. 1–π –∞—Ä–≥—É–º–µ–Ω—Ç-–ø—Ä–∏–º–µ–Ω—è–µ–º–∞—è —Ñ—É–Ω–∫—Ü–∏—è, 2–π - –Ω–∞–ø—Ä–∞–≤–ª–µ–Ω–∏–µ –ø—Ä–∏–º–µ–Ω–µ–Ω–∏—è (0 –∫ –∫–æ–ª–æ–Ω–∫–∞–º, 1 –∫–æ —Å—Ç—Ä–æ–∫–∞–º)\n",
    "albi.apply(lambda x: sum(x.isnull()), axis=0)\n",
    "\n",
    "#–ï—Å–ª–∏ –Ω–µ–ø–æ–ø—Ä–∞–≤–∏–º–æ –º–∞–ª–æ –¥–∞–Ω–Ω—ã—Ö, —É–¥–∞–ª—è–µ–º –∫–æ–ª–æ–Ω–∫—É\n",
    "del albi['AGE']\n",
    "del albi['TAX']\n",
    "\n",
    "#–ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º –∫–æ–ª–æ–Ω–∫—É –≥–¥–µ –º–æ–∂–Ω–æ –∑–∞–º–µ–Ω–∏—Ç—å –ø—Ä–æ–ø—É—Å–∫–∏\n",
    "#albi['TAX'].hist()\n",
    "\n",
    "#–ú–µ–Ω—è–µ–º –ø—Ä–æ–ø—É—â–µ–Ω–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è –Ω–∞ —Å—Ä–µ–¥–Ω–µ–µ –∑–Ω–∞—á–µ–Ω–∏–µ –ø–æ –∫–æ–ª–æ–Ω–∫–µ \n",
    "#albi['TAX'] = albi['TAX'].fillna(albi['TAX'].mean())\n",
    "\n",
    "#–°—Ç—Ä–æ–∏–º –º–æ–¥–µ–ª—å –ª–∏–Ω–µ–π–Ω–æ–π —Ä–µ–≥—Ä–µ—Å—Å–∏–∏\n",
    "X = albi.drop('PRICE', axis=1)\n",
    "y = albi['PRICE']\n",
    "model = LinearRegression()\n",
    "model.fit(X, y)\n",
    "\n",
    "#–°—á–∏—Ç–∞–µ–º –∫–∞—á–µ—Å—Ç–≤–æ –º–æ–¥–µ–ª–∏ (–∫–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç  ùëÖ**2 )\n",
    "print('R^2: {0}'.format(model.score(X, y)))\n",
    "\n",
    "#–ü—Ä–æ–º–µ–∂—É—Ç–æ—á–Ω—ã–µ –†–µ–≥—Ä–µ—Å—Å–∏–æ–Ω–Ω—ã–µ –ö–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç—ã –æ—Ç –º–µ—Ç–æ–¥–∞ model.coef_ –∏ —Å–≤–æ–±–æ–¥–Ω—ã–π —á–ª–µ–Ω –æ—Ç –º–µ—Ç–æ–¥–∞ model.intercept_\n",
    "coef = pd.DataFrame(zip(['intercept'] + X.columns.tolist(), [model.intercept_] + model.coef_.tolist()),\n",
    "                    columns=['predictor', 'coef'])\n",
    "\n",
    "#–ú–∞—Ç—Ä–∏—Ü–∞ –ø–æ–∫–∞–∑—ã–≤–∞–µ—Ç –±–∞–∑–æ–≤—É—é —Ü–µ–Ω—É –∏ –≤–µ—Å –∫–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç–æ–≤: 83.17 + 0.29*–ø–ª–æ—â–∞–¥—å SQFT + 12.17*—É–¥–æ–±—Å—Ç–≤–∞ –∏ —Ç.–¥.\n",
    "#–õ–æ–≥–∏–∫–∞ –ø–æ–∫–∞–∑—ã–≤–∞–µ—Ç, —á—Ç–æ —á—Ç–æ-—Ç–æ –Ω–µ —Ç–æ. –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞ –∫–æ–ª–∏–Ω–µ–∞—Ä–Ω–æ—Å—Ç—å\n",
    "albi.corr()\n",
    "\n",
    "#–í–∏–¥–∏–º, —á—Ç–æ –∫–æ–ª–∏–Ω–µ–∞—Ä–µ–Ω TAX. –£–±–∏—Ä–∞–µ–º –∏ —Å–Ω–æ–≤–∞ —Å—á–∏—Ç–∞–µ–º, –≤ —ç—Ç–æ—Ç —Ä–∞–∑ —Å p-–∑–Ω–∞—á–µ–Ω–∏–µ–º\n",
    "regression_coef(model, X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#–ü–æ–ª–∏–Ω–æ–º–∏–∞–ª—å–Ω–∞—è —Ä–µ–≥—Ä–µ—Å—Å–∏—è\n",
    "#–ü—Ä–µ–¥—Å–∫–∞–∑–∞—Ç—å —Ä–µ–∑—É–ª—å—Ç–∞—Ç –Ω–µ —Ç–æ–ª—å–∫–æ —Å –ø–æ–º–æ—â—å—é –ø–µ—Ä–µ–º–µ–Ω–Ω–æ–π (1—è –º–æ–¥–µ–ª—å), –Ω–æ –∏ –µ—ë –∫–≤–∞–¥—Ä–∞—Ç–∞(2—è –º–æ–¥–µ–ª—å) –∏ –∏—Ö –æ–±–µ–∏—Ö (3—è –º–æ–¥–µ–ª—å) \n",
    "#–ö–ª–∞—Å—Å PolynomialFeatures, –º–µ—Ç–æ–¥ fit_transform —Å–≥–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç –∏–∑ –º–Ω–æ–∂–µ—Å—Ç–≤–∞ —Ñ–∏—á –º–Ω–æ–∂–µ—Å—Ç–≤–æ –æ–¥–Ω–æ—á–ª–µ–Ω–æ–≤ –∑–∞–¥–∞–Ω–Ω–æ–π —Å—Ç–µ–ø–µ–Ω–∏ \n",
    "#–ù–∞–ø—Ä–∏–º–µ—Ä, –¥–ª—è —Å—Ç–µ–ø–µ–Ω–∏ 2 –∏ —Ñ–∏—á a, b –±—É–¥—É—Ç —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω—ã —Ñ–∏—á–∏ [a, b, a**2, b**2, ab] \n",
    "#–ø—Ä–∏ —É–∫–∞–∑–∞–Ω–Ω–æ–º –ø–∞—Ä–∞–º–µ—Ç—Ä–µ include_bias=True –µ—â—ë –∏ –≤–µ–∫—Ç–æ—Ä-—Å–≤–æ–±–æ–¥–Ω—ã–π —á–ª–µ–Ω –∏–∑ –µ–¥–∏–Ω–∏—Ü. \n",
    "\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "df = pd.read_csv('diamond.dat', header=None, sep='\\s+', names=['weight', 'price'])\n",
    "\n",
    "poly = PolynomialFeatures(\n",
    "                          # –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–∞—è —Å—Ç–µ–ø–µ–Ω—å\n",
    "                          degree=2,\n",
    "                          # –ù–µ –≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å —Å–≤–æ–±–æ–¥–Ω—ã–π —á–ª–µ–Ω\n",
    "                          include_bias=False)\n",
    "y = df['price']\n",
    "X0 = poly.fit_transform(df[['weight']])\n",
    "X0 = pd.DataFrame(X0, columns=['weight', 'weight**2'])\n",
    "\n",
    "X0 = [\n",
    "    # –û–¥–Ω–∞ –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω–∞—è –ø–µ—Ä–µ–º–µ–Ω–Ω–∞—è weight\n",
    "    X0[['weight']],\n",
    "    # –û–¥–Ω–∞ –ø–µ—Ä–µ–º–µ–Ω–Ω–∞—è weight**2\n",
    "    X0[['weight**2']],\n",
    "    # –î–≤–µ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö weight –∏ weight**2\n",
    "    X0.copy()]\n",
    "models = [LinearRegression() for _ in X0]\n",
    "\n",
    "for X, model in zip(X0, models):\n",
    "    model.fit(X, y)\n",
    "    print(model.score(X, y))\n",
    "    \n",
    "#ùëÖ**2  –≤–æ –≤—Å–µ—Ö –º–æ–¥–µ–ª—è—Ö –æ—á–µ–Ω—å –±–æ–ª—å—à–æ–π –∏ –ø—Ä–∏–º–µ—Ä–Ω–æ –æ–¥–∏–Ω–∞–∫–æ–≤. –ù–æ –Ω–∞ —Å–∞–º–æ–º –¥–µ–ª–µ –º–æ–¥–µ–ª–∏ —Ä–∞–∑–ª–∏—á–Ω—ã. –ü—Ä–æ–≤–µ—Ä–∏–º –∏—Ö –±–æ–ª–µ–µ —Ç—â–∞—Ç–µ–ª—å–Ω–æ\n",
    "\n",
    "regression_coef(models[0], X0[0], y)\n",
    "regression_coef(models[1], X0[1], y)\n",
    "regression_coef(models[2], X0[2], y)\n",
    "\n",
    "#–ö–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç—ã –ø–æ–∫–∞–∑—ã–≤–∞—é—Ç —Å–ø–æ—Ä–Ω—ã–µ –º–æ–º–µ–Ω—Ç—ã –≤ 1 –∏ 3 –º–æ–¥–µ–ª—è—Ö. 3-—è –æ—à–∏–±–∞–µ—Ç—Å—è –∏–∑-–∑–∞ –∫–æ–ª–∏–Ω–µ–∞—Ä–Ω–æ—Å—Ç–∏ (–ª–æ–∂–Ω–æ–π)\n",
    "\n",
    "import statsmodels.api as sm\n",
    "X2 = sm.add_constant(X0[2])\n",
    "est = sm.OLS(y, X2)\n",
    "est2 = est.fit()\n",
    "print(est2.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#–ü—Ä–æ–≥–Ω–æ–∑–∏—Ä–æ–≤–∞–Ω–∏–µ –≤—Ä–µ–º–µ–Ω–Ω—ã—Ö —Ä—è–¥–æ–≤\n",
    "#–õ–∏–Ω–µ–π–Ω–∞—è —Ä–µ–≥—Ä–µ—Å—Å–∏—è –ø–ª–æ—Ö–æ–π –º–µ—Ç–æ–¥, –Ω–æ –±–µ–∑–∞–ª—Ç–µ—Ä–Ω–∞—Ç–∏–≤–µ–Ω –ø—Ä–∏ –∫–æ—Ä–æ—Ç–∫–∏—Ö –≤—Ä–µ–º–µ–Ω–Ω—ã—Ö —Ä—è–¥–∞—Ö –∏–ª–∏ –¥–≤—É—Ö –∏–ª–∏ –±–æ–ª–µ–µ —Ñ–∞–∫—Ç–æ—Ä–∞—Ö —Å–µ–∑–æ–Ω–Ω–æ—Å—Ç–∏\n",
    "df = pd.read_csv('series_g.csv', sep=';')\n",
    "\n",
    "# –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º —Å—Ç—Ä–æ—á–∫–∏ —Å –¥–∞—Ç–∞–º–∏ –≤ –æ–±—ä–µ–∫—Ç datetime\n",
    "df['date'] = pd.to_datetime(df['date'], format='%b %Y') # format –ø–æ–∫–∞–∑—ã–≤–∞–µ—Ç —á—Ç–æ —á–∏—Ç–∞–µ–º: '%b %Y' —Ç—Ä–µ—Ö–±—É–∫–≤–µ–Ω–Ω—ã–π –º–µ—Å—è—Ü, –∑–∞—Ç–µ–º –≥–æ–¥ \n",
    "\n",
    "#–ü–æ—Å—Ç—Ä–æ–∏–º –≥—Ä–∞—Ñ–∏–∫ –ø—Ä–æ–≤–µ—Ä–∏—Ç—å —Ç–∏–ø —Ç—Ä–µ–Ω–¥–∞ (–ª–∏–Ω–µ–π–Ω—ã–π –∏–ª–∏ –Ω–µ—Ç), —Ç–∏–ø —Å–µ–∑–æ–Ω–Ω–æ—Å—Ç–∏ (–∞–¥–¥–∏—Ç–∏–≤–Ω—ã–π –∏–ª–∏ –º—É–ª—å—Ç–∏–ø–ª–∏–∫–∞—Ç–∏–≤–Ω—ã–π), –µ–≥–æ –¥–ª–∏–Ω—É, –≤—ã–±—Ä–æ—Å—ã\n",
    "#–í–∏–¥–∏–º –ª–∏–Ω–µ–π–Ω—ã–π —Ç—Ä–µ–Ω–¥ –∏ –º—É–ª—å—Ç–∏–ø–ª–∏–∫–∞—Ç–∏–≤–Ω—É—é —Å–µ–∑–æ–Ω–Ω–æ—Å—Ç—å. –≠—Ç–æ –ø–æ–¥—Ç–≤–µ—Ä–∂–¥–∞–µ—Ç—Å—è –ø–æ—Å–ª–µ –ª–æ–≥–∏—Ä–∞—Ñ–º–∏—Ä–æ–≤–∞–Ω–∏–µ —Ü–∏–∫–ª–∞ \n",
    "\n",
    "fig = plt.figure(figsize=(12, 4))\n",
    "ax1 = fig.add_subplot(121)\n",
    "df['series_g'].plot(ax=ax1)\n",
    "ax1.set_title(u'–û–±—ä—ë–º –ø–∞—Å—Å–∞–∂–∏—Ä–æ–ø–µ—Ä–µ–≤–æ–∑–æ–∫')\n",
    "ax1.set_ylabel(u'–¢—ã—Å—è—á —á–µ–ª–æ–≤–µ–∫')\n",
    "\n",
    "ax2 = fig.add_subplot(122)\n",
    "pd.Series(np.log10(df['series_g'])).plot(ax=ax2)\n",
    "ax2.set_title(u'log10 –æ—Ç –æ–±—ä—ë–º–∞ –ø–∞—Å—Å–∞–∂–∏—Ä–æ–ø–µ—Ä–µ–≤–æ–∑–æ–∫')\n",
    "ax2.set_ylabel(u'log10 –æ—Ç —Ç—ã—Å—è—á —á–µ–ª–æ–≤–µ–∫')\n",
    "\n",
    "#–í—ã–≤–æ–¥: –±—É–¥–µ–º —Å—Ç—Ä–æ–∏—Ç—å –º–æ–¥–µ–ª—å –ª–∏–Ω–µ–π–Ω–æ–π —Ä–µ–≥—Ä–µ—Å—Å–∏–∏ –¥–ª—è –ø—Ä–∏–±–ª–∏–∂–µ–Ω–∏—è –ª–æ–≥–∞—Ä–∏—Ñ–º–∞ –æ—Ç –æ–±—ä—ë–º–∞ –ø–µ—Ä–µ–≤–æ–∑–æ–∫. \n",
    "# logùë¶ùëñ=ùõΩùë•ùëñ+ùëê(ùë•ùëñ)+ùúÄùëñ, –≥–¥–µ  ùë¶ùëñ –æ–±—ä—ë–º –ø–µ—Ä–µ–≤–æ–∑–æ–∫,  ùë•ùëñ –ø–æ—Ä—è–¥–∫–æ–≤—ã–π –Ω–æ–º–µ—Ä –º–µ—Å—è—Ü–∞,  ùëê(ùë•ùëñ) —Å–µ–∑–æ–Ω–Ω–∞—è —Å–æ—Å—Ç–∞–≤–ª—è—é—â–∞—è,  ùúÄùëñ  —Å–ª—É—á–∞–π–Ω—ã–π —à—É–º\n",
    "#–°–æ–∑–¥–∞–¥–∏–º –Ω–æ–≤—ã–π –æ–±—ä–µ–∫—Ç –∫–ª–∞—Å—Å–∞ DateTimeIndex –¥–ª—è 12 –Ω–æ–≤—ã—Ö –¥–∞—Ç (–º–µ—Å—è—Ü–µ–≤) —Å –ø–æ–º–æ—â—å—é —Ñ—É–Ω–∫—Ü–∏–∏ pd.date_range. \n",
    "# –°–æ–∑–¥–∞—ë–º –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å—Å—Ç—å –º–µ—Å—è—Ü–µ–≤. freq='MS' –æ–∑–Ω–∞—á–∞–µ—Ç –ø–µ—Ä–≤–æ–µ —á–∏—Å–ª–æ –∫–∞–∂–¥–æ–≥–æ –º–µ—Å—è—Ü–∞ –∏–∑ —É–∫–∞–∑–∞–Ω–Ω–æ–≥–æ –¥–∏–∞–ø–∞–∑–æ–Ω–∞ \n",
    "new_dates = pd.date_range('1961-01-01', '1961-12-01', freq='MS')\n",
    "\n",
    "# –ü—Ä–∏–≤–æ–¥–∏–º df['date'] –∫ —Ç–∏–ø—É Index, –æ–±—ä–µ–¥–∏–Ω—è–µ–º —Å 12 –º–µ—Å—è—Ü–∞–º–∏, –ø–æ–ª—É—á–µ–Ω–Ω—ã–º–∏ –Ω–∞ –ø—Ä–µ–¥—ã–¥—É—â–µ–º —à–∞–≥–µ\n",
    "new_dates = pd.Index(df['date']) | new_dates\n",
    "\n",
    "# –°–æ–∑–¥–∞—ë–º –¥–∞—Ç–∞—Ñ—Ä–µ–π–º –∏–∑ –æ–¥–Ω–æ–π –∫–æ–ª–æ–Ω–∫–∏ —Å —Ä–∞—Å—à–∏—Ä–µ–Ω–Ω—ã–º –Ω–∞–±–æ—Ä–æ–º –¥–∞—Ç\n",
    "df2 = pd.DataFrame({'date': new_dates})\n",
    "# –û–±—ä–µ–¥–∏–Ω—è–µ–º –¥–≤–∞ –¥–∞—Ç–∞—Ñ—Ä–µ–π–º–∞ –ø–æ –∫–æ–ª–æ–Ω–∫–µ 'date'.\n",
    "df = pd.merge(df, df2, on='date', how='right') #–°–∫–ª–µ–∏–≤–∞–µ–º –ø–æ —É–∫–∞–∑–∞–Ω–Ω–æ–π –∫–æ–ª–æ–Ω–∫–µ (on) –∏ –ø—Ä–∞–≤–∏–ª—É —Å–∫–ª–µ–π–∫–∏ (how)\n",
    "\n",
    "#–†–µ–≥—Ä–µ—Å—Å–∏–æ–Ω–Ω–∞—è –ø–µ—Ä–µ–º–µ–Ω–Ω–∞—è month_num - –ø–æ—Ä—è–¥–∫–æ–≤—ã–π –Ω–æ–º–µ—Ä –ø–∞—Ä—ã (–º–µ—Å—è—Ü, –≥–æ–¥). –õ–æ–≥–∞—Ä–∏—Ñ–º–∏—Ä—É–µ–º —Ç–∞—Ä–≥–µ—Ç\n",
    "df['month_num'] = range(1, len(df) + 1)\n",
    "df['log_y'] = np.log10(df['series_g'])\n",
    "\n",
    "#–°–æ–∑–¥–∞–¥–µ–º 12 –∫–æ–ª–æ–Ω–æ–∫ season_1.., season_12, –≤ –∫–æ—Ç–æ—Ä—ã–µ –ø–æ–º–µ—Å—Ç–∏–º –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä—ã —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—â–µ–≥–æ –º–µ—Å—è—Ü–∞\n",
    "#–ß—Ç–æ–±—ã –∏–∑–±–µ–∂–∞—Ç—å –∫–æ–ª–∏–Ω–µ–∞—Ä–Ω–æ—Å—Ç–∏, –∏—Å–∫–ª—é—á–∞–µ–º –æ–¥–∏–Ω –∏–∑ –º–µ—Å—è—Ü–µ–≤(—è–Ω–≤–∞—Ä—å) –∏ –¥–µ–ª–∞–µ–º –µ–≥–æ —ç—Ç–∞–ª–æ–Ω–æ–º, —Å –∫–æ—Ç–æ—Ä—ã–º —Å—Ä–∞–≤–Ω–∏–≤–∞–µ–º –≤—Å–µ –æ—Å—Ç–∞–ª—å–Ω—ã–µ\n",
    "#–í–Ω—É—Ç—Ä–∏ —Ü–∏–∫–ª–∞ –ø—Ä–æ–≤–µ—Ä—è–µ–º, —Ä–∞–≤–µ–Ω –ª–∏ –æ—á–µ—Ä–µ–¥–Ω–æ–π –º–µ—Å—è—Ü —Ç–µ–∫—É—â–µ–º—É –∑–Ω–∞—á–µ–Ω–∏—é –∏–∑ —Ü–∏–∫–ª–∞\n",
    "for x in range(1, 13):\n",
    "    df['season_' + str(x)] = df['date'].dt.month == x\n",
    "    \n",
    "# xrange(2, 13) —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É–µ—Ç –≤—Å–µ–º –º–µ—Å—è—Ü–∞–º —Å —Ñ–µ–≤—Ä–∞–ª—è –ø–æ –¥–µ–∫–∞–±—Ä—å\n",
    "season_columns = ['season_' + str(x) for x in range(2, 13)]\n",
    "\n",
    "# –°–æ–∑–¥–∞–¥–∏–º –º–∞—Ç—Ä–∏—Ü—É X –∏ –≤–µ–∫—Ç–æ—Ä y –¥–ª—è –æ–±—É—á–µ–Ω–∏—è –º–æ–¥–µ–ª–∏\n",
    "X = df[['month_num'] + season_columns]\n",
    "y = df['log_y']\n",
    "\n",
    "# –û—Å—Ç–∞–≤–∏–º —Ç–æ–ª—å–∫–æ —Ç–µ —Å—Ç—Ä–æ—á–∫–∏, —É –∫–æ—Ç–æ—Ä—ã—Ö –∏–∑–≤–µ—Å—Ç–Ω—ã –∑–Ω–∞—á–µ–Ω–∏—è y (—Å –Ω–æ–º–µ—Ä–æ–º < 144)\n",
    "X1 = X[X.index < 144]\n",
    "y1 = y[y.index < 144]\n",
    "\n",
    "#–ù–∞—Å—Ç—Ä–æ–∏–º —Ä–µ–≥—Ä–µ—Å—Å–∏–æ–Ω–Ω—É—é –º–æ–¥–µ–ª—å. \"–ü–æ–¥–≥–æ–Ω–∫–∞\" —á–µ—Ä–µ–∑ .fit\n",
    "model = LinearRegression()\n",
    "model.fit(X1, y1)\n",
    "\n",
    "pred = pd.DataFrame({\n",
    "    'pred': model.predict(X1),\n",
    "    'real': y1})\n",
    "pred.plot()\n",
    "\n",
    "#—Å—Ç—Ä–æ–∏–º –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ –¥–ª—è –≤—Å–µ–π –º–∞—Ç—Ä–∏—Ü—ã X, –≤–∫–ª—é—á–∞—è –Ω–µ–∏–∑–≤–µ—Å—Ç–Ω—ã–µ 12 –º–µ—Å—è—Ü–µ–≤\n",
    "pred = pd.DataFrame({\n",
    "    'pred': model.predict(X),\n",
    "    'real': y})\n",
    "pred.plot()\n",
    "\n",
    "#–≠–∫—Å–ø–æ–Ω–∏—Ä—É–µ–º –ø—Ä–æ–≥–Ω–æ–∑, —á—Ç–æ–±—ã –ø–æ–ª—É—á–∏—Ç—å —Ä–µ–∞–ª—å–Ω—ã–µ —á–∏—Å–ª–∞\n",
    "pred['number'] = 10**pred['pred']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#–õ–æ–≥–∏—Å—Ç–∏—á–µ—Å–∫–∞—è —Ä–µ–≥—Ä–µ—Å—Å–∏—è –ø–æ–∑–≤–æ–ª—è–µ—Ç –∏—Å—Å–µ–¥–æ–≤–∞—Ç—å –≤–∑–∞–∏–º–æ—Å–≤—è–∑–∏ –¥–ª—è –∑–∞–≤–∏—Å–∏–º–æ–π –ø–µ—Ä–µ–º–µ–Ω–Ω–æ–π —Å –¥–≤—É–º—è –∑–Ω–∞—á–µ–Ω–∏—è–º–∏ (0,1)\n",
    "#–ú–Ω–æ–∂–µ—Å—Ç–≤–µ–Ω–Ω–∞—è —Ä–µ–≥—Ä–µ—Å—Å–∏—è  Y= B0+B1*X1 + ... + BN*XN   –ú–Ω–æ–≥–æ–º–µ—Ä–Ω—ã–π scatter-plot\n",
    "#–î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–æ —Ç—Ä–µ–±—É–µ—Ç: –º—É–ª—å—Ç–∏–∫–æ–ª–ª–∏–Ω–µ–∞—Ä–Ω–æ—Å—Ç—å(–±–µ–∑ —Å–∏–ª—å–Ω–æ–π –∫–æ—Ä—Ä–µ–ª—è—Ü–∏–∏ –∏–ª–∏ –∏–¥–µ–Ω—Ç–∏—á–Ω–æ—Å—Ç–∏), –Ω–æ—Ä–º–∞–ª—å–Ω–æ–µ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö.\n",
    "#t-–∫—Ä–∏—Ç–µ—Ä–∏–π –ø–æ–∫–∞–∑—ã–≤–∞–µ—Ç –æ–∫–∞–∑—ã–≤–∞–µ–º–æ–µ –≤–ª–∏—è–Ω–∏–µ –∫–∞–∂–¥–æ–≥–æ –ø—Ä–µ–¥–∏–∫—Ç–æ—Ä–∞. –ï—Å–ª–∏ 0, —Ç–æ –≤–ª–∏—è–Ω–∏—è –Ω–µ—Ç\n",
    "#–î–ª—è –º–Ω–æ–∂–µ—Å—Ç–≤–µ–Ω–Ω–æ–π —Ä–µ–≥—Ä–µ—Å—Å–∏–∏ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è \"–ò—Å–ø—Ä–∞–≤–ª–µ–Ω–Ω—ã–π\" R**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#–ó–∞–¥–∞—á–∞ —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏—è –Ω–∞–∏–º–µ–Ω–æ–≤–∞–Ω–∏–π –∏–ª–∏ –ø–æ—Ä—è–¥–∫–æ–≤ —á–µ—Ä–µ–∑ –¥–µ—Ä–µ–≤—å—è –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏. –ò —á–∏—Å–µ–ª —á–µ—Ä–µ–∑ —Ä–µ–≥—Ä–µ—Å—Å–∏—é\n",
    "#–ü–æ–º–∏–º–æ –≤–Ω—É—Ç—Ä–µ–Ω–Ω–∏—Ö –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ (–∑–∞–¥–∞–Ω–Ω—ã—Ö –∏–∑–Ω–∞—á–∞–ª—å–Ω–æ), –µ—Å—Ç—å –µ—â–µ –≤–Ω–µ—à–Ω–∏–µ (–∑–∞–¥–∞–≤–∞–µ–º—ã–µ –∞–Ω–∞–ª–∏—Ç–∏–∫–æ–º)\n",
    "#–í—ã–±–æ—Ä –º–æ–¥–µ–ª–∏ —Å –ø–æ–º–æ—â—å—é –æ–±—É—á–∞—é—â–µ–π/—Ç–µ—Å—Ç–æ–≤–æ–π –≤—ã–±–æ—Ä–æ–∫ —á–µ—Ä–µ–∑ –Ω–∞–∏–º–µ–Ω—å—à—É—é —Å—Ä–µ–¥–Ω—é—é –∫–≤–∞–¥—Ä–∞—Ç–∏—á–Ω—É—é –æ—à–∏–±–∫—É \n",
    "#–ö—Ä–∏—Ç–µ—Ä–∏–π –∫–∞—á–µ—Å—Ç–≤–∞ Q - —Å—É–º–º–∞ –º–æ–¥—É–ª–µ–π –æ—à–∏–±–æ–∫ –∏–ª–∏ —Å—É–º–º–∞ –∫–≤–∞–¥—Ä–∞—Ç–æ–≤ –æ—à–∏–±–æ–∫ –∏–ª–∏ –ø—Ä–æ—Ü–µ–Ω—Ç –æ—à–∏–±–æ–∫ –∏ —Ç.–¥.\n",
    "#–í–∞–ª–∏–¥–∞—Ü–∏—è - –º–µ—Ç–æ–¥ –ø—Ä–æ–≤–µ—Ä–∫–∏ –≤—ã–±—Ä–∞–Ω–Ω–æ–π –º–æ–¥–µ–ª–∏ –Ω–∞ –µ–µ –∞–¥–µ–∫–≤–∞—Ç–Ω–æ—Å—Ç—å\n",
    "#–†–µ–≥—É–ª—è—Ä–∏–∑–∞—Ü–∏—è - –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç –ø—Ä–æ–≤–µ—Ä–∫–∏ –º–æ–¥–µ–ª–µ–π"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CART - Classification and regression trees\n",
    "#–¥–µ–ª–µ–Ω–∏–µ –º–∞—Ç—Ä–∏—Ü—ã –ø—Ä—è–º—ã–º–∏\\–≥–∏–ø–µ—Ä–ø–ª–æ—Å–∫–æ—Å—Ç—è–º–∏, —á—Ç–æ–±—ã –≤ –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–Ω—ã—Ö –æ–±–ª–∞—Å—Ç—è—Ö –¥–æ–º–∏–Ω–∏—Ä–æ–≤–∞–ª–∏ —Å—Ö–æ–∂–∏–µ –æ–±—ä–µ–∫—Ç—ã\n",
    "#–£–∑–µ–ª(node) - –º–Ω–æ–∂–µ—Å—Ç–≤–æ, –∫–æ—Ç–æ—Ä–æ–µ —Ä–∞—Å—â–µ–ø–ª—è–µ—Ç—Å—è. –†–æ–¥–∏—Ç–µ–ª—å—Å–∫–∏–π, –ø–æ—Ç–æ–º–æ–∫, –∫–æ–Ω–µ—á–Ω—ã–π. \n",
    "#–ü–æ—Ä–æ–≥–æ–≤–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ - —ç—Ç–∞–ª–æ–Ω –¥–ª—è —Å—Ä–∞–≤–Ω–µ–Ω–∏—è\n",
    "#–û–≥—Ä–∞–Ω–∏—á–µ–Ω–∏—è –∑–∞–¥–∞—é—Ç—Å—è –æ–ø–µ—Ä–∞—Ç–æ—Ä–æ–º. –ù–∞ –∫–æ–ª-–≤–æ —Å–ª–æ–µ–≤, –Ω–∞ —Å–≤–æ–π—Å—Ç–≤–æ –ø–æ—Ç–æ–º–∫–æ–≤, –Ω–∞ —Ä–æ–¥–∏—Ç–µ–ª—è, –Ω–∞ –ø—Ä–∞–≤–∏–ª–∞ –æ—Å—Ç–∞–Ω–æ–≤–∫–∏ \n",
    "#–ß–∏—Å—Ç–æ—Ç–∞ - –ø–æ—Ä—è–¥–æ–∫ —Ä–∞–∑–¥–µ–ª–µ–Ω–∏—è –≤—ã–±–æ—Ä–∫–∏ –Ω–∞ —á–∞—Å—Ç–∏, –≤ –∫–∞–∂–¥–æ–π –∏–∑ –∫–æ—Ç–æ—Ä—ã—Ö \"–∑–∞–≥—Ä—è–∑–Ω–µ–Ω–∏–µ\" –¥–∞–Ω–Ω—ã—Ö –º–µ–Ω—å—à–µ\n",
    "#–ö—Ä–∏—Ç–µ—Ä–∏–π –∑–∞–≥—Ä–∞–∑–Ω–µ–Ω–Ω–æ—Å—Ç–∏(–≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å –ø—Ä–∏–Ω–∞–¥–ª–µ–∂–∞—Ç—å –∫ –∫–ª–∞—Å—Å—É P) –∏–∑–º–µ—Ä—è–µ—Ç—Å—è –≠–Ω—Ç—Ä–æ–ø–∏–µ–π, –ò–Ω–¥–µ–∫—Å–æ–º –î–∂–∏–Ω–∏ –∏–ª–∏ –û—à–∏–±–∫–æ–π –ö–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏\n",
    "#–≠–Ω—Ç—Ä–æ–ø–∏—è H1 = -–°—É–º–º–∞P*log2P. –ò–Ω–¥–µ–∫—Å –î–∂–∏–Ω–∏ H2 = 1-–°—É–º–º–∞P**2 = –°—É–º–º–∞P*(1-P). –û—à–∏–±–∫–∞ –ö–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏ H3 = 1-maxP\n",
    "#–î–µ–ª—å—Ç–∞ H - –≤–∫–ª–∞–¥ –ø–µ—Ä–µ–º–µ–Ω–Ω–æ–π –≤ –æ—á–∏—â–µ–Ω–∏–µ. –°—á–∏—Ç–∞–µ–º —Å—É–º–º—ã –¥–ª—è –∫–∞–∂–¥–æ–π –∏ –ø–æ–ª—É—á–∞–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ç–∏–≤–Ω–æ—Å—Ç—å –ø–µ—Ä–µ–º–µ–Ω–Ω–æ–π\n",
    "\n",
    "#–ó–∞–¥–∞—á–∞ –∫—Ä–µ–¥–∏—Ç–Ω–æ–≥–æ —Å–∫–æ—Ä–∏–Ω–≥–∞\n",
    "df = pd.read_csv('Credit.csv', sep=';', encoding='cp1251')\n",
    "\n",
    "# –ü—Ä–∞–≤–∏–ª—å–Ω—ã–π –æ—Ç–≤–µ—Ç –∑–∞–ø–∏—Å—ã–≤–∞–µ–º –≤ –≤–µ–∫—Ç–æ—Ä y\n",
    "y = df[u'–∫—Ä–µ–¥–∏—Ç']\n",
    "# –£–¥–∞–ª—è–µ–º –∫–æ–ª–æ–Ω–∫—É —Å –ø—Ä–∞–≤–∏–ª—å–Ω—ã–º –æ—Ç–≤–µ—Ç–æ–º\n",
    "X = df.drop(u'–∫—Ä–µ–¥–∏—Ç', axis=1)\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "#–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º –∏ –æ–±—É—á–∞–µ–º –º–æ–¥–µ–ª—å\n",
    "model = DecisionTreeClassifier(random_state=42,\n",
    "                               # —Ñ—É–Ω–∫—Ü–∏—è –¥–ª—è impurity ('gini' –∏–ª–∏ 'entropy')\n",
    "                               criterion='gini',\n",
    "                               # –º–∞–∫—Å–∏–º–∞–ª—å–Ω–∞—è –≥–ª—É–±–∏–Ω–∞ –¥–µ—Ä–µ–≤–∞\n",
    "                               max_depth=5,\n",
    "                               # –º–∏–Ω–∏–º–∞–ª—å–Ω–æ–µ —á–∏—Å–ª–æ —ç–ª–µ–º–µ–Ω—Ç–æ–≤ –≤ —É–∑–ª–µ –¥–ª—è —Ä–∞–∑–±–∏–µ–Ω–∏—è (–º–æ–∂–µ—Ç –±—ã—Ç—å –¥–æ–ª–µ–π)\n",
    "                               min_samples_split=5,\n",
    "                               # –º–∏–Ω–∏–º–∞–ª—å–Ω–æ–µ —á–∏—Å–ª–æ —ç–ª–µ–º–µ–Ω—Ç–æ–≤ –≤ –ª–∏—Å—Ç–µ (–º–æ–∂–µ—Ç –±—ã—Ç—å –¥–æ–ª–µ–π)\n",
    "                               min_samples_leaf=5,\n",
    "                               # –º–∏–Ω–∏–º–∞–ª—å–Ω–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ –¥–µ–ª—å—Ç—ã impurity\n",
    "                               # min_impurity_decrease=0,\n",
    "                               # –≤–µ—Å–∞ –¥–ª—è –∫–ª–∞—Å—Å–æ–≤ (–º–æ–∂–Ω–æ –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–æ —à—Ç—Ä–∞—Ñ–æ–≤–∞—Ç—å –∑–∞ –æ—à–∏–±–∫—É –≤ –Ω—É–∂–Ω—ã—Ö –∫–ª–∞—Å—Å–∞—Ö).\n",
    "                               # –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç –æ–ø—Ü–∏—é 'balanced'.\n",
    "                               class_weight=None\n",
    "                               \n",
    "                              )\n",
    "\n",
    "model.fit(X, y)\n",
    "\n",
    "#–î–ª—è –∏–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∞—Ü–∏–∏ –ø–æ–ª—É—á–∏–≤—à–µ–π—Å—è –º–æ–¥–µ–ª–∏ –∏–∑–æ–±—Ä–∞–∂–∞–µ–º –µ—ë –≤ –≤–∏–¥–µ –¥–µ—Ä–µ–≤–∞ –ø—Ä–µ–¥–∏–∫–∞—Ç–æ–≤ (—Ä–µ—à–∞—é—â–∏—Ö –ø—Ä–∞–≤–∏–ª)\n",
    "from IPython.display import Image\n",
    "from sklearn.tree import export_graphviz\n",
    "from subprocess import call\n",
    "\n",
    "export_graphviz(model,\n",
    "                out_file='tree.dot',\n",
    "                #–∑–∞–¥–∞—Ç—å –Ω–∞–∑–≤–∞–Ω–∏—è —Ñ–∏—á\n",
    "                #feature_names=X.columns,\n",
    "                class_names=None,\n",
    "                #–ø–æ–∫–∞–∑—ã–≤–∞—Ç—å –Ω–∞–∑–≤–∞–Ω–∏—è –ø–æ–ª–µ–π —É —á–∏—Å–ª–µ–Ω–Ω—ã—Ö –∑–Ω–∞—á–µ–Ω–∏–π –≤–Ω—É—Ç—Ä–∏ —É–∑–ª–∞\n",
    "                label='all',\n",
    "                #—Ä–∞—Å–∫—Ä–∞—à–∏–≤–∞—Ç—å —É–∑–ª—ã –≤ —Ü–≤–µ—Ç –ø—Ä–µ–æ–±–ª–∞–¥–∞—é—â–µ–≥–æ –∫–ª–∞—Å—Å–∞\n",
    "                filled=True,\n",
    "                #–ø–æ–∫–∞–∑—ã–≤–∞—Ç—å –∑–Ω–∞—á–µ–Ω–∏–µ impurity –¥–ª—è –∫–∞–∂–¥–æ–≥–æ —É–∑–ª–∞\n",
    "                impurity=True,\n",
    "                #–ø–æ–∫–∞–∑—ã–≤–∞—Ç—å –Ω–æ–º–µ—Ä–∞ —É–∑–ª–æ–≤\n",
    "                node_ids=True,\n",
    "                #–ü–æ–∫–∞–∑—ã–≤–∞—Ç—å –¥–æ–ª–∏ –∫–∞–∂–¥–æ–≥–æ –∫–ª–∞—Å—Å–∞ –≤ —É–∑–ª–∞—Ö (–∞ –Ω–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ)\n",
    "                proportion=True,\n",
    "                #–ü–æ–≤–µ—Ä–Ω—É—Ç—å –¥–µ—Ä–µ–≤–æ –Ω–∞ 90 –≥—Ä–∞–¥—É—Å–æ–≤ (–≤–µ—Ä—Ç–∏–∫–∞–ª—å–Ω–∞—è –æ—Ä–∏–µ–Ω—Ç–∞—Ü–∏—è)\n",
    "                rotate=True,\n",
    "                #–ß–∏—Å–ª–æ —Ç–æ—á–µ–∫ –ø–æ—Å–ª–µ –∑–∞–ø—è—Ç–æ–π –¥–ª—è –æ—Ç–æ–±—Ä–∞–∂–∞–µ–º—ã—Ö –¥—Ä–æ–±–µ–π\n",
    "                #precision=3\n",
    "               )\n",
    "\n",
    "#–ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º —Ñ–∞–π–ª .dot –≤ .png\n",
    "#node - –Ω–æ–º–µ—Ä —É–∑–ª–∞, X[1]<=1.5 –ø—Ä–∞–≤–∏–ª–æ —Ä–∞—Å—â–µ–ø–ª–µ–Ω–∏—è, gini, samples-–¥–æ–ª—è –Ω–∞–±–ª—é–¥–µ–Ω–∏–π –ø–æ–ø–∞–≤—à–∏—Ö –≤ —É–∑–µ–ª, p-value (p0, pX)\n",
    "(graph,) = pydot.graph_from_dot_file('tree.dot')\n",
    "graph.write_png('tree.png')\n",
    "Image(\"tree.png\")\n",
    "\n",
    "#–ú–æ–¥–µ–ª—å –ø–æ–∑–≤–æ–ª—è–µ—Ç –æ—Ü–µ–Ω–∏—Ç—å —Ü–µ–Ω–Ω–æ—Å—Ç—å (importance) –∏ —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ—Å—Ç—å –∫–∞–∂–¥–æ–π —Ñ–∏—á–∏, —Å—á–∏—Ç–∞—è –¥–ª—è –∫–∞–∂–¥–æ–π –∏–∑ —Å—É–º–º—É –¥–µ–ª—å—Ç—ã H \n",
    "pd.DataFrame({'feature': X.columns,\n",
    "              'importance': model.feature_importances_}).sort_values('importance', \n",
    "            ascending=False\n",
    "            )\n",
    "\n",
    "#–ú–µ—Ç–æ–¥ predict –ø–æ–∑–≤–æ–ª—è–µ—Ç –ø–æ–ª—É—á–∏—Ç—å –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è –∫–ª–∞—Å—Å–æ–≤ –¥–ª—è –≤—Ö–æ–¥–Ω–æ–≥–æ —Å–ø–∏—Å–∫–∞ —ç–ª–µ–º–µ–Ω—Ç–æ–≤ (–ø–æ–¥–∞—ë–º –Ω–∞ –≤—Ö–æ–¥ –º–∞—Ç—Ä–∏—Ü—É)\n",
    "# –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ –∫–ª–∞—Å—Å–∞ –¥–ª—è –Ω–æ–≤—ã—Ö —ç–ª–µ–º–µ–Ω—Ç–æ–≤\n",
    "new_item = [1, 1, 1, 1]\n",
    "model.predict([new_item])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#–†–∞—Å—â–µ–ø–ª–µ–Ω–∏–µ –Ω–∞ –æ–±—É—á–∞—é—â—É—é –∏ —Ç–µ—Å—Ç–æ–≤—ã–µ –≤—ã–±–æ—Ä–∫–∏\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42,\n",
    "                                                    # –¥–æ–ª—è –æ–±—ä—ë–º–∞ —Ç–µ—Å—Ç–æ–≤–æ–≥–æ –º–Ω–æ–∂–µ—Å—Ç–≤–∞\n",
    "                                                    test_size=0.2)\n",
    "#–æ–±—É—á–∞–µ–º –º–æ–¥–µ–ª—å\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "#–°—Ç—Ä–æ–∏–º –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ –º–æ–¥–µ–ª–∏ –Ω–∞ —Ç–µ—Å—Ç–æ–≤–æ–º –º–Ω–æ–∂–µ—Å—Ç–≤–µ\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "#–û—Ü–µ–Ω–∫–∞ –∫–∞—á–µ—Å—Ç–≤–∞ –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ç–æ—Ä–∞: –¥–æ–ª—è —Å–æ–≤–ø–∞–≤—à–∏—Ö –æ—Ç–≤–µ—Ç–æ–≤ –≤ y_pred –∏ y_test, –∏–ª–∏ —Å—á–∏—Ç–∞–µ–º —Ç–æ—á–Ω–æ—Å—Ç—å –∏ –ø–æ–ª–Ω–æ—Ç—É\n",
    "#–ï—Å–ª–∏ –¥–æ–ª—è –≤ –æ–±—É—á–∞—é—â–µ–º –≤—ã—à–µ —Ç–µ—Å—Ç–æ–≤–æ–≥–æ, –æ–∑–Ω–∞—á–∞–µ—Ç –ø–µ—Ä–µ–æ–±—É—á–µ–Ω–Ω–æ—Å—Ç—å –º–æ–¥–µ–ª–∏. –ù—É–∂–Ω–æ —É–ø—Ä–æ—â–∞—Ç—å –º–æ–¥–µ–ª—å\n",
    "#–ú–∞—Ç—Ä–∏—Ü–∞ –æ—à–∏–±–æ–∫  ùê∂=(ùëêùëñ,ùëó) , –≥–¥–µ  ùëêùëñ,ùëó –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —ç–ª–µ–º–µ–Ω—Ç–æ–≤ –∫–ª–∞—Å—Å–∞ ùëñ , –∫–æ—Ç–æ—Ä—ã–º –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ç–æ—Ä –ø—Ä–∏—Å–≤–æ–∏–ª –∫–ª–∞—Å—Å ùëó \n",
    "#–¢–æ—á–Ω–æ—Å—Ç—å(precision) - –¥–æ–ª—è –ø—Ä–∞–≤–∏–ª—å–Ω–æ –∫–ª–∞—Å—Å–∏—Ñ–∏—Ü–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö –æ–±—ä–µ–∫—Ç–æ–≤ –≤ –Ω–∞–π–¥–µ–Ω–Ω—ã—Ö –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ç–æ—Ä–æ–º. \n",
    "#–ü–æ–ª–Ω–æ—Ç–∞(recall) - –¥–æ–ª—è —ç—Ç–∏—Ö –æ–±—ä–µ–∫—Ç–æ–≤ –ù–ê –°–ê–ú–û–ú –î–ï–õ–ï\n",
    "from sklearn import metrics\n",
    "conf_mat = metrics.confusion_matrix(y_test, y_pred)\n",
    "conf_mat = pd.DataFrame(conf_mat, index=model.classes_, columns=model.classes_)\n",
    "conf_mat\n",
    "\n",
    "#–ì–∞—Ä–º–æ–Ω–∏—á–µ—Å–∫–æ–µ —Å—Ä–µ–¥–Ω–µ–µ F1 = 2*—Ç–æ—á–Ω–æ—Å—Ç—å*–ø–æ–ª–Ω–æ—Ç–∞/(—Ç–æ—á–Ω–æ—Å—Ç—å+–ø–æ–ª–Ω–æ—Ç–∞). –°—á–∏—Ç–∞–µ—Ç—Å—è —Å –ø–æ–º–æ—â—å—é classification_report\n",
    "print(metrics.classification_report(y_pred, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#–î–µ—Ä–µ–≤—å—è —Ä–µ—à–µ–Ω–∏–π –¥–ª—è –∑–∞–¥–∞—á —Ä–µ–≥—Ä–µ—Å—Å–∏–∏ (–æ—Ç–∫–ª–∏–∫ –Ω–µ –¥–∏—Å–∫—Ä–µ—Ç–Ω—ã–π, –∞ –Ω–µ–ø—Ä–µ—Ä—ã–≤–Ω—ã–π). –ú–µ—Ç–æ–¥—ã —Å—Ö–æ–∂—ã —Å –¥–µ—Ä–µ–≤–æ–º –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏\n",
    "#–ü—Ä–µ–¥–ø–æ—á—Ç–∏—Ç–µ–ª—å–Ω–∏–∏ –ª–∏–Ω–µ–π–Ω–æ–π —Ä–µ–≥—Ä–µ—Å—Å–∏–∏, –∫–æ–≥–¥–∞ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç—å –Ω–µ –ª–∏–Ω–µ–π–Ω–∞—è :)\n",
    "#–í —ç—Ç–æ–º —Å–ª—É—á–∞ –î–µ–ª—å—Ç–∞ H = —Å—É–º–º–∞ –∫–≤–∞–¥—Ä–∞—Ç–æ–≤ –æ—à–∏–±–æ–∫\n",
    "#Prune (–æ–±—Ä–µ–∑–∞–Ω–∏–µ) - –æ—á–∏—Å—Ç–∫–∞ –æ—Ç —É–∑–ª–æ–≤, –∫–æ—Ç–æ—Ä—ã–µ –Ω–µ –Ω—É–∂–Ω—ã, —á–µ—Ä–µ–∑ –¥–æ–±–∞–≤–ª–µ–Ω–∏–µ —Ç—Ä–µ—Ç—å–µ–π –≤—ã–±–æ—Ä–∫–∏ (–≤–∞–ª–∏–¥–∞—Ü–∏–∏)\n",
    "\n",
    "#–°–ª—É—á–∞–π–Ω—ã–π –ª–µ—Å. –ö–ª—é—á–µ–≤—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã:\n",
    "#ntree - —á–∏—Å–ª–æ –¥–µ—Ä–µ–≤—å–µ–≤(–≤ –Ω–∞—á–∞–ª–µ –º–∞–∫—Å, –ø–æ—Ç–æ–º —Å–æ–∫—Ä–∞—â–∞—Ç—å), mtry - —á–∏—Å–ª–æ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö –≤ –≤—ã–±–æ—Ä–∫–µ (M**0.5)\n",
    "#sampsize - —á–∏—Å–ª–æ –Ω–∞–±–ª—é–¥–µ–Ω–∏–π –≤ –ø–æ–¥–≤—ã–±–æ—Ä–∫–µ(0.632*N –¥–ª—è –¥–µ–∫–æ—Ä—Ä–µ–ª—è—Ü–∏–∏), nodesize - –º–∏–Ω. —á–∏—Å–ª–æ –Ω–∞–±–ª—é–¥–µ–Ω–∏–π –≤ —É–∑–ª–µ (10) \n",
    "#replace - –ø–æ–¥–≤—ã–±–æ—Ä–∫–∞ —Å  –≤–æ–∑–≤—Ä–∞—â–µ–Ω–∏–µ–º –∏–ª–∏ –±–µ–∑\n",
    "#out-of-bag - –Ω–µ–∏—Å–ø–æ–ª—å–∑—É–µ–º–∞—è –ø—Ä–∏ –æ–±—É—á–µ–Ω–∏–∏ —á–∞—Å—Ç—å –≤—ã–±–æ—Ä–∫–∏, –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –≤ –∫–∞—á–µ—Å—Ç–≤–µ –ø—Ä–µ–¥–≤–∞—Ä–∏—Ç–µ–ª—å–Ω–æ–≥–æ —Ç–µ—Å—Ç–∞ –º–æ–¥–µ–ª–∏\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "model = RandomForestClassifier(random_state=42, #–∑–µ—Ä–Ω–æ –¥–∞—Ç—á–∏–∫–∞ —Å–ª—É—á–∞–π–Ω—ã—Ö —á–∏—Å–µ–ª\n",
    "                               #—á–∏—Å–ª–æ –¥–µ—Ä–µ–≤—å–µ–≤ –≤ –ª–µ—Å—É\n",
    "                               n_estimators=30,\n",
    "                               #—Ñ—É–Ω–∫—Ü–∏—è –¥–ª—è –¥–µ–ª—å—Ç–∞ H, impurity ('gini' –∏–ª–∏ 'entropy')\n",
    "                               criterion='gini',\n",
    "                               #–ú–∞–∫—Å —á–∏—Å–ª–æ —Å–ª–æ–µ–≤\n",
    "                               max_depth=5,\n",
    "                               #–í—ã—á–∏—Å–ª—è—Ç—å out-of-bag –æ—à–∏–±–∫—É\n",
    "                               oob_score=True,\n",
    "                               #–∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –ø—Ä–µ–¥—ã–¥—É—â–µ–≥–æ –≤—ã–∑–æ–≤–∞ –∏ –Ω–∞—Ä–∞—Å—Ç–∏—Ç—å –ø—Ä–µ–¥—ã–¥—É—â–∏–π –ª–µ—Å \n",
    "                               warm_start=False,\n",
    "                               #–≤–µ—Å–∞ –∫–ª–∞—Å—Å–æ–≤ –¥–ª—è –±–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∫–∏ –≤—ã–±–æ—Ä–∫–∏ –¥–ª—è –æ–±—É—á–µ–Ω–∏—è\n",
    "                               class_weight=None\n",
    "                               \n",
    "                              )\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "print(metrics.classification_report(y_pred, y_test))\n",
    "\n",
    "print('Out-of-bag score: {0}'.format(model.oob_score_)) \n",
    "\n",
    "pd.DataFrame({'feature': X.columns,\n",
    "              'importance': model.feature_importances_}).sort_values('importance', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#–ü—Ä–∏–µ–º—ã —É–ª—É—á—à–µ–Ω–∏—è –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ç–æ—Ä–æ–≤: stacking, bagging, boosting\n",
    "#Stacking(–ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ –Ω–∞ –±–∞–∑–µ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π)\n",
    "#Bagging(—É—Å—Ä–µ–¥–Ω–µ–Ω–Ω–æ–µ –º–Ω–µ–Ω–∏–µ –≤—Å–µ—Ö –º–æ–¥–µ–ª–µ–π), –æ–Ω –∂–µ —Å–ª—É—á–∞–π–Ω—ã–π –ª–µ—Å. –ß—Ç–æ–±—ã –∏–∑–±–µ–∂–∞—Ç—å –∫–æ–ª–∏–Ω–µ–∞—Ä–Ω–æ—Å—Ç–∏, –≤—ã–±–æ—Ä–∫–∏ —Å–æ–±–∏—Ä–∞—é—Ç—Å—è —Ä–∞–Ω–¥–æ–º–Ω–æ\n",
    "#Boosting - –æ–±—É—á–µ–Ω–∏–µ –Ω–∞ –æ—Å–Ω–æ–≤–µ –æ—à–∏–±–æ–∫ –ø—Ä–µ–¥—ã–¥—É—â–µ–≥–æ –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ç–æ—Ä–∞ (—É–ª—É—á—à–µ–Ω–∏–µ–º —Å–ª–∞–±–æ–≥–æ –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ç–æ—Ä–∞)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#GBM - Gradient Boosting Machine. –û—Å—Ç–∞–Ω–æ–≤–∫–∞ –±—É—Å—Ç–∏–Ω–≥–∞, –∫–æ–≥–¥–∞ –æ—á–µ—Ä–µ–¥–Ω—ã–µ —Ü–∏–∫–ª—ã –ø–µ—Ä—Å—Ç–∞—é—Ç —É–ª—É—á—à–∞—Ç—å –º–æ–¥–µ–ª—å\n",
    "#–°—É–º–º–∞ –∫–≤–∞–¥—Ä–∞—Ç–æ–≤ –æ—à–∏–±–æ–∫ Zi = -2*(Yi - f(Xi))\n",
    "#–ú–µ—Ç–æ–¥ –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–≥–æ –ø—Ä–∞–≤–¥–æ–ø–æ–¥–æ–±–∏—è. –ü—Ä–µ–¥–ø–æ–ª–∞–≥–∞–µ–º –Ω–∞–∏–±–æ–ª–µ–µ –≤–µ—Ä–æ—è—Ç–Ω–æ–µ —Å–æ–±—ã—Ç–∏–µ. –ö—Ä–∏—Ç–µ—Ä–∏–π –∫–∞—á–µ—Å—Ç–≤–∞ = P**A*(1-P)**(n-A)\n",
    "#–ö—Ä–∏—Ç–µ—Ä–∏–∏ –∫–∞—á–µ—Å—Ç–≤–∞ –ì–∞—É—Å—Å–∞ –∏ –õ–∞–ø–ª–∞—Å–∞ —É–Ω–∏–≤–µ—Ä—Å–∞–ª—å–Ω—ã. –î–ª—è –¥–≤—É—Ö –∫–ª–∞—Å—Å–æ–≤ - –±–∏–Ω–æ–º–∏–∞–ª—å–Ω–æ–µ, –¥–ª—è –±–æ–ª—å—à–µ–≥–æ - –º—É–ª—å—Ç–∏–Ω–æ–º–∏–Ω–∞–ª—å–Ω–æ–µ\n",
    "#–ü—Ä–∏ –≤—Ä–µ–º–µ–Ω–Ω–æ–º –ø—Ä–æ–º–µ–∂—É—Ç–∫–µ - —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –ü—É–∞—Å—Å–æ–Ω–∞\n",
    "\n",
    "columns = ['age', 'workclass', 'fnlwgt', 'education', 'education-num',\n",
    "           'marital-status', 'occupation', 'relationship', 'race', 'sex',\n",
    "           'capital-gain', 'capital-loss', 'hours-per-week', 'native-country', 'income']\n",
    "df = pd.read_csv('adult.data', header=None, names=columns, na_values=' ?')\n",
    "\n",
    "# –£–¥–∞–ª—è–µ–º –∫–æ–ª–æ–Ω–∫—É education (–ø–æ—Ç–æ–º—É —á—Ç–æ –µ—Å—Ç—å —É–∂–µ –∑–∞–∫–æ–¥–∏—Ä–æ–≤–∞–Ω–Ω–∞—è –∫–æ–ª–æ–Ω–∫–∞ education-num)\n",
    "df = df.drop('education', axis=1)\n",
    "\n",
    "# –ö–æ–¥–∏—Ä—É–µ–º –æ—Ç–∫–ª–∏–∫ –≤ –±–∏–Ω–∞—Ä–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è\n",
    "df['income'] = df['income'].map({' <=50K': 0, ' >50K': 1})\n",
    "\n",
    "# —É–¥–∞–ª—è–µ–º —Å—Ç—Ä–æ–∫–∏ —Å NA –∑–Ω–∞—á–µ–Ω–∏—è–º–∏\n",
    "df = df.dropna()\n",
    "\n",
    "test = pd.read_csv('adult.test', header=None, names=columns, na_values=' ?', skiprows=1)\n",
    "test = test.drop('education', axis=1)\n",
    "test['income'] = test['income'].map({' <=50K.': 0, ' >50K.': 1})\n",
    "test = test.dropna()\n",
    "\n",
    "#–†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –∫–ª–∞—Å—Å–æ–≤ –≤ –æ—Ç–∫–ª–∏–∫–µ\n",
    "df['income'].value_counts(normalize=True)\n",
    "\n",
    "#–†–∞–∑–±–∏–≤–∞–µ–º –¥–∞—Ç—É. –ë–∏–Ω–∞—Ä–∏–∑—É–µ–º –∫–∞—Ç–µ–≥–æ—Ä–∏–∞–ª—å–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏ (one-hot encoding).\n",
    "X_train = pd.get_dummies(df).drop('income', axis=1)\n",
    "y_train = df['income']\n",
    "\n",
    "X_test = pd.get_dummies(test).drop('income', axis=1)\n",
    "y_test = test['income']\n",
    "\n",
    "#–í —Ç–µ—Å—Ç–æ–≤–æ–π –≤—ã–±–æ—Ä–∫–µ –Ω–µ —Ö–≤–∞—Ç–∞–µ—Ç –æ–¥–Ω–æ–π –∫–æ–ª–æ–Ω–∫–∏ \n",
    "print(len(X_train.columns))\n",
    "print(len(X_test.columns))\n",
    "\n",
    "#–ü—Ä–∏–≤–æ–¥–∏–º –º–Ω–æ–∂–µ—Å—Ç–≤–æ –Ω–∞–∑–≤–∞–Ω–∏–π –∫–æ–ª–æ–Ω–æ–∫ –∫ —Ç–∏–ø—É set, –Ω–∞—Ö–æ–¥–∏–º —Ä–∞–∑–Ω–æ—Å—Ç—å –¥–≤—É—Ö –º–Ω–æ–∂–µ—Å—Ç–≤: –ì–æ–ª–ª–∞–Ω–¥–∏–∏ –Ω–µ—Ç –≤ –∫–æ–ª–æ–Ω–∫–µ native-county \n",
    "print(set(X_train.columns) - set(X_test.columns))\n",
    "print(set(X_test.columns) - set(X_train.columns))\n",
    "\n",
    "#–î–æ–±–∞–≤–ª—è–µ–º –Ω–µ–¥–æ—Å—Ç–∞—é—â—É—é –∫–æ–ª–æ–Ω–∫—É\n",
    "columns = set(X_train.columns) | set(X_test.columns)\n",
    "X_train = X_train.reindex(columns=columns).fillna(0)\n",
    "X_test = X_test.reindex(columns=columns).fillna(0)\n",
    "\n",
    "#–ü—Ä–æ–≤–µ—Ä—è–µ–º —Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ –∫–æ–ª–æ–Ω–æ–∫ (–µ—Å–ª–∏ –¥–∞, —Ç–æ True)\n",
    "all(X_train.columns == X_test.columns)\n",
    "\n",
    "#–û–±—É—á–∞–µ–º –º–æ–¥–µ–ª—å\n",
    "model = GradientBoostingClassifier(random_state=42,\n",
    "                                   # –ß–∏—Å–ª–æ –¥–µ—Ä–µ–≤—å–µ–≤\n",
    "                                   n_estimators=500,\n",
    "                                   #–∑–∞–≥—Ä—è–∑–Ω–µ–Ω–∏–µ –∏–∑–º–µ—Ä—è–µ–º ‚Äúmse‚Äù, ‚Äúmae‚Äù –∏–ª–∏ ‚Äúfriedman_mse‚Äù (mse —Å —É–ª—É—á—à–µ–Ω–∏—è–º–∏)  \n",
    "                                   criterion='friedman_mse', \n",
    "                                   #–ú–∞–∫—Å–∏–º–∞–ª—å–Ω–∞—è –≥–ª—É–±–∏–Ω–∞ –∫–∞–∂–¥–æ–≥–æ –¥–µ—Ä–µ–≤–∞\n",
    "                                   #–∫—Ä–∏—Ç–µ—Ä–∏–π –∫–∞—á–µ—Å—Ç–≤–∞ ‚Äòdeviance‚Äô (–∫—Ä–æ—Å—Å-—ç–Ω—Ç—Ä–æ–ø–∏—è) –∏–ª–∏ ‚Äòexponential‚Äô\n",
    "                                   #‚Äòdeviance‚Äô –¥–ª—è –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏ —Å –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—è–º–∏ –Ω–∞ –≤—ã—Ö–æ–¥–µ\n",
    "                                   loss='deviance', \n",
    "                                   # –º–∏–Ω–∏–º–∞–ª—å–Ω–æ–µ —É–º–µ–Ω—å—à–µ–Ω–∏–µ –∑–∞–≥—Ä—è–∑–Ω–µ–Ω–∏—è \n",
    "                                   min_impurity_decrease=0.0, \n",
    "                                   # –£—Å—Ç–∞—Ä–µ–ª–æ\n",
    "                                   min_impurity_split=None,\n",
    "                                   # —á–∏—Å–ª–æ —É–∑–ª–æ–≤ –≤ –¥–µ—Ä–µ–≤–µ\n",
    "                                   max_depth=5,\n",
    "                                   #–º–∏–Ω–∏–º–∞–ª—å–Ω–æ–µ —á–∏—Å–ª–æ –Ω–∞–±–ª—é–¥–µ–Ω–∏–π –≤ –ø–æ—Ç–æ–º–∫–µ\n",
    "                                   min_samples_leaf=5, \n",
    "                                   #–º–∏–Ω–∏–º–∞–ª—å–Ω–æ–µ —á–∏—Å–ª–æ –Ω–∞–±–ª—é–¥–µ–Ω–∏–π –≤ —Ä–æ–¥–∏—Ç–µ–ª–µ\n",
    "                                   min_samples_split=10,\n",
    "                                   #–ü–∞—Ä–∞–º–µ—Ç—Ä, —É–º–µ–Ω—å—à–∞—é—â–∏–π –ø–µ—Ä–µ–æ–±—É—á–µ–Ω–∏–µ, —è–≤–ª—è—é—â–µ–º—Å—è –≤–µ—Å–æ–º –æ—Ç–¥–µ–ª—å–Ω–æ–≥–æ –¥–µ—Ä–µ–≤–∞ (–º–µ–Ω—å—à–µ –ª—É—á—à–µ)\n",
    "                                   learning_rate=0.01                                   \n",
    "                                   )\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "y_pred_train = model.predict(X_train)\n",
    "print(classification_report(y_train, y_pred_train))\n",
    "\n",
    "from sklearn import metrics\n",
    "conf_mat = metrics.confusion_matrix(y_test, y_pred)\n",
    "conf_mat = pd.DataFrame(conf_mat, index=model.classes_, columns=model.classes_)\n",
    "conf_mat\n",
    "\n",
    "from sklearn import metrics\n",
    "conf_mat = metrics.confusion_matrix(y_train, y_pred_train)\n",
    "conf_mat = pd.DataFrame(conf_mat, index=model.classes_, columns=model.classes_)\n",
    "conf_mat\n",
    "\n",
    "#C–º–æ—Ç—Ä–∏–º –≤–∞–∂–Ω–æ—Å—Ç—å –ø—Ä–∏–∑–Ω–∞–∫–æ–≤\n",
    "fi = pd.DataFrame({'features': X_train.columns, 'importance': model.feature_importances_})\n",
    "fi.sort_values('importance', ascending=False).head(10)\n",
    "\n",
    "#–ö–∞–ª–∏–±—Ä–æ–≤–∫–∞ (–∏–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∞—Ü–∏—è –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–∏)\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "model_sigmoid = CalibratedClassifierCV(model, cv=2, method='sigmoid')\n",
    "# method : ‚Äòsigmoid‚Äô or ‚Äòisotonic‚Äô\n",
    "\n",
    "# Calibrate probabilities\n",
    "model_sigmoid.fit(X_train, y_train)\n",
    "\n",
    "# View calibrated probabilities\n",
    "model_sigmoid.predict_proba(X_test)[0:11, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#–ú–µ—Ç–æ–¥ –≥—Ä–∞–¥–∏–µ–Ω—Ç–Ω–æ–≥–æ —Å–ø—É—Å–∫–∞\n",
    "#–ú–µ—Ç–æ–¥ –æ–±—Ä–∞—Ç–Ω–æ–≥–æ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è E = —Å—É–º–º–∞(Yi-Vi)**2 –ø–æ–∑–≤–æ–ª—è–µ—Ç —á–µ—Ä–µ–∑ MSE –Ω–∞—Ö–æ–¥–∏—Ç—å –æ—à–∏–±–∫—É –∏ –Ω–∞ –µ–µ –æ—Å–Ω–æ–≤–µ –∏—Å–ø—Ä–∞–≤–ª—è—Ç—å –≤–µ—Å–∞"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "12/12 [==============================] - 0s 668us/step - loss: 43.5210 - accuracy: 0.0840\n",
      "Epoch 2/300\n",
      "12/12 [==============================] - 0s 750us/step - loss: 32.8726 - accuracy: 0.0588\n",
      "Epoch 3/300\n",
      "12/12 [==============================] - 0s 665us/step - loss: 22.5263 - accuracy: 0.2017\n",
      "Epoch 4/300\n",
      "12/12 [==============================] - 0s 583us/step - loss: 12.8994 - accuracy: 0.2101\n",
      "Epoch 5/300\n",
      "12/12 [==============================] - 0s 667us/step - loss: 4.7547 - accuracy: 0.2269\n",
      "Epoch 6/300\n",
      "12/12 [==============================] - 0s 750us/step - loss: 1.4066 - accuracy: 0.5462\n",
      "Epoch 7/300\n",
      "12/12 [==============================] - 0s 667us/step - loss: 1.3519 - accuracy: 0.6555\n",
      "Epoch 8/300\n",
      "12/12 [==============================] - 0s 667us/step - loss: 1.0499 - accuracy: 0.6555\n",
      "Epoch 9/300\n",
      "12/12 [==============================] - 0s 583us/step - loss: 1.0295 - accuracy: 0.6807\n",
      "Epoch 10/300\n",
      "12/12 [==============================] - 0s 748us/step - loss: 1.0315 - accuracy: 0.6387\n",
      "Epoch 11/300\n",
      "12/12 [==============================] - 0s 750us/step - loss: 1.0046 - accuracy: 0.6303\n",
      "Epoch 12/300\n",
      "12/12 [==============================] - 0s 667us/step - loss: 0.9712 - accuracy: 0.6723\n",
      "Epoch 13/300\n",
      "12/12 [==============================] - 0s 667us/step - loss: 0.9548 - accuracy: 0.6807\n",
      "Epoch 14/300\n",
      "12/12 [==============================] - 0s 667us/step - loss: 0.9816 - accuracy: 0.6555\n",
      "Epoch 15/300\n",
      "12/12 [==============================] - 0s 669us/step - loss: 0.9543 - accuracy: 0.6555\n",
      "Epoch 16/300\n",
      "12/12 [==============================] - 0s 750us/step - loss: 0.9995 - accuracy: 0.5630\n",
      "Epoch 17/300\n",
      "12/12 [==============================] - 0s 581us/step - loss: 1.0229 - accuracy: 0.6218\n",
      "Epoch 18/300\n",
      "12/12 [==============================] - 0s 667us/step - loss: 0.9765 - accuracy: 0.6555\n",
      "Epoch 19/300\n",
      "12/12 [==============================] - 0s 750us/step - loss: 0.9166 - accuracy: 0.6471\n",
      "Epoch 20/300\n",
      "12/12 [==============================] - 0s 583us/step - loss: 0.9104 - accuracy: 0.6471\n",
      "Epoch 21/300\n",
      "12/12 [==============================] - 0s 667us/step - loss: 0.8671 - accuracy: 0.6639\n",
      "Epoch 22/300\n",
      "12/12 [==============================] - 0s 583us/step - loss: 0.8568 - accuracy: 0.6555\n",
      "Epoch 23/300\n",
      "12/12 [==============================] - 0s 583us/step - loss: 0.9560 - accuracy: 0.6975\n",
      "Epoch 24/300\n",
      "12/12 [==============================] - 0s 669us/step - loss: 0.8876 - accuracy: 0.6639\n",
      "Epoch 25/300\n",
      "12/12 [==============================] - 0s 583us/step - loss: 0.8650 - accuracy: 0.6555\n",
      "Epoch 26/300\n",
      "12/12 [==============================] - 0s 667us/step - loss: 0.8254 - accuracy: 0.6639\n",
      "Epoch 27/300\n",
      "12/12 [==============================] - 0s 750us/step - loss: 0.8491 - accuracy: 0.6891\n",
      "Epoch 28/300\n",
      "12/12 [==============================] - 0s 586us/step - loss: 0.8248 - accuracy: 0.6723\n",
      "Epoch 29/300\n",
      "12/12 [==============================] - 0s 750us/step - loss: 0.8123 - accuracy: 0.6723\n",
      "Epoch 30/300\n",
      "12/12 [==============================] - 0s 667us/step - loss: 0.8030 - accuracy: 0.6975\n",
      "Epoch 31/300\n",
      "12/12 [==============================] - 0s 667us/step - loss: 0.7975 - accuracy: 0.6891\n",
      "Epoch 32/300\n",
      "12/12 [==============================] - 0s 667us/step - loss: 0.8316 - accuracy: 0.6723\n",
      "Epoch 33/300\n",
      "12/12 [==============================] - 0s 666us/step - loss: 0.7688 - accuracy: 0.6723\n",
      "Epoch 34/300\n",
      "12/12 [==============================] - 0s 583us/step - loss: 0.7809 - accuracy: 0.6891\n",
      "Epoch 35/300\n",
      "12/12 [==============================] - 0s 666us/step - loss: 0.7552 - accuracy: 0.6807\n",
      "Epoch 36/300\n",
      "12/12 [==============================] - 0s 583us/step - loss: 0.7542 - accuracy: 0.6723\n",
      "Epoch 37/300\n",
      "12/12 [==============================] - 0s 750us/step - loss: 0.7441 - accuracy: 0.6891\n",
      "Epoch 38/300\n",
      "12/12 [==============================] - 0s 750us/step - loss: 0.7685 - accuracy: 0.6723\n",
      "Epoch 39/300\n",
      "12/12 [==============================] - 0s 667us/step - loss: 0.7670 - accuracy: 0.6975\n",
      "Epoch 40/300\n",
      "12/12 [==============================] - 0s 666us/step - loss: 0.7457 - accuracy: 0.6639\n",
      "Epoch 41/300\n",
      "12/12 [==============================] - 0s 668us/step - loss: 0.7400 - accuracy: 0.6807\n",
      "Epoch 42/300\n",
      "12/12 [==============================] - 0s 583us/step - loss: 0.7256 - accuracy: 0.6723\n",
      "Epoch 43/300\n",
      "12/12 [==============================] - 0s 752us/step - loss: 0.7106 - accuracy: 0.7059\n",
      "Epoch 44/300\n",
      "12/12 [==============================] - 0s 586us/step - loss: 0.7282 - accuracy: 0.6723\n",
      "Epoch 45/300\n",
      "12/12 [==============================] - 0s 667us/step - loss: 0.7207 - accuracy: 0.7143\n",
      "Epoch 46/300\n",
      "12/12 [==============================] - 0s 667us/step - loss: 0.7606 - accuracy: 0.6807\n",
      "Epoch 47/300\n",
      "12/12 [==============================] - 0s 624us/step - loss: 0.7112 - accuracy: 0.6807\n",
      "Epoch 48/300\n",
      "12/12 [==============================] - 0s 712us/step - loss: 0.6864 - accuracy: 0.6891\n",
      "Epoch 49/300\n",
      "12/12 [==============================] - 0s 750us/step - loss: 0.7403 - accuracy: 0.6639\n",
      "Epoch 50/300\n",
      "12/12 [==============================] - 0s 667us/step - loss: 0.7126 - accuracy: 0.6807\n",
      "Epoch 51/300\n",
      "12/12 [==============================] - 0s 747us/step - loss: 0.6919 - accuracy: 0.6891\n",
      "Epoch 52/300\n",
      "12/12 [==============================] - 0s 667us/step - loss: 0.6746 - accuracy: 0.6975\n",
      "Epoch 53/300\n",
      "12/12 [==============================] - 0s 586us/step - loss: 0.6753 - accuracy: 0.7143\n",
      "Epoch 54/300\n",
      "12/12 [==============================] - 0s 666us/step - loss: 0.6613 - accuracy: 0.7059\n",
      "Epoch 55/300\n",
      "12/12 [==============================] - 0s 667us/step - loss: 0.6654 - accuracy: 0.7311\n",
      "Epoch 56/300\n",
      "12/12 [==============================] - 0s 750us/step - loss: 0.6544 - accuracy: 0.7143\n",
      "Epoch 57/300\n",
      "12/12 [==============================] - 0s 750us/step - loss: 0.6776 - accuracy: 0.6807\n",
      "Epoch 58/300\n",
      "12/12 [==============================] - 0s 667us/step - loss: 0.6528 - accuracy: 0.6891\n",
      "Epoch 59/300\n",
      "12/12 [==============================] - 0s 669us/step - loss: 0.6294 - accuracy: 0.6891\n",
      "Epoch 60/300\n",
      "12/12 [==============================] - 0s 664us/step - loss: 0.6470 - accuracy: 0.6723\n",
      "Epoch 61/300\n",
      "12/12 [==============================] - 0s 583us/step - loss: 0.6460 - accuracy: 0.6975\n",
      "Epoch 62/300\n",
      "12/12 [==============================] - 0s 581us/step - loss: 0.6480 - accuracy: 0.6975\n",
      "Epoch 63/300\n",
      "12/12 [==============================] - 0s 583us/step - loss: 0.6441 - accuracy: 0.6723\n",
      "Epoch 64/300\n",
      "12/12 [==============================] - 0s 626us/step - loss: 0.6386 - accuracy: 0.7059\n",
      "Epoch 65/300\n",
      "12/12 [==============================] - 0s 667us/step - loss: 0.6461 - accuracy: 0.6723\n",
      "Epoch 66/300\n",
      "12/12 [==============================] - 0s 626us/step - loss: 0.6165 - accuracy: 0.6723\n",
      "Epoch 67/300\n",
      "12/12 [==============================] - 0s 748us/step - loss: 0.5997 - accuracy: 0.6891\n",
      "Epoch 68/300\n",
      "12/12 [==============================] - 0s 669us/step - loss: 0.6041 - accuracy: 0.7143\n",
      "Epoch 69/300\n",
      "12/12 [==============================] - 0s 665us/step - loss: 0.6102 - accuracy: 0.7227\n",
      "Epoch 70/300\n",
      "12/12 [==============================] - 0s 750us/step - loss: 0.5815 - accuracy: 0.7143\n",
      "Epoch 71/300\n",
      "12/12 [==============================] - 0s 667us/step - loss: 0.5815 - accuracy: 0.7311\n",
      "Epoch 72/300\n",
      "12/12 [==============================] - 0s 667us/step - loss: 0.5799 - accuracy: 0.7143\n",
      "Epoch 73/300\n",
      "12/12 [==============================] - 0s 581us/step - loss: 0.5651 - accuracy: 0.7143\n",
      "Epoch 74/300\n",
      "12/12 [==============================] - 0s 670us/step - loss: 0.5615 - accuracy: 0.7143\n",
      "Epoch 75/300\n",
      "12/12 [==============================] - 0s 750us/step - loss: 0.5897 - accuracy: 0.7227\n",
      "Epoch 76/300\n",
      "12/12 [==============================] - 0s 664us/step - loss: 0.5868 - accuracy: 0.7311\n",
      "Epoch 77/300\n",
      "12/12 [==============================] - 0s 752us/step - loss: 0.6115 - accuracy: 0.7059\n",
      "Epoch 78/300\n",
      "12/12 [==============================] - 0s 711us/step - loss: 0.5641 - accuracy: 0.6975\n",
      "Epoch 79/300\n",
      "12/12 [==============================] - 0s 665us/step - loss: 0.5565 - accuracy: 0.6807\n",
      "Epoch 80/300\n",
      "12/12 [==============================] - 0s 668us/step - loss: 0.5401 - accuracy: 0.6975\n",
      "Epoch 81/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12/12 [==============================] - 0s 664us/step - loss: 0.5951 - accuracy: 0.7311\n",
      "Epoch 82/300\n",
      "12/12 [==============================] - 0s 584us/step - loss: 0.6437 - accuracy: 0.7227\n",
      "Epoch 83/300\n",
      "12/12 [==============================] - 0s 714us/step - loss: 0.5375 - accuracy: 0.7395\n",
      "Epoch 84/300\n",
      "12/12 [==============================] - 0s 750us/step - loss: 0.6066 - accuracy: 0.7227\n",
      "Epoch 85/300\n",
      "12/12 [==============================] - 0s 585us/step - loss: 0.6681 - accuracy: 0.6555\n",
      "Epoch 86/300\n",
      "12/12 [==============================] - 0s 709us/step - loss: 0.6455 - accuracy: 0.7563\n",
      "Epoch 87/300\n",
      "12/12 [==============================] - 0s 664us/step - loss: 0.5379 - accuracy: 0.7311\n",
      "Epoch 88/300\n",
      "12/12 [==============================] - 0s 583us/step - loss: 0.5712 - accuracy: 0.6975\n",
      "Epoch 89/300\n",
      "12/12 [==============================] - 0s 748us/step - loss: 0.5849 - accuracy: 0.7563\n",
      "Epoch 90/300\n",
      "12/12 [==============================] - 0s 583us/step - loss: 0.5072 - accuracy: 0.7143\n",
      "Epoch 91/300\n",
      "12/12 [==============================] - 0s 666us/step - loss: 0.5472 - accuracy: 0.7143\n",
      "Epoch 92/300\n",
      "12/12 [==============================] - 0s 667us/step - loss: 0.5220 - accuracy: 0.7311\n",
      "Epoch 93/300\n",
      "12/12 [==============================] - 0s 583us/step - loss: 0.5065 - accuracy: 0.7143\n",
      "Epoch 94/300\n",
      "12/12 [==============================] - 0s 712us/step - loss: 0.5031 - accuracy: 0.7647\n",
      "Epoch 95/300\n",
      "12/12 [==============================] - 0s 585us/step - loss: 0.4955 - accuracy: 0.7479\n",
      "Epoch 96/300\n",
      "12/12 [==============================] - 0s 586us/step - loss: 0.4884 - accuracy: 0.7479\n",
      "Epoch 97/300\n",
      "12/12 [==============================] - 0s 750us/step - loss: 0.5031 - accuracy: 0.7227\n",
      "Epoch 98/300\n",
      "12/12 [==============================] - 0s 669us/step - loss: 0.4738 - accuracy: 0.7227\n",
      "Epoch 99/300\n",
      "12/12 [==============================] - 0s 667us/step - loss: 0.4879 - accuracy: 0.7395\n",
      "Epoch 100/300\n",
      "12/12 [==============================] - 0s 669us/step - loss: 0.4593 - accuracy: 0.7731\n",
      "Epoch 101/300\n",
      "12/12 [==============================] - 0s 667us/step - loss: 0.4669 - accuracy: 0.7311\n",
      "Epoch 102/300\n",
      "12/12 [==============================] - 0s 667us/step - loss: 0.4887 - accuracy: 0.7479\n",
      "Epoch 103/300\n",
      "12/12 [==============================] - 0s 669us/step - loss: 0.4766 - accuracy: 0.7143\n",
      "Epoch 104/300\n",
      "12/12 [==============================] - 0s 583us/step - loss: 0.4573 - accuracy: 0.7395\n",
      "Epoch 105/300\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.2393 - accuracy: 0.80 - 0s 669us/step - loss: 0.4414 - accuracy: 0.7479\n",
      "Epoch 106/300\n",
      "12/12 [==============================] - 0s 583us/step - loss: 0.4564 - accuracy: 0.7563\n",
      "Epoch 107/300\n",
      "12/12 [==============================] - 0s 664us/step - loss: 0.4713 - accuracy: 0.7731\n",
      "Epoch 108/300\n",
      "12/12 [==============================] - 0s 748us/step - loss: 0.4573 - accuracy: 0.7563\n",
      "Epoch 109/300\n",
      "12/12 [==============================] - 0s 664us/step - loss: 0.4581 - accuracy: 0.7563\n",
      "Epoch 110/300\n",
      "12/12 [==============================] - 0s 667us/step - loss: 0.4646 - accuracy: 0.7815\n",
      "Epoch 111/300\n",
      "12/12 [==============================] - 0s 583us/step - loss: 0.4332 - accuracy: 0.7731\n",
      "Epoch 112/300\n",
      "12/12 [==============================] - 0s 667us/step - loss: 0.4095 - accuracy: 0.7983\n",
      "Epoch 113/300\n",
      "12/12 [==============================] - 0s 752us/step - loss: 0.4155 - accuracy: 0.7731\n",
      "Epoch 114/300\n",
      "12/12 [==============================] - 0s 584us/step - loss: 0.4346 - accuracy: 0.7731\n",
      "Epoch 115/300\n",
      "12/12 [==============================] - 0s 750us/step - loss: 0.4129 - accuracy: 0.8067\n",
      "Epoch 116/300\n",
      "12/12 [==============================] - 0s 665us/step - loss: 0.3946 - accuracy: 0.8067\n",
      "Epoch 117/300\n",
      "12/12 [==============================] - 0s 583us/step - loss: 0.3964 - accuracy: 0.8235\n",
      "Epoch 118/300\n",
      "12/12 [==============================] - 0s 632us/step - loss: 0.3893 - accuracy: 0.8235\n",
      "Epoch 119/300\n",
      "12/12 [==============================] - 0s 667us/step - loss: 0.4044 - accuracy: 0.8151\n",
      "Epoch 120/300\n",
      "12/12 [==============================] - 0s 583us/step - loss: 0.3851 - accuracy: 0.8319\n",
      "Epoch 121/300\n",
      "12/12 [==============================] - 0s 664us/step - loss: 0.3980 - accuracy: 0.8319\n",
      "Epoch 122/300\n",
      "12/12 [==============================] - 0s 583us/step - loss: 0.3911 - accuracy: 0.7983\n",
      "Epoch 123/300\n",
      "12/12 [==============================] - 0s 583us/step - loss: 0.3803 - accuracy: 0.8151\n",
      "Epoch 124/300\n",
      "12/12 [==============================] - 0s 669us/step - loss: 0.3726 - accuracy: 0.8571\n",
      "Epoch 125/300\n",
      "12/12 [==============================] - 0s 583us/step - loss: 0.3575 - accuracy: 0.8824\n",
      "Epoch 126/300\n",
      "12/12 [==============================] - 0s 669us/step - loss: 0.3108 - accuracy: 0.8571\n",
      "Epoch 127/300\n",
      "12/12 [==============================] - 0s 748us/step - loss: 0.3353 - accuracy: 0.8739\n",
      "Epoch 128/300\n",
      "12/12 [==============================] - 0s 585us/step - loss: 0.3791 - accuracy: 0.7983\n",
      "Epoch 129/300\n",
      "12/12 [==============================] - 0s 667us/step - loss: 0.3656 - accuracy: 0.8319\n",
      "Epoch 130/300\n",
      "12/12 [==============================] - 0s 583us/step - loss: 0.3751 - accuracy: 0.8487\n",
      "Epoch 131/300\n",
      "12/12 [==============================] - 0s 583us/step - loss: 0.3026 - accuracy: 0.8908\n",
      "Epoch 132/300\n",
      "12/12 [==============================] - 0s 667us/step - loss: 0.2807 - accuracy: 0.8908\n",
      "Epoch 133/300\n",
      "12/12 [==============================] - 0s 583us/step - loss: 0.2950 - accuracy: 0.8824\n",
      "Epoch 134/300\n",
      "12/12 [==============================] - 0s 669us/step - loss: 0.2829 - accuracy: 0.8992\n",
      "Epoch 135/300\n",
      "12/12 [==============================] - 0s 667us/step - loss: 0.2923 - accuracy: 0.8571\n",
      "Epoch 136/300\n",
      "12/12 [==============================] - 0s 667us/step - loss: 0.2814 - accuracy: 0.9160\n",
      "Epoch 137/300\n",
      "12/12 [==============================] - 0s 667us/step - loss: 0.2802 - accuracy: 0.8487\n",
      "Epoch 138/300\n",
      "12/12 [==============================] - 0s 583us/step - loss: 0.2582 - accuracy: 0.9160\n",
      "Epoch 139/300\n",
      "12/12 [==============================] - 0s 669us/step - loss: 0.3279 - accuracy: 0.8487\n",
      "Epoch 140/300\n",
      "12/12 [==============================] - 0s 669us/step - loss: 0.3051 - accuracy: 0.8908\n",
      "Epoch 141/300\n",
      "12/12 [==============================] - 0s 664us/step - loss: 0.3593 - accuracy: 0.8487\n",
      "Epoch 142/300\n",
      "12/12 [==============================] - 0s 750us/step - loss: 0.3487 - accuracy: 0.8739\n",
      "Epoch 143/300\n",
      "12/12 [==============================] - 0s 667us/step - loss: 0.3167 - accuracy: 0.9076\n",
      "Epoch 144/300\n",
      "12/12 [==============================] - 0s 667us/step - loss: 0.2577 - accuracy: 0.8992\n",
      "Epoch 145/300\n",
      "12/12 [==============================] - 0s 584us/step - loss: 0.2817 - accuracy: 0.8824\n",
      "Epoch 146/300\n",
      "12/12 [==============================] - 0s 583us/step - loss: 0.3039 - accuracy: 0.8908\n",
      "Epoch 147/300\n",
      "12/12 [==============================] - 0s 668us/step - loss: 0.3164 - accuracy: 0.8487\n",
      "Epoch 148/300\n",
      "12/12 [==============================] - 0s 667us/step - loss: 0.3036 - accuracy: 0.8908\n",
      "Epoch 149/300\n",
      "12/12 [==============================] - 0s 667us/step - loss: 0.2301 - accuracy: 0.9412\n",
      "Epoch 150/300\n",
      "12/12 [==============================] - 0s 667us/step - loss: 0.2327 - accuracy: 0.9244\n",
      "Epoch 151/300\n",
      "12/12 [==============================] - 0s 602us/step - loss: 0.2416 - accuracy: 0.9160\n",
      "Epoch 152/300\n",
      "12/12 [==============================] - 0s 666us/step - loss: 0.2484 - accuracy: 0.9244\n",
      "Epoch 153/300\n",
      "12/12 [==============================] - 0s 666us/step - loss: 0.2399 - accuracy: 0.9244\n",
      "Epoch 154/300\n",
      "12/12 [==============================] - 0s 583us/step - loss: 0.2373 - accuracy: 0.8992\n",
      "Epoch 155/300\n",
      "12/12 [==============================] - 0s 708us/step - loss: 0.2451 - accuracy: 0.9412\n",
      "Epoch 156/300\n",
      "12/12 [==============================] - 0s 667us/step - loss: 0.2118 - accuracy: 0.9244\n",
      "Epoch 157/300\n",
      "12/12 [==============================] - 0s 583us/step - loss: 0.2460 - accuracy: 0.9328\n",
      "Epoch 158/300\n",
      "12/12 [==============================] - 0s 667us/step - loss: 0.2178 - accuracy: 0.9160\n",
      "Epoch 159/300\n",
      "12/12 [==============================] - 0s 665us/step - loss: 0.2460 - accuracy: 0.8992\n",
      "Epoch 160/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12/12 [==============================] - 0s 581us/step - loss: 0.2019 - accuracy: 0.9244\n",
      "Epoch 161/300\n",
      "12/12 [==============================] - 0s 583us/step - loss: 0.2219 - accuracy: 0.8992\n",
      "Epoch 162/300\n",
      "12/12 [==============================] - 0s 667us/step - loss: 0.2278 - accuracy: 0.9076\n",
      "Epoch 163/300\n",
      "12/12 [==============================] - 0s 664us/step - loss: 0.2280 - accuracy: 0.9496\n",
      "Epoch 164/300\n",
      "12/12 [==============================] - 0s 667us/step - loss: 0.2400 - accuracy: 0.9328\n",
      "Epoch 165/300\n",
      "12/12 [==============================] - 0s 583us/step - loss: 0.2057 - accuracy: 0.9580\n",
      "Epoch 166/300\n",
      "12/12 [==============================] - 0s 669us/step - loss: 0.2239 - accuracy: 0.9244\n",
      "Epoch 167/300\n",
      "12/12 [==============================] - 0s 581us/step - loss: 0.1897 - accuracy: 0.9412\n",
      "Epoch 168/300\n",
      "12/12 [==============================] - 0s 666us/step - loss: 0.2214 - accuracy: 0.9076\n",
      "Epoch 169/300\n",
      "12/12 [==============================] - 0s 583us/step - loss: 0.2224 - accuracy: 0.9328\n",
      "Epoch 170/300\n",
      "12/12 [==============================] - 0s 502us/step - loss: 0.1954 - accuracy: 0.9328\n",
      "Epoch 171/300\n",
      "12/12 [==============================] - 0s 667us/step - loss: 0.2063 - accuracy: 0.9412\n",
      "Epoch 172/300\n",
      "12/12 [==============================] - 0s 583us/step - loss: 0.2337 - accuracy: 0.9244\n",
      "Epoch 173/300\n",
      "12/12 [==============================] - 0s 668us/step - loss: 0.2346 - accuracy: 0.9076\n",
      "Epoch 174/300\n",
      "12/12 [==============================] - 0s 750us/step - loss: 0.2411 - accuracy: 0.9076\n",
      "Epoch 175/300\n",
      "12/12 [==============================] - 0s 664us/step - loss: 0.2061 - accuracy: 0.9160\n",
      "Epoch 176/300\n",
      "12/12 [==============================] - 0s 630us/step - loss: 0.2476 - accuracy: 0.8824\n",
      "Epoch 177/300\n",
      "12/12 [==============================] - 0s 664us/step - loss: 0.2362 - accuracy: 0.9412\n",
      "Epoch 178/300\n",
      "12/12 [==============================] - 0s 667us/step - loss: 0.1774 - accuracy: 0.9328\n",
      "Epoch 179/300\n",
      "12/12 [==============================] - 0s 752us/step - loss: 0.1843 - accuracy: 0.9412\n",
      "Epoch 180/300\n",
      "12/12 [==============================] - 0s 584us/step - loss: 0.1968 - accuracy: 0.9496\n",
      "Epoch 181/300\n",
      "12/12 [==============================] - 0s 750us/step - loss: 0.1950 - accuracy: 0.9412\n",
      "Epoch 182/300\n",
      "12/12 [==============================] - 0s 750us/step - loss: 0.1680 - accuracy: 0.9496\n",
      "Epoch 183/300\n",
      "12/12 [==============================] - 0s 583us/step - loss: 0.2470 - accuracy: 0.9412\n",
      "Epoch 184/300\n",
      "12/12 [==============================] - 0s 583us/step - loss: 0.3214 - accuracy: 0.8824\n",
      "Epoch 185/300\n",
      "12/12 [==============================] - 0s 680us/step - loss: 0.3271 - accuracy: 0.9160\n",
      "Epoch 186/300\n",
      "12/12 [==============================] - 0s 583us/step - loss: 0.2702 - accuracy: 0.9076\n",
      "Epoch 187/300\n",
      "12/12 [==============================] - 0s 750us/step - loss: 0.2407 - accuracy: 0.8824\n",
      "Epoch 188/300\n",
      "12/12 [==============================] - 0s 583us/step - loss: 0.2033 - accuracy: 0.9412\n",
      "Epoch 189/300\n",
      "12/12 [==============================] - 0s 666us/step - loss: 0.1948 - accuracy: 0.9328\n",
      "Epoch 190/300\n",
      "12/12 [==============================] - 0s 750us/step - loss: 0.2069 - accuracy: 0.8992\n",
      "Epoch 191/300\n",
      "12/12 [==============================] - 0s 583us/step - loss: 0.2487 - accuracy: 0.9160\n",
      "Epoch 192/300\n",
      "12/12 [==============================] - 0s 668us/step - loss: 0.1698 - accuracy: 0.9580\n",
      "Epoch 193/300\n",
      "12/12 [==============================] - 0s 667us/step - loss: 0.1789 - accuracy: 0.9412\n",
      "Epoch 194/300\n",
      "12/12 [==============================] - 0s 666us/step - loss: 0.1805 - accuracy: 0.9496\n",
      "Epoch 195/300\n",
      "12/12 [==============================] - 0s 667us/step - loss: 0.1877 - accuracy: 0.9412\n",
      "Epoch 196/300\n",
      "12/12 [==============================] - 0s 664us/step - loss: 0.1901 - accuracy: 0.9328\n",
      "Epoch 197/300\n",
      "12/12 [==============================] - 0s 667us/step - loss: 0.1733 - accuracy: 0.9412\n",
      "Epoch 198/300\n",
      "12/12 [==============================] - 0s 583us/step - loss: 0.1652 - accuracy: 0.9412\n",
      "Epoch 199/300\n",
      "12/12 [==============================] - 0s 669us/step - loss: 0.1907 - accuracy: 0.9328\n",
      "Epoch 200/300\n",
      "12/12 [==============================] - 0s 750us/step - loss: 0.1805 - accuracy: 0.9580\n",
      "Epoch 201/300\n",
      "12/12 [==============================] - 0s 665us/step - loss: 0.1743 - accuracy: 0.9412\n",
      "Epoch 202/300\n",
      "12/12 [==============================] - 0s 669us/step - loss: 0.1944 - accuracy: 0.9496\n",
      "Epoch 203/300\n",
      "12/12 [==============================] - 0s 667us/step - loss: 0.1866 - accuracy: 0.9328\n",
      "Epoch 204/300\n",
      "12/12 [==============================] - 0s 583us/step - loss: 0.1748 - accuracy: 0.9580\n",
      "Epoch 205/300\n",
      "12/12 [==============================] - 0s 666us/step - loss: 0.1827 - accuracy: 0.9496\n",
      "Epoch 206/300\n",
      "12/12 [==============================] - 0s 667us/step - loss: 0.1486 - accuracy: 0.9496\n",
      "Epoch 207/300\n",
      "12/12 [==============================] - 0s 666us/step - loss: 0.1635 - accuracy: 0.9412\n",
      "Epoch 208/300\n",
      "12/12 [==============================] - 0s 750us/step - loss: 0.1561 - accuracy: 0.9496\n",
      "Epoch 209/300\n",
      "12/12 [==============================] - 0s 667us/step - loss: 0.2185 - accuracy: 0.9076\n",
      "Epoch 210/300\n",
      "12/12 [==============================] - 0s 667us/step - loss: 0.1703 - accuracy: 0.9580\n",
      "Epoch 211/300\n",
      "12/12 [==============================] - 0s 667us/step - loss: 0.2383 - accuracy: 0.9244\n",
      "Epoch 212/300\n",
      "12/12 [==============================] - 0s 581us/step - loss: 0.2061 - accuracy: 0.9412\n",
      "Epoch 213/300\n",
      "12/12 [==============================] - 0s 667us/step - loss: 0.1869 - accuracy: 0.9328\n",
      "Epoch 214/300\n",
      "12/12 [==============================] - 0s 628us/step - loss: 0.2208 - accuracy: 0.9328\n",
      "Epoch 215/300\n",
      "12/12 [==============================] - 0s 666us/step - loss: 0.1560 - accuracy: 0.9580\n",
      "Epoch 216/300\n",
      "12/12 [==============================] - 0s 583us/step - loss: 0.2053 - accuracy: 0.9244\n",
      "Epoch 217/300\n",
      "12/12 [==============================] - 0s 667us/step - loss: 0.1896 - accuracy: 0.9328\n",
      "Epoch 218/300\n",
      "12/12 [==============================] - 0s 626us/step - loss: 0.2132 - accuracy: 0.9160\n",
      "Epoch 219/300\n",
      "12/12 [==============================] - 0s 664us/step - loss: 0.1595 - accuracy: 0.9496\n",
      "Epoch 220/300\n",
      "12/12 [==============================] - 0s 583us/step - loss: 0.1429 - accuracy: 0.9496\n",
      "Epoch 221/300\n",
      "12/12 [==============================] - 0s 750us/step - loss: 0.1467 - accuracy: 0.9496\n",
      "Epoch 222/300\n",
      "12/12 [==============================] - 0s 667us/step - loss: 0.1631 - accuracy: 0.9412\n",
      "Epoch 223/300\n",
      "12/12 [==============================] - 0s 583us/step - loss: 0.1508 - accuracy: 0.9580\n",
      "Epoch 224/300\n",
      "12/12 [==============================] - 0s 667us/step - loss: 0.1398 - accuracy: 0.9496\n",
      "Epoch 225/300\n",
      "12/12 [==============================] - 0s 583us/step - loss: 0.1738 - accuracy: 0.9412\n",
      "Epoch 226/300\n",
      "12/12 [==============================] - 0s 667us/step - loss: 0.1761 - accuracy: 0.9496\n",
      "Epoch 227/300\n",
      "12/12 [==============================] - 0s 667us/step - loss: 0.1715 - accuracy: 0.9160\n",
      "Epoch 228/300\n",
      "12/12 [==============================] - 0s 583us/step - loss: 0.1463 - accuracy: 0.9664\n",
      "Epoch 229/300\n",
      "12/12 [==============================] - 0s 565us/step - loss: 0.1359 - accuracy: 0.9580\n",
      "Epoch 230/300\n",
      "12/12 [==============================] - 0s 586us/step - loss: 0.1358 - accuracy: 0.9580\n",
      "Epoch 231/300\n",
      "12/12 [==============================] - 0s 583us/step - loss: 0.1504 - accuracy: 0.9580\n",
      "Epoch 232/300\n",
      "12/12 [==============================] - 0s 750us/step - loss: 0.1323 - accuracy: 0.9496\n",
      "Epoch 233/300\n",
      "12/12 [==============================] - 0s 582us/step - loss: 0.1714 - accuracy: 0.9496\n",
      "Epoch 234/300\n",
      "12/12 [==============================] - 0s 669us/step - loss: 0.1712 - accuracy: 0.9412\n",
      "Epoch 235/300\n",
      "12/12 [==============================] - 0s 670us/step - loss: 0.2032 - accuracy: 0.8992\n",
      "Epoch 236/300\n",
      "12/12 [==============================] - 0s 583us/step - loss: 0.1853 - accuracy: 0.9412\n",
      "Epoch 237/300\n",
      "12/12 [==============================] - 0s 667us/step - loss: 0.1180 - accuracy: 0.9580\n",
      "Epoch 238/300\n",
      "12/12 [==============================] - 0s 667us/step - loss: 0.1979 - accuracy: 0.9160\n",
      "Epoch 239/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12/12 [==============================] - 0s 586us/step - loss: 0.1203 - accuracy: 0.9664\n",
      "Epoch 240/300\n",
      "12/12 [==============================] - 0s 667us/step - loss: 0.1419 - accuracy: 0.9664\n",
      "Epoch 241/300\n",
      "12/12 [==============================] - 0s 664us/step - loss: 0.1813 - accuracy: 0.9412\n",
      "Epoch 242/300\n",
      "12/12 [==============================] - 0s 667us/step - loss: 0.1371 - accuracy: 0.9664\n",
      "Epoch 243/300\n",
      "12/12 [==============================] - 0s 833us/step - loss: 0.1265 - accuracy: 0.9496\n",
      "Epoch 244/300\n",
      "12/12 [==============================] - 0s 667us/step - loss: 0.1481 - accuracy: 0.9496\n",
      "Epoch 245/300\n",
      "12/12 [==============================] - 0s 585us/step - loss: 0.1319 - accuracy: 0.9580\n",
      "Epoch 246/300\n",
      "12/12 [==============================] - 0s 664us/step - loss: 0.1371 - accuracy: 0.9496\n",
      "Epoch 247/300\n",
      "12/12 [==============================] - 0s 583us/step - loss: 0.1431 - accuracy: 0.9748\n",
      "Epoch 248/300\n",
      "12/12 [==============================] - 0s 583us/step - loss: 0.1341 - accuracy: 0.9412\n",
      "Epoch 249/300\n",
      "12/12 [==============================] - 0s 669us/step - loss: 0.1324 - accuracy: 0.9748\n",
      "Epoch 250/300\n",
      "12/12 [==============================] - 0s 583us/step - loss: 0.1816 - accuracy: 0.9160\n",
      "Epoch 251/300\n",
      "12/12 [==============================] - 0s 750us/step - loss: 0.2262 - accuracy: 0.9244\n",
      "Epoch 252/300\n",
      "12/12 [==============================] - 0s 665us/step - loss: 0.1895 - accuracy: 0.9160\n",
      "Epoch 253/300\n",
      "12/12 [==============================] - 0s 667us/step - loss: 0.1486 - accuracy: 0.9328\n",
      "Epoch 254/300\n",
      "12/12 [==============================] - 0s 665us/step - loss: 0.1700 - accuracy: 0.9328\n",
      "Epoch 255/300\n",
      "12/12 [==============================] - 0s 581us/step - loss: 0.1493 - accuracy: 0.9328\n",
      "Epoch 256/300\n",
      "12/12 [==============================] - 0s 750us/step - loss: 0.1284 - accuracy: 0.9496\n",
      "Epoch 257/300\n",
      "12/12 [==============================] - 0s 667us/step - loss: 0.1335 - accuracy: 0.9580\n",
      "Epoch 258/300\n",
      "12/12 [==============================] - 0s 667us/step - loss: 0.1256 - accuracy: 0.9664\n",
      "Epoch 259/300\n",
      "12/12 [==============================] - 0s 664us/step - loss: 0.1240 - accuracy: 0.9664\n",
      "Epoch 260/300\n",
      "12/12 [==============================] - 0s 583us/step - loss: 0.1365 - accuracy: 0.9496\n",
      "Epoch 261/300\n",
      "12/12 [==============================] - 0s 585us/step - loss: 0.1351 - accuracy: 0.9580\n",
      "Epoch 262/300\n",
      "12/12 [==============================] - 0s 664us/step - loss: 0.1342 - accuracy: 0.9580\n",
      "Epoch 263/300\n",
      "12/12 [==============================] - 0s 669us/step - loss: 0.1578 - accuracy: 0.9412\n",
      "Epoch 264/300\n",
      "12/12 [==============================] - 0s 667us/step - loss: 0.1100 - accuracy: 0.9580\n",
      "Epoch 265/300\n",
      "12/12 [==============================] - 0s 583us/step - loss: 0.1274 - accuracy: 0.9580\n",
      "Epoch 266/300\n",
      "12/12 [==============================] - 0s 667us/step - loss: 0.1353 - accuracy: 0.9496\n",
      "Epoch 267/300\n",
      "12/12 [==============================] - 0s 750us/step - loss: 0.1298 - accuracy: 0.9580\n",
      "Epoch 268/300\n",
      "12/12 [==============================] - 0s 583us/step - loss: 0.1275 - accuracy: 0.9496\n",
      "Epoch 269/300\n",
      "12/12 [==============================] - 0s 748us/step - loss: 0.1187 - accuracy: 0.9664\n",
      "Epoch 270/300\n",
      "12/12 [==============================] - 0s 748us/step - loss: 0.1202 - accuracy: 0.9496\n",
      "Epoch 271/300\n",
      "12/12 [==============================] - 0s 586us/step - loss: 0.1325 - accuracy: 0.9580\n",
      "Epoch 272/300\n",
      "12/12 [==============================] - 0s 667us/step - loss: 0.1239 - accuracy: 0.9580\n",
      "Epoch 273/300\n",
      "12/12 [==============================] - 0s 667us/step - loss: 0.1318 - accuracy: 0.9664\n",
      "Epoch 274/300\n",
      "12/12 [==============================] - 0s 748us/step - loss: 0.1420 - accuracy: 0.9496\n",
      "Epoch 275/300\n",
      "12/12 [==============================] - 0s 752us/step - loss: 0.1303 - accuracy: 0.9580\n",
      "Epoch 276/300\n",
      "12/12 [==============================] - 0s 667us/step - loss: 0.1409 - accuracy: 0.9496\n",
      "Epoch 277/300\n",
      "12/12 [==============================] - 0s 666us/step - loss: 0.1928 - accuracy: 0.9160\n",
      "Epoch 278/300\n",
      "12/12 [==============================] - 0s 667us/step - loss: 0.1419 - accuracy: 0.9412\n",
      "Epoch 279/300\n",
      "12/12 [==============================] - 0s 667us/step - loss: 0.1351 - accuracy: 0.9496\n",
      "Epoch 280/300\n",
      "12/12 [==============================] - 0s 750us/step - loss: 0.1326 - accuracy: 0.9664\n",
      "Epoch 281/300\n",
      "12/12 [==============================] - 0s 667us/step - loss: 0.1157 - accuracy: 0.9580\n",
      "Epoch 282/300\n",
      "12/12 [==============================] - 0s 667us/step - loss: 0.1405 - accuracy: 0.9580\n",
      "Epoch 283/300\n",
      "12/12 [==============================] - 0s 669us/step - loss: 0.1716 - accuracy: 0.9160\n",
      "Epoch 284/300\n",
      "12/12 [==============================] - 0s 583us/step - loss: 0.1179 - accuracy: 0.9580\n",
      "Epoch 285/300\n",
      "12/12 [==============================] - 0s 667us/step - loss: 0.1432 - accuracy: 0.9412\n",
      "Epoch 286/300\n",
      "12/12 [==============================] - 0s 667us/step - loss: 0.1331 - accuracy: 0.9412\n",
      "Epoch 287/300\n",
      "12/12 [==============================] - 0s 668us/step - loss: 0.1548 - accuracy: 0.9496\n",
      "Epoch 288/300\n",
      "12/12 [==============================] - 0s 667us/step - loss: 0.1536 - accuracy: 0.9328\n",
      "Epoch 289/300\n",
      "12/12 [==============================] - 0s 667us/step - loss: 0.2054 - accuracy: 0.9160\n",
      "Epoch 290/300\n",
      "12/12 [==============================] - 0s 667us/step - loss: 0.1211 - accuracy: 0.9580\n",
      "Epoch 291/300\n",
      "12/12 [==============================] - 0s 667us/step - loss: 0.1171 - accuracy: 0.9748\n",
      "Epoch 292/300\n",
      "12/12 [==============================] - 0s 667us/step - loss: 0.1090 - accuracy: 0.9496\n",
      "Epoch 293/300\n",
      "12/12 [==============================] - 0s 669us/step - loss: 0.1069 - accuracy: 0.9664\n",
      "Epoch 294/300\n",
      "12/12 [==============================] - 0s 667us/step - loss: 0.1100 - accuracy: 0.9580\n",
      "Epoch 295/300\n",
      "12/12 [==============================] - 0s 669us/step - loss: 0.1082 - accuracy: 0.9664\n",
      "Epoch 296/300\n",
      "12/12 [==============================] - 0s 669us/step - loss: 0.1249 - accuracy: 0.9580\n",
      "Epoch 297/300\n",
      "12/12 [==============================] - 0s 667us/step - loss: 0.1276 - accuracy: 0.9496\n",
      "Epoch 298/300\n",
      "12/12 [==============================] - 0s 667us/step - loss: 0.1131 - accuracy: 0.9496\n",
      "Epoch 299/300\n",
      "12/12 [==============================] - 0s 750us/step - loss: 0.1362 - accuracy: 0.9496\n",
      "Epoch 300/300\n",
      "12/12 [==============================] - 0s 667us/step - loss: 0.1256 - accuracy: 0.9580\n",
      "Epoch 1/300\n",
      "12/12 [==============================] - 0s 500us/step - loss: 177.2482 - accuracy: 0.4118\n",
      "Epoch 2/300\n",
      "12/12 [==============================] - 0s 586us/step - loss: 1.0871 - accuracy: 0.4118\n",
      "Epoch 3/300\n",
      "12/12 [==============================] - 0s 586us/step - loss: 1.0859 - accuracy: 0.4118\n",
      "Epoch 4/300\n",
      "12/12 [==============================] - 0s 664us/step - loss: 1.0848 - accuracy: 0.4118\n",
      "Epoch 5/300\n",
      "12/12 [==============================] - 0s 581us/step - loss: 1.0847 - accuracy: 0.4118\n",
      "Epoch 6/300\n",
      "12/12 [==============================] - 0s 583us/step - loss: 1.0839 - accuracy: 0.4118\n",
      "Epoch 7/300\n",
      "12/12 [==============================] - 0s 666us/step - loss: 1.0855 - accuracy: 0.4118\n",
      "Epoch 8/300\n",
      "12/12 [==============================] - 0s 584us/step - loss: 1.0876 - accuracy: 0.4118\n",
      "Epoch 9/300\n",
      "12/12 [==============================] - 0s 583us/step - loss: 1.0845 - accuracy: 0.4118\n",
      "Epoch 10/300\n",
      "12/12 [==============================] - 0s 583us/step - loss: 1.0856 - accuracy: 0.4118\n",
      "Epoch 11/300\n",
      "12/12 [==============================] - 0s 669us/step - loss: 1.0848 - accuracy: 0.4118\n",
      "Epoch 12/300\n",
      "12/12 [==============================] - 0s 583us/step - loss: 1.0847 - accuracy: 0.4118\n",
      "Epoch 13/300\n",
      "12/12 [==============================] - 0s 666us/step - loss: 1.0858 - accuracy: 0.4118\n",
      "Epoch 14/300\n",
      "12/12 [==============================] - 0s 584us/step - loss: 1.0853 - accuracy: 0.4118\n",
      "Epoch 15/300\n",
      "12/12 [==============================] - 0s 500us/step - loss: 1.0848 - accuracy: 0.4118\n",
      "Epoch 16/300\n",
      "12/12 [==============================] - 0s 583us/step - loss: 1.0855 - accuracy: 0.4118\n",
      "Epoch 17/300\n",
      "12/12 [==============================] - 0s 581us/step - loss: 1.0845 - accuracy: 0.4118\n",
      "Epoch 18/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12/12 [==============================] - 0s 666us/step - loss: 1.0858 - accuracy: 0.4118\n",
      "Epoch 19/300\n",
      "12/12 [==============================] - 0s 583us/step - loss: 1.0851 - accuracy: 0.4118\n",
      "Epoch 20/300\n",
      "12/12 [==============================] - 0s 500us/step - loss: 1.0854 - accuracy: 0.4118\n",
      "Epoch 21/300\n",
      "12/12 [==============================] - 0s 583us/step - loss: 1.0843 - accuracy: 0.4118\n",
      "Epoch 22/300\n",
      "12/12 [==============================] - 0s 581us/step - loss: 1.0867 - accuracy: 0.4118\n",
      "Epoch 23/300\n",
      "12/12 [==============================] - 0s 583us/step - loss: 1.0849 - accuracy: 0.4118\n",
      "Epoch 24/300\n",
      "12/12 [==============================] - 0s 581us/step - loss: 1.0841 - accuracy: 0.4118\n",
      "Epoch 25/300\n",
      "12/12 [==============================] - 0s 585us/step - loss: 1.0853 - accuracy: 0.4118\n",
      "Epoch 26/300\n",
      "12/12 [==============================] - 0s 583us/step - loss: 1.0854 - accuracy: 0.4118\n",
      "Epoch 27/300\n",
      "12/12 [==============================] - 0s 583us/step - loss: 1.0842 - accuracy: 0.4118\n",
      "Epoch 28/300\n",
      "12/12 [==============================] - 0s 661us/step - loss: 1.0851 - accuracy: 0.4118\n",
      "Epoch 29/300\n",
      "12/12 [==============================] - 0s 582us/step - loss: 1.0843 - accuracy: 0.4118\n",
      "Epoch 30/300\n",
      "12/12 [==============================] - 0s 647us/step - loss: 1.0852 - accuracy: 0.4118\n",
      "Epoch 31/300\n",
      "12/12 [==============================] - 0s 636us/step - loss: 1.0858 - accuracy: 0.4118\n",
      "Epoch 32/300\n",
      "12/12 [==============================] - 0s 583us/step - loss: 1.0849 - accuracy: 0.4118\n",
      "Epoch 33/300\n",
      "12/12 [==============================] - 0s 584us/step - loss: 1.0850 - accuracy: 0.4118\n",
      "Epoch 34/300\n",
      "12/12 [==============================] - 0s 583us/step - loss: 1.0860 - accuracy: 0.4118\n",
      "Epoch 35/300\n",
      "12/12 [==============================] - 0s 667us/step - loss: 1.0841 - accuracy: 0.4118\n",
      "Epoch 36/300\n",
      "12/12 [==============================] - 0s 750us/step - loss: 1.0854 - accuracy: 0.4118\n",
      "Epoch 37/300\n",
      "12/12 [==============================] - 0s 583us/step - loss: 1.0846 - accuracy: 0.4118\n",
      "Epoch 38/300\n",
      "12/12 [==============================] - 0s 583us/step - loss: 1.0840 - accuracy: 0.4118\n",
      "Epoch 39/300\n",
      "12/12 [==============================] - 0s 750us/step - loss: 1.0845 - accuracy: 0.4118\n",
      "Epoch 40/300\n",
      "12/12 [==============================] - 0s 500us/step - loss: 1.0862 - accuracy: 0.4118\n",
      "Epoch 41/300\n",
      "12/12 [==============================] - 0s 667us/step - loss: 1.0845 - accuracy: 0.4118\n",
      "Epoch 42/300\n",
      "12/12 [==============================] - 0s 585us/step - loss: 1.0849 - accuracy: 0.4118\n",
      "Epoch 43/300\n",
      "12/12 [==============================] - 0s 584us/step - loss: 1.0839 - accuracy: 0.4118\n",
      "Epoch 44/300\n",
      "12/12 [==============================] - 0s 667us/step - loss: 1.0847 - accuracy: 0.4118\n",
      "Epoch 45/300\n",
      "12/12 [==============================] - 0s 667us/step - loss: 1.0850 - accuracy: 0.4118\n",
      "Epoch 46/300\n",
      "12/12 [==============================] - 0s 583us/step - loss: 1.0838 - accuracy: 0.4118\n",
      "Epoch 47/300\n",
      "12/12 [==============================] - 0s 726us/step - loss: 1.0855 - accuracy: 0.4118\n",
      "Epoch 48/300\n",
      "12/12 [==============================] - 0s 583us/step - loss: 1.0843 - accuracy: 0.4118\n",
      "Epoch 49/300\n",
      "12/12 [==============================] - 0s 667us/step - loss: 1.0841 - accuracy: 0.4118\n",
      "Epoch 50/300\n",
      "12/12 [==============================] - 0s 581us/step - loss: 1.0857 - accuracy: 0.4118\n",
      "Epoch 51/300\n",
      "12/12 [==============================] - 0s 583us/step - loss: 1.0844 - accuracy: 0.4118\n",
      "Epoch 52/300\n",
      "12/12 [==============================] - 0s 665us/step - loss: 1.0853 - accuracy: 0.4118\n",
      "Epoch 53/300\n",
      "12/12 [==============================] - 0s 667us/step - loss: 1.0858 - accuracy: 0.4118\n",
      "Epoch 54/300\n",
      "12/12 [==============================] - 0s 667us/step - loss: 1.0863 - accuracy: 0.4118\n",
      "Epoch 55/300\n",
      "12/12 [==============================] - 0s 583us/step - loss: 1.0842 - accuracy: 0.4118\n",
      "Epoch 56/300\n",
      "12/12 [==============================] - 0s 583us/step - loss: 1.0850 - accuracy: 0.4118\n",
      "Epoch 57/300\n",
      "12/12 [==============================] - 0s 664us/step - loss: 1.0848 - accuracy: 0.4118\n",
      "Epoch 58/300\n",
      "12/12 [==============================] - 0s 643us/step - loss: 1.0857 - accuracy: 0.4118\n",
      "Epoch 59/300\n",
      "12/12 [==============================] - 0s 583us/step - loss: 1.0850 - accuracy: 0.4118\n",
      "Epoch 60/300\n",
      "12/12 [==============================] - 0s 502us/step - loss: 1.0837 - accuracy: 0.4118\n",
      "Epoch 61/300\n",
      "12/12 [==============================] - 0s 583us/step - loss: 1.0848 - accuracy: 0.4118\n",
      "Epoch 62/300\n",
      "12/12 [==============================] - 0s 582us/step - loss: 1.0856 - accuracy: 0.4118\n",
      "Epoch 63/300\n",
      "12/12 [==============================] - 0s 667us/step - loss: 1.0868 - accuracy: 0.4118\n",
      "Epoch 64/300\n",
      "12/12 [==============================] - 0s 584us/step - loss: 1.0857 - accuracy: 0.4118\n",
      "Epoch 65/300\n",
      "12/12 [==============================] - 0s 502us/step - loss: 1.0855 - accuracy: 0.4118\n",
      "Epoch 66/300\n",
      "12/12 [==============================] - 0s 603us/step - loss: 1.0855 - accuracy: 0.4118\n",
      "Epoch 67/300\n",
      "12/12 [==============================] - 0s 583us/step - loss: 1.0848 - accuracy: 0.4118\n",
      "Epoch 68/300\n",
      "12/12 [==============================] - 0s 667us/step - loss: 1.0859 - accuracy: 0.4118\n",
      "Epoch 69/300\n",
      "12/12 [==============================] - 0s 667us/step - loss: 1.0842 - accuracy: 0.4118\n",
      "Epoch 70/300\n",
      "12/12 [==============================] - 0s 583us/step - loss: 1.0856 - accuracy: 0.4118\n",
      "Epoch 71/300\n",
      "12/12 [==============================] - 0s 583us/step - loss: 1.0847 - accuracy: 0.4118\n",
      "Epoch 72/300\n",
      "12/12 [==============================] - 0s 500us/step - loss: 1.0843 - accuracy: 0.4118\n",
      "Epoch 73/300\n",
      "12/12 [==============================] - 0s 668us/step - loss: 1.0849 - accuracy: 0.4118\n",
      "Epoch 74/300\n",
      "12/12 [==============================] - 0s 583us/step - loss: 1.0845 - accuracy: 0.4118\n",
      "Epoch 75/300\n",
      "12/12 [==============================] - 0s 585us/step - loss: 1.0852 - accuracy: 0.4118\n",
      "Epoch 76/300\n",
      "12/12 [==============================] - 0s 583us/step - loss: 1.0843 - accuracy: 0.4118\n",
      "Epoch 77/300\n",
      "12/12 [==============================] - 0s 580us/step - loss: 1.0861 - accuracy: 0.4118\n",
      "Epoch 78/300\n",
      "12/12 [==============================] - 0s 664us/step - loss: 1.0858 - accuracy: 0.4118\n",
      "Epoch 79/300\n",
      "12/12 [==============================] - 0s 673us/step - loss: 1.0853 - accuracy: 0.4118\n",
      "Epoch 80/300\n",
      "12/12 [==============================] - 0s 583us/step - loss: 1.0842 - accuracy: 0.4118\n",
      "Epoch 81/300\n",
      "12/12 [==============================] - 0s 581us/step - loss: 1.0840 - accuracy: 0.4118\n",
      "Epoch 82/300\n",
      "12/12 [==============================] - ETA: 0s - loss: 1.0913 - accuracy: 0.40 - 0s 583us/step - loss: 1.0854 - accuracy: 0.4118\n",
      "Epoch 83/300\n",
      "12/12 [==============================] - 0s 629us/step - loss: 1.0846 - accuracy: 0.4118\n",
      "Epoch 84/300\n",
      "12/12 [==============================] - 0s 585us/step - loss: 1.0841 - accuracy: 0.4118\n",
      "Epoch 85/300\n",
      "12/12 [==============================] - 0s 666us/step - loss: 1.0851 - accuracy: 0.4118\n",
      "Epoch 86/300\n",
      "12/12 [==============================] - 0s 666us/step - loss: 1.0851 - accuracy: 0.4118\n",
      "Epoch 87/300\n",
      "12/12 [==============================] - 0s 585us/step - loss: 1.0848 - accuracy: 0.4118\n",
      "Epoch 88/300\n",
      "12/12 [==============================] - 0s 667us/step - loss: 1.0851 - accuracy: 0.4118\n",
      "Epoch 89/300\n",
      "12/12 [==============================] - 0s 581us/step - loss: 1.0860 - accuracy: 0.4118\n",
      "Epoch 90/300\n",
      "12/12 [==============================] - 0s 583us/step - loss: 1.0852 - accuracy: 0.4118\n",
      "Epoch 91/300\n",
      "12/12 [==============================] - 0s 667us/step - loss: 1.0839 - accuracy: 0.4118\n",
      "Epoch 92/300\n",
      "12/12 [==============================] - 0s 583us/step - loss: 1.0848 - accuracy: 0.4118\n",
      "Epoch 93/300\n",
      "12/12 [==============================] - 0s 665us/step - loss: 1.0843 - accuracy: 0.4118\n",
      "Epoch 94/300\n",
      "12/12 [==============================] - 0s 600us/step - loss: 1.0841 - accuracy: 0.4118\n",
      "Epoch 95/300\n",
      "12/12 [==============================] - 0s 584us/step - loss: 1.0845 - accuracy: 0.4118\n",
      "Epoch 96/300\n",
      "12/12 [==============================] - 0s 667us/step - loss: 1.0842 - accuracy: 0.4118\n",
      "Epoch 97/300\n",
      "12/12 [==============================] - 0s 500us/step - loss: 1.0862 - accuracy: 0.4118\n",
      "Epoch 98/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12/12 [==============================] - 0s 584us/step - loss: 1.0847 - accuracy: 0.4118\n",
      "Epoch 99/300\n",
      "12/12 [==============================] - 0s 583us/step - loss: 1.0845 - accuracy: 0.4118\n",
      "Epoch 100/300\n",
      "12/12 [==============================] - 0s 582us/step - loss: 1.0858 - accuracy: 0.4118\n",
      "Epoch 101/300\n",
      "12/12 [==============================] - 0s 583us/step - loss: 1.0840 - accuracy: 0.4118\n",
      "Epoch 102/300\n",
      "12/12 [==============================] - 0s 583us/step - loss: 1.0844 - accuracy: 0.4118\n",
      "Epoch 103/300\n",
      "12/12 [==============================] - 0s 583us/step - loss: 1.0842 - accuracy: 0.4118\n",
      "Epoch 104/300\n",
      "12/12 [==============================] - 0s 581us/step - loss: 1.0844 - accuracy: 0.4118\n",
      "Epoch 105/300\n",
      "12/12 [==============================] - 0s 586us/step - loss: 1.0843 - accuracy: 0.4118\n",
      "Epoch 106/300\n",
      "12/12 [==============================] - 0s 584us/step - loss: 1.0847 - accuracy: 0.4118\n",
      "Epoch 107/300\n",
      "12/12 [==============================] - 0s 583us/step - loss: 1.0873 - accuracy: 0.4118\n",
      "Epoch 108/300\n",
      "12/12 [==============================] - 0s 664us/step - loss: 1.0862 - accuracy: 0.4118\n",
      "Epoch 109/300\n",
      "12/12 [==============================] - 0s 500us/step - loss: 1.0847 - accuracy: 0.4118\n",
      "Epoch 110/300\n",
      "12/12 [==============================] - 0s 585us/step - loss: 1.0853 - accuracy: 0.4118\n",
      "Epoch 111/300\n",
      "12/12 [==============================] - 0s 583us/step - loss: 1.0852 - accuracy: 0.4118\n",
      "Epoch 112/300\n",
      "12/12 [==============================] - 0s 667us/step - loss: 1.0844 - accuracy: 0.4118\n",
      "Epoch 113/300\n",
      "12/12 [==============================] - 0s 667us/step - loss: 1.0849 - accuracy: 0.4118\n",
      "Epoch 114/300\n",
      "12/12 [==============================] - 0s 500us/step - loss: 1.0841 - accuracy: 0.4118\n",
      "Epoch 115/300\n",
      "12/12 [==============================] - 0s 664us/step - loss: 1.0848 - accuracy: 0.4118\n",
      "Epoch 116/300\n",
      "12/12 [==============================] - 0s 500us/step - loss: 1.0849 - accuracy: 0.4118\n",
      "Epoch 117/300\n",
      "12/12 [==============================] - 0s 667us/step - loss: 1.0852 - accuracy: 0.4118\n",
      "Epoch 118/300\n",
      "12/12 [==============================] - 0s 582us/step - loss: 1.0844 - accuracy: 0.4118\n",
      "Epoch 119/300\n",
      "12/12 [==============================] - 0s 586us/step - loss: 1.0849 - accuracy: 0.4118\n",
      "Epoch 120/300\n",
      "12/12 [==============================] - 0s 583us/step - loss: 1.0848 - accuracy: 0.4118\n",
      "Epoch 121/300\n",
      "12/12 [==============================] - 0s 583us/step - loss: 1.0862 - accuracy: 0.4118\n",
      "Epoch 122/300\n",
      "12/12 [==============================] - 0s 583us/step - loss: 1.0846 - accuracy: 0.4118\n",
      "Epoch 123/300\n",
      "12/12 [==============================] - 0s 583us/step - loss: 1.0845 - accuracy: 0.4118\n",
      "Epoch 124/300\n",
      "12/12 [==============================] - 0s 583us/step - loss: 1.0856 - accuracy: 0.4118\n",
      "Epoch 125/300\n",
      "12/12 [==============================] - 0s 583us/step - loss: 1.0845 - accuracy: 0.4118\n",
      "Epoch 126/300\n",
      "12/12 [==============================] - 0s 583us/step - loss: 1.0845 - accuracy: 0.4118\n",
      "Epoch 127/300\n",
      "12/12 [==============================] - 0s 585us/step - loss: 1.0857 - accuracy: 0.4118\n",
      "Epoch 128/300\n",
      "12/12 [==============================] - 0s 502us/step - loss: 1.0838 - accuracy: 0.4118\n",
      "Epoch 129/300\n",
      "12/12 [==============================] - 0s 667us/step - loss: 1.0861 - accuracy: 0.4118\n",
      "Epoch 130/300\n",
      "12/12 [==============================] - 0s 665us/step - loss: 1.0847 - accuracy: 0.4118\n",
      "Epoch 131/300\n",
      "12/12 [==============================] - 0s 669us/step - loss: 1.0847 - accuracy: 0.4118\n",
      "Epoch 132/300\n",
      "12/12 [==============================] - 0s 581us/step - loss: 1.0857 - accuracy: 0.4118\n",
      "Epoch 133/300\n",
      "12/12 [==============================] - 0s 669us/step - loss: 1.0843 - accuracy: 0.4118\n",
      "Epoch 134/300\n",
      "12/12 [==============================] - 0s 583us/step - loss: 1.0839 - accuracy: 0.4118\n",
      "Epoch 135/300\n",
      "12/12 [==============================] - 0s 581us/step - loss: 1.0840 - accuracy: 0.4118\n",
      "Epoch 136/300\n",
      "12/12 [==============================] - 0s 666us/step - loss: 1.0848 - accuracy: 0.4118\n",
      "Epoch 137/300\n",
      "12/12 [==============================] - 0s 667us/step - loss: 1.0846 - accuracy: 0.4118\n",
      "Epoch 138/300\n",
      "12/12 [==============================] - 0s 583us/step - loss: 1.0855 - accuracy: 0.4118\n",
      "Epoch 139/300\n",
      "12/12 [==============================] - 0s 667us/step - loss: 1.0851 - accuracy: 0.4118\n",
      "Epoch 140/300\n",
      "12/12 [==============================] - 0s 503us/step - loss: 1.0843 - accuracy: 0.4118\n",
      "Epoch 141/300\n",
      "12/12 [==============================] - 0s 666us/step - loss: 1.0867 - accuracy: 0.4118\n",
      "Epoch 142/300\n",
      "12/12 [==============================] - 0s 582us/step - loss: 1.0871 - accuracy: 0.4118\n",
      "Epoch 143/300\n",
      "12/12 [==============================] - 0s 667us/step - loss: 1.0847 - accuracy: 0.4118\n",
      "Epoch 144/300\n",
      "12/12 [==============================] - 0s 586us/step - loss: 1.0845 - accuracy: 0.4118\n",
      "Epoch 145/300\n",
      "12/12 [==============================] - 0s 583us/step - loss: 1.0864 - accuracy: 0.4118\n",
      "Epoch 146/300\n",
      "12/12 [==============================] - ETA: 0s - loss: 1.0788 - accuracy: 0.50 - 0s 667us/step - loss: 1.0854 - accuracy: 0.4118\n",
      "Epoch 147/300\n",
      "12/12 [==============================] - 0s 583us/step - loss: 1.0857 - accuracy: 0.4118\n",
      "Epoch 148/300\n",
      "12/12 [==============================] - 0s 626us/step - loss: 1.0836 - accuracy: 0.4118\n",
      "Epoch 149/300\n",
      "12/12 [==============================] - 0s 612us/step - loss: 1.0850 - accuracy: 0.4118\n",
      "Epoch 150/300\n",
      "12/12 [==============================] - 0s 667us/step - loss: 1.0845 - accuracy: 0.4118\n",
      "Epoch 151/300\n",
      "12/12 [==============================] - 0s 664us/step - loss: 1.0849 - accuracy: 0.4118\n",
      "Epoch 152/300\n",
      "12/12 [==============================] - 0s 583us/step - loss: 1.0845 - accuracy: 0.4118\n",
      "Epoch 153/300\n",
      "12/12 [==============================] - 0s 586us/step - loss: 1.0844 - accuracy: 0.4118\n",
      "Epoch 154/300\n",
      "12/12 [==============================] - 0s 664us/step - loss: 1.0844 - accuracy: 0.4118\n",
      "Epoch 155/300\n",
      "12/12 [==============================] - 0s 583us/step - loss: 1.0846 - accuracy: 0.4118\n",
      "Epoch 156/300\n",
      "12/12 [==============================] - 0s 627us/step - loss: 1.0852 - accuracy: 0.4118\n",
      "Epoch 157/300\n",
      "12/12 [==============================] - 0s 502us/step - loss: 1.0854 - accuracy: 0.4118\n",
      "Epoch 158/300\n",
      "12/12 [==============================] - 0s 667us/step - loss: 1.0853 - accuracy: 0.4118\n",
      "Epoch 159/300\n",
      "12/12 [==============================] - 0s 583us/step - loss: 1.0844 - accuracy: 0.4118\n",
      "Epoch 160/300\n",
      "12/12 [==============================] - 0s 583us/step - loss: 1.0846 - accuracy: 0.4118\n",
      "Epoch 161/300\n",
      "12/12 [==============================] - 0s 627us/step - loss: 1.0848 - accuracy: 0.4118\n",
      "Epoch 162/300\n",
      "12/12 [==============================] - 0s 582us/step - loss: 1.0848 - accuracy: 0.4118\n",
      "Epoch 163/300\n",
      "12/12 [==============================] - 0s 665us/step - loss: 1.0884 - accuracy: 0.4118\n",
      "Epoch 164/300\n",
      "12/12 [==============================] - 0s 585us/step - loss: 1.0872 - accuracy: 0.4118\n",
      "Epoch 165/300\n",
      "12/12 [==============================] - 0s 667us/step - loss: 1.0843 - accuracy: 0.4118\n",
      "Epoch 166/300\n",
      "12/12 [==============================] - 0s 667us/step - loss: 1.0845 - accuracy: 0.4118\n",
      "Epoch 167/300\n",
      "12/12 [==============================] - 0s 583us/step - loss: 1.0859 - accuracy: 0.4118\n",
      "Epoch 168/300\n",
      "12/12 [==============================] - 0s 667us/step - loss: 1.0853 - accuracy: 0.4118\n",
      "Epoch 169/300\n",
      "12/12 [==============================] - 0s 583us/step - loss: 1.0848 - accuracy: 0.4118\n",
      "Epoch 170/300\n",
      "12/12 [==============================] - 0s 583us/step - loss: 1.0847 - accuracy: 0.4118\n",
      "Epoch 171/300\n",
      "12/12 [==============================] - 0s 581us/step - loss: 1.0849 - accuracy: 0.4118\n",
      "Epoch 172/300\n",
      "12/12 [==============================] - 0s 667us/step - loss: 1.0841 - accuracy: 0.4118\n",
      "Epoch 173/300\n",
      "12/12 [==============================] - 0s 667us/step - loss: 1.0847 - accuracy: 0.4118\n",
      "Epoch 174/300\n",
      "12/12 [==============================] - 0s 583us/step - loss: 1.0851 - accuracy: 0.4118\n",
      "Epoch 175/300\n",
      "12/12 [==============================] - 0s 583us/step - loss: 1.0848 - accuracy: 0.4118\n",
      "Epoch 176/300\n",
      "12/12 [==============================] - 0s 583us/step - loss: 1.0850 - accuracy: 0.4118\n",
      "Epoch 177/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12/12 [==============================] - 0s 667us/step - loss: 1.0840 - accuracy: 0.4118\n",
      "Epoch 178/300\n",
      "12/12 [==============================] - 0s 583us/step - loss: 1.0849 - accuracy: 0.4118\n",
      "Epoch 179/300\n",
      "12/12 [==============================] - 0s 667us/step - loss: 1.0843 - accuracy: 0.4118\n",
      "Epoch 180/300\n",
      "12/12 [==============================] - 0s 667us/step - loss: 1.0847 - accuracy: 0.4118\n",
      "Epoch 181/300\n",
      "12/12 [==============================] - 0s 581us/step - loss: 1.0859 - accuracy: 0.4118\n",
      "Epoch 182/300\n",
      "12/12 [==============================] - 0s 624us/step - loss: 1.0849 - accuracy: 0.4118\n",
      "Epoch 183/300\n",
      "12/12 [==============================] - 0s 665us/step - loss: 1.0860 - accuracy: 0.4118\n",
      "Epoch 184/300\n",
      "12/12 [==============================] - 0s 586us/step - loss: 1.0853 - accuracy: 0.4118\n",
      "Epoch 185/300\n",
      "12/12 [==============================] - 0s 583us/step - loss: 1.0854 - accuracy: 0.4118\n",
      "Epoch 186/300\n",
      "12/12 [==============================] - 0s 583us/step - loss: 1.0857 - accuracy: 0.4118\n",
      "Epoch 187/300\n",
      "12/12 [==============================] - 0s 667us/step - loss: 1.0843 - accuracy: 0.4118\n",
      "Epoch 188/300\n",
      "12/12 [==============================] - 0s 581us/step - loss: 1.0854 - accuracy: 0.4118\n",
      "Epoch 189/300\n",
      "12/12 [==============================] - 0s 583us/step - loss: 1.0850 - accuracy: 0.4118\n",
      "Epoch 190/300\n",
      "12/12 [==============================] - 0s 583us/step - loss: 1.0842 - accuracy: 0.4118\n",
      "Epoch 191/300\n",
      "12/12 [==============================] - 0s 585us/step - loss: 1.0852 - accuracy: 0.4118\n",
      "Epoch 192/300\n",
      "12/12 [==============================] - 0s 750us/step - loss: 1.0839 - accuracy: 0.4118\n",
      "Epoch 193/300\n",
      "12/12 [==============================] - 0s 580us/step - loss: 1.0849 - accuracy: 0.4118\n",
      "Epoch 194/300\n",
      "12/12 [==============================] - 0s 586us/step - loss: 1.0841 - accuracy: 0.4118\n",
      "Epoch 195/300\n",
      "12/12 [==============================] - 0s 583us/step - loss: 1.0846 - accuracy: 0.4118\n",
      "Epoch 196/300\n",
      "12/12 [==============================] - 0s 664us/step - loss: 1.0850 - accuracy: 0.4118\n",
      "Epoch 197/300\n",
      "12/12 [==============================] - 0s 664us/step - loss: 1.0842 - accuracy: 0.4118\n",
      "Epoch 198/300\n",
      "12/12 [==============================] - 0s 583us/step - loss: 1.0843 - accuracy: 0.4118\n",
      "Epoch 199/300\n",
      "12/12 [==============================] - 0s 665us/step - loss: 1.0858 - accuracy: 0.4118\n",
      "Epoch 200/300\n",
      "12/12 [==============================] - 0s 500us/step - loss: 1.0851 - accuracy: 0.4118\n",
      "Epoch 201/300\n",
      "12/12 [==============================] - 0s 668us/step - loss: 1.0841 - accuracy: 0.4118\n",
      "Epoch 202/300\n",
      "12/12 [==============================] - 0s 583us/step - loss: 1.0846 - accuracy: 0.4118\n",
      "Epoch 203/300\n",
      "12/12 [==============================] - 0s 586us/step - loss: 1.0846 - accuracy: 0.4118\n",
      "Epoch 204/300\n",
      "12/12 [==============================] - 0s 583us/step - loss: 1.0844 - accuracy: 0.4118\n",
      "Epoch 205/300\n",
      "12/12 [==============================] - 0s 585us/step - loss: 1.0857 - accuracy: 0.4118\n",
      "Epoch 206/300\n",
      "12/12 [==============================] - 0s 583us/step - loss: 1.0844 - accuracy: 0.4118\n",
      "Epoch 207/300\n",
      "12/12 [==============================] - 0s 584us/step - loss: 1.0846 - accuracy: 0.4118\n",
      "Epoch 208/300\n",
      "12/12 [==============================] - 0s 667us/step - loss: 1.0870 - accuracy: 0.4118\n",
      "Epoch 209/300\n",
      "12/12 [==============================] - 0s 583us/step - loss: 1.0862 - accuracy: 0.4118\n",
      "Epoch 210/300\n",
      "12/12 [==============================] - 0s 585us/step - loss: 1.0849 - accuracy: 0.4118\n",
      "Epoch 211/300\n",
      "12/12 [==============================] - 0s 665us/step - loss: 1.0846 - accuracy: 0.4118\n",
      "Epoch 212/300\n",
      "12/12 [==============================] - 0s 583us/step - loss: 1.0847 - accuracy: 0.4118\n",
      "Epoch 213/300\n",
      "12/12 [==============================] - 0s 750us/step - loss: 1.0857 - accuracy: 0.4118\n",
      "Epoch 214/300\n",
      "12/12 [==============================] - 0s 500us/step - loss: 1.0851 - accuracy: 0.4118\n",
      "Epoch 215/300\n",
      "12/12 [==============================] - 0s 581us/step - loss: 1.0847 - accuracy: 0.4118\n",
      "Epoch 216/300\n",
      "12/12 [==============================] - 0s 583us/step - loss: 1.0857 - accuracy: 0.4118\n",
      "Epoch 217/300\n",
      "12/12 [==============================] - 0s 586us/step - loss: 1.0844 - accuracy: 0.4118\n",
      "Epoch 218/300\n",
      "12/12 [==============================] - 0s 583us/step - loss: 1.0853 - accuracy: 0.4118\n",
      "Epoch 219/300\n",
      "12/12 [==============================] - 0s 583us/step - loss: 1.0852 - accuracy: 0.4118\n",
      "Epoch 220/300\n",
      "12/12 [==============================] - 0s 581us/step - loss: 1.0853 - accuracy: 0.4118\n",
      "Epoch 221/300\n",
      "12/12 [==============================] - 0s 665us/step - loss: 1.0845 - accuracy: 0.4118\n",
      "Epoch 222/300\n",
      "12/12 [==============================] - 0s 669us/step - loss: 1.0851 - accuracy: 0.4118\n",
      "Epoch 223/300\n",
      "12/12 [==============================] - 0s 667us/step - loss: 1.0871 - accuracy: 0.4118\n",
      "Epoch 224/300\n",
      "12/12 [==============================] - 0s 583us/step - loss: 1.0846 - accuracy: 0.4118\n",
      "Epoch 225/300\n",
      "12/12 [==============================] - 0s 667us/step - loss: 1.0841 - accuracy: 0.4118\n",
      "Epoch 226/300\n",
      "12/12 [==============================] - 0s 581us/step - loss: 1.0838 - accuracy: 0.4118\n",
      "Epoch 227/300\n",
      "12/12 [==============================] - 0s 664us/step - loss: 1.0848 - accuracy: 0.4118\n",
      "Epoch 228/300\n",
      "12/12 [==============================] - 0s 581us/step - loss: 1.0850 - accuracy: 0.4118\n",
      "Epoch 229/300\n",
      "12/12 [==============================] - 0s 583us/step - loss: 1.0844 - accuracy: 0.4118\n",
      "Epoch 230/300\n",
      "12/12 [==============================] - 0s 666us/step - loss: 1.0857 - accuracy: 0.4118\n",
      "Epoch 231/300\n",
      "12/12 [==============================] - 0s 583us/step - loss: 1.0850 - accuracy: 0.4118\n",
      "Epoch 232/300\n",
      "12/12 [==============================] - 0s 665us/step - loss: 1.0858 - accuracy: 0.4118\n",
      "Epoch 233/300\n",
      "12/12 [==============================] - 0s 583us/step - loss: 1.0855 - accuracy: 0.4118\n",
      "Epoch 234/300\n",
      "12/12 [==============================] - 0s 584us/step - loss: 1.0863 - accuracy: 0.4118\n",
      "Epoch 235/300\n",
      "12/12 [==============================] - 0s 667us/step - loss: 1.0841 - accuracy: 0.4118\n",
      "Epoch 236/300\n",
      "12/12 [==============================] - 0s 586us/step - loss: 1.0865 - accuracy: 0.4118\n",
      "Epoch 237/300\n",
      "12/12 [==============================] - 0s 583us/step - loss: 1.0857 - accuracy: 0.4118\n",
      "Epoch 238/300\n",
      "12/12 [==============================] - 0s 583us/step - loss: 1.0840 - accuracy: 0.4118\n",
      "Epoch 239/300\n",
      "12/12 [==============================] - 0s 665us/step - loss: 1.0851 - accuracy: 0.4118\n",
      "Epoch 240/300\n",
      "12/12 [==============================] - 0s 665us/step - loss: 1.0841 - accuracy: 0.4118\n",
      "Epoch 241/300\n",
      "12/12 [==============================] - 0s 581us/step - loss: 1.0840 - accuracy: 0.4118\n",
      "Epoch 242/300\n",
      "12/12 [==============================] - 0s 606us/step - loss: 1.0861 - accuracy: 0.4118\n",
      "Epoch 243/300\n",
      "12/12 [==============================] - 0s 582us/step - loss: 1.0841 - accuracy: 0.4118\n",
      "Epoch 244/300\n",
      "12/12 [==============================] - 0s 583us/step - loss: 1.0855 - accuracy: 0.4118\n",
      "Epoch 245/300\n",
      "12/12 [==============================] - 0s 580us/step - loss: 1.0845 - accuracy: 0.4118\n",
      "Epoch 246/300\n",
      "12/12 [==============================] - 0s 669us/step - loss: 1.0859 - accuracy: 0.4118\n",
      "Epoch 247/300\n",
      "12/12 [==============================] - 0s 583us/step - loss: 1.0860 - accuracy: 0.4118\n",
      "Epoch 248/300\n",
      "12/12 [==============================] - 0s 583us/step - loss: 1.0839 - accuracy: 0.4118\n",
      "Epoch 249/300\n",
      "12/12 [==============================] - 0s 583us/step - loss: 1.0846 - accuracy: 0.4118\n",
      "Epoch 250/300\n",
      "12/12 [==============================] - 0s 583us/step - loss: 1.0850 - accuracy: 0.4118\n",
      "Epoch 251/300\n",
      "12/12 [==============================] - 0s 586us/step - loss: 1.0862 - accuracy: 0.4118\n",
      "Epoch 252/300\n",
      "12/12 [==============================] - 0s 584us/step - loss: 1.0846 - accuracy: 0.4118\n",
      "Epoch 253/300\n",
      "12/12 [==============================] - 0s 586us/step - loss: 1.0847 - accuracy: 0.4118\n",
      "Epoch 254/300\n",
      "12/12 [==============================] - 0s 664us/step - loss: 1.0843 - accuracy: 0.4118\n",
      "Epoch 255/300\n",
      "12/12 [==============================] - 0s 584us/step - loss: 1.0849 - accuracy: 0.4118\n",
      "Epoch 256/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12/12 [==============================] - 0s 667us/step - loss: 1.0841 - accuracy: 0.4118\n",
      "Epoch 257/300\n",
      "12/12 [==============================] - 0s 583us/step - loss: 1.0854 - accuracy: 0.4118\n",
      "Epoch 258/300\n",
      "12/12 [==============================] - 0s 583us/step - loss: 1.0850 - accuracy: 0.4118\n",
      "Epoch 259/300\n",
      "12/12 [==============================] - 0s 667us/step - loss: 1.0850 - accuracy: 0.4118\n",
      "Epoch 260/300\n",
      "12/12 [==============================] - 0s 583us/step - loss: 1.0850 - accuracy: 0.4118\n",
      "Epoch 261/300\n",
      "12/12 [==============================] - 0s 585us/step - loss: 1.0857 - accuracy: 0.4118\n",
      "Epoch 262/300\n",
      "12/12 [==============================] - 0s 667us/step - loss: 1.0862 - accuracy: 0.4118\n",
      "Epoch 263/300\n",
      "12/12 [==============================] - 0s 583us/step - loss: 1.0839 - accuracy: 0.4118\n",
      "Epoch 264/300\n",
      "12/12 [==============================] - 0s 583us/step - loss: 1.0851 - accuracy: 0.4118\n",
      "Epoch 265/300\n",
      "12/12 [==============================] - 0s 499us/step - loss: 1.0848 - accuracy: 0.4118\n",
      "Epoch 266/300\n",
      "12/12 [==============================] - 0s 592us/step - loss: 1.0847 - accuracy: 0.4118\n",
      "Epoch 267/300\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 1.0846 - accuracy: 0.4118\n",
      "Epoch 268/300\n",
      "12/12 [==============================] - 0s 667us/step - loss: 1.0840 - accuracy: 0.4118\n",
      "Epoch 269/300\n",
      "12/12 [==============================] - 0s 667us/step - loss: 1.0859 - accuracy: 0.4118\n",
      "Epoch 270/300\n",
      "12/12 [==============================] - 0s 666us/step - loss: 1.0846 - accuracy: 0.4118\n",
      "Epoch 271/300\n",
      "12/12 [==============================] - 0s 583us/step - loss: 1.0850 - accuracy: 0.4118\n",
      "Epoch 272/300\n",
      "12/12 [==============================] - 0s 586us/step - loss: 1.0845 - accuracy: 0.4118\n",
      "Epoch 273/300\n",
      "12/12 [==============================] - 0s 500us/step - loss: 1.0858 - accuracy: 0.4118\n",
      "Epoch 274/300\n",
      "12/12 [==============================] - 0s 667us/step - loss: 1.0871 - accuracy: 0.4118\n",
      "Epoch 275/300\n",
      "12/12 [==============================] - 0s 586us/step - loss: 1.0841 - accuracy: 0.4118\n",
      "Epoch 276/300\n",
      "12/12 [==============================] - 0s 581us/step - loss: 1.0844 - accuracy: 0.4118\n",
      "Epoch 277/300\n",
      "12/12 [==============================] - 0s 667us/step - loss: 1.0845 - accuracy: 0.4118\n",
      "Epoch 278/300\n",
      "12/12 [==============================] - 0s 500us/step - loss: 1.0843 - accuracy: 0.4118\n",
      "Epoch 279/300\n",
      "12/12 [==============================] - 0s 586us/step - loss: 1.0857 - accuracy: 0.4118\n",
      "Epoch 280/300\n",
      "12/12 [==============================] - 0s 583us/step - loss: 1.0860 - accuracy: 0.4118\n",
      "Epoch 281/300\n",
      "12/12 [==============================] - 0s 585us/step - loss: 1.0848 - accuracy: 0.4118\n",
      "Epoch 282/300\n",
      "12/12 [==============================] - 0s 664us/step - loss: 1.0850 - accuracy: 0.4118\n",
      "Epoch 283/300\n",
      "12/12 [==============================] - 0s 500us/step - loss: 1.0851 - accuracy: 0.4118\n",
      "Epoch 284/300\n",
      "12/12 [==============================] - 0s 669us/step - loss: 1.0843 - accuracy: 0.4118\n",
      "Epoch 285/300\n",
      "12/12 [==============================] - 0s 581us/step - loss: 1.0844 - accuracy: 0.4118\n",
      "Epoch 286/300\n",
      "12/12 [==============================] - 0s 586us/step - loss: 1.0839 - accuracy: 0.4118\n",
      "Epoch 287/300\n",
      "12/12 [==============================] - 0s 585us/step - loss: 1.0840 - accuracy: 0.4118\n",
      "Epoch 288/300\n",
      "12/12 [==============================] - 0s 583us/step - loss: 1.0855 - accuracy: 0.4118\n",
      "Epoch 289/300\n",
      "12/12 [==============================] - 0s 664us/step - loss: 1.0845 - accuracy: 0.4118\n",
      "Epoch 290/300\n",
      "12/12 [==============================] - 0s 581us/step - loss: 1.0863 - accuracy: 0.4118\n",
      "Epoch 291/300\n",
      "12/12 [==============================] - 0s 667us/step - loss: 1.0844 - accuracy: 0.4118\n",
      "Epoch 292/300\n",
      "12/12 [==============================] - 0s 586us/step - loss: 1.0837 - accuracy: 0.4118\n",
      "Epoch 293/300\n",
      "12/12 [==============================] - 0s 583us/step - loss: 1.0852 - accuracy: 0.4118\n",
      "Epoch 294/300\n",
      "12/12 [==============================] - 0s 667us/step - loss: 1.0844 - accuracy: 0.4118\n",
      "Epoch 295/300\n",
      "12/12 [==============================] - 0s 585us/step - loss: 1.0838 - accuracy: 0.4118\n",
      "Epoch 296/300\n",
      "12/12 [==============================] - 0s 664us/step - loss: 1.0847 - accuracy: 0.4118\n",
      "Epoch 297/300\n",
      "12/12 [==============================] - 0s 583us/step - loss: 1.0850 - accuracy: 0.4118\n",
      "Epoch 298/300\n",
      "12/12 [==============================] - 0s 583us/step - loss: 1.0856 - accuracy: 0.4118\n",
      "Epoch 299/300\n",
      "12/12 [==============================] - 0s 669us/step - loss: 1.0862 - accuracy: 0.4118\n",
      "Epoch 300/300\n",
      "12/12 [==============================] - 0s 584us/step - loss: 1.0841 - accuracy: 0.4118\n",
      "Epoch 1/300\n",
      "12/12 [==============================] - 0s 583us/step - loss: 1.1132 - accuracy: 0.3697\n",
      "Epoch 2/300\n",
      "12/12 [==============================] - 0s 583us/step - loss: 1.0909 - accuracy: 0.4118\n",
      "Epoch 3/300\n",
      "12/12 [==============================] - 0s 585us/step - loss: 1.0850 - accuracy: 0.4118\n",
      "Epoch 4/300\n",
      "12/12 [==============================] - 0s 583us/step - loss: 1.0842 - accuracy: 0.4118\n",
      "Epoch 5/300\n",
      "12/12 [==============================] - 0s 564us/step - loss: 1.0859 - accuracy: 0.4118\n",
      "Epoch 6/300\n",
      "12/12 [==============================] - 0s 581us/step - loss: 1.0863 - accuracy: 0.4118\n",
      "Epoch 7/300\n",
      "12/12 [==============================] - 0s 586us/step - loss: 1.0857 - accuracy: 0.4118\n",
      "Epoch 8/300\n",
      "12/12 [==============================] - 0s 583us/step - loss: 1.0840 - accuracy: 0.4118\n",
      "Epoch 9/300\n",
      "12/12 [==============================] - 0s 583us/step - loss: 1.0862 - accuracy: 0.4118\n",
      "Epoch 10/300\n",
      "12/12 [==============================] - 0s 583us/step - loss: 1.0863 - accuracy: 0.4118\n",
      "Epoch 11/300\n",
      "12/12 [==============================] - 0s 583us/step - loss: 1.0874 - accuracy: 0.4118\n",
      "Epoch 12/300\n",
      "12/12 [==============================] - 0s 667us/step - loss: 1.0856 - accuracy: 0.4118\n",
      "Epoch 13/300\n",
      "12/12 [==============================] - 0s 667us/step - loss: 1.0854 - accuracy: 0.4118\n",
      "Epoch 14/300\n",
      "12/12 [==============================] - 0s 583us/step - loss: 1.0840 - accuracy: 0.4118\n",
      "Epoch 15/300\n",
      "12/12 [==============================] - 0s 583us/step - loss: 1.0849 - accuracy: 0.4118\n",
      "Epoch 16/300\n",
      "12/12 [==============================] - 0s 583us/step - loss: 1.0849 - accuracy: 0.4118\n",
      "Epoch 17/300\n",
      "12/12 [==============================] - 0s 583us/step - loss: 1.0873 - accuracy: 0.4118\n",
      "Epoch 18/300\n",
      "12/12 [==============================] - 0s 583us/step - loss: 1.0875 - accuracy: 0.4118\n",
      "Epoch 19/300\n",
      "12/12 [==============================] - 0s 583us/step - loss: 1.0859 - accuracy: 0.4118\n",
      "Epoch 20/300\n",
      "12/12 [==============================] - 0s 583us/step - loss: 1.0872 - accuracy: 0.4118\n",
      "Epoch 21/300\n",
      "12/12 [==============================] - 0s 667us/step - loss: 1.0865 - accuracy: 0.4118\n",
      "Epoch 22/300\n",
      "12/12 [==============================] - 0s 667us/step - loss: 1.0843 - accuracy: 0.4118\n",
      "Epoch 23/300\n",
      "12/12 [==============================] - 0s 583us/step - loss: 1.0841 - accuracy: 0.4118\n",
      "Epoch 24/300\n",
      "12/12 [==============================] - 0s 585us/step - loss: 1.0868 - accuracy: 0.4118\n",
      "Epoch 25/300\n",
      "12/12 [==============================] - 0s 599us/step - loss: 1.0860 - accuracy: 0.4118\n",
      "Epoch 26/300\n",
      "12/12 [==============================] - 0s 585us/step - loss: 1.0853 - accuracy: 0.4118\n",
      "Epoch 27/300\n",
      "12/12 [==============================] - 0s 582us/step - loss: 1.0860 - accuracy: 0.4118\n",
      "Epoch 28/300\n",
      "12/12 [==============================] - 0s 502us/step - loss: 1.0869 - accuracy: 0.4118\n",
      "Epoch 29/300\n",
      "12/12 [==============================] - 0s 584us/step - loss: 1.0848 - accuracy: 0.4118\n",
      "Epoch 30/300\n",
      "12/12 [==============================] - 0s 583us/step - loss: 1.0842 - accuracy: 0.4118\n",
      "Epoch 31/300\n",
      "12/12 [==============================] - 0s 586us/step - loss: 1.0844 - accuracy: 0.4118\n",
      "Epoch 32/300\n",
      "12/12 [==============================] - 0s 583us/step - loss: 1.0840 - accuracy: 0.4118\n",
      "Epoch 33/300\n",
      "12/12 [==============================] - 0s 586us/step - loss: 1.0854 - accuracy: 0.4118\n",
      "Epoch 34/300\n",
      "12/12 [==============================] - 0s 667us/step - loss: 1.0849 - accuracy: 0.4118\n",
      "Epoch 35/300\n",
      "12/12 [==============================] - 0s 583us/step - loss: 1.0846 - accuracy: 0.4118\n",
      "Epoch 36/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12/12 [==============================] - 0s 667us/step - loss: 1.0843 - accuracy: 0.4118\n",
      "Epoch 37/300\n",
      "12/12 [==============================] - 0s 583us/step - loss: 1.0840 - accuracy: 0.4118\n",
      "Epoch 38/300\n",
      "12/12 [==============================] - 0s 583us/step - loss: 1.0849 - accuracy: 0.4118\n",
      "Epoch 39/300\n",
      "12/12 [==============================] - 0s 626us/step - loss: 1.0863 - accuracy: 0.4118\n",
      "Epoch 40/300\n",
      "12/12 [==============================] - 0s 583us/step - loss: 1.0840 - accuracy: 0.4118\n",
      "Epoch 41/300\n",
      "12/12 [==============================] - 0s 583us/step - loss: 1.0854 - accuracy: 0.4118\n",
      "Epoch 42/300\n",
      "12/12 [==============================] - 0s 583us/step - loss: 1.0847 - accuracy: 0.4118\n",
      "Epoch 43/300\n",
      "12/12 [==============================] - 0s 666us/step - loss: 1.0854 - accuracy: 0.4118\n",
      "Epoch 44/300\n",
      "12/12 [==============================] - 0s 583us/step - loss: 1.0844 - accuracy: 0.4118\n",
      "Epoch 45/300\n",
      "12/12 [==============================] - 0s 583us/step - loss: 1.0866 - accuracy: 0.4118\n",
      "Epoch 46/300\n",
      "12/12 [==============================] - 0s 750us/step - loss: 1.0840 - accuracy: 0.4118\n",
      "Epoch 47/300\n",
      "12/12 [==============================] - 0s 500us/step - loss: 1.0867 - accuracy: 0.4118\n",
      "Epoch 48/300\n",
      "12/12 [==============================] - 0s 583us/step - loss: 1.0847 - accuracy: 0.4118\n",
      "Epoch 49/300\n",
      "12/12 [==============================] - 0s 581us/step - loss: 1.0882 - accuracy: 0.4118\n",
      "Epoch 50/300\n",
      "12/12 [==============================] - 0s 583us/step - loss: 1.0847 - accuracy: 0.4118\n",
      "Epoch 51/300\n",
      "12/12 [==============================] - 0s 586us/step - loss: 1.0847 - accuracy: 0.4118\n",
      "Epoch 52/300\n",
      "12/12 [==============================] - 0s 586us/step - loss: 1.0847 - accuracy: 0.4118\n",
      "Epoch 53/300\n",
      "12/12 [==============================] - 0s 583us/step - loss: 1.0847 - accuracy: 0.4118\n",
      "Epoch 54/300\n",
      "12/12 [==============================] - 0s 583us/step - loss: 1.0846 - accuracy: 0.4118\n",
      "Epoch 55/300\n",
      "12/12 [==============================] - 0s 531us/step - loss: 1.0870 - accuracy: 0.4118\n",
      "Epoch 56/300\n",
      "12/12 [==============================] - 0s 581us/step - loss: 1.0859 - accuracy: 0.4118\n",
      "Epoch 57/300\n",
      "12/12 [==============================] - 0s 585us/step - loss: 1.0860 - accuracy: 0.4118\n",
      "Epoch 58/300\n",
      "12/12 [==============================] - 0s 665us/step - loss: 1.0862 - accuracy: 0.4118\n",
      "Epoch 59/300\n",
      "12/12 [==============================] - 0s 583us/step - loss: 1.0873 - accuracy: 0.4118\n",
      "Epoch 60/300\n",
      "12/12 [==============================] - 0s 585us/step - loss: 1.0858 - accuracy: 0.4118\n",
      "Epoch 61/300\n",
      "12/12 [==============================] - 0s 583us/step - loss: 1.0856 - accuracy: 0.4118\n",
      "Epoch 62/300\n",
      "12/12 [==============================] - 0s 583us/step - loss: 1.0882 - accuracy: 0.4118\n",
      "Epoch 63/300\n",
      "12/12 [==============================] - 0s 585us/step - loss: 1.0840 - accuracy: 0.4118\n",
      "Epoch 64/300\n",
      "12/12 [==============================] - 0s 583us/step - loss: 1.0853 - accuracy: 0.4118\n",
      "Epoch 65/300\n",
      "12/12 [==============================] - 0s 583us/step - loss: 1.0846 - accuracy: 0.4118\n",
      "Epoch 66/300\n",
      "12/12 [==============================] - 0s 498us/step - loss: 1.0864 - accuracy: 0.4118\n",
      "Epoch 67/300\n",
      "12/12 [==============================] - 0s 585us/step - loss: 1.0852 - accuracy: 0.4118\n",
      "Epoch 68/300\n",
      "12/12 [==============================] - 0s 581us/step - loss: 1.0852 - accuracy: 0.4118\n",
      "Epoch 69/300\n",
      "12/12 [==============================] - 0s 664us/step - loss: 1.0855 - accuracy: 0.4118\n",
      "Epoch 70/300\n",
      "12/12 [==============================] - 0s 583us/step - loss: 1.0858 - accuracy: 0.4118\n",
      "Epoch 71/300\n",
      "12/12 [==============================] - 0s 497us/step - loss: 1.0842 - accuracy: 0.4118\n",
      "Epoch 72/300\n",
      "12/12 [==============================] - 0s 582us/step - loss: 1.0849 - accuracy: 0.4118\n",
      "Epoch 73/300\n",
      "12/12 [==============================] - 0s 665us/step - loss: 1.0848 - accuracy: 0.4118\n",
      "Epoch 74/300\n",
      "12/12 [==============================] - 0s 665us/step - loss: 1.0847 - accuracy: 0.4118\n",
      "Epoch 75/300\n",
      "12/12 [==============================] - 0s 583us/step - loss: 1.0842 - accuracy: 0.4118\n",
      "Epoch 76/300\n",
      "12/12 [==============================] - 0s 583us/step - loss: 1.0855 - accuracy: 0.4118\n",
      "Epoch 77/300\n",
      "12/12 [==============================] - 0s 500us/step - loss: 1.0862 - accuracy: 0.4118\n",
      "Epoch 78/300\n",
      "12/12 [==============================] - 0s 583us/step - loss: 1.0863 - accuracy: 0.4118\n",
      "Epoch 79/300\n",
      "12/12 [==============================] - 0s 667us/step - loss: 1.0855 - accuracy: 0.4118\n",
      "Epoch 80/300\n",
      "12/12 [==============================] - 0s 583us/step - loss: 1.0868 - accuracy: 0.4118\n",
      "Epoch 81/300\n",
      "12/12 [==============================] - 0s 585us/step - loss: 1.0865 - accuracy: 0.4118\n",
      "Epoch 82/300\n",
      "12/12 [==============================] - 0s 500us/step - loss: 1.0862 - accuracy: 0.4118\n",
      "Epoch 83/300\n",
      "12/12 [==============================] - 0s 585us/step - loss: 1.0873 - accuracy: 0.4118\n",
      "Epoch 84/300\n",
      "12/12 [==============================] - 0s 583us/step - loss: 1.0860 - accuracy: 0.4118\n",
      "Epoch 85/300\n",
      "12/12 [==============================] - 0s 585us/step - loss: 1.0854 - accuracy: 0.4118\n",
      "Epoch 86/300\n",
      "12/12 [==============================] - 0s 667us/step - loss: 1.0850 - accuracy: 0.4118\n",
      "Epoch 87/300\n",
      "12/12 [==============================] - 0s 500us/step - loss: 1.0859 - accuracy: 0.4118\n",
      "Epoch 88/300\n",
      "12/12 [==============================] - 0s 586us/step - loss: 1.0864 - accuracy: 0.4118\n",
      "Epoch 89/300\n",
      "12/12 [==============================] - 0s 583us/step - loss: 1.0859 - accuracy: 0.4118\n",
      "Epoch 90/300\n",
      "12/12 [==============================] - 0s 667us/step - loss: 1.0904 - accuracy: 0.4118\n",
      "Epoch 91/300\n",
      "12/12 [==============================] - 0s 583us/step - loss: 1.0846 - accuracy: 0.4118\n",
      "Epoch 92/300\n",
      "12/12 [==============================] - 0s 585us/step - loss: 1.0846 - accuracy: 0.4118\n",
      "Epoch 93/300\n",
      "12/12 [==============================] - 0s 667us/step - loss: 1.0854 - accuracy: 0.4118\n",
      "Epoch 94/300\n",
      "12/12 [==============================] - 0s 583us/step - loss: 1.0843 - accuracy: 0.4118\n",
      "Epoch 95/300\n",
      "12/12 [==============================] - 0s 583us/step - loss: 1.0858 - accuracy: 0.4118\n",
      "Epoch 96/300\n",
      "12/12 [==============================] - 0s 627us/step - loss: 1.0864 - accuracy: 0.4118\n",
      "Epoch 97/300\n",
      "12/12 [==============================] - 0s 667us/step - loss: 1.0849 - accuracy: 0.4118\n",
      "Epoch 98/300\n",
      "12/12 [==============================] - 0s 583us/step - loss: 1.0853 - accuracy: 0.4118\n",
      "Epoch 99/300\n",
      "12/12 [==============================] - 0s 586us/step - loss: 1.0872 - accuracy: 0.4118\n",
      "Epoch 100/300\n",
      "12/12 [==============================] - 0s 669us/step - loss: 1.0853 - accuracy: 0.4118\n",
      "Epoch 101/300\n",
      "12/12 [==============================] - 0s 584us/step - loss: 1.0866 - accuracy: 0.4118\n",
      "Epoch 102/300\n",
      "12/12 [==============================] - 0s 583us/step - loss: 1.0853 - accuracy: 0.4118\n",
      "Epoch 103/300\n",
      "12/12 [==============================] - 0s 665us/step - loss: 1.0847 - accuracy: 0.4118\n",
      "Epoch 104/300\n",
      "12/12 [==============================] - 0s 586us/step - loss: 1.0887 - accuracy: 0.4118\n",
      "Epoch 105/300\n",
      "12/12 [==============================] - 0s 666us/step - loss: 1.0835 - accuracy: 0.4118\n",
      "Epoch 106/300\n",
      "12/12 [==============================] - 0s 585us/step - loss: 1.0858 - accuracy: 0.4118\n",
      "Epoch 107/300\n",
      "12/12 [==============================] - 0s 667us/step - loss: 1.0854 - accuracy: 0.4118\n",
      "Epoch 108/300\n",
      "12/12 [==============================] - 0s 581us/step - loss: 1.0851 - accuracy: 0.4118\n",
      "Epoch 109/300\n",
      "12/12 [==============================] - 0s 665us/step - loss: 1.0860 - accuracy: 0.4118\n",
      "Epoch 110/300\n",
      "12/12 [==============================] - 0s 584us/step - loss: 1.0837 - accuracy: 0.4118\n",
      "Epoch 111/300\n",
      "12/12 [==============================] - 0s 583us/step - loss: 1.0864 - accuracy: 0.4118\n",
      "Epoch 112/300\n",
      "12/12 [==============================] - 0s 583us/step - loss: 1.0865 - accuracy: 0.4118\n",
      "Epoch 113/300\n",
      "12/12 [==============================] - 0s 583us/step - loss: 1.0847 - accuracy: 0.4118\n",
      "Epoch 114/300\n",
      "12/12 [==============================] - 0s 583us/step - loss: 1.0856 - accuracy: 0.4118\n",
      "Epoch 115/300\n",
      "12/12 [==============================] - 0s 581us/step - loss: 1.0863 - accuracy: 0.4118\n",
      "Epoch 116/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12/12 [==============================] - 0s 664us/step - loss: 1.0848 - accuracy: 0.4118\n",
      "Epoch 117/300\n",
      "12/12 [==============================] - 0s 583us/step - loss: 1.0852 - accuracy: 0.4118\n",
      "Epoch 118/300\n",
      "12/12 [==============================] - 0s 667us/step - loss: 1.0853 - accuracy: 0.4118\n",
      "Epoch 119/300\n",
      "12/12 [==============================] - 0s 667us/step - loss: 1.0844 - accuracy: 0.4118\n",
      "Epoch 120/300\n",
      "12/12 [==============================] - 0s 581us/step - loss: 1.0857 - accuracy: 0.4118\n",
      "Epoch 121/300\n",
      "12/12 [==============================] - 0s 583us/step - loss: 1.0846 - accuracy: 0.4118\n",
      "Epoch 122/300\n",
      "12/12 [==============================] - 0s 667us/step - loss: 1.0864 - accuracy: 0.4118\n",
      "Epoch 123/300\n",
      "12/12 [==============================] - 0s 500us/step - loss: 1.0843 - accuracy: 0.4118\n",
      "Epoch 124/300\n",
      "12/12 [==============================] - 0s 669us/step - loss: 1.0856 - accuracy: 0.4118\n",
      "Epoch 125/300\n",
      "12/12 [==============================] - 0s 583us/step - loss: 1.0842 - accuracy: 0.4118\n",
      "Epoch 126/300\n",
      "12/12 [==============================] - 0s 583us/step - loss: 1.0864 - accuracy: 0.4118\n",
      "Epoch 127/300\n",
      "12/12 [==============================] - 0s 583us/step - loss: 1.0841 - accuracy: 0.4118\n",
      "Epoch 128/300\n",
      "12/12 [==============================] - 0s 583us/step - loss: 1.0853 - accuracy: 0.4118\n",
      "Epoch 129/300\n",
      "12/12 [==============================] - 0s 750us/step - loss: 1.0852 - accuracy: 0.4118\n",
      "Epoch 130/300\n",
      "12/12 [==============================] - 0s 500us/step - loss: 1.0852 - accuracy: 0.4118\n",
      "Epoch 131/300\n",
      "12/12 [==============================] - 0s 583us/step - loss: 1.0850 - accuracy: 0.4118\n",
      "Epoch 132/300\n",
      "12/12 [==============================] - 0s 583us/step - loss: 1.0859 - accuracy: 0.4118\n",
      "Epoch 133/300\n",
      "12/12 [==============================] - 0s 669us/step - loss: 1.0837 - accuracy: 0.4118\n",
      "Epoch 134/300\n",
      "12/12 [==============================] - 0s 585us/step - loss: 1.0879 - accuracy: 0.4118\n",
      "Epoch 135/300\n",
      "12/12 [==============================] - 0s 581us/step - loss: 1.0886 - accuracy: 0.4118\n",
      "Epoch 136/300\n",
      "12/12 [==============================] - 0s 500us/step - loss: 1.0854 - accuracy: 0.4118\n",
      "Epoch 137/300\n",
      "12/12 [==============================] - 0s 583us/step - loss: 1.0859 - accuracy: 0.4118\n",
      "Epoch 138/300\n",
      "12/12 [==============================] - 0s 629us/step - loss: 1.0851 - accuracy: 0.4118\n",
      "Epoch 139/300\n",
      "12/12 [==============================] - 0s 667us/step - loss: 1.0844 - accuracy: 0.4118\n",
      "Epoch 140/300\n",
      "12/12 [==============================] - 0s 583us/step - loss: 1.0855 - accuracy: 0.4118\n",
      "Epoch 141/300\n",
      "12/12 [==============================] - 0s 585us/step - loss: 1.0856 - accuracy: 0.4118\n",
      "Epoch 142/300\n",
      "12/12 [==============================] - 0s 581us/step - loss: 1.0844 - accuracy: 0.4118\n",
      "Epoch 143/300\n",
      "12/12 [==============================] - 0s 502us/step - loss: 1.0861 - accuracy: 0.4118\n",
      "Epoch 144/300\n",
      "12/12 [==============================] - 0s 584us/step - loss: 1.0853 - accuracy: 0.4118\n",
      "Epoch 145/300\n",
      "12/12 [==============================] - 0s 585us/step - loss: 1.0855 - accuracy: 0.4118\n",
      "Epoch 146/300\n",
      "12/12 [==============================] - 0s 583us/step - loss: 1.0853 - accuracy: 0.4118\n",
      "Epoch 147/300\n",
      "12/12 [==============================] - 0s 667us/step - loss: 1.0861 - accuracy: 0.4118\n",
      "Epoch 148/300\n",
      "12/12 [==============================] - 0s 748us/step - loss: 1.0857 - accuracy: 0.4118\n",
      "Epoch 149/300\n",
      "12/12 [==============================] - 0s 500us/step - loss: 1.0866 - accuracy: 0.4118\n",
      "Epoch 150/300\n",
      "12/12 [==============================] - 0s 583us/step - loss: 1.0849 - accuracy: 0.4118\n",
      "Epoch 151/300\n",
      "12/12 [==============================] - 0s 667us/step - loss: 1.0845 - accuracy: 0.4118\n",
      "Epoch 152/300\n",
      "12/12 [==============================] - 0s 667us/step - loss: 1.0842 - accuracy: 0.4118\n",
      "Epoch 153/300\n",
      "12/12 [==============================] - 0s 583us/step - loss: 1.0853 - accuracy: 0.4118\n",
      "Epoch 154/300\n",
      "12/12 [==============================] - 0s 502us/step - loss: 1.0856 - accuracy: 0.4118\n",
      "Epoch 155/300\n",
      "12/12 [==============================] - 0s 567us/step - loss: 1.0854 - accuracy: 0.4118\n",
      "Epoch 156/300\n",
      "12/12 [==============================] - 0s 583us/step - loss: 1.0847 - accuracy: 0.4118\n",
      "Epoch 157/300\n",
      "12/12 [==============================] - 0s 667us/step - loss: 1.0881 - accuracy: 0.4118\n",
      "Epoch 158/300\n",
      "12/12 [==============================] - 0s 586us/step - loss: 1.0908 - accuracy: 0.4118\n",
      "Epoch 159/300\n",
      "12/12 [==============================] - 0s 583us/step - loss: 1.0863 - accuracy: 0.4118\n",
      "Epoch 160/300\n",
      "12/12 [==============================] - 0s 583us/step - loss: 1.0851 - accuracy: 0.4118\n",
      "Epoch 161/300\n",
      "12/12 [==============================] - 0s 583us/step - loss: 1.0864 - accuracy: 0.4118\n",
      "Epoch 162/300\n",
      "12/12 [==============================] - 0s 585us/step - loss: 1.0874 - accuracy: 0.4118\n",
      "Epoch 163/300\n",
      "12/12 [==============================] - 0s 581us/step - loss: 1.0842 - accuracy: 0.4118\n",
      "Epoch 164/300\n",
      "12/12 [==============================] - 0s 585us/step - loss: 1.0841 - accuracy: 0.4118\n",
      "Epoch 165/300\n",
      "12/12 [==============================] - 0s 585us/step - loss: 1.0854 - accuracy: 0.4118\n",
      "Epoch 166/300\n",
      "12/12 [==============================] - 0s 583us/step - loss: 1.0862 - accuracy: 0.4118\n",
      "Epoch 167/300\n",
      "12/12 [==============================] - 0s 667us/step - loss: 1.0853 - accuracy: 0.4118\n",
      "Epoch 168/300\n",
      "12/12 [==============================] - 0s 583us/step - loss: 1.0853 - accuracy: 0.4118\n",
      "Epoch 169/300\n",
      "12/12 [==============================] - 0s 581us/step - loss: 1.0848 - accuracy: 0.4118\n",
      "Epoch 170/300\n",
      "12/12 [==============================] - 0s 581us/step - loss: 1.0892 - accuracy: 0.4118\n",
      "Epoch 171/300\n",
      "12/12 [==============================] - 0s 643us/step - loss: 1.0846 - accuracy: 0.4118\n",
      "Epoch 172/300\n",
      "12/12 [==============================] - 0s 583us/step - loss: 1.0863 - accuracy: 0.4118\n",
      "Epoch 173/300\n",
      "12/12 [==============================] - 0s 584us/step - loss: 1.0849 - accuracy: 0.4118\n",
      "Epoch 174/300\n",
      "12/12 [==============================] - 0s 586us/step - loss: 1.0841 - accuracy: 0.4118\n",
      "Epoch 175/300\n",
      "12/12 [==============================] - 0s 583us/step - loss: 1.0854 - accuracy: 0.4118\n",
      "Epoch 176/300\n",
      "12/12 [==============================] - 0s 583us/step - loss: 1.0861 - accuracy: 0.4118\n",
      "Epoch 177/300\n",
      "12/12 [==============================] - 0s 586us/step - loss: 1.0847 - accuracy: 0.4118\n",
      "Epoch 178/300\n",
      "12/12 [==============================] - 0s 668us/step - loss: 1.0870 - accuracy: 0.4118\n",
      "Epoch 179/300\n",
      "12/12 [==============================] - 0s 667us/step - loss: 1.0849 - accuracy: 0.4118\n",
      "Epoch 180/300\n",
      "12/12 [==============================] - 0s 583us/step - loss: 1.0852 - accuracy: 0.4118\n",
      "Epoch 181/300\n",
      "12/12 [==============================] - 0s 586us/step - loss: 1.0854 - accuracy: 0.4118\n",
      "Epoch 182/300\n",
      "12/12 [==============================] - 0s 583us/step - loss: 1.0895 - accuracy: 0.4118\n",
      "Epoch 183/300\n",
      "12/12 [==============================] - 0s 583us/step - loss: 1.0845 - accuracy: 0.4118\n",
      "Epoch 184/300\n",
      "12/12 [==============================] - 0s 665us/step - loss: 1.0841 - accuracy: 0.4118\n",
      "Epoch 185/300\n",
      "12/12 [==============================] - 0s 583us/step - loss: 1.0857 - accuracy: 0.4118\n",
      "Epoch 186/300\n",
      "12/12 [==============================] - 0s 583us/step - loss: 1.0844 - accuracy: 0.4118\n",
      "Epoch 187/300\n",
      "12/12 [==============================] - 0s 667us/step - loss: 1.0845 - accuracy: 0.4118\n",
      "Epoch 188/300\n",
      "12/12 [==============================] - 0s 585us/step - loss: 1.0852 - accuracy: 0.4118\n",
      "Epoch 189/300\n",
      "12/12 [==============================] - 0s 581us/step - loss: 1.0854 - accuracy: 0.4118\n",
      "Epoch 190/300\n",
      "12/12 [==============================] - 0s 583us/step - loss: 1.0836 - accuracy: 0.4118\n",
      "Epoch 191/300\n",
      "12/12 [==============================] - 0s 667us/step - loss: 1.0858 - accuracy: 0.4118\n",
      "Epoch 192/300\n",
      "12/12 [==============================] - 0s 500us/step - loss: 1.0861 - accuracy: 0.4118\n",
      "Epoch 193/300\n",
      "12/12 [==============================] - 0s 669us/step - loss: 1.0881 - accuracy: 0.4118\n",
      "Epoch 194/300\n",
      "12/12 [==============================] - 0s 584us/step - loss: 1.0858 - accuracy: 0.4118\n",
      "Epoch 195/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12/12 [==============================] - 0s 583us/step - loss: 1.0853 - accuracy: 0.4118\n",
      "Epoch 196/300\n",
      "12/12 [==============================] - 0s 583us/step - loss: 1.0846 - accuracy: 0.4118\n",
      "Epoch 197/300\n",
      "12/12 [==============================] - 0s 585us/step - loss: 1.0859 - accuracy: 0.4118\n",
      "Epoch 198/300\n",
      "12/12 [==============================] - 0s 583us/step - loss: 1.0853 - accuracy: 0.4118\n",
      "Epoch 199/300\n",
      "12/12 [==============================] - 0s 639us/step - loss: 1.0857 - accuracy: 0.4118\n",
      "Epoch 200/300\n",
      "12/12 [==============================] - 0s 500us/step - loss: 1.0872 - accuracy: 0.4118\n",
      "Epoch 201/300\n",
      "12/12 [==============================] - 0s 665us/step - loss: 1.0895 - accuracy: 0.4118\n",
      "Epoch 202/300\n",
      "12/12 [==============================] - 0s 581us/step - loss: 1.0840 - accuracy: 0.4118\n",
      "Epoch 203/300\n",
      "12/12 [==============================] - 0s 586us/step - loss: 1.0862 - accuracy: 0.4118\n",
      "Epoch 204/300\n",
      "12/12 [==============================] - 0s 583us/step - loss: 1.0888 - accuracy: 0.4118\n",
      "Epoch 205/300\n",
      "12/12 [==============================] - 0s 582us/step - loss: 1.0864 - accuracy: 0.4118\n",
      "Epoch 206/300\n",
      "12/12 [==============================] - 0s 583us/step - loss: 1.0852 - accuracy: 0.4118\n",
      "Epoch 207/300\n",
      "12/12 [==============================] - 0s 583us/step - loss: 1.0850 - accuracy: 0.4118\n",
      "Epoch 208/300\n",
      "12/12 [==============================] - 0s 665us/step - loss: 1.0864 - accuracy: 0.4118\n",
      "Epoch 209/300\n",
      "12/12 [==============================] - 0s 583us/step - loss: 1.0854 - accuracy: 0.4118\n",
      "Epoch 210/300\n",
      "12/12 [==============================] - 0s 748us/step - loss: 1.0858 - accuracy: 0.4118\n",
      "Epoch 211/300\n",
      "12/12 [==============================] - ETA: 0s - loss: 1.0564 - accuracy: 0.40 - 0s 583us/step - loss: 1.0855 - accuracy: 0.4118\n",
      "Epoch 212/300\n",
      "12/12 [==============================] - 0s 643us/step - loss: 1.0863 - accuracy: 0.4118\n",
      "Epoch 213/300\n",
      "12/12 [==============================] - 0s 582us/step - loss: 1.0853 - accuracy: 0.4118\n",
      "Epoch 214/300\n",
      "12/12 [==============================] - 0s 583us/step - loss: 1.0858 - accuracy: 0.4118\n",
      "Epoch 215/300\n",
      "12/12 [==============================] - 0s 583us/step - loss: 1.0844 - accuracy: 0.4118\n",
      "Epoch 216/300\n",
      "12/12 [==============================] - 0s 667us/step - loss: 1.0841 - accuracy: 0.4118\n",
      "Epoch 217/300\n",
      "12/12 [==============================] - 0s 669us/step - loss: 1.0862 - accuracy: 0.4118\n",
      "Epoch 218/300\n",
      "12/12 [==============================] - 0s 667us/step - loss: 1.0875 - accuracy: 0.4118\n",
      "Epoch 219/300\n",
      "12/12 [==============================] - 0s 583us/step - loss: 1.0871 - accuracy: 0.4118\n",
      "Epoch 220/300\n",
      "12/12 [==============================] - 0s 585us/step - loss: 1.0844 - accuracy: 0.4118\n",
      "Epoch 221/300\n",
      "12/12 [==============================] - 0s 583us/step - loss: 1.0839 - accuracy: 0.4118\n",
      "Epoch 222/300\n",
      "12/12 [==============================] - 0s 583us/step - loss: 1.0856 - accuracy: 0.4118\n",
      "Epoch 223/300\n",
      "12/12 [==============================] - 0s 667us/step - loss: 1.0855 - accuracy: 0.4118\n",
      "Epoch 224/300\n",
      "12/12 [==============================] - 0s 667us/step - loss: 1.0854 - accuracy: 0.4118\n",
      "Epoch 225/300\n",
      "12/12 [==============================] - 0s 583us/step - loss: 1.0838 - accuracy: 0.4118\n",
      "Epoch 226/300\n",
      "12/12 [==============================] - 0s 583us/step - loss: 1.0849 - accuracy: 0.4118\n",
      "Epoch 227/300\n",
      "12/12 [==============================] - 0s 583us/step - loss: 1.0846 - accuracy: 0.4118\n",
      "Epoch 228/300\n",
      "12/12 [==============================] - 0s 585us/step - loss: 1.0854 - accuracy: 0.4118\n",
      "Epoch 229/300\n",
      "12/12 [==============================] - 0s 750us/step - loss: 1.0853 - accuracy: 0.4118\n",
      "Epoch 230/300\n",
      "12/12 [==============================] - 0s 585us/step - loss: 1.0872 - accuracy: 0.4118\n",
      "Epoch 231/300\n",
      "12/12 [==============================] - 0s 583us/step - loss: 1.0861 - accuracy: 0.4118\n",
      "Epoch 232/300\n",
      "12/12 [==============================] - 0s 667us/step - loss: 1.0840 - accuracy: 0.4118\n",
      "Epoch 233/300\n",
      "12/12 [==============================] - 0s 502us/step - loss: 1.0873 - accuracy: 0.4118\n",
      "Epoch 234/300\n",
      "12/12 [==============================] - 0s 583us/step - loss: 1.0862 - accuracy: 0.4118\n",
      "Epoch 235/300\n",
      "12/12 [==============================] - 0s 750us/step - loss: 1.0854 - accuracy: 0.4118\n",
      "Epoch 236/300\n",
      "12/12 [==============================] - 0s 583us/step - loss: 1.0846 - accuracy: 0.4118\n",
      "Epoch 237/300\n",
      "12/12 [==============================] - 0s 584us/step - loss: 1.0861 - accuracy: 0.4118\n",
      "Epoch 238/300\n",
      "12/12 [==============================] - 0s 633us/step - loss: 1.0848 - accuracy: 0.4118\n",
      "Epoch 239/300\n",
      "12/12 [==============================] - 0s 583us/step - loss: 1.0849 - accuracy: 0.4118\n",
      "Epoch 240/300\n",
      "12/12 [==============================] - 0s 667us/step - loss: 1.0880 - accuracy: 0.4118\n",
      "Epoch 241/300\n",
      "12/12 [==============================] - 0s 583us/step - loss: 1.0859 - accuracy: 0.4118\n",
      "Epoch 242/300\n",
      "12/12 [==============================] - 0s 665us/step - loss: 1.0864 - accuracy: 0.4118\n",
      "Epoch 243/300\n",
      "12/12 [==============================] - 0s 585us/step - loss: 1.0854 - accuracy: 0.4118\n",
      "Epoch 244/300\n",
      "12/12 [==============================] - 0s 583us/step - loss: 1.0855 - accuracy: 0.4118\n",
      "Epoch 245/300\n",
      "12/12 [==============================] - 0s 664us/step - loss: 1.0846 - accuracy: 0.4118\n",
      "Epoch 246/300\n",
      "12/12 [==============================] - 0s 583us/step - loss: 1.0873 - accuracy: 0.4118\n",
      "Epoch 247/300\n",
      "12/12 [==============================] - 0s 583us/step - loss: 1.0860 - accuracy: 0.4118\n",
      "Epoch 248/300\n",
      "12/12 [==============================] - 0s 583us/step - loss: 1.0854 - accuracy: 0.4118\n",
      "Epoch 249/300\n",
      "12/12 [==============================] - 0s 585us/step - loss: 1.0851 - accuracy: 0.4118\n",
      "Epoch 250/300\n",
      "12/12 [==============================] - 0s 664us/step - loss: 1.0843 - accuracy: 0.4118\n",
      "Epoch 251/300\n",
      "12/12 [==============================] - 0s 583us/step - loss: 1.0859 - accuracy: 0.4118\n",
      "Epoch 252/300\n",
      "12/12 [==============================] - 0s 583us/step - loss: 1.0887 - accuracy: 0.4118\n",
      "Epoch 253/300\n",
      "12/12 [==============================] - 0s 586us/step - loss: 1.0842 - accuracy: 0.4118\n",
      "Epoch 254/300\n",
      "12/12 [==============================] - 0s 583us/step - loss: 1.0869 - accuracy: 0.4118\n",
      "Epoch 255/300\n",
      "12/12 [==============================] - 0s 583us/step - loss: 1.0896 - accuracy: 0.4118\n",
      "Epoch 256/300\n",
      "12/12 [==============================] - 0s 664us/step - loss: 1.0885 - accuracy: 0.4118\n",
      "Epoch 257/300\n",
      "12/12 [==============================] - 0s 664us/step - loss: 1.0849 - accuracy: 0.4118\n",
      "Epoch 258/300\n",
      "12/12 [==============================] - 0s 585us/step - loss: 1.0852 - accuracy: 0.4118\n",
      "Epoch 259/300\n",
      "12/12 [==============================] - 0s 667us/step - loss: 1.0851 - accuracy: 0.4118\n",
      "Epoch 260/300\n",
      "12/12 [==============================] - 0s 583us/step - loss: 1.0845 - accuracy: 0.4118\n",
      "Epoch 261/300\n",
      "12/12 [==============================] - 0s 667us/step - loss: 1.0875 - accuracy: 0.4118\n",
      "Epoch 262/300\n",
      "12/12 [==============================] - 0s 583us/step - loss: 1.0839 - accuracy: 0.4118\n",
      "Epoch 263/300\n",
      "12/12 [==============================] - 0s 581us/step - loss: 1.0864 - accuracy: 0.4118\n",
      "Epoch 264/300\n",
      "12/12 [==============================] - 0s 583us/step - loss: 1.0838 - accuracy: 0.4118\n",
      "Epoch 265/300\n",
      "12/12 [==============================] - 0s 583us/step - loss: 1.0864 - accuracy: 0.4118\n",
      "Epoch 266/300\n",
      "12/12 [==============================] - 0s 583us/step - loss: 1.0842 - accuracy: 0.4118\n",
      "Epoch 267/300\n",
      "12/12 [==============================] - 0s 586us/step - loss: 1.0895 - accuracy: 0.4118\n",
      "Epoch 268/300\n",
      "12/12 [==============================] - 0s 583us/step - loss: 1.0868 - accuracy: 0.4118\n",
      "Epoch 269/300\n",
      "12/12 [==============================] - 0s 667us/step - loss: 1.0859 - accuracy: 0.4118\n",
      "Epoch 270/300\n",
      "12/12 [==============================] - 0s 585us/step - loss: 1.0854 - accuracy: 0.4118\n",
      "Epoch 271/300\n",
      "12/12 [==============================] - 0s 502us/step - loss: 1.0852 - accuracy: 0.4118\n",
      "Epoch 272/300\n",
      "12/12 [==============================] - 0s 664us/step - loss: 1.0849 - accuracy: 0.4118\n",
      "Epoch 273/300\n",
      "12/12 [==============================] - 0s 667us/step - loss: 1.0844 - accuracy: 0.4118\n",
      "Epoch 274/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12/12 [==============================] - 0s 583us/step - loss: 1.0837 - accuracy: 0.4118\n",
      "Epoch 275/300\n",
      "12/12 [==============================] - 0s 583us/step - loss: 1.0852 - accuracy: 0.4118\n",
      "Epoch 276/300\n",
      "12/12 [==============================] - 0s 586us/step - loss: 1.0846 - accuracy: 0.4118\n",
      "Epoch 277/300\n",
      "12/12 [==============================] - 0s 583us/step - loss: 1.0857 - accuracy: 0.4118\n",
      "Epoch 278/300\n",
      "12/12 [==============================] - 0s 500us/step - loss: 1.0863 - accuracy: 0.4118\n",
      "Epoch 279/300\n",
      "12/12 [==============================] - 0s 747us/step - loss: 1.0883 - accuracy: 0.4118\n",
      "Epoch 280/300\n",
      "12/12 [==============================] - 0s 581us/step - loss: 1.0852 - accuracy: 0.4118\n",
      "Epoch 281/300\n",
      "12/12 [==============================] - 0s 621us/step - loss: 1.0848 - accuracy: 0.4118\n",
      "Epoch 282/300\n",
      "12/12 [==============================] - 0s 665us/step - loss: 1.0857 - accuracy: 0.4118\n",
      "Epoch 283/300\n",
      "12/12 [==============================] - 0s 583us/step - loss: 1.0854 - accuracy: 0.4118\n",
      "Epoch 284/300\n",
      "12/12 [==============================] - 0s 752us/step - loss: 1.0848 - accuracy: 0.4118\n",
      "Epoch 285/300\n",
      "12/12 [==============================] - 0s 584us/step - loss: 1.0843 - accuracy: 0.4118\n",
      "Epoch 286/300\n",
      "12/12 [==============================] - 0s 666us/step - loss: 1.0853 - accuracy: 0.4118\n",
      "Epoch 287/300\n",
      "12/12 [==============================] - 0s 667us/step - loss: 1.0836 - accuracy: 0.4118\n",
      "Epoch 288/300\n",
      "12/12 [==============================] - 0s 583us/step - loss: 1.0855 - accuracy: 0.4118\n",
      "Epoch 289/300\n",
      "12/12 [==============================] - 0s 593us/step - loss: 1.0843 - accuracy: 0.4118\n",
      "Epoch 290/300\n",
      "12/12 [==============================] - 0s 750us/step - loss: 1.0868 - accuracy: 0.4118\n",
      "Epoch 291/300\n",
      "12/12 [==============================] - 0s 583us/step - loss: 1.0851 - accuracy: 0.4118\n",
      "Epoch 292/300\n",
      "12/12 [==============================] - 0s 665us/step - loss: 1.0883 - accuracy: 0.4118\n",
      "Epoch 293/300\n",
      "12/12 [==============================] - 0s 582us/step - loss: 1.0866 - accuracy: 0.4118\n",
      "Epoch 294/300\n",
      "12/12 [==============================] - 0s 585us/step - loss: 1.0843 - accuracy: 0.4118\n",
      "Epoch 295/300\n",
      "12/12 [==============================] - 0s 667us/step - loss: 1.0841 - accuracy: 0.4118\n",
      "Epoch 296/300\n",
      "12/12 [==============================] - 0s 502us/step - loss: 1.0864 - accuracy: 0.4118\n",
      "Epoch 297/300\n",
      "12/12 [==============================] - 0s 586us/step - loss: 1.0845 - accuracy: 0.4118\n",
      "Epoch 298/300\n",
      "12/12 [==============================] - 0s 583us/step - loss: 1.0862 - accuracy: 0.4118\n",
      "Epoch 299/300\n",
      "12/12 [==============================] - 0s 669us/step - loss: 1.0854 - accuracy: 0.4118\n",
      "Epoch 300/300\n",
      "12/12 [==============================] - 0s 750us/step - loss: 1.0874 - accuracy: 0.4118\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x000002904F44C1F0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "2/2 [==============================] - 0s 499us/step - loss: 0.3737 - accuracy: 0.8644\n",
      "\n",
      "Accuracy: 86.44%\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x0000029051C7A310> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 1.0932 - accuracy: 0.3729\n",
      "\n",
      "Accuracy2: 37.29%\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x00000290533BC4C0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "2/2 [==============================] - 0s 487us/step - loss: 1.0937 - accuracy: 0.3729\n",
      "\n",
      "Accuracy3: 37.29%\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x000002905371B670> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x000002905371B550> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x0000029051C7A0D0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "[[2.61392500e-02 1.84928195e-03 9.72011507e-01]\n",
      " [1.06049076e-01 1.44709542e-01 7.49241352e-01]\n",
      " [1.14454573e-03 9.98456717e-01 3.98764183e-04]\n",
      " [9.43152189e-01 6.51249569e-03 5.03352508e-02]\n",
      " [1.76165413e-05 9.99579728e-01 4.02613223e-04]]\n",
      "[[0.32000455 0.26878783 0.41120762]\n",
      " [0.32000455 0.26878783 0.41120762]\n",
      " [0.32000455 0.26878783 0.41120762]\n",
      " [0.32000455 0.26878783 0.41120762]\n",
      " [0.32000455 0.26878783 0.41120762]]\n",
      "[[0.3223921  0.26088637 0.41672155]\n",
      " [0.3223921  0.26088637 0.41672155]\n",
      " [0.3223921  0.26088637 0.41672155]\n",
      " [0.3223921  0.26088637 0.41672155]\n",
      " [0.3223921  0.26088637 0.41672155]]\n"
     ]
    }
   ],
   "source": [
    "#–ù–µ–π—Ä–æ–Ω–Ω—ã–µ —Å–µ—Ç–∏. Deep Learning\n",
    "#–ê–∫—Ç–∏–≤–∞—Ü–∏–æ–Ω–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è = —Å—É–º–º–∞(Wi*Xi) –æ—Ç —á–∏—Å–ª–∞ –≤—Ö–æ–¥–æ–≤ –Ω–µ–π—Ä–æ–Ω–∞. \n",
    "#–õ–æ–≥–∏—Å—Ç–∏—á–µ—Å–∫–∞—è —Ñ—É–Ω–∫—Ü–∏—è f(x)=e**x/(1+e**x) –∏–ª–∏ –≥–∏–ø–µ—Ä–±–æ–ª–∏—á–µ—Å–∫–∏–π —Ç–∞–Ω–≥–µ–Ω—Å\n",
    "#ReLU —Ñ—É–Ω–∫—Ü–∏—è f(x) = max(0, X) –ø—Ä–æ—â–µ, –Ω–æ —á—É—Ç—å –º–µ–Ω–µ–µ —Ç–æ—á–Ω–∞—è –∏ —Å–ª–æ–∂–Ω–µ–µ –≤ –¥–æ–±–∞–≤–ª–µ–Ω–∏–∏ –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤\n",
    "#–ü–æ–¥–±–æ—Ä –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—ã –ù–° –ø–æ–∑–≤–æ–ª—è–µ—Ç –æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞—Ç—å —á–∏—Å–ª–æ –Ω–µ–π—Ä–æ–Ω–æ–≤, –Ω–∞—Å—Ç—Ä–æ–∏–≤ –≤—Ö–æ–¥–Ω–æ–π, —Å–∫—Ä—ã—Ç—ã–µ, –≤—ã—Ö–æ–¥–Ω–æ–π —Å–ª–æ–∏. \n",
    "#–°–µ—Ç–∏ –ø—Ä—è–º–æ–≥–æ —Ä–∞—Å–ø—Ä–æ—Å—Ç—Ä–∞–Ω–µ–Ω–∏—è: –≤ –ø—Ä–µ–¥–µ–ª–∞—Ö —Å–ª–æ—è –Ω–µ–π—Ä–æ–Ω—ã –Ω–µ —Å–≤—è–∑–∞–Ω—ã, –ø–µ—Ä–µ–¥–∞—é—Ç —Ç–æ–ª—å–∫–æ –≤ —Å–ª–µ–¥. —Å–ª–æ–π, –ø–µ—Ä–µ–ø—Ä—ã–≥–∏–≤–∞—Ç—å –Ω–µ–ª—å–∑—è\n",
    "#–û–±—É—á–µ–Ω–∏–µ –ù–° = –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –∑–Ω–∞—á–µ–Ω–∏–π –í–ï–°–û–í (–≤–Ω—É—Ç—Ä–µ–Ω–Ω–∏—Ö –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤)  –∫–∞–∂–¥–æ–≥–æ —Å–æ–µ–¥–∏–Ω–µ–Ω–∏—è. –û—Å—Ç–∞–ª—å–Ω–æ–µ –∑–∞–¥–∞–µ—Ç—Å—è –∞–Ω–∞–ª–∏—Ç–∏–∫–æ–º –∑–∞—Ä–∞–Ω–µ–µ\n",
    "#Keras –º–æ–¥—É–ª–∏: –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞, –≤—Ö–æ–¥–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è, —É—Å–ª–æ–≤–∏—è –æ–±—É—á–µ–Ω–∏—è, –æ—Ü–µ–Ω–∫–∞ –∫–∞—á–µ—Å—Ç–≤–∞\n",
    "\n",
    "wine['Desired1(3)'].value_counts(normalize=True)\n",
    "\n",
    "#–ò–º–µ–Ω—É–µ–º –ø—Ä–µ–¥–∏–∫—Ç–æ—Ä—ã –∏ –æ—Ç–∫–ª–∏–∫\n",
    "y = wine['Desired1(3)']\n",
    "X = wine.drop('Desired1(3)', axis=1)\n",
    "\n",
    "#—Ä–∞—Å—â–µ–ø–ª–µ–Ω–∏–µ –Ω–∞ –≤—ã–±–æ—Ä–∫–∏ —Å —É–∫–∞–∑–∞–Ω–∏–µ–º –æ–±—ä—ë–º–∞ —Ç–µ—Å—Ç–æ–≤–æ–≥–æ –º–Ω–æ–∂–µ—Å—Ç–≤–∞\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=12345, test_size=0.33)\n",
    "\n",
    "#–ü—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ –≤ np.array –¥–ª—è Keras\n",
    "X_train = X_train.values\n",
    "X_test = X_test.values\n",
    "y_train = y_train.values\n",
    "y_test = y_test.values\n",
    "\n",
    "#–ü–æ—Å–∫–æ–ª—å–∫—É –±–æ–ª—å—à–µ –¥–≤—É—Ö –∫–ª–∞—Å—Å–æ–≤ –∏ –æ–Ω–∏ –Ω–µ —É–ø–æ—Ä—è–¥–æ—á–µ–Ω—ã, —Ç–æ —Ä–∞–∑–±–∏–≤–∞–µ–º –∫–æ–ª–æ–Ω–∫—É \"y\" –Ω–∞ —Ç—Ä–∏, —Å –±–∏–Ω–∞—Ä–Ω—ã–º–∏ –∑–Ω–∞—á–µ–Ω–∏—è–º–∏\n",
    "y_train_bin = np_utils.to_categorical(y_train)\n",
    "y_test_bin = np_utils.to_categorical(y_test)\n",
    "y_train_bin[0:5]\n",
    "\n",
    "#–ú–µ—Ç–æ–¥ —Å–∫–æ—Ä–µ–π—à–µ–≥–æ(–≥—Ä–∞–¥–∏–µ–Ω—Ç–Ω–æ–≥–æ) —Å–ø—É—Å–∫–∞ SGD. –£–ª—É—á—à–µ–Ω–∏–µ –º–µ—Ç–æ–¥–∞: Momentum, Nesterov momentum, Adam –∏ –¥—Ä.\n",
    "#Argmin, –ø—Ä–∞–≤–∏–ª–æ –æ—Å—Ç–∞–Ω–æ–≤–∫–∏: —á–∏—Å–ª–æ –∏—Ç–µ—Ä–∞—Ü–∏–π –∏–ª–∏ –º–∞–ª–æ–µ —É–º–µ–Ω—å—à–µ–Ω–∏–µ —Ñ—É–Ω–∫—Ü–∏–∏\n",
    "#–ù–∞—á–∞–ª—å–Ω–∞—è —Ç–æ—á–∫–∞(–∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è). –ù–∞—á–∞–ª—å–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏–µ –¥.–±. –º–∏–Ω–∏–º–∞–ª—å–Ω—ã–º, –±–ª–∏–∂–µ –∫ –Ω—É–ª—é (–∫—Ä–æ–º–µ —Å–≤–æ–±–æ–¥–Ω—ã—Ö —Å–ª–∞–≥–∞–µ–º—ã—Ö)\n",
    "#–ì—Ä–∞—Ñ–∏–∫ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –∫—Ä–∏—Ç–µ—Ä–∏—è –∫–∞–∞—á-–≤–∞ Q –æ—Ç –Ω–æ–º–µ—Ä–∞ –∏—Ç–µ—Ä–∞—Ü–∏–∏. –ú–∞–ª–∞—è —Å–∫–æ—Ä–æ—Å—Ç—å –æ–±—É—á–µ–Ω–∏—è(0.001 –∏ —Ç.–¥.) –¥–∞–µ—Ç –∫–∞—á–µ—Å—Ç–≤–æ, –Ω–æ –∏–¥–µ—Ç –¥–æ–ª—å—à–µ\n",
    "#–í—Ö–æ–¥–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è —Ä–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è —Å—Ç–∞–Ω–¥–∞—Ä—Ç–∏–∑–æ–≤–∞—Ç—å(—Å–Ω–∏–∂–∞–µ—Ç —Ä–∏—Å–∫ –Ω–∞—Å—ã—â–µ–Ω–∏—è) (Xi-Xmin)/(Xmax-Xmin)\n",
    "#Batch - –∫–æ—Ä—Ä–µ–∫—Ü–∏—è –≤–µ—Å–æ–≤ –ø–æ—Å–ª–µ –∫–∞–∂–¥–æ–π —ç–ø–æ—Ö–∏. –ù–∞—Å—ã—â–µ–Ω–∏–µ - –æ—Ç—Å—É—Ç—Å—Ç–≤–∏–µ –∫–æ—Ä—Ä–µ–∫—Ü–∏–π. Gradient clipping - –±–ª–æ–∫ –æ—Ç –±–æ–ª—å—à–∏—Ö –ø–æ–ø—Ä–∞–≤–æ–∫\n",
    "\n",
    "#–°–æ–∑–¥–∞–µ–º –º–æ–¥–µ–ª–∏. –î–ª—è –Ω–µ–±–æ–ª—å—à–∏—Ö –¥–∞–Ω–Ω—ã—Ö –º–æ–∂–Ω–æ –≤—Å–µ–≥–æ –ø–∞—Ä—É —Å–ª–æ–µ–≤ –≤ 5-7 –Ω–µ–π—Ä–æ–Ω–æ–≤\n",
    "#–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è. –ü—Ä–∏—Å–≤–æ–µ–Ω–∏–µ —Å—Ç–∞—Ä—Ç–æ–≤—ã—Ö –≤–µ—Å–æ–≤\n",
    "init = initializers.RandomNormal(mean=0.0, stddev=0.05, seed=None) #–ó–µ—Ä–Ω–æ –Ω–µ —É–∫–∞–∑–∞–Ω–æ, –∫–æ–Ω—Ç—Ä–æ–ª—è –Ω–∞–¥ –æ–±—É—á–µ–Ω–∏–µ–º –º–µ–Ω—å—à–µ\n",
    "init_2 = initializers.TruncatedNormal(mean=0.0, stddev=0.05, seed=12345) #–£—Å–µ—á–µ–Ω–Ω–æ–µ –Ω–æ—Ä–º–∞–ª—å–Ω–æ–µ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ. –ò–Ω–∏—Ü–∏–∞—Ü–∏—è –≤–µ—Å–æ–≤\n",
    "init_3 = initializers.Constant(value = 1e-3) #–ò–Ω–∏—Ü–∏–∞—Ü–∏—è —Å–≤–æ–±–æ–¥–Ω—ã—Ö —á–ª–µ–Ω–æ–≤\n",
    "\n",
    "model = Sequential() #–£–∫–∞–∑—ã–≤–∞–µ–º –Ω–∞ —Ç–∏–ø –º–æ–¥–µ–ª–∏ (—Å–µ—Ç—å –ø—Ä—è–º–æ–≥–æ —Ä–∞—Å–ø—Ä–æ—Å—Ç—Ä–∞–Ω–µ–Ω–∏—è)\n",
    "model.add(Dense(9, input_dim=13, activation='relu')) #–ü–µ—Ä–≤—ã–π —Å–ª–æ–π, 9 –Ω–µ–π—Ä–æ–Ω–æ–≤, –≤—Ö–æ–¥–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è (13 –ø—Ä–µ–¥–∏–∫—Ç–æ—Ä–æ–≤)\n",
    "model.add(Dense(10, activation='relu', )) #–í—Ç–æ–æ–π —Å–ª–æ–π, 10 –Ω–µ–π—Ä–æ–Ω–æ–≤\n",
    "model.add(Dense(3, activation='softmax')) #–¢—Ä–µ—Ç–∏–π —Å–ª–æ–π, —Ä–∞–Ω–∂–∏—Ä–æ–≤–∫–∞ —Å–æ—Ñ—Ç–º–∞–∫—Å–æ–º –¥–ª—è —Å—Ç–∞–Ω–¥–∞—Ä—Ç–∏–∑–∞—Ü–∏–∏ –∏ –∞–∫—Ç–∏–≤–∞—Ü–∏–∏. –¢—Ä–∏ –≤—ã—Ö–æ–¥–∞\n",
    "\n",
    "model2 = Sequential()\n",
    "model2.add(Dense(9, input_dim=13, activation='relu'))\n",
    "model2.add(Dense(10, activation='relu' ))\n",
    "model2.add(Dense(3, activation='softmax'))\n",
    "\n",
    "model3 = Sequential()\n",
    "model3.add(Dense(9, input_dim=13, activation='relu', kernel_initializer=init_2, bias_initializer=init_3))\n",
    "model3.add(Dense(10, activation='relu', kernel_initializer=init_2, bias_initializer=init_3 ))\n",
    "model3.add(Dense(3, activation='softmax', kernel_initializer=init_2, bias_initializer=init_3))\n",
    "\n",
    "#MSE, MAE –∏–ª–∏ Mean absolute percentage error (MAPE) - –ø–æ–∫–∞–∑—ã–≤–∞—é—Ç –æ—Ç–Ω–æ—Å–∏—Ç–µ–ª—å–Ω—É—é –æ—à–∏–±–∫—É –≤ —Ä–µ–≥—Ä–µ—Å—Å–∏–∏\n",
    "#Categorical crossentropy (CC) –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –¥–ª—è –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–∏ –ø—Ä–∏–Ω–∞–¥–ª–µ–∂–Ω–æ—Å—Ç–∏ –æ–±—ä–µ–∫—Ç–∞ –∫ –∫–ª–∞—Å—Å—É (—É–ø–æ—Ä—è–¥–æ—á–Ω–æ–º—É)\n",
    "\n",
    "#–ö–æ–º–ø–∏–ª–∏—Ä—É–µ–º: optimizer(rmsprop –∏–ª–∏ adam), loss function(categorical_crossentropy(–∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è) –∏–ª–∏ mse(—Ä–µ–≥—Ä–µ—Å—Å–∏—è)). –¢–æ—á–Ω–æ—Å—Ç—å\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "sgd2 = optimizers.SGD(lr=0.02, decay=1e-6, momentum=0.8, nesterov=True)\n",
    "model2.compile(loss='categorical_crossentropy', optimizer=sgd2, metrics=['accuracy'])\n",
    "\n",
    "sgd3 = optimizers.SGD(lr=0.02, decay=1e-7, momentum=0.9, nesterov=True)\n",
    "model3.compile(loss='categorical_crossentropy', optimizer=sgd3, metrics=['accuracy'])\n",
    "\n",
    "#–û–±—É—á–∞–µ–º –º–æ–¥–µ–ª—å: 300 —ç–ø–æ—Ö, –ø—Ä–æ–ø—É—Å–∫ 10 —ç–ª–µ–º–µ–Ω—Ç–æ–≤ –¥–æ —Å–º–µ–Ω—ã –≤–µ—Å–æ–≤\n",
    "model.fit(X_train, y_train_bin, epochs=300, batch_size=10)\n",
    "model2.fit(X_train, y_train_bin, epochs=300, batch_size=10)\n",
    "model3.fit(X_train, y_train_bin, epochs=300, batch_size=10)\n",
    "\n",
    "#–ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞ —Ç–µ—Å—Ç–æ–≤–æ–º –º–Ω–æ–∂–µ—Å—Ç–≤–µ\n",
    "scores = model.evaluate(X_test, y_test_bin)\n",
    "print(\"\\nAccuracy: %.2f%%\" % (scores[1]*100))\n",
    "\n",
    "scores2 = model2.evaluate(X_test, y_test_bin)\n",
    "print(\"\\nAccuracy2: %.2f%%\" % (scores2[1]*100))\n",
    "\n",
    "scores3 = model3.evaluate(X_test, y_test_bin)\n",
    "print(\"\\nAccuracy3: %.2f%%\" % (scores3[1]*100))\n",
    "\n",
    "\n",
    "#–†–∞—Å—Å—á–∏—Ç—ã–≤–∞–µ–º –ø—Ä–µ–¥–∏–∫—Ç–æ—Ä—ã\n",
    "predictions = model.predict(X_test)\n",
    "predictions2 = model2.predict(X_test)\n",
    "predictions3 = model3.predict(X_test)\n",
    "#round predictions\n",
    "#rounded = [round(x[0]) for x in predictions]\n",
    "#print(rounded)\n",
    "print(predictions[0:5])\n",
    "print(predictions2[0:5])\n",
    "print(predictions3[0:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "3/3 [==============================] - 0s 654us/step - loss: 1421692800.0000 - mean_absolute_percentage_error: 257.6722\n",
      "Epoch 2/300\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 1310995968.0000 - mean_absolute_percentage_error: 247.0419\n",
      "Epoch 3/300\n",
      "3/3 [==============================] - 0s 667us/step - loss: 1205636864.0000 - mean_absolute_percentage_error: 236.9829\n",
      "Epoch 4/300\n",
      "3/3 [==============================] - 0s 1000us/step - loss: 1109377408.0000 - mean_absolute_percentage_error: 227.0369\n",
      "Epoch 5/300\n",
      "3/3 [==============================] - 0s 667us/step - loss: 1018493696.0000 - mean_absolute_percentage_error: 217.4474\n",
      "Epoch 6/300\n",
      "3/3 [==============================] - 0s 992us/step - loss: 936271936.0000 - mean_absolute_percentage_error: 207.9816\n",
      "Epoch 7/300\n",
      "3/3 [==============================] - 0s 667us/step - loss: 853955328.0000 - mean_absolute_percentage_error: 198.6808\n",
      "Epoch 8/300\n",
      "3/3 [==============================] - 0s 655us/step - loss: 778371968.0000 - mean_absolute_percentage_error: 189.2512\n",
      "Epoch 9/300\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 708108864.0000 - mean_absolute_percentage_error: 180.2153\n",
      "Epoch 10/300\n",
      "3/3 [==============================] - 0s 667us/step - loss: 640250816.0000 - mean_absolute_percentage_error: 171.1566\n",
      "Epoch 11/300\n",
      "3/3 [==============================] - 0s 666us/step - loss: 579130112.0000 - mean_absolute_percentage_error: 162.2569\n",
      "Epoch 12/300\n",
      "3/3 [==============================] - 0s 999us/step - loss: 519831424.0000 - mean_absolute_percentage_error: 153.4585\n",
      "Epoch 13/300\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 466332256.0000 - mean_absolute_percentage_error: 144.5226\n",
      "Epoch 14/300\n",
      "3/3 [==============================] - 0s 666us/step - loss: 415924704.0000 - mean_absolute_percentage_error: 136.1132\n",
      "Epoch 15/300\n",
      "3/3 [==============================] - 0s 658us/step - loss: 369596384.0000 - mean_absolute_percentage_error: 127.8334\n",
      "Epoch 16/300\n",
      "3/3 [==============================] - 0s 666us/step - loss: 326695840.0000 - mean_absolute_percentage_error: 119.5590\n",
      "Epoch 17/300\n",
      "3/3 [==============================] - 0s 657us/step - loss: 288179712.0000 - mean_absolute_percentage_error: 111.4404\n",
      "Epoch 18/300\n",
      "3/3 [==============================] - 0s 667us/step - loss: 253317840.0000 - mean_absolute_percentage_error: 103.8372\n",
      "Epoch 19/300\n",
      "3/3 [==============================] - 0s 666us/step - loss: 220449600.0000 - mean_absolute_percentage_error: 96.1785\n",
      "Epoch 20/300\n",
      "3/3 [==============================] - 0s 667us/step - loss: 191377728.0000 - mean_absolute_percentage_error: 88.9280\n",
      "Epoch 21/300\n",
      "3/3 [==============================] - 0s 666us/step - loss: 166042144.0000 - mean_absolute_percentage_error: 81.7462\n",
      "Epoch 22/300\n",
      "3/3 [==============================] - 0s 332us/step - loss: 143016720.0000 - mean_absolute_percentage_error: 74.8873\n",
      "Epoch 23/300\n",
      "3/3 [==============================] - 0s 1000us/step - loss: 123071744.0000 - mean_absolute_percentage_error: 68.2471\n",
      "Epoch 24/300\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 105493496.0000 - mean_absolute_percentage_error: 61.9494\n",
      "Epoch 25/300\n",
      "3/3 [==============================] - 0s 657us/step - loss: 90009536.0000 - mean_absolute_percentage_error: 56.2789\n",
      "Epoch 26/300\n",
      "3/3 [==============================] - 0s 658us/step - loss: 76724120.0000 - mean_absolute_percentage_error: 50.8860\n",
      "Epoch 27/300\n",
      "3/3 [==============================] - 0s 1000us/step - loss: 65530340.0000 - mean_absolute_percentage_error: 45.8026\n",
      "Epoch 28/300\n",
      "3/3 [==============================] - 0s 1000us/step - loss: 56176392.0000 - mean_absolute_percentage_error: 41.1407\n",
      "Epoch 29/300\n",
      "3/3 [==============================] - 0s 667us/step - loss: 47929584.0000 - mean_absolute_percentage_error: 36.8809\n",
      "Epoch 30/300\n",
      "3/3 [==============================] - 0s 666us/step - loss: 41167676.0000 - mean_absolute_percentage_error: 33.0853\n",
      "Epoch 31/300\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 35781564.0000 - mean_absolute_percentage_error: 30.4299\n",
      "Epoch 32/300\n",
      "3/3 [==============================] - 0s 658us/step - loss: 31216044.0000 - mean_absolute_percentage_error: 28.1645\n",
      "Epoch 33/300\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 27489320.0000 - mean_absolute_percentage_error: 26.3840\n",
      "Epoch 34/300\n",
      "3/3 [==============================] - 0s 673us/step - loss: 24651466.0000 - mean_absolute_percentage_error: 24.9878\n",
      "Epoch 35/300\n",
      "3/3 [==============================] - 0s 659us/step - loss: 22318442.0000 - mean_absolute_percentage_error: 24.3197\n",
      "Epoch 36/300\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 20487906.0000 - mean_absolute_percentage_error: 23.6677\n",
      "Epoch 37/300\n",
      "3/3 [==============================] - 0s 666us/step - loss: 19089922.0000 - mean_absolute_percentage_error: 23.3860\n",
      "Epoch 38/300\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 18123252.0000 - mean_absolute_percentage_error: 23.3500\n",
      "Epoch 39/300\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 17467452.0000 - mean_absolute_percentage_error: 23.4351\n",
      "Epoch 40/300\n",
      "3/3 [==============================] - 0s 1000us/step - loss: 16755886.0000 - mean_absolute_percentage_error: 23.3193\n",
      "Epoch 41/300\n",
      "3/3 [==============================] - 0s 667us/step - loss: 16420711.0000 - mean_absolute_percentage_error: 23.4573\n",
      "Epoch 42/300\n",
      "3/3 [==============================] - 0s 667us/step - loss: 16029382.0000 - mean_absolute_percentage_error: 23.3927\n",
      "Epoch 43/300\n",
      "3/3 [==============================] - 0s 998us/step - loss: 15820855.0000 - mean_absolute_percentage_error: 23.4880\n",
      "Epoch 44/300\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 15646674.0000 - mean_absolute_percentage_error: 23.4970\n",
      "Epoch 45/300\n",
      "3/3 [==============================] - 0s 667us/step - loss: 15551509.0000 - mean_absolute_percentage_error: 23.5413\n",
      "Epoch 46/300\n",
      "3/3 [==============================] - 0s 1000us/step - loss: 15496977.0000 - mean_absolute_percentage_error: 23.5939\n",
      "Epoch 47/300\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 15390267.0000 - mean_absolute_percentage_error: 23.5899\n",
      "Epoch 48/300\n",
      "3/3 [==============================] - 0s 667us/step - loss: 15309796.0000 - mean_absolute_percentage_error: 23.5902\n",
      "Epoch 49/300\n",
      "3/3 [==============================] - 0s 666us/step - loss: 15254082.0000 - mean_absolute_percentage_error: 23.5818\n",
      "Epoch 50/300\n",
      "3/3 [==============================] - 0s 674us/step - loss: 15188958.0000 - mean_absolute_percentage_error: 23.5557\n",
      "Epoch 51/300\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 15116935.0000 - mean_absolute_percentage_error: 23.5245\n",
      "Epoch 52/300\n",
      "3/3 [==============================] - 0s 667us/step - loss: 15051793.0000 - mean_absolute_percentage_error: 23.4856\n",
      "Epoch 53/300\n",
      "3/3 [==============================] - 0s 667us/step - loss: 14988808.0000 - mean_absolute_percentage_error: 23.4500\n",
      "Epoch 54/300\n",
      "3/3 [==============================] - 0s 1000us/step - loss: 14916668.0000 - mean_absolute_percentage_error: 23.4033\n",
      "Epoch 55/300\n",
      "3/3 [==============================] - 0s 667us/step - loss: 14850643.0000 - mean_absolute_percentage_error: 23.3583\n",
      "Epoch 56/300\n",
      "3/3 [==============================] - 0s 668us/step - loss: 14784225.0000 - mean_absolute_percentage_error: 23.3093\n",
      "Epoch 57/300\n",
      "3/3 [==============================] - 0s 660us/step - loss: 14723159.0000 - mean_absolute_percentage_error: 23.2586\n",
      "Epoch 58/300\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 14645079.0000 - mean_absolute_percentage_error: 23.1869\n",
      "Epoch 59/300\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 14574612.0000 - mean_absolute_percentage_error: 23.1305\n",
      "Epoch 60/300\n",
      "3/3 [==============================] - 0s 667us/step - loss: 14499834.0000 - mean_absolute_percentage_error: 23.0732\n",
      "Epoch 61/300\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 14433158.0000 - mean_absolute_percentage_error: 23.0158\n",
      "Epoch 62/300\n",
      "3/3 [==============================] - 0s 999us/step - loss: 14364638.0000 - mean_absolute_percentage_error: 22.9596\n",
      "Epoch 63/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 1000us/step - loss: 14297358.0000 - mean_absolute_percentage_error: 22.9044\n",
      "Epoch 64/300\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 14226111.0000 - mean_absolute_percentage_error: 22.8468\n",
      "Epoch 65/300\n",
      "3/3 [==============================] - 0s 667us/step - loss: 14164812.0000 - mean_absolute_percentage_error: 22.7930\n",
      "Epoch 66/300\n",
      "3/3 [==============================] - 0s 666us/step - loss: 14092105.0000 - mean_absolute_percentage_error: 22.7351\n",
      "Epoch 67/300\n",
      "3/3 [==============================] - 0s 824us/step - loss: 14020948.0000 - mean_absolute_percentage_error: 22.6754\n",
      "Epoch 68/300\n",
      "3/3 [==============================] - 0s 675us/step - loss: 13956510.0000 - mean_absolute_percentage_error: 22.6226\n",
      "Epoch 69/300\n",
      "3/3 [==============================] - 0s 992us/step - loss: 13887107.0000 - mean_absolute_percentage_error: 22.5726\n",
      "Epoch 70/300\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 13813417.0000 - mean_absolute_percentage_error: 22.5212\n",
      "Epoch 71/300\n",
      "3/3 [==============================] - 0s 999us/step - loss: 13745011.0000 - mean_absolute_percentage_error: 22.4697\n",
      "Epoch 72/300\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 13680844.0000 - mean_absolute_percentage_error: 22.4219\n",
      "Epoch 73/300\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 13609239.0000 - mean_absolute_percentage_error: 22.3719\n",
      "Epoch 74/300\n",
      "3/3 [==============================] - 0s 667us/step - loss: 13538799.0000 - mean_absolute_percentage_error: 22.3142\n",
      "Epoch 75/300\n",
      "3/3 [==============================] - 0s 1000us/step - loss: 13470937.0000 - mean_absolute_percentage_error: 22.2648\n",
      "Epoch 76/300\n",
      "3/3 [==============================] - 0s 667us/step - loss: 13398631.0000 - mean_absolute_percentage_error: 22.2096\n",
      "Epoch 77/300\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 13329754.0000 - mean_absolute_percentage_error: 22.1550\n",
      "Epoch 78/300\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 13263584.0000 - mean_absolute_percentage_error: 22.0974\n",
      "Epoch 79/300\n",
      "3/3 [==============================] - 0s 667us/step - loss: 13183532.0000 - mean_absolute_percentage_error: 22.0379\n",
      "Epoch 80/300\n",
      "3/3 [==============================] - 0s 342us/step - loss: 13118180.0000 - mean_absolute_percentage_error: 21.9769\n",
      "Epoch 81/300\n",
      "3/3 [==============================] - 0s 667us/step - loss: 13044569.0000 - mean_absolute_percentage_error: 21.9191\n",
      "Epoch 82/300\n",
      "3/3 [==============================] - 0s 667us/step - loss: 12981083.0000 - mean_absolute_percentage_error: 21.8737\n",
      "Epoch 83/300\n",
      "3/3 [==============================] - 0s 1000us/step - loss: 12906367.0000 - mean_absolute_percentage_error: 21.8152\n",
      "Epoch 84/300\n",
      "3/3 [==============================] - 0s 667us/step - loss: 12840797.0000 - mean_absolute_percentage_error: 21.7577\n",
      "Epoch 85/300\n",
      "3/3 [==============================] - 0s 819us/step - loss: 12772407.0000 - mean_absolute_percentage_error: 21.6991\n",
      "Epoch 86/300\n",
      "3/3 [==============================] - 0s 1000us/step - loss: 12702655.0000 - mean_absolute_percentage_error: 21.6451\n",
      "Epoch 87/300\n",
      "3/3 [==============================] - 0s 667us/step - loss: 12633344.0000 - mean_absolute_percentage_error: 21.5880\n",
      "Epoch 88/300\n",
      "3/3 [==============================] - 0s 667us/step - loss: 12571047.0000 - mean_absolute_percentage_error: 21.5435\n",
      "Epoch 89/300\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 12507057.0000 - mean_absolute_percentage_error: 21.4936\n",
      "Epoch 90/300\n",
      "3/3 [==============================] - 0s 667us/step - loss: 12441053.0000 - mean_absolute_percentage_error: 21.4370\n",
      "Epoch 91/300\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 12372645.0000 - mean_absolute_percentage_error: 21.3904\n",
      "Epoch 92/300\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 12301524.0000 - mean_absolute_percentage_error: 21.3297\n",
      "Epoch 93/300\n",
      "3/3 [==============================] - 0s 667us/step - loss: 12233825.0000 - mean_absolute_percentage_error: 21.2666\n",
      "Epoch 94/300\n",
      "3/3 [==============================] - 0s 666us/step - loss: 12176120.0000 - mean_absolute_percentage_error: 21.2173\n",
      "Epoch 95/300\n",
      "3/3 [==============================] - 0s 666us/step - loss: 12110260.0000 - mean_absolute_percentage_error: 21.1684\n",
      "Epoch 96/300\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 12037210.0000 - mean_absolute_percentage_error: 21.1195\n",
      "Epoch 97/300\n",
      "3/3 [==============================] - 0s 1000us/step - loss: 11982022.0000 - mean_absolute_percentage_error: 21.0740\n",
      "Epoch 98/300\n",
      "3/3 [==============================] - 0s 666us/step - loss: 11916223.0000 - mean_absolute_percentage_error: 21.0214\n",
      "Epoch 99/300\n",
      "3/3 [==============================] - 0s 1000us/step - loss: 11841263.0000 - mean_absolute_percentage_error: 20.9517\n",
      "Epoch 100/300\n",
      "3/3 [==============================] - 0s 667us/step - loss: 11780691.0000 - mean_absolute_percentage_error: 20.8972\n",
      "Epoch 101/300\n",
      "3/3 [==============================] - 0s 657us/step - loss: 11722721.0000 - mean_absolute_percentage_error: 20.8476\n",
      "Epoch 102/300\n",
      "3/3 [==============================] - 0s 1000us/step - loss: 11659398.0000 - mean_absolute_percentage_error: 20.7920\n",
      "Epoch 103/300\n",
      "3/3 [==============================] - 0s 668us/step - loss: 11587652.0000 - mean_absolute_percentage_error: 20.7374\n",
      "Epoch 104/300\n",
      "3/3 [==============================] - 0s 1000us/step - loss: 11530455.0000 - mean_absolute_percentage_error: 20.6905\n",
      "Epoch 105/300\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 11465364.0000 - mean_absolute_percentage_error: 20.6385\n",
      "Epoch 106/300\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 11400437.0000 - mean_absolute_percentage_error: 20.5811\n",
      "Epoch 107/300\n",
      "3/3 [==============================] - 0s 1000us/step - loss: 11344321.0000 - mean_absolute_percentage_error: 20.5305\n",
      "Epoch 108/300\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 11283584.0000 - mean_absolute_percentage_error: 20.4781\n",
      "Epoch 109/300\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 11218440.0000 - mean_absolute_percentage_error: 20.4235\n",
      "Epoch 110/300\n",
      "3/3 [==============================] - 0s 1000us/step - loss: 11160394.0000 - mean_absolute_percentage_error: 20.3700\n",
      "Epoch 111/300\n",
      "3/3 [==============================] - 0s 993us/step - loss: 11104151.0000 - mean_absolute_percentage_error: 20.3103\n",
      "Epoch 112/300\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 11032698.0000 - mean_absolute_percentage_error: 20.2475\n",
      "Epoch 113/300\n",
      "3/3 [==============================] - 0s 667us/step - loss: 10975167.0000 - mean_absolute_percentage_error: 20.2039\n",
      "Epoch 114/300\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 10919736.0000 - mean_absolute_percentage_error: 20.1554\n",
      "Epoch 115/300\n",
      "3/3 [==============================] - 0s 999us/step - loss: 10850682.0000 - mean_absolute_percentage_error: 20.0957\n",
      "Epoch 116/300\n",
      "3/3 [==============================] - 0s 667us/step - loss: 10794412.0000 - mean_absolute_percentage_error: 20.0440\n",
      "Epoch 117/300\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 10733249.0000 - mean_absolute_percentage_error: 19.9845\n",
      "Epoch 118/300\n",
      "3/3 [==============================] - 0s 655us/step - loss: 10672079.0000 - mean_absolute_percentage_error: 19.9246\n",
      "Epoch 119/300\n",
      "3/3 [==============================] - 0s 1000us/step - loss: 10608421.0000 - mean_absolute_percentage_error: 19.8682\n",
      "Epoch 120/300\n",
      "3/3 [==============================] - 0s 993us/step - loss: 10546587.0000 - mean_absolute_percentage_error: 19.8056\n",
      "Epoch 121/300\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 10490026.0000 - mean_absolute_percentage_error: 19.7485\n",
      "Epoch 122/300\n",
      "3/3 [==============================] - 0s 657us/step - loss: 10437833.0000 - mean_absolute_percentage_error: 19.7063\n",
      "Epoch 123/300\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 10365549.0000 - mean_absolute_percentage_error: 19.6466\n",
      "Epoch 124/300\n",
      "3/3 [==============================] - 0s 667us/step - loss: 10308469.0000 - mean_absolute_percentage_error: 19.5858\n",
      "Epoch 125/300\n",
      "3/3 [==============================] - 0s 666us/step - loss: 10251621.0000 - mean_absolute_percentage_error: 19.5289\n",
      "Epoch 126/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 1ms/step - loss: 10193955.0000 - mean_absolute_percentage_error: 19.4691\n",
      "Epoch 127/300\n",
      "3/3 [==============================] - 0s 666us/step - loss: 10136462.0000 - mean_absolute_percentage_error: 19.4143\n",
      "Epoch 128/300\n",
      "3/3 [==============================] - 0s 666us/step - loss: 10080183.0000 - mean_absolute_percentage_error: 19.3631\n",
      "Epoch 129/300\n",
      "3/3 [==============================] - 0s 667us/step - loss: 10023337.0000 - mean_absolute_percentage_error: 19.3078\n",
      "Epoch 130/300\n",
      "3/3 [==============================] - 0s 774us/step - loss: 9972456.0000 - mean_absolute_percentage_error: 19.2500\n",
      "Epoch 131/300\n",
      "3/3 [==============================] - 0s 667us/step - loss: 9916649.0000 - mean_absolute_percentage_error: 19.1967\n",
      "Epoch 132/300\n",
      "3/3 [==============================] - 0s 667us/step - loss: 9865125.0000 - mean_absolute_percentage_error: 19.1461\n",
      "Epoch 133/300\n",
      "3/3 [==============================] - 0s 772us/step - loss: 9812484.0000 - mean_absolute_percentage_error: 19.0946\n",
      "Epoch 134/300\n",
      "3/3 [==============================] - 0s 667us/step - loss: 9755839.0000 - mean_absolute_percentage_error: 19.0381\n",
      "Epoch 135/300\n",
      "3/3 [==============================] - 0s 992us/step - loss: 9702043.0000 - mean_absolute_percentage_error: 18.9965\n",
      "Epoch 136/300\n",
      "3/3 [==============================] - 0s 667us/step - loss: 9650473.0000 - mean_absolute_percentage_error: 18.9465\n",
      "Epoch 137/300\n",
      "3/3 [==============================] - 0s 654us/step - loss: 9600663.0000 - mean_absolute_percentage_error: 18.9032\n",
      "Epoch 138/300\n",
      "3/3 [==============================] - 0s 999us/step - loss: 9547862.0000 - mean_absolute_percentage_error: 18.8471\n",
      "Epoch 139/300\n",
      "3/3 [==============================] - 0s 1000us/step - loss: 9498168.0000 - mean_absolute_percentage_error: 18.8032\n",
      "Epoch 140/300\n",
      "3/3 [==============================] - 0s 667us/step - loss: 9445326.0000 - mean_absolute_percentage_error: 18.7567\n",
      "Epoch 141/300\n",
      "3/3 [==============================] - 0s 667us/step - loss: 9395906.0000 - mean_absolute_percentage_error: 18.7096\n",
      "Epoch 142/300\n",
      "3/3 [==============================] - 0s 659us/step - loss: 9346910.0000 - mean_absolute_percentage_error: 18.6630\n",
      "Epoch 143/300\n",
      "3/3 [==============================] - 0s 668us/step - loss: 9297745.0000 - mean_absolute_percentage_error: 18.6179\n",
      "Epoch 144/300\n",
      "3/3 [==============================] - 0s 666us/step - loss: 9249545.0000 - mean_absolute_percentage_error: 18.5735\n",
      "Epoch 145/300\n",
      "3/3 [==============================] - 0s 664us/step - loss: 9202767.0000 - mean_absolute_percentage_error: 18.5278\n",
      "Epoch 146/300\n",
      "3/3 [==============================] - 0s 667us/step - loss: 9144704.0000 - mean_absolute_percentage_error: 18.4719\n",
      "Epoch 147/300\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 9100036.0000 - mean_absolute_percentage_error: 18.4239\n",
      "Epoch 148/300\n",
      "3/3 [==============================] - 0s 1000us/step - loss: 9050014.0000 - mean_absolute_percentage_error: 18.3598\n",
      "Epoch 149/300\n",
      "3/3 [==============================] - 0s 667us/step - loss: 9001973.0000 - mean_absolute_percentage_error: 18.3038\n",
      "Epoch 150/300\n",
      "3/3 [==============================] - 0s 666us/step - loss: 8952288.0000 - mean_absolute_percentage_error: 18.2526\n",
      "Epoch 151/300\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 8906378.0000 - mean_absolute_percentage_error: 18.1974\n",
      "Epoch 152/300\n",
      "3/3 [==============================] - 0s 666us/step - loss: 8856897.0000 - mean_absolute_percentage_error: 18.1532\n",
      "Epoch 153/300\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 8812012.0000 - mean_absolute_percentage_error: 18.1125\n",
      "Epoch 154/300\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 8762888.0000 - mean_absolute_percentage_error: 18.0662\n",
      "Epoch 155/300\n",
      "3/3 [==============================] - 0s 667us/step - loss: 8722756.0000 - mean_absolute_percentage_error: 18.0212\n",
      "Epoch 156/300\n",
      "3/3 [==============================] - 0s 1000us/step - loss: 8674002.0000 - mean_absolute_percentage_error: 17.9855\n",
      "Epoch 157/300\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 8619045.0000 - mean_absolute_percentage_error: 17.9317\n",
      "Epoch 158/300\n",
      "3/3 [==============================] - 0s 667us/step - loss: 8573591.0000 - mean_absolute_percentage_error: 17.8785\n",
      "Epoch 159/300\n",
      "3/3 [==============================] - 0s 666us/step - loss: 8531109.0000 - mean_absolute_percentage_error: 17.8324\n",
      "Epoch 160/300\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 8482035.0000 - mean_absolute_percentage_error: 17.7735\n",
      "Epoch 161/300\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 8437863.0000 - mean_absolute_percentage_error: 17.7286\n",
      "Epoch 162/300\n",
      "3/3 [==============================] - 0s 666us/step - loss: 8397330.0000 - mean_absolute_percentage_error: 17.6879\n",
      "Epoch 163/300\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 8350192.5000 - mean_absolute_percentage_error: 17.6424\n",
      "Epoch 164/300\n",
      "3/3 [==============================] - 0s 988us/step - loss: 8307596.5000 - mean_absolute_percentage_error: 17.5907\n",
      "Epoch 165/300\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 8267354.0000 - mean_absolute_percentage_error: 17.5434\n",
      "Epoch 166/300\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 8222198.0000 - mean_absolute_percentage_error: 17.4945\n",
      "Epoch 167/300\n",
      "3/3 [==============================] - 0s 667us/step - loss: 8179475.5000 - mean_absolute_percentage_error: 17.4419\n",
      "Epoch 168/300\n",
      "3/3 [==============================] - 0s 666us/step - loss: 8139234.5000 - mean_absolute_percentage_error: 17.3907\n",
      "Epoch 169/300\n",
      "3/3 [==============================] - 0s 1000us/step - loss: 8104867.0000 - mean_absolute_percentage_error: 17.3514\n",
      "Epoch 170/300\n",
      "3/3 [==============================] - 0s 666us/step - loss: 8058899.5000 - mean_absolute_percentage_error: 17.3049\n",
      "Epoch 171/300\n",
      "3/3 [==============================] - 0s 667us/step - loss: 8022664.5000 - mean_absolute_percentage_error: 17.2684\n",
      "Epoch 172/300\n",
      "3/3 [==============================] - 0s 659us/step - loss: 7975920.5000 - mean_absolute_percentage_error: 17.2120\n",
      "Epoch 173/300\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 7939521.5000 - mean_absolute_percentage_error: 17.1636\n",
      "Epoch 174/300\n",
      "3/3 [==============================] - 0s 654us/step - loss: 7899742.0000 - mean_absolute_percentage_error: 17.1148\n",
      "Epoch 175/300\n",
      "3/3 [==============================] - 0s 666us/step - loss: 7866494.0000 - mean_absolute_percentage_error: 17.0763\n",
      "Epoch 176/300\n",
      "3/3 [==============================] - 0s 663us/step - loss: 7824249.5000 - mean_absolute_percentage_error: 17.0332\n",
      "Epoch 177/300\n",
      "3/3 [==============================] - 0s 667us/step - loss: 7788403.5000 - mean_absolute_percentage_error: 16.9940\n",
      "Epoch 178/300\n",
      "3/3 [==============================] - 0s 667us/step - loss: 7747448.5000 - mean_absolute_percentage_error: 16.9525\n",
      "Epoch 179/300\n",
      "3/3 [==============================] - 0s 667us/step - loss: 7716269.0000 - mean_absolute_percentage_error: 16.9190\n",
      "Epoch 180/300\n",
      "3/3 [==============================] - 0s 789us/step - loss: 7679368.5000 - mean_absolute_percentage_error: 16.8763\n",
      "Epoch 181/300\n",
      "3/3 [==============================] - 0s 677us/step - loss: 7635166.0000 - mean_absolute_percentage_error: 16.8234\n",
      "Epoch 182/300\n",
      "3/3 [==============================] - 0s 667us/step - loss: 7601194.0000 - mean_absolute_percentage_error: 16.7757\n",
      "Epoch 183/300\n",
      "3/3 [==============================] - 0s 667us/step - loss: 7569582.5000 - mean_absolute_percentage_error: 16.7384\n",
      "Epoch 184/300\n",
      "3/3 [==============================] - 0s 988us/step - loss: 7529415.5000 - mean_absolute_percentage_error: 16.6926\n",
      "Epoch 185/300\n",
      "3/3 [==============================] - 0s 1000us/step - loss: 7493177.5000 - mean_absolute_percentage_error: 16.6504\n",
      "Epoch 186/300\n",
      "3/3 [==============================] - 0s 1000us/step - loss: 7456105.5000 - mean_absolute_percentage_error: 16.6089\n",
      "Epoch 187/300\n",
      "3/3 [==============================] - 0s 667us/step - loss: 7424536.5000 - mean_absolute_percentage_error: 16.5713\n",
      "Epoch 188/300\n",
      "3/3 [==============================] - 0s 999us/step - loss: 7387200.5000 - mean_absolute_percentage_error: 16.5308\n",
      "Epoch 189/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 666us/step - loss: 7353755.5000 - mean_absolute_percentage_error: 16.4922\n",
      "Epoch 190/300\n",
      "3/3 [==============================] - 0s 770us/step - loss: 7319369.0000 - mean_absolute_percentage_error: 16.4547\n",
      "Epoch 191/300\n",
      "3/3 [==============================] - 0s 677us/step - loss: 7285733.5000 - mean_absolute_percentage_error: 16.4094\n",
      "Epoch 192/300\n",
      "3/3 [==============================] - 0s 658us/step - loss: 7253205.0000 - mean_absolute_percentage_error: 16.3714\n",
      "Epoch 193/300\n",
      "3/3 [==============================] - 0s 667us/step - loss: 7220952.5000 - mean_absolute_percentage_error: 16.3374\n",
      "Epoch 194/300\n",
      "3/3 [==============================] - 0s 658us/step - loss: 7187141.0000 - mean_absolute_percentage_error: 16.2997\n",
      "Epoch 195/300\n",
      "3/3 [==============================] - 0s 660us/step - loss: 7154923.5000 - mean_absolute_percentage_error: 16.2624\n",
      "Epoch 196/300\n",
      "3/3 [==============================] - 0s 667us/step - loss: 7122566.5000 - mean_absolute_percentage_error: 16.2240\n",
      "Epoch 197/300\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 7090356.0000 - mean_absolute_percentage_error: 16.1859\n",
      "Epoch 198/300\n",
      "3/3 [==============================] - 0s 667us/step - loss: 7057515.5000 - mean_absolute_percentage_error: 16.1513\n",
      "Epoch 199/300\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 7029701.0000 - mean_absolute_percentage_error: 16.1158\n",
      "Epoch 200/300\n",
      "3/3 [==============================] - 0s 887us/step - loss: 6999493.0000 - mean_absolute_percentage_error: 16.0816\n",
      "Epoch 201/300\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 6971359.0000 - mean_absolute_percentage_error: 16.0432\n",
      "Epoch 202/300\n",
      "3/3 [==============================] - 0s 667us/step - loss: 6936856.0000 - mean_absolute_percentage_error: 16.0037\n",
      "Epoch 203/300\n",
      "3/3 [==============================] - 0s 992us/step - loss: 6909285.5000 - mean_absolute_percentage_error: 15.9705\n",
      "Epoch 204/300\n",
      "3/3 [==============================] - 0s 667us/step - loss: 6877371.0000 - mean_absolute_percentage_error: 15.9318\n",
      "Epoch 205/300\n",
      "3/3 [==============================] - 0s 667us/step - loss: 6848719.0000 - mean_absolute_percentage_error: 15.8958\n",
      "Epoch 206/300\n",
      "3/3 [==============================] - 0s 658us/step - loss: 6821625.5000 - mean_absolute_percentage_error: 15.8591\n",
      "Epoch 207/300\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 6795035.5000 - mean_absolute_percentage_error: 15.8250\n",
      "Epoch 208/300\n",
      "3/3 [==============================] - 0s 659us/step - loss: 6762617.0000 - mean_absolute_percentage_error: 15.7866\n",
      "Epoch 209/300\n",
      "3/3 [==============================] - 0s 658us/step - loss: 6733568.0000 - mean_absolute_percentage_error: 15.7513\n",
      "Epoch 210/300\n",
      "3/3 [==============================] - 0s 766us/step - loss: 6707011.5000 - mean_absolute_percentage_error: 15.7150\n",
      "Epoch 211/300\n",
      "3/3 [==============================] - 0s 666us/step - loss: 6681232.0000 - mean_absolute_percentage_error: 15.6797\n",
      "Epoch 212/300\n",
      "3/3 [==============================] - 0s 658us/step - loss: 6651583.5000 - mean_absolute_percentage_error: 15.6437\n",
      "Epoch 213/300\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 6623930.5000 - mean_absolute_percentage_error: 15.6048\n",
      "Epoch 214/300\n",
      "3/3 [==============================] - 0s 667us/step - loss: 6598350.0000 - mean_absolute_percentage_error: 15.5769\n",
      "Epoch 215/300\n",
      "3/3 [==============================] - 0s 657us/step - loss: 6572513.0000 - mean_absolute_percentage_error: 15.5433\n",
      "Epoch 216/300\n",
      "3/3 [==============================] - 0s 992us/step - loss: 6548438.0000 - mean_absolute_percentage_error: 15.5123\n",
      "Epoch 217/300\n",
      "3/3 [==============================] - 0s 673us/step - loss: 6521170.5000 - mean_absolute_percentage_error: 15.4822\n",
      "Epoch 218/300\n",
      "3/3 [==============================] - 0s 667us/step - loss: 6495984.0000 - mean_absolute_percentage_error: 15.4524\n",
      "Epoch 219/300\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 6471680.0000 - mean_absolute_percentage_error: 15.4176\n",
      "Epoch 220/300\n",
      "3/3 [==============================] - 0s 667us/step - loss: 6443909.5000 - mean_absolute_percentage_error: 15.3837\n",
      "Epoch 221/300\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 6422919.0000 - mean_absolute_percentage_error: 15.3538\n",
      "Epoch 222/300\n",
      "3/3 [==============================] - 0s 333us/step - loss: 6395039.5000 - mean_absolute_percentage_error: 15.3223\n",
      "Epoch 223/300\n",
      "3/3 [==============================] - 0s 657us/step - loss: 6378043.0000 - mean_absolute_percentage_error: 15.2941\n",
      "Epoch 224/300\n",
      "3/3 [==============================] - 0s 667us/step - loss: 6349610.0000 - mean_absolute_percentage_error: 15.2617\n",
      "Epoch 225/300\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 6326569.0000 - mean_absolute_percentage_error: 15.2309\n",
      "Epoch 226/300\n",
      "3/3 [==============================] - 0s 667us/step - loss: 6302662.5000 - mean_absolute_percentage_error: 15.2019\n",
      "Epoch 227/300\n",
      "3/3 [==============================] - 0s 667us/step - loss: 6279287.5000 - mean_absolute_percentage_error: 15.1681\n",
      "Epoch 228/300\n",
      "3/3 [==============================] - 0s 667us/step - loss: 6257054.0000 - mean_absolute_percentage_error: 15.1428\n",
      "Epoch 229/300\n",
      "3/3 [==============================] - ETA: 0s - loss: 4483632.5000 - mean_absolute_percentage_error: 11.708 - 0s 676us/step - loss: 6233120.5000 - mean_absolute_percentage_error: 15.1122\n",
      "Epoch 230/300\n",
      "3/3 [==============================] - 0s 658us/step - loss: 6212964.0000 - mean_absolute_percentage_error: 15.0885\n",
      "Epoch 231/300\n",
      "3/3 [==============================] - 0s 667us/step - loss: 6190687.0000 - mean_absolute_percentage_error: 15.0621\n",
      "Epoch 232/300\n",
      "3/3 [==============================] - 0s 667us/step - loss: 6167861.5000 - mean_absolute_percentage_error: 15.0348\n",
      "Epoch 233/300\n",
      "3/3 [==============================] - 0s 660us/step - loss: 6148341.5000 - mean_absolute_percentage_error: 15.0085\n",
      "Epoch 234/300\n",
      "3/3 [==============================] - 0s 781us/step - loss: 6123693.0000 - mean_absolute_percentage_error: 14.9780\n",
      "Epoch 235/300\n",
      "3/3 [==============================] - 0s 667us/step - loss: 6101644.0000 - mean_absolute_percentage_error: 14.9502\n",
      "Epoch 236/300\n",
      "3/3 [==============================] - 0s 667us/step - loss: 6084890.0000 - mean_absolute_percentage_error: 14.9284\n",
      "Epoch 237/300\n",
      "3/3 [==============================] - 0s 659us/step - loss: 6059467.5000 - mean_absolute_percentage_error: 14.8978\n",
      "Epoch 238/300\n",
      "3/3 [==============================] - 0s 1000us/step - loss: 6042931.5000 - mean_absolute_percentage_error: 14.8724\n",
      "Epoch 239/300\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 6019149.5000 - mean_absolute_percentage_error: 14.8390\n",
      "Epoch 240/300\n",
      "3/3 [==============================] - 0s 667us/step - loss: 6002315.5000 - mean_absolute_percentage_error: 14.8095\n",
      "Epoch 241/300\n",
      "3/3 [==============================] - 0s 666us/step - loss: 5983280.5000 - mean_absolute_percentage_error: 14.7813\n",
      "Epoch 242/300\n",
      "3/3 [==============================] - 0s 667us/step - loss: 5967404.5000 - mean_absolute_percentage_error: 14.7542\n",
      "Epoch 243/300\n",
      "3/3 [==============================] - 0s 658us/step - loss: 5946044.5000 - mean_absolute_percentage_error: 14.7192\n",
      "Epoch 244/300\n",
      "3/3 [==============================] - 0s 668us/step - loss: 5921908.5000 - mean_absolute_percentage_error: 14.6912\n",
      "Epoch 245/300\n",
      "3/3 [==============================] - 0s 868us/step - loss: 5904440.5000 - mean_absolute_percentage_error: 14.6748\n",
      "Epoch 246/300\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 5892051.0000 - mean_absolute_percentage_error: 14.6688\n",
      "Epoch 247/300\n",
      "3/3 [==============================] - 0s 666us/step - loss: 5872685.5000 - mean_absolute_percentage_error: 14.6511\n",
      "Epoch 248/300\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 5851390.0000 - mean_absolute_percentage_error: 14.6311\n",
      "Epoch 249/300\n",
      "3/3 [==============================] - 0s 1000us/step - loss: 5833995.5000 - mean_absolute_percentage_error: 14.6077\n",
      "Epoch 250/300\n",
      "3/3 [==============================] - 0s 992us/step - loss: 5816661.0000 - mean_absolute_percentage_error: 14.5874\n",
      "Epoch 251/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 667us/step - loss: 5798147.0000 - mean_absolute_percentage_error: 14.5642\n",
      "Epoch 252/300\n",
      "3/3 [==============================] - 0s 667us/step - loss: 5781370.5000 - mean_absolute_percentage_error: 14.5362\n",
      "Epoch 253/300\n",
      "3/3 [==============================] - 0s 1000us/step - loss: 5761231.0000 - mean_absolute_percentage_error: 14.5079\n",
      "Epoch 254/300\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 5748145.0000 - mean_absolute_percentage_error: 14.4846\n",
      "Epoch 255/300\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 5741538.5000 - mean_absolute_percentage_error: 14.4644\n",
      "Epoch 256/300\n",
      "3/3 [==============================] - 0s 674us/step - loss: 5711460.0000 - mean_absolute_percentage_error: 14.4184\n",
      "Epoch 257/300\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 5707000.5000 - mean_absolute_percentage_error: 14.4244\n",
      "Epoch 258/300\n",
      "3/3 [==============================] - 0s 667us/step - loss: 5684402.5000 - mean_absolute_percentage_error: 14.4002\n",
      "Epoch 259/300\n",
      "3/3 [==============================] - 0s 1000us/step - loss: 5661598.0000 - mean_absolute_percentage_error: 14.3788\n",
      "Epoch 260/300\n",
      "3/3 [==============================] - 0s 666us/step - loss: 5647705.5000 - mean_absolute_percentage_error: 14.3558\n",
      "Epoch 261/300\n",
      "3/3 [==============================] - 0s 667us/step - loss: 5634444.5000 - mean_absolute_percentage_error: 14.3345\n",
      "Epoch 262/300\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 5617992.0000 - mean_absolute_percentage_error: 14.3067\n",
      "Epoch 263/300\n",
      "3/3 [==============================] - 0s 667us/step - loss: 5604840.0000 - mean_absolute_percentage_error: 14.2773\n",
      "Epoch 264/300\n",
      "3/3 [==============================] - 0s 1000us/step - loss: 5589868.0000 - mean_absolute_percentage_error: 14.2457\n",
      "Epoch 265/300\n",
      "3/3 [==============================] - 0s 668us/step - loss: 5572638.0000 - mean_absolute_percentage_error: 14.2185\n",
      "Epoch 266/300\n",
      "3/3 [==============================] - 0s 666us/step - loss: 5565133.0000 - mean_absolute_percentage_error: 14.2113\n",
      "Epoch 267/300\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 5542509.5000 - mean_absolute_percentage_error: 14.1938\n",
      "Epoch 268/300\n",
      "3/3 [==============================] - 0s 667us/step - loss: 5527741.0000 - mean_absolute_percentage_error: 14.1745\n",
      "Epoch 269/300\n",
      "3/3 [==============================] - 0s 667us/step - loss: 5514725.5000 - mean_absolute_percentage_error: 14.1608\n",
      "Epoch 270/300\n",
      "3/3 [==============================] - 0s 658us/step - loss: 5508440.5000 - mean_absolute_percentage_error: 14.1603\n",
      "Epoch 271/300\n",
      "3/3 [==============================] - 0s 1000us/step - loss: 5489958.0000 - mean_absolute_percentage_error: 14.1290\n",
      "Epoch 272/300\n",
      "3/3 [==============================] - 0s 666us/step - loss: 5473939.0000 - mean_absolute_percentage_error: 14.1018\n",
      "Epoch 273/300\n",
      "3/3 [==============================] - 0s 661us/step - loss: 5456696.5000 - mean_absolute_percentage_error: 14.0706\n",
      "Epoch 274/300\n",
      "3/3 [==============================] - 0s 992us/step - loss: 5444803.5000 - mean_absolute_percentage_error: 14.0527\n",
      "Epoch 275/300\n",
      "3/3 [==============================] - 0s 660us/step - loss: 5432259.0000 - mean_absolute_percentage_error: 14.0395\n",
      "Epoch 276/300\n",
      "3/3 [==============================] - 0s 333us/step - loss: 5422168.5000 - mean_absolute_percentage_error: 14.0212\n",
      "Epoch 277/300\n",
      "3/3 [==============================] - 0s 658us/step - loss: 5404695.0000 - mean_absolute_percentage_error: 13.9978\n",
      "Epoch 278/300\n",
      "3/3 [==============================] - 0s 1000us/step - loss: 5391842.0000 - mean_absolute_percentage_error: 13.9796\n",
      "Epoch 279/300\n",
      "3/3 [==============================] - 0s 666us/step - loss: 5380911.0000 - mean_absolute_percentage_error: 13.9557\n",
      "Epoch 280/300\n",
      "3/3 [==============================] - 0s 657us/step - loss: 5370978.5000 - mean_absolute_percentage_error: 13.9332\n",
      "Epoch 281/300\n",
      "3/3 [==============================] - 0s 659us/step - loss: 5361465.0000 - mean_absolute_percentage_error: 13.9121\n",
      "Epoch 282/300\n",
      "3/3 [==============================] - 0s 666us/step - loss: 5341540.5000 - mean_absolute_percentage_error: 13.8817\n",
      "Epoch 283/300\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 5332042.0000 - mean_absolute_percentage_error: 13.8811\n",
      "Epoch 284/300\n",
      "3/3 [==============================] - 0s 667us/step - loss: 5318405.5000 - mean_absolute_percentage_error: 13.8596\n",
      "Epoch 285/300\n",
      "3/3 [==============================] - 0s 993us/step - loss: 5310125.5000 - mean_absolute_percentage_error: 13.8453\n",
      "Epoch 286/300\n",
      "3/3 [==============================] - 0s 667us/step - loss: 5296740.0000 - mean_absolute_percentage_error: 13.8223\n",
      "Epoch 287/300\n",
      "3/3 [==============================] - 0s 666us/step - loss: 5286074.5000 - mean_absolute_percentage_error: 13.8091\n",
      "Epoch 288/300\n",
      "3/3 [==============================] - 0s 1000us/step - loss: 5276310.5000 - mean_absolute_percentage_error: 13.7937\n",
      "Epoch 289/300\n",
      "3/3 [==============================] - 0s 667us/step - loss: 5264744.5000 - mean_absolute_percentage_error: 13.7670\n",
      "Epoch 290/300\n",
      "3/3 [==============================] - 0s 657us/step - loss: 5255012.0000 - mean_absolute_percentage_error: 13.7575\n",
      "Epoch 291/300\n",
      "3/3 [==============================] - 0s 667us/step - loss: 5239985.0000 - mean_absolute_percentage_error: 13.7321\n",
      "Epoch 292/300\n",
      "3/3 [==============================] - 0s 666us/step - loss: 5230230.0000 - mean_absolute_percentage_error: 13.7136\n",
      "Epoch 293/300\n",
      "3/3 [==============================] - 0s 667us/step - loss: 5218674.5000 - mean_absolute_percentage_error: 13.6895\n",
      "Epoch 294/300\n",
      "3/3 [==============================] - 0s 660us/step - loss: 5211983.5000 - mean_absolute_percentage_error: 13.6751\n",
      "Epoch 295/300\n",
      "3/3 [==============================] - 0s 785us/step - loss: 5199194.5000 - mean_absolute_percentage_error: 13.6448\n",
      "Epoch 296/300\n",
      "3/3 [==============================] - 0s 660us/step - loss: 5190614.0000 - mean_absolute_percentage_error: 13.6159\n",
      "Epoch 297/300\n",
      "3/3 [==============================] - 0s 659us/step - loss: 5178482.5000 - mean_absolute_percentage_error: 13.5896\n",
      "Epoch 298/300\n",
      "3/3 [==============================] - 0s 667us/step - loss: 5174552.0000 - mean_absolute_percentage_error: 13.5843\n",
      "Epoch 299/300\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 5169223.0000 - mean_absolute_percentage_error: 13.5666\n",
      "Epoch 300/300\n",
      "3/3 [==============================] - 0s 667us/step - loss: 5155939.0000 - mean_absolute_percentage_error: 13.5374\n",
      "WARNING:tensorflow:8 out of the last 12 calls to <function Model.make_test_function.<locals>.test_function at 0x00000290507FE8B0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 0s 973us/step - loss: 13689846.0000 - mean_absolute_percentage_error: 21.2638\n",
      "\n",
      "MAPE: 21.26%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x29054e689d0>]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#–ù–µ–π—Ä–æ–Ω–Ω—ã–µ —Å–µ—Ç–∏: –ü—Ä–æ–≥–Ω–æ–∑–∏—Ä–æ–≤–∞–Ω–∏–µ \n",
    "\n",
    "sales = pd.read_csv('monthly-car-sales-in-quebec-1960.csv', sep=';', header=0, parse_dates=[0])\n",
    "\n",
    "#–ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º –¥–∞–Ω–Ω—ã–µ\n",
    "sales_2 = pd.DataFrame()\n",
    "\n",
    "for i in range(12,0,-1):\n",
    "    sales_2['t-'+str(i)] = sales.iloc[:,1].shift(i) #–ù–æ–≤—ã–µ –∫–æ–ª–æ–Ω–∫–∏, –≥–¥–µ –∑–Ω–∞—á–µ–Ω–∏—è –∏–¥—É—Ç —Å –æ–±—Ä–∞—Ç–Ω—ã–º –≤—Ä–µ–º–µ–Ω–Ω—ã–º —à–∞–≥–æ–º(–ø–æ–º–µ—Å—è—á–Ω–æ)\n",
    "\n",
    "sales_2['t'] = sales.iloc[:,1].values #–î—É–±–ª–∏—Ä—É–µ–º –ø–µ—Ä–≤–æ–Ω–∞—á–∞–ª—å–Ω—É—é –∫–æ–ª–æ–Ω–∫—É\n",
    "sales_4 = sales_2[12:] #–û—Ç—Ä–µ–∑–∞–µ–º –ø–µ—Ä–≤—ã–µ 12 —Å—Ç—Ä–æ–∫\n",
    "\n",
    "#–ó–∞–¥–∞–µ–º –ø—Ä–µ–¥–∏–∫—Ç–æ—Ä—ã –∏ –æ—Ç–∫–ª–∏–∫\n",
    "y = sales_4['t']\n",
    "X = sales_4.drop('t', axis=1)\n",
    "\n",
    "#–†–∞–∑–¥–µ–ª—è–µ–º –Ω–∞ –æ–±—É—á–∞—é—â—É—é –∏ —Ç–µ—Å—Ç–æ–≤—É—é. –¢–µ—Å—Ç–æ–≤–∞—è - –ø–æ—Å–ª–µ–¥–Ω–∏–µ –Ω–∞–±–ª—é–¥–µ–Ω–∏—è\n",
    "X_train = X[:91]\n",
    "y_train = y[:91]\n",
    "X_test  = X[91:]\n",
    "y_test  = y[91:]\n",
    "\n",
    "#–ü—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ –≤ np.array\n",
    "X_train = X_train.values\n",
    "X_test = X_test.values\n",
    "y_train = y_train.values\n",
    "y_test = y_test.values\n",
    "\n",
    "#–°–æ–∑–¥–∞–µ–º, –∫–æ–º–ø–∏–ª–∏—Ä—É–µ–º –∏ –æ–±—É—á–∞–µ–º –º–æ–¥–µ–ª—å\n",
    "model = Sequential()\n",
    "model.add(Dense(8, input_dim=12, activation='relu'))\n",
    "model.add(Dense(1, activation='linear'))\n",
    "model.compile(loss='mean_squared_error', optimizer='adam', metrics=['mean_absolute_percentage_error'])\n",
    "model.fit(X_train, y_train, epochs=300, batch_size=None)\n",
    "\n",
    "#–æ—Ü–µ–Ω–∫–∞ –∫–∞—á–µ—Å—Ç–≤–∞ –º–æ–¥–µ–ª–∏ –Ω–∞ —Ç–µ—Å—Ç–æ–≤–æ–º –º–Ω–æ–∂–µ—Å—Ç–≤–µ\n",
    "scores = model.evaluate(X_test, y_test)\n",
    "print(\"\\nMAPE: %.2f%%\" % (scores[1]))\n",
    "\n",
    "# –í—ã—á–∏—Å–ª—è–µ–º –ø—Ä–æ–≥–Ω–æ–∑\n",
    "predictions = model.predict(X_test)\n",
    "\n",
    "# –í—ã—á–∏—Å–ª—è–µ–º –ø–æ–¥–≥–æ–Ω–∫—É\n",
    "predictions_train = model.predict(X_train)\n",
    "\n",
    "#–ì—Ä–∞—Ñ–∏–∫ —Å —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º–∏ numpy.arange(start, stop, step, dtype=None)\n",
    "x2 = np.arange(0, 91, 1)\n",
    "x3 = np.arange(91, 96, 1)\n",
    "\n",
    "plt.plot(x2, y_train, color='blue')\n",
    "plt.plot(x2, predictions_train, color='green')\n",
    "plt.plot(x3, y_test, color='blue')\n",
    "plt.plot(x3, predictions, color='red') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sales.iloc[:,1].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      t-12    t-11     t-10      t-9      t-8      t-7      t-6      t-5  \\\n",
      "0      NaN     NaN      NaN      NaN      NaN      NaN      NaN      NaN   \n",
      "1      NaN     NaN      NaN      NaN      NaN      NaN      NaN      NaN   \n",
      "2      NaN     NaN      NaN      NaN      NaN      NaN      NaN      NaN   \n",
      "3      NaN     NaN      NaN      NaN      NaN      NaN      NaN      NaN   \n",
      "4      NaN     NaN      NaN      NaN      NaN      NaN      NaN      NaN   \n",
      "5      NaN     NaN      NaN      NaN      NaN      NaN      NaN   6550.0   \n",
      "6      NaN     NaN      NaN      NaN      NaN      NaN   6550.0   8728.0   \n",
      "7      NaN     NaN      NaN      NaN      NaN   6550.0   8728.0  12026.0   \n",
      "8      NaN     NaN      NaN      NaN   6550.0   8728.0  12026.0  14395.0   \n",
      "9      NaN     NaN      NaN   6550.0   8728.0  12026.0  14395.0  14587.0   \n",
      "10     NaN     NaN   6550.0   8728.0  12026.0  14395.0  14587.0  13791.0   \n",
      "11     NaN  6550.0   8728.0  12026.0  14395.0  14587.0  13791.0   9498.0   \n",
      "12  6550.0  8728.0  12026.0  14395.0  14587.0  13791.0   9498.0   8251.0   \n",
      "\n",
      "        t-4      t-3      t-2      t-1      t  \n",
      "0       NaN      NaN      NaN      NaN   6550  \n",
      "1       NaN      NaN      NaN   6550.0   8728  \n",
      "2       NaN      NaN   6550.0   8728.0  12026  \n",
      "3       NaN   6550.0   8728.0  12026.0  14395  \n",
      "4    6550.0   8728.0  12026.0  14395.0  14587  \n",
      "5    8728.0  12026.0  14395.0  14587.0  13791  \n",
      "6   12026.0  14395.0  14587.0  13791.0   9498  \n",
      "7   14395.0  14587.0  13791.0   9498.0   8251  \n",
      "8   14587.0  13791.0   9498.0   8251.0   7049  \n",
      "9   13791.0   9498.0   8251.0   7049.0   9545  \n",
      "10   9498.0   8251.0   7049.0   9545.0   9364  \n",
      "11   8251.0   7049.0   9545.0   9364.0   8456  \n",
      "12   7049.0   9545.0   9364.0   8456.0   7237  \n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#–í—ã—á–∏—Å–ª–µ–Ω–∏–µ —Å—Ç–∞—Ç–∏—Å—Ç–∏—á–µ—Å–∫–æ–π –ø–æ–≥—Ä–µ—à–Ω–æ—Å—Ç–∏ –¥–ª—è —Å–ª—É—á–∞–π–Ω–æ–π –≤—ã–±–æ—Ä–∫–∏\n",
    "\n",
    "#–†–∞—Å—á–µ—Ç –æ–±—ä–µ–º–∞ –≤—ã–±–æ—Ä–∫–∏\n",
    "N = 40000 #–ì–µ–Ω–µ—Ä–∞–ª—å–Ω–∞—è —Å–æ–≤–æ–∫—É–ø–Ω–æ—Å—Ç—å\n",
    "P = 0.95 #–î–æ–≤–µ—Ä–∏—Ç–µ–ª—å–Ω—ã–π —É—Ä–æ–≤–µ–Ω—å –≤ 95% \n",
    "Z = 1.96 #–∫–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç –¥–æ–≤–µ—Ä–∏—Ç–µ–ª—å–Ω–æ–≥–æ —É—Ä–æ–≤–Ω—è (p = 95%, Z=1,96)(p=99%,   Z=2,58)\n",
    "p = 0.5 #–¥–æ–ª—è —Ä–µ—Å–ø–æ–Ω–¥–µ–Ω—Ç–æ–≤ —Å  –Ω–∞–ª–∏—á–∏–µ–º –∏—Å—Å–ª–µ–¥—É–µ–º–æ–≥–æ –ø—Ä–∏–∑–Ω–∞–∫–∞,\n",
    "q = (1 - p) #–¥–æ–ª—è —Ä–µ—Å–ø–æ–Ω–¥–µ–Ω—Ç–æ–≤, —É –∫–æ—Ç–æ—Ä—ã—Ö –∏—Å—Å–ª–µ–¥—É–µ–º—ã–π –ø—Ä–∏–∑–Ω–∞–∫ –æ—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç,\n",
    "delta = 0.05 #–ó–∞–¥–∞–≤–∞–µ–º–∞—è –ø—Ä–µ–¥–µ–ª—å–Ω–∞—è –æ—à–∏–±–∫–∞ –≤—ã–±–æ—Ä–∫–∏.\n",
    "n = (Z**2)*p*q/delta**2 #–æ–±—ä–µ–º –≤—ã–±–æ—Ä–∫–∏\n",
    "\n",
    "print(\"–†–µ–∫–æ–º–µ–Ω–¥—É–µ–º—ã–π –æ–±—ä–µ–º –≤—ã–±–æ—Ä–∫–∏ –¥–ª—è –¥–∞–Ω–Ω–æ–π –∞—É–¥–∏—Ç–æ—Ä–∏–∏:\", int(n), \"—á–µ–ª–æ–≤–µ–∫\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#–†–∞—Å—á–µ—Ç –æ—à–∏–±–∫–∏ –≤—ã–±–æ–∫–∏ –¥–ª—è –¥–æ–ª–∏ –ø—Ä–∏–∑–Ω–∞–∫–∞\n",
    "#–°–ª—É—á–∞–π 1. –ì–µ–Ω–µ—Ä–∞–ª—å–Ω–∞—è —Å–æ–≤–æ–∫—É–ø–Ω–æ—Å—Ç—å –∑–Ω–∞—á–∏—Ç–µ–ª—å–Ω–æ –±–æ–ª—å—à–µ –≤—ã–±–æ—Ä–∫–∏\n",
    "n = 384 #–û–±—ä–µ–º –≤—ã–±–æ—Ä–∫–∏\n",
    "m = 276 #–ß–∏—Å–ª–æ –æ–±—ä–µ–∫—Ç–æ–≤ –≤—ã–±–æ—Ä–∫–∏ —Å –Ω—É–∂–Ω—ã–º–∏ –ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º–∏ (True)\n",
    "p = m/n #–í–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å –Ω–∞ –æ—Å–Ω–æ–≤–µ –ø—Ä–∞–∫—Ç–∏—á–µ—Å–∫–∏—Ö –¥–∞–Ω–Ω—ã—Ö\n",
    "sigma = n/2*((p*(1-p)/n*(1-n/N)))**0.5 \n",
    "print('–†–µ–∑—É–ª—å—Ç–∞—Ç –≤—ã–±–æ—Ä–∫–∏ –æ–¥–∏–Ω —Å–æ—Å—Ç–∞–≤–∏—Ç: ', \\\n",
    "      float(\"{0:.1f}\".format(p*100)), \"¬±\", float(\"{0:.1f}\".format(sigma)), \"%\")\n",
    "\n",
    "#–°–ª—É—á–∞–π 2. –ì–µ–Ω–µ—Ä–∞–ª—å–Ω–∞—è —Å–æ–≤–æ–∫—É–ø–Ω–æ—Å—Ç—å —Å–æ–ø–æ—Å—Ç–∞–≤–∏–º–∞ —Å –æ–±—ä–µ–º–æ–º –≤—ã–±–æ—Ä–∫–∏\n",
    "N = 2500\n",
    "delta = Z*((p*q/n)*((N-n)/(N-1)))**0.5 \n",
    "print(\"–¢–æ—á–Ω–æ—Å—Ç—å —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –≤—ã–±–æ—Ä–∫–∏ –¥–≤–∞ —Å–æ—Å—Ç–∞–≤–∏—Ç: \", \"¬±\", float(\"{0:.1f}\".format(delta*100)), \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#–†–∞—Å—Å—á–µ—Ç –¥–æ–≤–µ—Ä–∏—Ç–µ–ª—å–Ω–æ–≥–æ –∏–Ω—Ç–µ—Ä–≤–∞–ª–∞\n",
    "P = 0.99 #–î–æ–≤–µ—Ä–∏—Ç–µ–ª—å–Ω—ã–π —É—Ä–æ–≤–µ–Ω—å –≤ 99% \n",
    "Z = 2.58 #–∫–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç –¥–æ–≤–µ—Ä–∏—Ç–µ–ª—å–Ω–æ–≥–æ —É—Ä–æ–≤–Ω—è \n",
    "p = 0.2 #–¥–æ–ª—è —Ä–µ—Å–ø–æ–Ω–¥–µ–Ω—Ç–æ–≤ —Å –Ω–∞–ª–∏—á–∏–µ–º –∏—Å—Å–ª–µ–¥—É–µ–º–æ–≥–æ –ø—Ä–∏–∑–Ω–∞–∫–∞,\n",
    "q = (1 - p) #–¥–æ–ª—è —Ä–µ—Å–ø–æ–Ω–¥–µ–Ω—Ç–æ–≤, —É –∫–æ—Ç–æ—Ä—ã—Ö –∏—Å—Å–ª–µ–¥—É–µ–º—ã–π –ø—Ä–∏–∑–Ω–∞–∫ –æ—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç,\n",
    "n = 1000 #–û–±—ä–µ–º –≤—ã–±–æ—Ä–∫–∏\n",
    "\n",
    "sigma = Z*(p*q/n)**0.5 #–ü–æ–≥—Ä–µ—à–Ω–æ—Å—Ç—å –æ—Ü–µ–Ω–∫–∏\n",
    "\n",
    "print('–¢–æ—á–Ω–æ—Å—Ç—å —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–π –≤—ã–±–æ—Ä–∫–∏ —Å–æ—Å—Ç–∞–≤–∏—Ç: ¬±', float(\"{0:.2f}\".format(sigma*100)), \"%\")\n",
    "print('–î–æ–≤–µ—Ä–∏—Ç–µ–ª—å–Ω—ã–π –∏–Ω—Ç–µ—Ä–≤–∞–ª —Å–æ—Å—Ç–∞–≤–∏—Ç:', float(\"{0:.2f}\".format((p - sigma)*100)), \"% ;\", \\\n",
    "                                            float(\"{0:.2f}\".format((p + sigma)*100)), \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#–ù–µ–Ω–æ—Ä–º–∞–ª—å–Ω—ã–µ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è\n",
    "#–°–≥–ª–∞–¥–∏—Ç—å —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ, —É–º–µ–Ω—å—à–∏–≤ —à–∫–∞–ª—É –Ω–∞ –æ—Å–Ω–æ–≤–∞–Ω–∏–∏ –ø–æ–ª–µ–∑–Ω–æ—Å—Ç–∏ –¥–∞–Ω–Ω—ã—Ö, —É–¥–∞–ª–∏–≤ –∞–Ω–æ–º–∞–ª–∏–∏\n",
    "#–õ–æ–≥–∞—Ä–∏—Ñ–º–∏—Ä–æ–≤–∞—Ç—å –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ (–Ω–µ –∑–∞–±—ã–≤–∞–µ–º –ø—Ä–æ –Ω–æ–ª—å –≤ –∏—Å—Ö–æ–¥–Ω–æ–π –ø–µ—Ä–µ–º–µ–Ω–Ω–æ–π). –°—Ö–ª–æ–ø—ã–≤–∞–µ—Ç —ç–∫—Å—Ç—Ä–µ–º–∞–ª—å–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è\n",
    "#–õ–æ–≥–∞—Ä–∏—Ñ–º–∏—Ä–æ–≤–∞–Ω–∏–µ –æ—Ç–ª–∏—á–Ω–æ —Ä–∞–±–æ—Ç–∞–µ—Ç —Å –∞—Å—Å–∏–º–µ—Ç—Ä–∏—á–Ω—ã–º–∏ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è–º–∏\n",
    "#–ï—Å–ª–∏ –ª–æ–≥–∞—Ä–∏—Ñ–º—ã –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö –∑–∞–≤–∏—Å–∏–º—ã –ª–∏–Ω–µ–π–Ω–æ, —Ç–æ –∑–Ω–∞—á–∏—Ç —Å–∞–º–∏ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –∑–∞–≤–∏—Å—è—Ç –Ω–µ–ª–∏–Ω–µ–π–Ω–æ \n",
    "#–ü—Ä–∏–º–µ–Ω–∏—Ç—å –Ω–µ–ø–∞—Ä–∞–º–µ—Ç—Ä–∏—á–µ—Å–∫–∏–π –∫—Ä–∏—Ç–µ—Ä–∏–π (—Ä–∞–Ω–≥–æ–≤–æ–µ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ)\n",
    "#–ü—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ –ë–æ–∫—Å–∞-–ö–æ–∫—Å–∞ –ø–æ–¥–±–∏—Ä–∞–µ—Ç –æ–ø—Ç–∏–º–∞–ª—å–Ω—É—é —Å—Ç–µ–ø–µ–Ω—å –¥–ª—è –≤–æ–∑–≤–µ–¥–µ–Ω–∏—è –≤ –Ω–µ–µ mathworks.com/help/finance/boxcox.html \n",
    "#Bootstrap –∏ –º–µ—Ç–æ–¥ –ú–æ–Ω—Ç–µ-–ö–∞—Ä–ª–æ. –°—Ä–∞–≤–Ω–∏–≤–∞—Ç—å –º–µ–¥–∏–∞–Ω—É, –º–∏–Ω, –º–∞–∫—Å, 13-–ø—Ä–æ—Ü–µ–Ω—Ç–∏–ª—å, —Å—Ä–µ–¥–Ω–µ–µ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* –ü—Ä–æ–≤–µ—Ä–∫–∞ –≥–∏–ø–æ—Ç–µ–∑—ã –æ –Ω–æ—Ä–º–∞–ª—å–Ω–æ—Å—Ç–∏ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è.<br>\n",
    "H0: $X \\sim N(\\cdot, \\cdot)$<br>\n",
    "H1: $X \\nsim N(\\cdot, \\cdot)$<br>\n",
    "–ö—Ä–∏—Ç–µ—Ä–∏–π –®–∞–ø–∏—Ä–æ-–£–∏–ª–∫–∞ [scipy.stats.shapiro](https://docs.scipy.org/doc/scipy-0.14.0/reference/generated/scipy.stats.shapiro.html).<br>\n",
    "\n",
    "\n",
    "* –ö—Ä–∏—Ç–µ—Ä–∏–π —Å–æ–≥–ª–∞—Å–∏—è –°—Ç—å—é–¥–µ–Ω—Ç–∞.<br>\n",
    "H0: $\\mu = M$<br>\n",
    "H1: $\\mu \\ne M$<br>\n",
    "[scipy.stats.ttest_1samp](https://docs.scipy.org/doc/scipy-0.14.0/reference/generated/scipy.stats.ttest_1samp.html).<br>\n",
    "\n",
    "\n",
    "* –ü—Ä–æ–≤–µ—Ä–∫–∞ –≥–∏–ø–æ—Ç–µ–∑—ã –æ —Ä–∞–≤–µ–Ω—Å—Ç–≤–µ —Å—Ä–µ–¥–Ω–∏—Ö –∑–Ω–∞—á–µ–Ω–∏–π.<br>\n",
    "H0: $\\mu_1 = \\mu_2$<br>\n",
    "H1: $\\mu_1 \\ne \\mu_2$<br>\n",
    "–†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –≤—ã–±–æ—Ä–æ–∫ –¥–æ–ª–∂–Ω–æ –±—ã—Ç—å –±–ª–∏–∑–∫–æ –∫ –Ω–æ—Ä–º–∞–ª—å–Ω–æ–º—É.<br>\n",
    "  * –î–ª—è –Ω–µ—Å–≤—è–∑–Ω—ã—Ö –≤—ã–±–æ—Ä–æ–∫: [scipy.stats.ttest_ind](https://docs.scipy.org/doc/scipy-0.14.0/reference/generated/scipy.stats.ttest_ind.html).<br>\n",
    "  * –î–ª—è —Å–≤—è–∑–Ω—ã—Ö –≤—ã–±–æ—Ä–æ–∫: [scipy.stats.ttest_rel](https://docs.scipy.org/doc/scipy-0.14.0/reference/generated/scipy.stats.ttest_rel.html).<br>\n",
    "  \n",
    "\n",
    "* –ü—Ä–æ–≤–µ—Ä–∫–∞ –≥–∏–ø–æ—Ç–µ–∑—ã –æ —Ä–∞–≤–µ–Ω—Å—Ç–≤–µ –º–µ–¥–∏–∞–Ω.<br>\n",
    "  * –î–ª—è –Ω–µ—Å–≤—è–∑–Ω—ã—Ö –≤—ã–±–æ—Ä–æ–∫: –∫—Ä–∏—Ç–µ—Ä–∏–π –ú–∞–Ω–Ω–∞-–£–∏—Ç–Ω–∏ [scipy.stats.mannwhitneyu](https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.mannwhitneyu.html).<br>\n",
    "  * –î–ª—è —Å–≤—è–∑–Ω—ã—Ö –≤—ã–±–æ—Ä–æ–∫: –∫—Ä–∏—Ç–µ—Ä–∏–π –£–∏–ª–∫–æ–∫—Å–æ–Ω–∞ [scipy.stats.wilcoxon](https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.wilcoxon.html).<br>\n",
    "  * –ö—Ä–∏—Ç–µ—Ä–∏–π –ú—É–¥–∞ [scipy.stats.median_test](https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.median_test.html).<br>\n",
    "\n",
    "\n",
    "* –ü—Ä–æ–≤–µ—Ä–∫–∞ –≥–∏–ø–æ—Ç–µ–∑—ã –æ —Ä–∞–≤–µ–Ω—Å—Ç–≤–µ –¥–∏—Å–ø–µ—Ä—Å–∏–π.<br>\n",
    "H0: $\\sigma_1 = \\sigma_2$<br>\n",
    "H1: $\\sigma_1 \\neq \\sigma_2$<br>\n",
    "–ö—Ä–∏—Ç–µ—Ä–∏–π –§–ª–∏–Ω–≥–µ—Ä–∞-–ö–∏–ª–∏–Ω–∞ [scipy.stats.fligner](https://docs.scipy.org/doc/scipy-0.17.0/reference/generated/scipy.stats.fligner.html).<br>\n",
    "\n",
    "\n",
    "* –ü—Ä–æ–≤–µ—Ä–∫–∞ –≥–∏–ø–æ—Ç–µ–∑—ã –æ —Ä–∞–≤–µ–Ω—Å—Ç–≤–µ –¥–æ–ª–µ–π –∫–∞—Ç–µ–≥–æ—Ä–∏–∞–ª—å–Ω–æ–≥–æ –ø—Ä–∏–∑–Ω–∞–∫–∞.<br>\n",
    "H0: $p_1 = p_2$<br>\n",
    "H1: $p_1 \\ne p_2$<br>\n",
    "–ö—Ä–∏—Ç–µ—Ä–∏–π —Ö–∏-–∫–≤–∞–¥—Ä–∞—Ç [scipy.stats.chi2_contingency](https://docs.scipy.org/doc/scipy-0.17.0/reference/generated/scipy.stats.chi2_contingency.html).<br>\n",
    "\n",
    "\n",
    "* –ü—Ä–æ–≤–µ—Ä–∫–∞ –≥–∏–ø–æ—Ç–µ–∑—ã –æ –Ω–µ–∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ (–∫–æ—Ä—Ä–µ–ª—è—Ü–∏—è).<br>\n",
    "H0: X –∏ Y –Ω–µ–∑–∞–≤–∏—Å–∏–º—ã<br>\n",
    "H1: X –∏ Y –∑–∞–≤–∏—Å–∏–º—ã<br>\n",
    "  * –î–ª—è –Ω–µ–ø—Ä–µ—Ä—ã–Ω—ã—Ö –≤–µ–ª–∏—á–∏–Ω: –∫–æ—Ä—Ä–µ–ª—è—Ü–∏—è –ü–∏—Ä—Å–æ–Ω–∞ [scipy.stats.pearsonr](https://docs.scipy.org/doc/scipy-0.14.0/reference/generated/scipy.stats.pearsonr.html),<br>\n",
    "  * –î–ª—è –¥–∏—Å–∫—Ä–µ—Ç–Ω—ã—Ö –≤–µ–ª–∏—á–∏–Ω: –∫–æ—Ä—Ä–µ–ª—è—Ü–∏—è –°–ø–∏—Ä–º—ç–Ω–∞ [scipy.stats.kendalltau](https://docs.scipy.org/doc/scipy-0.14.0/reference/generated/scipy.stats.kendalltau.html).<br>\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
