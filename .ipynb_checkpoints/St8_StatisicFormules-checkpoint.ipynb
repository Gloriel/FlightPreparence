{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib \n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "from pylab import plot,show,hist\n",
    "from scipy.stats.kde import gaussian_kde\n",
    "from scipy.stats import norm, chi2_contingency\n",
    "import statsmodels.api as sm\n",
    "from numpy import linspace,hstack\n",
    "from pylab import plot,show,hist\n",
    "import pydot\n",
    "#%config InlineBackend.figure_format = 'svg' –¥–ª—è –±–æ–ª—å—à–µ–π —á–µ—Ç–∫–æ—Å—Ç–∏ –≥—Ä–∞—Ñ–∏–∫–æ–≤\n",
    "matplotlib.style.use('ggplot')\n",
    "%matplotlib inline\n",
    "\n",
    "#–°—Ç–∞–Ω–¥–∞—Ä—Ç–∏–∑–∞—Ü–∏—è –¥–∞–Ω–Ω—ã—Ö\n",
    "from sklearn import preprocessing\n",
    "\n",
    "#–î–ª—è –ø–æ—Å—Ç—Ä–æ–µ–Ω–∏—è –¥–∏–∞–≥—Ä–∞–º–º —Ä–∞—Å—Å–µ–∏–≤–∞–Ω–∏—è\n",
    "from pandas.plotting import scatter_matrix\n",
    "\n",
    "#–ò–µ—Ä–∞—Ä—Ö–∏—á–µ—Å–∫–∏–π –∫–ª–∞—Å—Ç–µ—Ä–Ω—ã–π –∞–Ω–∞–ª–∏–∑\n",
    "from scipy.cluster.hierarchy import dendrogram, linkage, fcluster\n",
    "\n",
    "#–ö–ª–∞—Å—Ç–µ—Ä–Ω—ã–π –∞–Ω–∞–ª–∏–∑ –º–µ—Ç–æ–¥–æ–º –ö-—Å—Ä–µ–¥–Ω–∏—Ö\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "#–õ–∏–Ω–µ–π–Ω–∞—è —Ä–µ–≥—Ä–µ—Å—Å–∏—è\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "#–†–∞—Å—â–µ–ø–ª–µ–Ω–∏–µ –Ω–∞ –æ–±—É—á–∞—é—â—É—é –∏ —Ç–µ—Å—Ç–æ–≤—É—é –≤—ã–±–æ—Ä–∫–∏\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#–î–µ—Ä–µ–≤—å—è —Ä–µ—à–µ–Ω–∏–π –¥–ª—è –∑–∞–¥–∞—á–∏ –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "#–î–µ—Ä–µ–≤—å—è —Ä–µ—à–µ–Ω–∏–π –¥–ª—è –∑–∞–¥–∞—á —Ä–µ–≥—Ä–µ—Å—Å–∏–∏ \n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "#XGBoost\n",
    "from sklearn import metrics\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "\n",
    "#–ù–µ–π—Ä–æ–Ω–Ω—ã–µ —Å–µ—Ç–∏\n",
    "from keras.models import Sequential #—Ç–∏–ø —Å–µ—Ç–∏\n",
    "from keras.layers import Dense #–º–µ—Ç–æ–¥ —Å–æ–µ–¥–∏–Ω–µ–Ω–∏—è —Å–ª–æ–µ–≤\n",
    "from keras.utils import np_utils #–æ–±—Ä–∞–±–æ—Ç–∫–∞ –¥–∞–Ω–Ω—ã—Ö –ø–æ–¥ –ö–µ—Ä–∞—Å\n",
    "from keras import optimizers\n",
    "from keras import initializers\n",
    "\n",
    "\n",
    "columns = ['age', 'workclass', 'fnlwgt', 'education', 'education-num',\n",
    "           'marital-status', 'occupation', 'relationship', 'race', 'sex',\n",
    "           'capital-gain', 'capital-loss', 'hours-per-week', 'native-country', 'income']\n",
    "\n",
    "os.chdir(r'C:\\Users\\Mr Alex\\Documents\\GitHub\\FlightPreparence')\n",
    "data = pd.read_csv('AmesHousing.txt', sep=\"\\t\", header = 0, index_col=False)\n",
    "town = pd.read_csv('town_1959_2.csv', header = 0,)\n",
    "df = pd.read_csv('swiss_bank_notes.csv', index_col=0)\n",
    "beer = pd.read_csv('beverage_r.csv', sep=\";\", index_col='numb.obs')\n",
    "food = pd.read_csv('Protein Consumption in Europe.csv', sep=';', decimal=',', index_col='Country')\n",
    "ass = pd.read_csv('assess.dat', sep='\\t', index_col='NAME')\n",
    "albi = pd.read_csv('Albuquerque Home Prices_data.txt', sep='\\t')\n",
    "noble = pd.read_csv('agedeath.dat.txt', sep='\\s+', header=None, names=['group', 'age', 'index'])\n",
    "inter = pd.read_csv('interference.csv')\n",
    "diamond = pd.read_csv('diamond.dat', header=None, sep='\\s+', names=['weight', 'price'])\n",
    "cred = pd.read_csv('Credit.csv', sep=';', encoding='cp1251')\n",
    "test = pd.read_csv('adult.test', header=None, names=columns, na_values=' ?', skiprows=1)\n",
    "wine = pd.read_csv('Wine.txt', sep='\\t', header=0)\n",
    "sales = pd.read_csv('monthly-car-sales-in-quebec-1960.csv', sep=';', header=0, parse_dates=[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def two_histograms(x, y):\n",
    "    \"\"\"\n",
    "    –§—É–Ω–∫—Ü–∏—è, –∫–æ—Ç–æ—Ä–∞—è –ø–æ—Å—Ç—Ä–æ–∏—Ç –¥–≤–µ –≥–∏—Å—Ç–æ–≥—Ä–∞–º–º—ã –Ω–∞ –æ–¥–Ω–æ–π –∫–∞—Ä—Ç–∏–Ω–∫–µ.\n",
    "    –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–æ –ø—É–Ω–∫—Ç–∏—Ä–Ω—ã–º–∏ –ª–∏–Ω–∏—è–º–∏ —É–∫–∞–∑—ã–≤–∞—é—Ç—Å—è —Å—Ä–µ–¥–Ω–∏–µ –∑–Ω–∞—á–µ–Ω–∏—è –≤—ã–±–æ—Ä–æ–∫.\n",
    "    x: –≤–µ–∫—Ç–æ—Ä pd.Series,\n",
    "    y: –≤–µ–∫—Ç–æ—Ä pd.Series\n",
    "    \"\"\"\n",
    "    x.hist(alpha=0.5, weights=[1./len(x)]*len(x))\n",
    "    y.hist(alpha=0.5, weights=[1./len(y)]*len(y))\n",
    "    plt.axvline(x.mean(), color='red', alpha=0.8, linestyle='dashed')\n",
    "    plt.axvline(y.mean(), color='blue', alpha=0.8, linestyle='dashed')\n",
    "    plt.legend([x.name, y.name])\n",
    "    \n",
    "def regression_coef(model, X, y):\n",
    "    \"\"\"\n",
    "    –§—É–Ω–∫—Ü–∏—è –¥–ª—è –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è —Å—Ç–∞—Ç–∏—Å—Ç–∏—á–µ—Å–∫–æ–π –∑–Ω–∞—á–∏–º–æ—Å—Ç–∏ —Ä–µ–≥—Ä–µ—Å—Å–∏–æ–Ω–Ω—ã—Ö –∫–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç–æ–≤\n",
    "    \"\"\"\n",
    "    coef = pd.DataFrame(zip(['intercept'] + X.columns.tolist(), [model.intercept_] + model.coef_.tolist()),\n",
    "                    columns=['predictor', 'coef'])\n",
    "    X1 = np.append(np.ones((len(X),1)), X, axis=1)\n",
    "    b = np.append(model.intercept_, model.coef_)\n",
    "    MSE = np.sum((model.predict(X) - y) ** 2, axis=0) / float(X.shape[0] - X.shape[1])\n",
    "    var_b = MSE * (np.linalg.inv(np.dot(X1.T, X1)).diagonal())\n",
    "    sd_b = np.sqrt(var_b)\n",
    "    t = b / sd_b\n",
    "    coef['pvalue'] = [2 * (1 - stats.t.cdf(np.abs(i), (len(X1) - 1))) for i in t]\n",
    "    return coef"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#–ö–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è - –ø—Ä–∏–ø–∏—Å–∞–Ω–∏–µ –æ–±—ä–µ–∫—Ç–∞ –∫ –∫–ª–∞—Å—Å—É –Ω–∞ –æ—Å–Ω–æ–≤–∞–Ω–∏–∏ –∫–ª—é—á–µ–≤–æ–π (–≥—Ä—É–ø–ø–∏—Ä—É—é—â–µ–π) –ø–µ—Ä–µ–º–µ–Ω–Ω–æ–π –∏–ª–∏ —Å–æ–≤–æ–∫—É–ø–Ω–æ—Å—Ç–∏ –µ–≥–æ —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫\n",
    "#–¢–∏–ø—ã –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö. –ö–æ–ª–∏—á–µ—Å—Ç–≤–µ–Ω–Ω—ã–µ(–Ω–µ–ø—Ä–µ—Ä—ã–≤–Ω—ã–µ, –¥–∏—Å–∫—Ä–µ—Ç–Ω—ã–µ). –ù–æ–º–∏–Ω–∞–ª—å–Ω—ã–µ (–Ω–µ—Å—Ä–∞–≤–Ω–∏–≤–∞–µ–º—ã–µ). –†–∞–Ω–≥–æ–≤—ã–µ (–ø–æ—Ä—è–¥–∫–æ–≤—ã–µ)\n",
    "#–ì–∏—Å—Ç–æ–≥—Ä–∞–º–º–∞ —á–∞—Å—Ç–æ—Ç - —Ñ–æ—Ä–º–∞ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è –∫–æ–ª–∏—á–µ—Å—Ç–≤–µ–Ω–Ω–æ–≥–æ –ø—Ä–∏–∑–Ω–∞–∫–∞\n",
    "#–û–ø–∏—Å–∞—Ç–µ–ª—å–Ω–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞. –ú–µ—Ä—ã —Ü–µ–Ω—Ç—Ä–∞–ª—å–Ω–æ–π —Ç–µ–Ω–¥–µ–Ω—Ü–∏–∏. –ú–µ—Ä—ã –∏–∑–º–µ–Ω—á–∏–≤–æ—Å—Ç–∏ (–†–∞–∑–º–∞—Ö - Xmax-Xmin)\n",
    "#–ú–¶–¢. –ú–æ–¥–∞ - —Å–∞–º—ã–π —á–∞—Å—Ç—ã–π –ø—Ä–∏–∑–Ω–∞–∫. –ú–µ–¥–∏–∞–Ω–∞ - –¥–µ–ª–∏—Ç —É–ø–æ—Ä—è–¥–æ—á–µ–Ω–Ω–æ–µ –º–Ω–æ–∂–µ—Å—Ç–≤–æ –ø–æ–ø–æ–ª–∞–º. –°—Ä–µ–¥–Ω–µ–µ (–ú–∞—Ç–µ–º–∞—Ç–∏—á–µ—Å–∫–æ–µ –æ–∂–∏–¥–∞–Ω–∏–µ, EX)\n",
    "#–î–∏—Å–ø–µ—Ä—Å–∏—è D - —Å—Ä–µ–¥–Ω–∏–π –∫–≤–∞–¥—Ä–∞—Ç –æ—Ç–∫–ª–æ–Ω–µ–Ω–∏–π –∏–Ω–¥–∏–≤–∏–¥—É–∞–ª—å–Ω—ã—Ö –∑–Ω–∞—á–µ–Ω–∏–π –æ—Ç —Å—Ä–µ–¥–Ω–µ–π –≤–µ–ª–∏—á–∏–Ω—ã. –° —Ä–æ—Å—Ç–æ–º n, –¥–∏—Å–ø–µ—Ä—Å–∏—è —Å–æ–∫—Ä–∞—â–∞–µ—Ç—Å—è\n",
    "#D = —Å—É–º–º–∞(X–∏–Ω–¥ - X—Å—Ä–µ–¥)**2/n-1. –•—Å—Ä–µ–¥ –≥–µ–Ω–µ—Ä–∞–ª—å–Ω–æ–π —Å–æ–≤–æ–∫—É–ø–Ω–æ—Å—Ç–∏ –æ–±–æ–∑–Ω–∞—á–∞–µ—Ç—Å—è –∫–∞–∫ –º—é, –ú\n",
    "#–°—Ç–∞–Ω–¥–∞—Ä—Ç–Ω–æ–µ –æ—Ç–∫–ª–æ–Ω–µ–Ω–∏–µ, \"—Å–∏–≥–º–∞\", sd = D**0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#–ù–æ—Ä–º–∞–ª—å–Ω–æ–µ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ. –£–Ω–∏–º–æ–¥–∞–ª—å–Ω–æ –∏ —Å–∏–º–º–µ—Ç—Ä–∏—á–Ω–æ \n",
    "#–¶–µ–Ω—Ç—Ä–∞–ª—å–Ω–∞—è –ø—Ä–µ–¥–µ–ª—å–Ω–∞—è —Ç–µ–æ—Ä–µ–º–∞. –î–ª—è –≤—ã–±–æ—Ä–æ–∫ —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω–∞—è –æ—à–∏–±–∫–∞ —Å—Ä–µ–¥–Ω–µ–≥–æ se=SD–∏–Ω–¥/n**0.5, –≥–¥–µ n - —á–∏—Å–ª–æ —ç–ª–µ–º–µ–Ω—Ç–æ–≤ –≤—ã–±–æ—Ä–∫–∏\n",
    "#–ï—Å–ª–∏ n –≤—ã–±–æ—Ä–∫–∞ —Ä–µ–ø—Ä–µ–∑–µ–Ω—Ç–∞—Ç–∏–≤–Ω–∞—è –∏ —á–∏—Å–ª–æ —ç–ª–µ–º–µ–Ω—Ç–æ–≤ > 30, —Ç–æ se=0.5\n",
    "#–ò–Ω—Ç–µ—Ä–≤–∞–ª –¥–ª—è –ø–æ–∏—Å–∫–∞ –ú –≥–µ–Ω–µ—Ä–∞–ª—å–Ω–æ–π —Å–æ–≤–æ–∫—É–ø–Ω–æ—Å—Ç–∏(–¥–æ–≤–µ—Ä–∏—Ç–µ–ª—å–Ω—ã–π –∏–Ω—Ç–µ—Ä–≤–∞–ª): –¥–ª—è 95% –≤—ã–±–æ—Ä–æ–∫ –•—Å—Ä–µ–¥ ¬± 1.96*se –≤–∫–ª—é—á–∞—Ç –≤ —Å–µ–±—è –ú"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#–ß–∏—Å–ª–æ –Ω–∞–±–ª—é–¥–µ–Ω–∏–π(N1), –ø–æ–ø–∞–≤—à–∏—Ö –≤ —Å—Ç–æ–ª–±–µ—Ü. H = C*N1 \n",
    "#H = N1/(N*–¥–ª–∏–Ω–∞ –∏–Ω—Ç–µ—Ä–≤–∞–ª–∞) - –≤ —Ç–∞–∫–æ–º —Å–ª—É—á–∞–µ –≥–∏—Å—Ç–æ–≥—Ä–∞–º–º–∞ –±—É–¥–µ—Ç –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–Ω–æ–π, —Ç–æ –µ—Å—Ç—å –≤ –ø—Ä–µ–¥–µ–ª–∞—Ö –µ–¥–∏–Ω–∏—Ü—ã\n",
    "#–ü–ª–æ—Ç–Ω–æ—Å—Ç—å —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è f(x) –ø–æ–∑–≤–æ–ª—è–µ—Ç —Ä–∞—Å—Å—á–∏—Ç–∞—Ç—å –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å P(A) –ø–æ–ø–∞–¥–∞–Ω–∏–π –≤ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–Ω—ã–π –∏–Ω—Ç–µ—Ä–≤–∞–ª\n",
    "#–í –≥–∏—Å—Ç–æ–≥—Ä–∞–º–º–µ –Ω–∞–∏–±–æ–ª—å—à–∏–π –≤–µ—Å –∏–º–µ–µ—Ç –ø–ª–æ—â–∞–¥—å —Å—Ç–æ–ª–±—Ü–∞\n",
    "data['SalePrice'].hist(bins=60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#–ì–∏—Å—Ç–æ–≥—Ä–∞–º–º–∞ –Ω—É–∂–Ω–∞ —á—Ç–æ–±—ã –æ—Ü–µ–Ω–∏—Ç—å –æ–¥–Ω—É –≥—Ä—É–ø–ø—É\n",
    "#–í–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–Ω–∞—è –≥–∏—Å—Ç–æ–≥—Ä–∞–º–º–∞ \n",
    "data['SalePrice'].hist(density=True, bins=60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#–Ø–¥–µ—Ä–Ω–∞—è –æ—Ü–µ–Ω–∫–∞ –ø–ª–æ—Ç–Ω–æ—Å—Ç–∏ –°–∫–æ—Ç—Ç–∞-–°–∏–ª—å–≤–µ—Ä–º–∞–Ω–∞ - –æ–±–æ–±—â–µ–Ω–∏–µ –≥–∏—Å—Ç–æ–≥—Ä–∞–º–º—ã F(t) = (1/n*h)*—Å—É–º–º–∞ –≤—Å–µ—Ö –Ω–∞–±–ª—é–¥–µ–Ω–∏–π K(t-Xi/h)\n",
    "#–†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –Ø–ø–æ–Ω–µ—á–Ω–∏–∫–æ–≤–∞ –æ–ø—Ä–µ–¥–µ–ª—è–µ—Ç –ø–ª–æ—Ç–Ω–æ—Å—Ç—å –ö - —Å–∏–º–º–µ—Ç—Ä–∏—á–Ω–∞—è, –Ω–µ–æ—Ç—Ä–∏—Ü–∞—Ç–µ–ª—å–Ω–∞—è, —Å –∏–Ω—Ç–µ–≥—Ä–∞–ª–æ–º=1\n",
    "my_density = gaussian_kde(data['SalePrice'], bw_method = 1) #–ú–µ—Ç–æ–¥ –æ–ø—Ä–µ–¥–µ–ª—è–µ—Ç –º–µ—Ä—É —Å–≥–ª–∞–∂–∏–≤–∞–Ω–∏—è\n",
    "x = linspace(min(data['SalePrice']), max(data['SalePrice']),1000)\n",
    "plot(x, my_density(x),'g') #—Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —Ñ—É–Ω–∫—Ü–∏–∏\n",
    "hist(data['SalePrice'], density=True, alpha=.3) \n",
    "show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#–î–ª—è —Å—Ä–∞–≤–Ω–µ–Ω–∏—è –Ω–µ—Å–∫–æ–ª—å–∫–∏—Ö –≥—Ä—É–ø–ø –º–æ–∂–Ω–æ —Å–ª–æ–∂–∏—Ç—å –≥–∏—Å—Ç–æ–≥—Ä–∞–º–º—ã \n",
    "df.groupby('Status')['Length'].plot.hist(alpha=.6)\n",
    "plt.legend()\n",
    "#–ù–æ –ª—É—á—à–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å box-plot. –£—Å—ã - 1,5 –º–µ–∂–∫–≤–∞—Ä—Ç–∏–ª—è. Outlies - 3. Extremes - –¥–∞–ª—å—à–µ.\n",
    "#–í–Ω–∏–º–∞—Ç–µ–ª—å–Ω–æ —Å–º–æ—Ç—Ä–∏–º –Ω–∞ —á–∏—Å–ª–æ –Ω–∞–±–ª—é–¥–µ–Ω–∏–π –≤ –∫–∞–∂–¥–æ–π –∏–∑ –≤—ã–±–æ—Ä–æ–∫, —á—Ç–æ–±—ã –ø—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å boxplot\n",
    "data['MS Zoning'].value_counts()\n",
    "ax=data.boxplot(column='SalePrice', by='MS Zoning')\n",
    "ax.get_figure().suptitle('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#–î–ª—è –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è \"—Ç–∏–ø–∏—á–Ω–æ–≥–æ\" –æ–±—ä–µ–∫—Ç–∞ —Å–æ–≤–æ–∫—É–ø–Ω–æ—Å—Ç–∏ –º–æ–∂–Ω–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å —Å—Ä–µ–¥–Ω–µ–µ(–µ—Å–ª–∏ –Ω–µ—Ç –≤—ã–±—Ä–æ—Å–æ–≤) –∏–ª–∏ –º–µ–¥–∏–∞–Ω—É(–µ—Å–ª–∏ –µ—Å—Ç—å)\n",
    "#–ü—Ä–∏ –Ω–µ—Ä–∞–≤–Ω–æ–º–µ—Ä–Ω–æ–º —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–∏ –º–æ–∂–Ω–æ —É–±—Ä–∞—Ç—å –≤—ã–±—Ä–æ—Å—ã\n",
    "town_2 = town.iloc[2:1004]\n",
    "#–ò–ª–∏ –ª–æ–≥–∞—Ä–∏—Ñ–º–∏—Ä–æ–≤–∞—Ç—å –ø–µ—Ä–µ–º–µ–Ω–Ω—É—é (–¥–ª—è –ª–æ–≥-–Ω–æ—Ä–º–∞–ª—å–Ω–æ–≥–æ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è)\n",
    "x = np.log10(town[u'–Ω–∞—Å–µ–ª–µ–Ω–∏–µ'])\n",
    "pd.Series(x).hist(bins=45)\n",
    "#–£—Å–µ—á–µ–Ω–Ω–æ–µ —Å—Ä–µ–¥–Ω–µ–µ. –í—ã–±—Ä–∞—Å—ã–≤–∞–µ—Ç—Å—è 2,5% —Å–∞–º—ã—Ö –º–∞–ª—ã—Ö –∏ 2,5% –Ω–∞–∏–±–æ–ª—å—à–∏—Ö –∑–Ω–∞—á–µ–Ω–∏–π –ø–µ—Ä–µ–º–µ–Ω–Ω–æ–π. –î–ª—è –Ω–æ–≤–æ–π –ë–î —Å—á–∏—Ç–∞–µ—Ç—Å—è —Å—Ä–µ–¥–Ω–µ–µ\n",
    "exclude = int(len(town)/100*2.5)\n",
    "redacted_town = town[exclude:len(town)-exclude]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#–î–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è –∫–æ–º–ø–ª–µ–∫—Å–Ω–æ–≥–æ —Å—Ä–∞–≤–Ω–µ–Ω–∏—è –æ–±—ä–µ–∫—Ç–æ–≤ –ø–æ –Ω–µ—Å–∫–æ–ª—å–∫–∏–º –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–º\n",
    "#–î–∏–∞–≥–æ–Ω–∞–ª—å –ø–æ–∫–∞–∑—ã–≤–∞–µ—Ç —è–¥–µ—Ä–Ω—É—é –æ—Ü–µ–Ω–∫—É –ø–ª–æ—Ç–Ω–æ—Å—Ç–∏\n",
    "#–ú–∞—Ç—Ä–∏—Ü–∞ —Å–æ—Å—Ç–æ–∏—Ç –∏–∑ –¥–∏–∞–≥—Ä–∞–º–º —Ä–∞—Å—Å–µ–∏–≤–∞–Ω–∏—è\n",
    "colors = {'genuine': 'green', 'counterfeit': 'red'}\n",
    "scatter_matrix(df,\n",
    "               # —Ä–∞–∑–º–µ—Ä –∫–∞—Ä—Ç–∏–Ω–∫–∏\n",
    "               figsize=(6, 6),\n",
    "               # –ø–ª–æ—Ç–Ω–æ—Å—Ç—å –≤–º–µ—Å—Ç–æ –≥–∏—Å—Ç–æ–≥—Ä–∞–º–º—ã –Ω–∞ –¥–∏–∞–≥–æ–Ω–∞–ª–∏\n",
    "               diagonal='kde',\n",
    "               # —Ü–≤–µ—Ç–∞ –∫–ª–∞—Å—Å–æ–≤\n",
    "               c=df['Status'].replace(colors),\n",
    "               # —Å—Ç–µ–ø–µ–Ω—å –ø—Ä–æ–∑—Ä–∞—á–Ω–æ—Å—Ç–∏ —Ç–æ—á–µ–∫\n",
    "               alpha=0.2,\n",
    "              )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#–í —Å–ª—É—á–∞–µ –æ—á–µ–≤–∏–¥–Ω–æ–≥–æ —Å–º–µ—à–µ–Ω–∏—è –¥–≤—É—Ö –Ω–æ—Ä–º–∞–ª—å–Ω—ã—Ö —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–π, –º–æ–∂–Ω–æ –æ—Ü–µ–Ω–∏—Ç—å –∏—Ö –±–æ–ª–µ–µ –ø–æ–¥—Ä–æ–±–Ω–æ\n",
    "df.groupby('Status')['Diagonal'].plot.hist(alpha=0.6)\n",
    "plt.legend(loc='upper left')\n",
    "\n",
    "#–î–ª—è —Å—Ä–∞–≤–Ω–µ–Ω–∏—è –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ –≤–∞–∂–Ω–æ –∏—Ö –Ω–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞—Ç—å\n",
    "data.groupby('MS Zoning')['SalePrice'].plot.hist(density=True)\n",
    "plt.legend()\n",
    "\n",
    "#–ï—Å–ª–∏ —Ä–∞—Å—Å–µ–≤–∞–Ω–∏–µ –Ω–µ–ª—å–∑—è —Ä–∞–∑–¥–µ–ª–∏—Ç—å –ª–∏–Ω–µ–π–Ω–æ, —Ç–æ –º–µ–Ω—è–µ–º —Ç–æ—á–∫—É –Ω–∞—á–∞–ª–∞ –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç –∏ –≤—ã–±–∏—Ä–∞–µ–º –Ω–æ–≤—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –¥–ª—è —Ä–∞–∑–¥–µ–ª–µ–Ω–∏—è"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#–ò–µ—Ä–∞—Ä—Ö–∏—á–µ—Å–∫–∏–π –∫–ª–∞—Å—Ç–µ—Ä–Ω—ã–π –∞–Ω–∞–ª–∏–∑ —Ä–∞–∑–¥–µ–ª—è–µ—Ç –æ–±—ä–µ–∫—Ç—ã –Ω–∞ –≥—Ä—É–ø–ø—ã (—Å—Ç—Ä–∞—Ç–∏—Ñ–∏–∫–∞—Ü–∏—è). –ß–∏—Å–ª–æ –≥—Ä—É–ø–ø –∑–∞—Ä–∞–Ω–µ–µ –Ω–µ–∏–∑–≤–µ—Å—Ç–Ω–æ\n",
    "#–ö–ª–∞—Å—Ç–µ—Ä–Ω—ã–π –∞–Ω–∞–ª–∏–∑ –ø–æ–∑–≤–æ–ª—è–µ—Ç —Å–æ–∫—Ä–∞—Ç–∏—Ç—å —á–∏—Å–ª–æ –Ω–∞–±–ª—é–¥–µ–Ω–∏–π –∏ –ø—Ä–æ–∏–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∏—Ä–æ–≤–∞—Ç—å –∏—Ö\n",
    "#–°—Ö–æ–∂–µ—Å—Ç—å –≤–Ω—É—Ç—Ä–∏ –∫–ª–∞—Å—Ç–µ—Ä–∞ –æ—Ç–æ–±—Ä–∞–∂–∞–µ—Ç—Å—è –∫–∞–∫ —Ä–∞—Å—Å—Ç–æ—è–Ω–∏–µ–º –º–µ–∂–¥—É –±–ª–∏–∑–∫–∏–º–∏ –æ–±—ä–µ–∫—Ç–∞–º–∏ –Ω–∞ –¥–∏–∞–≥—Ä–∞–º–º–µ –∫–ª–∞—Å—Ç–µ—Ä–æ–≤\n",
    "#–†–∞—Å—Å—Ç–æ—è–Ω–∏–µ –º–æ–∂–Ω–æ —Ä–∞—Å—Å—á–∏—Ç–∞—Ç—å –º–µ—Ç–æ–¥–∞–º–∏: –ï–≤–∫–ª–∏–¥–∞(–∏–ª–∏ –∫–≤–∞–¥—Ä–∞—Ç–∞ –ï–≤–∫–ª–∏–¥–∞), –ë–ª–æ–∫(–ú–∞–Ω—Ö–µ—Ç—Ç–µ–Ω), –•—ç–º–º–∏–Ω–≥–∞(–¥–ª—è —Å–ª–æ–≤) –∏ —Ç–¥.\n",
    "#–ú–∞–Ω—Ö–µ—Ç—Ç–µ–Ω –ø—Ä–µ–¥–ø–æ—á—Ç–∏—Ç–µ–ª—å–Ω–µ–µ, –∫–æ–≥–¥–∞ –Ω–µ—Ç –±–æ–ª—å—à–∏—Ö —Ä–∞–∑–ª–∏—á–∏–π –≤ —Ä–∞–Ω–¥–æ–º–Ω—ã—Ö –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö, –ø–æ—Ç–æ–º—É —á—Ç–æ –≤–µ—Å –∞–Ω–æ–º–∞–ª–∏–π —Ç–æ–≥–¥–∞ –º–µ–Ω—å—à–µ\n",
    "#–†–∞—Å—Å—Ç–æ—è–Ω–∏–µ –º–µ–∂–¥—É –∫–ª–∞—Å—Ç–µ—Ä–∞–º–∏ —Ä–∞—Å—Å—á–∏—Ç—ã–≤–∞–µ—Ç—Å—è:\n",
    "#–ú–µ—Ç–æ–¥ –í–∞—Ä–¥–∞ (WARD) - –ø–æ–∑–≤–æ–ª—è–µ—Ç —Ä–∞–±–æ—Ç–∞—Ç—å —Å —à–∞—Ä–æ–≤—ã–º–∏ —Å–∫–æ–ø–ª–µ–Ω–∏—è–º–∏\n",
    "#–ú–µ—Ç–æ–¥ –±–ª–∏–∂–∞–π—à–∏—Ö —Å–æ—Å–µ–¥–µ–π (–ø–æ–∑–≤–æ–ª—è–µ—Ç –æ–ø—Ä–µ–¥–µ–ª—è—Ç—å –ª–µ–Ω—Ç–æ—á–Ω—ã–µ –∫–ª–∞—Å—Ç–µ—Ä—ã)\n",
    "#–°—Ä–µ–¥–Ω–µ–≤–∑–≤–µ—à–µ–Ω–Ω–æ–µ —Ä–∞—Å—Å—Ç–æ—è–Ω–∏–µ: —Å—Ä–µ–¥–Ω–µ–µ –¥–ª—è —Å—É–º–º—ã –≤—Å–µ—Ö —Ä–∞—Å—Å—Ç–æ—è–Ω–∏–π (—Ç–∞–∫–∂–µ –¥–ª—è –ª–µ–Ω—Ç–æ—á–Ω—ã—Ö)\n",
    "#–¶–µ–Ω—Ç—Ä–æ–∏–¥: —Ä–∞—Å—Å—Ç–æ—è–Ω–∏–µ –º–µ–∂–¥—É –∫–ª–∞—Å—Ç–µ—Ä–∞–º–∏ —Ä–∞–≤–Ω–æ —Ä–∞—Å—Å—Ç–æ—è–Ω–∏—é –º–µ–∂–¥—É –∏—Ö —Ü–µ–Ω—Ç—Ä–∞–º–∏ —Ç—è–∂–µ—Å—Ç–∏\n",
    "#–ú–µ—Ç–æ–¥—ã –¥–∞–ª—å–Ω–µ–≥–æ –∏ –±–ª–∏–∂–∞–π—à–µ–≥–æ —Å–æ—Å–µ–¥–∞: —Ä–∞—Å—Å—Ç–æ—è–Ω–∏–µ –º–µ–∂–¥—É —Å–∞–º—ã–º–∏ –¥–∞–ª—å–Ω–∏–º–∏\\–±–ª–∏–∑–∫–∏–º–∏ –æ–±—ä–µ–∫—Ç–∞–º–∏ –µ—Å—Ç—å –º–µ–∂–∫–ª–∞—Å—Ç–µ—Ä\n",
    "#–ú–µ—Ç–æ–¥ —Ä–∞—Å—Å—Ç–æ—è–Ω–∏—è Sorencen-Dice Q = 2*|A^B|/|A|+|B|. –ù–µ —Ä–∞–±–æ—Ç–∞–µ—Ç –µ—Å–ª–∏ –º–Ω–æ–∂–µ—Å—Ç–≤–∞ —Å–ª–∞–±–æ –ø–µ—Ä–µ—Å–µ–∫–∞—é—Ç—Å—è"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#–ê–ª–≥–æ—Ä–∏—Ç–º—ã –∫–ª–∞—Å—Ç–µ—Ä–Ω–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞. –û–±—ä–µ–∫—Ç—ã –≥—Ä—É–ø–ø–∏—Ä—É—é—Ç—Å—è —Å –±–ª–∏–∂–∞–π—à–∏–º–∏, –ø–æ–∫–∞ –Ω–µ—Ç —Å–∫–∞—á–∫–∞ –≤ —Ä–∞—Å—Å—Ç–æ—è–Ω–∏—è—Ö –¥–ª—è —Å–ª–µ–¥—É—é—â–µ–≥–æ —Å–ª–∏—è–Ω–∏—è\n",
    "#–ú–æ–º–µ–Ω—Ç –¥–ª—è –ø—Ä–µ–∫—Ä–∞—â–µ–Ω–∏—è —Å–ª–∏—è–Ω–∏—è –æ–ø—Ä–µ–¥–µ–ª—è–µ—Ç—Å—è –¥–µ–Ω–¥—Ä–æ–≥—Ä–∞–º–º–æ–π (–¥–ª—è —É–º–µ—Ä–µ–Ω–Ω–æ–≥–æ —á–∏—Å–ª–∞ –æ–±—ä–µ–∫—Ç–æ–≤)\n",
    "#–ö–∞–º–µ–Ω–∏—Å—Ç–∞—è –æ—Å—ã–ø—å/–ª–æ–∫–æ—Ç—å –ø–æ–∫–∞–∑—ã–≤–∞—é—Ç —Å–∫–∞—á–æ–∫ (—Ä–µ–∑–∫–∏–π –≤–∑–ª–µ—Ç –≥—Ä–∞—Ñ–∏–∫–∞) —à–∞–≥–æ–≤ –æ–±—ä–µ–¥–∏–Ω–µ–Ω–∏–π, –∫–æ–≥–¥–∞ –∫–ª–∞—Å—Ç–µ—Ä–∏–∑—É—é—Ç—Å—è —Ç—ã—Å—è—á–∏ –æ–±—ä–µ–∫—Ç–æ–≤\n",
    "#–ó–∞–¥–∞—á–∞ –∞–Ω–∞–ª–∏—Ç–∏–∫–∞: –æ—Ç–æ–±—Ä–∞—Ç—å –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ, –≤—ã–±—Ä–∞—Ç—å –º–µ—Ç–æ–¥ —Å—Ç–∞–Ω–¥–∞—Ä—Ç–∏–∑–∞—Ü–∏–∏, —É—Å—Ç–∞–Ω–æ–≤–∏—Ç—å —Ä–∞—Å—Å—Ç–æ—è–Ω–∏–µ –º–µ–∂–¥—É –∫–ª–∞—Å—Ç–µ—Ä–∞–º–∏ –∏ –º–µ–∂–¥—É –æ–±—ä–µ–∫—Ç–∞–º–∏ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#–û–±—ä–µ–∫—Ç, –≤ –∫–æ—Ç–æ—Ä–æ–º –±—É–¥–µ—Ç —Ö—Ä–∞–Ω–∏—Ç—Å—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ–º —Å–ª–∏—è–Ω–∏–∏ –∫–ª–∞—Å—Ç–µ—Ä–æ–≤\n",
    "#–î–ª—è —Ñ—É–Ω–∫—Ü–∏–∏ –Ω—É–∂–µ–Ω —Ñ—Ä–µ–π–º, –º–µ—Ç–æ–¥ –º–µ–∂–∫–ª–∞—Å—Ç–µ—Ä–∞ –∏ –º–µ—Ç–æ–¥ –º–µ–∂–æ–±—ä–µ–∫—Ç–æ–≤\n",
    "link = linkage(beer, 'ward', 'euclidean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#link - –º–∞—Ç—Ä–∏—Ü–∞ (n-1) x 4, –≥–¥–µ n - —á–∏—Å–ª–æ –Ω–∞–±–ª—é–¥–µ–Ω–∏–π. \n",
    "#–ö–∞–∂–¥–∞—è —Å—Ç—Ä–æ–∫–∞ - —Ä–µ–∑—É–ª—å—Ç–∞—Ç —Å–ª–∏—è–Ω–∏—è –æ—á–µ—Ä–µ–¥–Ω–æ–π –ø–∞—Ä—ã –∫–ª–∞—Å—Ç–µ—Ä–æ–≤ —Å –Ω–æ–º–µ—Ä–∞–º–∏ link[i, 0] –∏ link[i, 1]. \n",
    "#–ù–æ–≤–æ–º—É –∫–ª–∞—Å—Ç–µ—Ä—É –ø—Ä–∏—Å–≤–∞–∏–≤–∞–µ—Ç—Å—è –Ω–æ–º–µ—Ä n + i \n",
    "#link[i, 2] –æ–∑–Ω–∞—á–∞–µ—Ç —Ä–∞—Å—Å—Ç–æ—è–Ω–∏–µ –º–µ–∂–¥—É —Å–ª–∏—Ç—ã–º–∏ –∫–ª–∞—Å—Ç–µ—Ä–∞–º–∏, –∞ link[i, 3] - —Ä–∞–∑–º–µ—Ä –Ω–æ–≤–æ–≥–æ –∫–ª–∞—Å—Ç–µ—Ä–∞.\n",
    "link[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#–ü–æ—Å—Ç—Ä–æ–µ–Ω–∏–µ –¥–µ–Ω–¥—Ä–æ–≥—Ä–∞–º–º—ã\n",
    "dn = dendrogram(link, orientation='right')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#–ö–ª—é—á–µ–≤—ã–µ —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫–∏ –∫–ª–∞—Å—Ç–µ—Ä–æ–≤\n",
    "#–í –∫–æ–ª–æ–Ω–∫—É cluster –∑–∞–ø–∏—à–µ–º –Ω–æ–º–µ—Ä –∫–ª–∞—Å—Ç–µ—Ä–∞ –æ–±—ä–µ–∫—Ç–∞ —Å –ø–æ–º–æ—â—å—é —Ñ—É–Ω–∫—Ü–∏–∏ fcluster. \n",
    "#–ê—Ä–≥—É–º–µ–Ω—Ç—ã: linkage, –ø–æ—Ä–æ–≥–æ–≤–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ –¥–ª—è –º–µ–∂–∫–ª–∞—Å—Ç–µ—Ä–∞ (–ª–∏–±–æ —á–∏—Å–ª–æ –∫–ª–∞—Å—Ç–µ—Ä–æ–≤), criterion: distance –¥–ª—è –æ—Å—Ç–∞–Ω–æ–≤–∫–∏ —Ä–∞–∑–±–∏–µ–Ω–∏—è \n",
    "# –û—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º –æ–±—ä–µ–¥–∏–Ω–µ–Ω–∏–µ, –µ—Å–ª–∏ —Ä–∞—Å—Å—Ç–æ—è–Ω–∏–µ –º–µ–∂–¥—É –∫–ª–∞—Å—Ç–µ—Ä–∞–º–∏ –ø—Ä–µ–≤—ã—à–∞–µ—Ç 3\n",
    "beer['cluster'] = fcluster(link, 3, criterion='distance')\n",
    "#–î–æ–ª—è –æ–±—ä–µ–∫—Ç–æ–≤ –≤ –∫–ª–∞—Å—Ç–µ—Ä–µ, –∫–æ—Ç–æ—Ä—ã–µ –∏–º–µ—é—Ç —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—â–∏–µ —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫–∏\n",
    "beer.groupby(\"cluster\").mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#–ö–ª–∞—Å—Ç–µ—Ä–Ω—ã–π –∞–Ω–∞–ª–∏–∑ –º–µ—Ç–æ–¥–æ–º –ö-—Å—Ä–µ–¥–Ω–∏—Ö\n",
    "#–∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –º–æ–¥–µ–ª–∏\n",
    "model = KMeans(n_clusters=2, random_state=42) #random_state - –∑–µ—Ä–Ω–æ –¥–∞—Ç—á–∏–∫–∞ —Å–ª—É—á–∞–π–Ω—ã—Ö —á–∏—Å–µ–ª. –î–ª—è –≤–æ—Å–ø—Ä–æ–∏–∑–≤–æ–¥–∏–º–æ—Å—Ç–∏ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞ \n",
    "#–ü—Ä–∏ –∫–∞–∂–¥–æ–º –Ω–æ–≤–æ–º –≤—ã–∑–æ–≤–µ —Å –æ–¥–∏–Ω–∞–∫–æ–≤—ã–º–∏ random_state –º–æ–¥–µ–ª—å –±—É–¥–µ—Ç –¥–∞–≤–∞—Ç—å –æ–¥–∏–Ω–∞–∫–æ–≤—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#–ø–æ–¥–≥–æ–Ω–∫–∞ –º–æ–¥–µ–ª–∏ –ø–æ –¥–∞–Ω–Ω—ã–º –∏–∑ –ë–î\n",
    "model.fit(beer)\n",
    "\n",
    "#–†–µ–∑—É–ª—å—Ç–∞—Ç –∫–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü–∏–∏ –Ω–∞ –¥–∞–Ω–Ω—ã—Ö –∏–∑ –ë–î\n",
    "model.labels_\n",
    "\n",
    "#–∫–æ–æ—Ä–¥–∏–Ω–∞—Ç—ã —Ü–µ–Ω—Ç—Ä–æ–≤ –∫–ª–∞—Å—Ç–µ—Ä–æ–≤\n",
    "model.cluster_centers_\n",
    "\n",
    "#–î–æ–±–∞–≤–ª–µ–Ω–∏–µ –≤ –∫–ª–∞—Å—Ç–µ—Ä –¥–∞–Ω–Ω—ã—Ö. –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ –¥–ª—è –Ω–æ–≤—ã—Ö –Ω–∞–±–ª—é–¥–µ–Ω–∏–π. –ú–µ—Ç–æ–¥ predict\n",
    "new_items = [\n",
    "    [1, 1, 1, 1, 1, 1, 1, 1],\n",
    "    [0, 0, 0, 0, 0, 0, 0, 0]\n",
    "]\n",
    "model.predict(new_items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#–ß–∏—Å–ª–æ –∫–ª–∞—Å—Ç–µ—Ä–æ–≤ –º–æ–∂–Ω–æ –æ–ø—Ä–µ–¥–µ–ª–∏—Ç—å —á–µ—Ä–µ–∑ –≥—Ä–∞—Ñ–∏–∫ –ª–æ–∫—Ç—è –¥–ª—è –¥–ª—è —Ä–∞–∑–Ω–æ–≥–æ —á–∏—Å–ª–∞ –∫–ª–∞—Å—Ç–µ—Ä–æ–≤\n",
    "#–ú–µ—Ç–æ–¥ inertia_ –≤–µ—Ä–Ω—ë—Ç —Å—É–º–º—É —Ä–∞—Å—Å—Ç–æ—è–Ω–∏–π –æ—Ç –∫–∞–∂–¥–æ–π —Ç–æ—á–∫–∏ –¥–∞–Ω–Ω—ã—Ö –¥–æ —Ü–µ–Ω—Ç—Ä–∞ –±–ª–∏–∂–∞–π—à–µ–≥–æ —É –Ω–µ–π –∫–ª–∞—Å—Ç–µ—Ä–∞ \n",
    "#–ö–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü–∏—é –º–æ–∂–Ω–æ —Å—á–∏—Ç–∞—Ç—å —É—Å–ª–æ–≤–Ω–æ —Ö–æ—Ä–æ—à–µ–π, –∫–æ–≥–¥–∞ –∏–Ω–µ—Ä—Ü–∏—è –ø–µ—Ä–µ—Å—Ç–∞—ë—Ç —Å–∏–ª—å–Ω–æ —É–º–µ–Ω—å—à–∞—Ç—å—Å—è –ø—Ä–∏ —É–≤–µ–ª–∏—á–µ–Ω–∏–∏ —á–∏—Å–ª–∞ –∫–ª–∞—Å—Ç–µ—Ä–æ–≤\n",
    "K = range(1, 11)\n",
    "models = [KMeans(n_clusters=k, random_state=42).fit(beer) for k in K]\n",
    "dist = [model.inertia_ for model in models]\n",
    "\n",
    "#–ì—Ä–∞—Ñ–∏–∫ –ª–æ–∫—Ç—è\n",
    "plt.plot(K, dist, marker='o')\n",
    "plt.xlabel('k')\n",
    "plt.ylabel('Sum of distances')\n",
    "plt.title('The Elbow Method showing the optimal k')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# –í –∫–æ–ª–æ–Ω–∫–µ NR –Ω–∞—Ö–æ–¥–∏—Ç—Å—è –Ω–æ–º–µ—Ä –æ–±—ä–µ–∫—Ç–∞, –µ–≥–æ –Ω—É–∂–Ω–æ –∏—Å–∫–ª—é—á–∏—Ç—å –∏–∑ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –∫–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü–∏–∏\n",
    "del ass['NR']\n",
    "\n",
    "#–û–ø—Ç–∏–º–∏–∑–∏—Ä—É–µ–º –º–æ–¥–µ–ª—å, –º–µ–Ω—è—è —á–∏—Å–ª–æ –∑–∞–¥–∞–≤–∞–µ–º—ã—Ö –∫–ª–∞—Å—Ç–µ—Ä–æ–≤ –Ω–∞ –æ—Å–Ω–æ–≤–∞–Ω–∏–∏ –≥—Ä–∞—Ñ–∏–∫–∞ –ª–æ–∫—Ç—è\n",
    "model = KMeans(n_clusters=4, random_state=42)\n",
    "model.fit(ass)\n",
    "ass['cluster'] = model.labels_\n",
    "ass.groupby('cluster').mean()\n",
    "\n",
    "#–°–º–æ—Ç—Ä–∏–º –∫ –∫–∞–∫–æ–º—É –∫–ª–∞—Å—Ç–µ—Ä—É –∫–∞–∫–∏–µ –æ–±—ä–µ–∫—Ç—ã –æ—Ç–Ω–æ—Å—è—Ç—Å—è\n",
    "ass['cluster'].sort_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#–ü—Ä–æ–≤–µ—Ä–∫–∞ —Å—Ç–∞—Ç–∏—Å—Ç–∏—á–µ—Å–∫–∏—Ö –≥–∏–ø–æ—Ç–µ–∑:\n",
    "#–ì–∏–ø–æ—Ç–µ–∑–∞ —Å–æ–≥–ª–∞—Å–∏—è. –°–æ–≤–ø–∞–¥–∞–µ—Ç —Ä–∞–Ω–¥–æ–º–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è —Å –Ω–æ—Ä–º–∞–ª—å–Ω—ã–º —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ–º? –°–∞–º—ã–π –¥–µ—à–µ–≤—ã–π –∏ –ø—Ä–æ—Å—Ç–æ–π –≤–∞—Ä–∏–∞–Ω—Ç\n",
    "#–ì–∏–ø–æ—Ç–µ–∑–∞ —Å–æ–≥–ª–∞—Å–∏—è2. –ì–∏–ø–æ—Ç–µ–∑–∞ –æ–± —ç–∫—Å–ø–æ–Ω–µ–Ω—Ü–∏–∞–ª—å–Ω–æ—Å—Ç–∏ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è. –ù—É–∂–Ω–∞, –∫–æ–≥–¥–∞ –µ—Å—Ç—å –ø–µ—Ä–µ–º–µ–Ω–Ω–∞—è –≤—Ä–µ–º–µ–Ω–∏ –æ–∂–∏–¥–∞–Ω–∏—è\n",
    "#–ì–∏–ø–æ—Ç–µ–∑–∞ –æ–¥–Ω–æ—Ä–æ–¥–Ω–æ—Å—Ç–∏. –°–æ–≤–ø–∞–¥–∞—é—Ç –¥–≤–µ —Ä–∞–Ω–¥–æ–º–Ω—ã–µ —Ñ—É–Ω–∫—Ü–∏–∏ —Ä–∞—Å–ø—Ä–µ–¥–ª–µ–Ω–∏—è? –ù–∞–ø—Ä–∏–º–µ—Ä, —á—Ç–æ–±—ã —Å—Ä–∞–≤–Ω–∏—Ç—å –¥–∞–Ω–Ω—ã–µ –¥–æ –∏ –ø–æ—Å–ª–µ —Å–æ–±—ã—Ç–∏—è\n",
    "#–ì–∏–ø–æ—Ç–µ–∑–∞ –Ω–µ–∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏. –ù—É–ª–µ–≤–∞—è –≥–∏–ø–æ—Ç–µ–∑–∞ –¥–ª—è —Ä–∞–Ω–¥–æ–º–Ω—ã—Ö –æ–±—ä–µ–∫—Ç–æ–≤. –ü—Ä–æ–≤–µ—Ä—è–µ—Ç—Å—è —á–µ—Ä–µ–∑ –∫–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç –∫–æ—Ä—Ä–µ–ª—è—Ü–∏–∏ (—Å–∫–∞–ª—è—Ä—ã) \n",
    "#–ì–∏–ø–æ—Ç–µ–∑–∞ –æ –ø–∞—Ä–∞–º–µ—Ç—Ä–µ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è. –û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –∫–ª—é—á–µ–≤—ã—Ö –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤. –ù–∞–ø—Ä–∏–º–µ—Ä –æ–¥–∏–Ω–∞–∫–æ–≤—ã–µ —Å—Ä–µ–¥–Ω–∏–µ –∏–ª–∏ –º–µ–¥–∏–∞–Ω—ã."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#–ê–ª—å—Ñ–∞-—ç—Ç–æ —É—Ä–æ–≤–µ–Ω—å –∑–Ω–∞—á–∏–º–æ—Å—Ç–∏(0.05, 0.01. 0.005). –û–ø—Ä–µ–¥–µ–ª–µ—è–µ—Ç —á–∏—Å–ª–æ –æ—à–∏–±–æ–∫ –ø–µ—Ä–≤–æ–≥–æ —Ä–æ–¥–∞. –ù–∞ –≤—Ç–æ—Ä–æ–≥–æ —Ä–æ–¥–∞ –≤–ª–∏—è–µ—Ç —Ä–∞–∑–º–µ—Ä –≤—ã–±–æ—Ä–∫–∏\n",
    "#–¢- —ç—Ç–æ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –∫—Ä–∏—Ç–µ—Ä–∏—è. –ï—Å–ª–∏ T<C–∞–ª—å—Ñ–∞, —Ç–æ –≤–µ—Ä–Ω–∞ –Ω—É–ª–µ–≤–∞—è –≥–∏–ø–æ—Ç–µ–∑–∞\n",
    "#C–∞–ª—å—Ñ–∞- —ç—Ç–æ –∫—Ä–∏—Ç–∏—á–µ—Å–∫–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ. –í–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å –æ—Ç–≤–µ—Ä–≥–Ω—É—Ç—å –ø—Ä–∞–≤–∏–ª—å–Ω—É—é –≥–∏–ø–æ—Ç–µ–∑—É(T>C) –Ω–µ –¥–æ–ª–∂–Ω–∞ –ø—Ä–µ–≤—ã—à–∞—Ç—å –ê(–∞–ª—å—Ñ–∞)\n",
    "#p-value –ø–æ–∫–∞–∑—ã–≤–∞–µ—Ç –Ω–∞—Å–∫–æ–ª—å–∫–æ —á–∞—Å—Ç–æ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –∫—Ä–∏—Ç–µ—Ä–∏—è –≤ –≤–µ—Ä–Ω–æ–π –≥–∏–ø–æ—Ç–µ–∑–µ –±—É–¥–µ—Ç –ø—Ä–µ–≤—ã—à–∞—Ç—å —Ä–µ–∞–ª—å–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è p=P{T>T—ç–∫—Å–ø}\n",
    "#–ï—Å–ª–∏ p<A, –≥–∏–ø–æ—Ç–µ–∑—É –æ—Ç–≤–µ—Ä–≥–∞–µ–º. –ï—Å–ª–∏ p>A, –≥–∏–ø–æ—Ç–µ–∑—É –Ω–µ –æ—Ç–≤–µ—Ä–≥–∞–µ–º. –ü—Ä–æ–≤–µ—Ä—è—é—Ç—Å—è –≤—Å–µ —É—Å–ª–æ–≤–∏—è, –ø—Ä–∏ –∫–æ—Ç–æ—Ä—ã—Ö –∫—Ä–∏—Ç–µ—Ä–∏–π –±—É–¥–µ—Ç —Ä–∞–±–æ—Ç–∞—Ç—å"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#–¢–µ—Å—Ç—ã –ö–æ–ª–º–æ–≥–æ—Ä–æ–≤–∞-–°–º–∏—Ä–Ω–æ–≤–∞ –∏ Shapiro-Wilk –ø–æ–∑–≤–æ–ª—è—é—Ç –ø—Ä–æ–≤–µ—Ä–∏—Ç—å –≤—ã–±–æ—Ä–∫—É –Ω–∞ –ø—Ä–∏–Ω–∞–¥–ª–µ–∂–Ω–æ—Å—Ç—å –∫ –ì–° –∏ –Ω–æ—Ä–º–∞–ª—å–Ω–æ—Å—Ç—å —Ä–∞—Å–ø—Ä–µ–¥–µ–µ–ª–Ω–∏—è\n",
    "\n",
    "#–ü—Ä–∏–º–µ–Ω—è–µ–º –∫—Ä–∏—Ç–µ—Ä–∏–π –®–∞–ø–∏—Ä–æ-–í–∏–ª–∫–∞ –ø–æ—Å–ª–µ –ª–æ–≥–∞—Ä–∏—Ñ–º–∏—Ä–æ–≤–∞–Ω–∏—è. \n",
    "town = town.set_index(u'–Ω–æ–º–µ—Ä')\n",
    "plt.hist(np.log10(town[u'–Ω–∞—Å–µ–ª–µ–Ω–∏–µ']), bins=50)\n",
    "res = stats.shapiro(np.log10(town[u'–Ω–∞—Å–µ–ª–µ–Ω–∏–µ']))\n",
    "print('p-value: ', res[1])\n",
    "#P –æ—á–µ–Ω—å –º–∞–ª–µ–Ω—å–∫–æ–µ, –ø–æ—ç—Ç–æ–º—É –≥–∏–ø–æ—Ç–µ–∑—É –æ –Ω–æ—Ä–º–∞–ª—å–Ω–æ—Å—Ç–∏ –æ—Ç–≤–µ—Ä–≥–∞–µ–º. \n",
    "#–û—Ç–∫–ª–æ–Ω–µ–Ω–∏—è –æ—Ç –Ω–æ—Ä–º–∞–ª—å–Ω–æ—Å—Ç–∏ –±—É–¥—É—Ç –Ω–µ—Å—É—â–µ—Å—Ç–≤–µ–Ω–Ω—ã, –µ—Å–ª–∏ —É–±—Ä–∞—Ç—å –≤—ã–±—Ä–æ—Å—ã"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#–¢–µ—Å—Ç –Ω–∞ –≥–∏–ø–æ—Ç–µ–∑—É –æ–¥–Ω–æ—Ä–æ–¥–Ω–æ—Å—Ç–∏\n",
    "#–ó–∞ –æ–¥–∏–Ω –≤–∞—Ä–∏–∞–Ω—Ç –¥–∏–∑–∞–π–Ω–∞ –≤—ã–∫–∞–∑–∞–ª–æ—Å—å 28 –∏–∑ 100 –æ–ø—Ä–æ—à–µ–Ω–Ω—ã—Ö, –∑–∞ –≤—Ç–æ—Ä–æ–π 20 –∏–∑ 100 –æ–ø—Ä–æ—à–µ–Ω–Ω—ã—Ö. \n",
    "#–ü—Ä–æ–≤–µ—Ä—è–µ–º, —è–≤–ª—è–µ—Ç—Å—è –ª–∏ —ç—Ç–∞ —Ä–∞–∑–Ω–∏—Ü–∞ —Å—Ç–∞—Ç–∏—Å—Ç–∏—á–µ—Å–∫–∏ –∑–Ω–∞—á–∏–º–æ–π —Å –ø–æ–º–æ—â—å—é –∫—Ä–∏—Ç–µ—Ä–∏—è —Ö–∏-–∫–≤–∞–¥—Ä–∞—Ç. \n",
    "\n",
    "#C—Ç—Ä–æ–∏–º —Ç–∞–±–ª–∏—Ü—É —Å–æ–ø—Ä—è–∂—ë–Ω–Ω–æ—Å—Ç–∏.\n",
    "contingency_table = pd.DataFrame([[28, 72], [20, 80]],\n",
    "                                 index=['first', 'second'],\n",
    "                                 columns=['for', 'against'])\n",
    "\n",
    "res = stats.chi2_contingency(contingency_table) #AB-—Ç–µ—Å—Ç. –ü—Ä–æ–≤–µ—Ä–∫–∞ —Ä–∞–∑–Ω—ã—Ö –≤–∞—Ä–∏–∞–Ω—Ç–∞—Ö –Ω–∞ —Å—Ö–æ–∂–∏—Ö –≤—ã–±–æ—Ä–∫–∞—Ö\n",
    "print('p-value: {0}'.format(res[1]))\n",
    "\n",
    "#p-value –ø–æ–ª—É—á–∏–ª—Å—è –¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –±–æ–ª—å—à–∏–º, –ø–æ—ç—Ç–æ–º—É –æ—Å–Ω–æ–≤–∞–Ω–∏–π –æ—Ç–≤–µ—Ä–≥–Ω—É—Ç—å –≥–∏–ø–æ—Ç–µ–∑—É –æ —Ä–∞–≤–µ–Ω—Å—Ç–≤–µ –¥–æ–ª–µ–π –Ω–µ—Ç"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Z-–º–µ—Ç–∫–∞ (–æ—Ä–≥–∞–Ω–∏–∑–∞—Ü–∏—è –≤—ã–±–æ—Ä–æ–∫ —Ç–∞–∫, —á—Ç–æ–±—ã –æ–Ω–∏ –º–∞–ª–æ –æ—Ç–ª–∏—á–∞–ª–∏—Å—å –æ—Ç –Ω–æ—Ä–º–∞–ª—å–Ω–æ–≥–æ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è)\n",
    "\n",
    "s1 = 135       # —É—Å–ø–µ—Ö –≤ –≤—ã–±–æ—Ä–∫–µ –ê\n",
    "n1 = 1781      # –≤—ã–±–æ—Ä–∫–∞ –ê\n",
    "s2 = 47        # —É—Å–ø–µ—Ö –≤ –≤—ã–±–æ—Ä–∫–µ –ë\n",
    "n2 = 1443      # –≤—ã–±–æ—Ä–∫–∞ –ë\n",
    "p1 = s1/n1               #  –æ—Ü–µ–Ω–∫–∞ –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–∏ —É—Å–ø–µ—Ö–∞ –≤—ã–±–æ—Ä–∫–∞ –ê\n",
    "p2 = s2/n2               #  –æ—Ü–µ–Ω–∫–∞ –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–∏ —É—Å–ø–µ—Ö–∞ –≤—ã–±–æ—Ä–∫–∞ –ë\n",
    "p = (s1 + s2)/(n1+n2)    #  –æ—Ü–µ–Ω–∫–∞ –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–∏ —É—Å–ø–µ—Ö–∞ –≤—ã–±–æ—Ä–∫–∏ –ê+–ë\n",
    "z = (p2-p1)/ ((p*(1-p)*((1/n1)+(1/n2)))**0.5) #Z-–º–µ—Ç–∫–∞ \n",
    "\n",
    "p_value = norm.cdf(z) #–§—É–Ω–∫—Ü–∏—è —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è –Ω–æ—Ä–º–∞–ª—å–Ω–æ–≥–æ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è\n",
    "\n",
    "#  z-–º–µ—Ç–∫–∞ –∏ p-–∑–Ω–∞—á–µ–Ω–∏–µ\n",
    "print(['{:.12f}'.format(a) for a in (abs(z), p_value * 2)])\n",
    "#–ù—É–ª–µ–≤–∞—è –≥–∏–ø–æ—Ç–µ–∑–∞ –æ—Ç–≤–µ—Ä–≥–Ω—É—Ç–∞, —Å—Ç–∞—Ç–∏—Å—Ç–∏—á–µ—Å–∫–∏–µ –¥–æ–ª–∏ –æ—Ç–ª–∏—á–∞—é—Ç—Å—è\n",
    "\n",
    "#–¢–æ –∂–µ —Å–∞–º–æ–µ, –Ω–æ —Å–æ –≤—Å—Ç—Ä–æ–µ–Ω–Ω—ã–º –º–µ—Ç–æ–¥–æ–º –±–∏–±–ª–∏–æ—Ç–µ–∫–∏ statsmodels\n",
    "z1, p_value1 = sm.stats.proportions_ztest([s1, s2], [n1, n2])\n",
    "print(['{:.12f}'.format(b) for b in (z1, p_value1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#–¢–µ—Å—Ç –°—Ç—å—é–¥–µ–Ω—Ç–∞ –Ω–∞ –Ω–µ–∑–∞–≤–∏—Å–∏–º–æ—Å—Ç—å –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö\n",
    "x = noble[noble['group'] == 'sovr']['age']\n",
    "y = noble[noble['group'] == 'aris']['age']\n",
    "x.name, y.name = 'sovr', 'aris'\n",
    "two_histograms(x, y) #–î–∞–Ω–Ω—ã–µ —É—Å–ª–æ–≤–Ω–æ –Ω–æ—Ä–º–∞–ª—å–Ω—ã. \n",
    "\n",
    "#–ü—Ä–æ–≤–µ—Ä–∏–º c –ø–æ–º–æ—â—å—é –∫—Ä–∏—Ç–µ—Ä–∏—è –§–ª–∏–≥–Ω–µ—Ä–∞-–ö–∏–ª–∏–Ω–∞, —Ä–∞–≤–Ω—ã –ª–∏ –¥–∏—Å–ø–µ—Ä—Å–∏–∏.\n",
    "res = stats.fligner(x, y)\n",
    "print('p-value: ', res[1]) #p-value –Ω–∏–∑–∫–æ–µ, –≥–∏–ø–æ—Ç–µ–∑—É –æ —Ä–∞–≤–µ–Ω—Å—Ç–≤–µ –¥–∏—Å–ø–µ—Ä—Å–∏–π –æ—Ç–≤–µ—Ä–≥–∞–µ–º, –Ω–∞–±–ª—é–¥–∞–µ–º—ã–µ –æ–±—ä–µ–∫—Ç—ã –Ω–µ—Å–≤—è–∑–Ω—ã–µ \n",
    "\n",
    "#–ì–∏–ø–æ—Ç–µ–∑—É –æ —Ä–∞–≤–µ–Ω—Å—Ç–≤–µ —Å—Ä–µ–¥–Ω–∏—Ö –∑–Ω–∞—á–µ–Ω–∏–π –±—É–¥–µ–º –ø—Ä–æ–≤–µ—Ä—è—Ç—å —Å –ø–æ–º–æ—â—å—é —Ç–µ—Å—Ç–∞ –°—Ç—å—é–¥–µ–Ω—Ç–∞ –ø—Ä–∏ –Ω–µ—Ä–∞–≤–Ω—ã—Ö –¥–∏—Å–ø–µ—Ä—Å–∏—è—Ö\n",
    "res = stats.ttest_ind(x, y, equal_var=False) #–û–ø—Ü–∏—è equal_var=False –≥–æ–≤–æ—Ä–∏—Ç, —á—Ç–æ —Ä–∞–≤–µ–Ω—Å—Ç–≤–æ –¥–∏—Å–ø–µ—Ä—Å–∏–∏ –Ω–µ –ø—Ä–µ–¥–ø–æ–ª–∞–≥–∞—Ç—å\n",
    "print('p-value: ', res[1]) #P-–∑–Ω–∞—á–µ–Ω–∏–µ –∑–Ω–∞—á–∏—Ç–µ–ª—å–Ω–æ –º–µ–Ω—å—à–µ –∞–ª—å—Ñ—ã, –≥–∏–ø–æ—Ç–µ–∑–∞ –æ —Ä–∞–≤–µ–Ω—Å—Ç–≤–µ –æ—Ç–≤–µ—Ä–≥–∞–µ—Ç—Å—è\n",
    "\n",
    "#–ò—â–µ–º –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç—å —Ü–µ–Ω—ã –æ—Ç –ø–µ—Ä–µ–º–µ–Ω–Ω–æ–π COR=1 –∏ 0. –ß—Ç–æ–±—ã –ø—Ä–∏–º–µ–Ω–∏—Ç—å –°—Ç—å—é–¥–µ–Ω—Ç–∞, –ø—Ä–æ–≤–µ—Ä–∏–º –Ω–æ—Ä–º–∞–ª—å–Ω–æ—Å—Ç—å –¥–∞–Ω–Ω—ã—Ö –∏ —Ä–∞–≤–µ–Ω—Å—Ç–≤–æ –¥–∏—Å–ø–µ—Ä—Å–∏–π\n",
    "#–ó–∞–º–µ–Ω—è–µ–º -9999 (–∑–¥–µ—Å—å=–ø—É—Å—Ç–æ–µ) –Ω–∞ –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ–µ –ø—É—Å—Ç–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ.\n",
    "albi = albi.replace(-9999, np.nan)\n",
    "#–°–æ—Ö—Ä–∞–Ω–∏–º –≤ –æ—Ç–¥–µ–ª—å–Ω—ã–µ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –≤—ã–±–æ—Ä–∫–∏, –∫–æ—Ç–æ—Ä—ã–µ —Å–æ–±–∏—Ä–∞–µ–º—Å—è —Å—Ä–∞–≤–Ω–∏–≤–∞—Ç—å.\n",
    "x = albi[albi['COR'] == 1]['PRICE']\n",
    "y = albi[albi['COR'] == 0]['PRICE']\n",
    "x.name, y.name = 'corner', 'not corner'    \n",
    "\n",
    "two_histograms(x, y)  #–í–∏–¥–Ω–æ, —á—Ç–æ –≤—ã–±—Ä–æ—Å—ã –Ω–µ –¥–∞—é—Ç –ø—Ä–∏–º–µ–Ω–∏—Ç—å –°—Ç—é–¥–µ–Ω—Ç–∞ –∏ –Ω—É–∂–Ω–æ –ø—Ä–æ–±–æ–≤–∞—Ç—å –ú–∞–Ω–Ω–∞-–í–∏—Ç–Ω–∏"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#–†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –°—Ç—å—é–¥–µ–Ω—Ç–∞ (t-distribution) –¥–ª—è n<30 - –±–æ–ª–µ–µ –≤—ã—Å–æ–∫–∏–µ —Ö–≤–æ—Å—Ç—ã —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–π.–ß–∏—Å–ª–æ —Å—Ç–µ–ø–µ–Ω–µ–π —Å–≤–æ–±–æ–¥—ã df=n-1\n",
    "#t –∑–∞–º–µ–Ω—è–µ—Ç Z –≤ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–∏ –°—Ç—å—é–¥–µ–Ω—Ç–∞. t=(X–∏–Ω–¥-M)/(sd/n**0.5)\n",
    "#–ü–æ–º–∏–º–æ —Å—Ä–µ–¥–Ω–∏—Ö —Ç–∞–∫–∂–µ –Ω—É–∂–Ω–æ —Å—Ä–∞–≤–Ω–∏—Ç—å –¥–∏—Å–ø–µ—Ä—Å–∏–∏ D (—Ç–µ—Å—Ç –§–ª–∏–≥–Ω–µ—Ä–∞-–ö–∏–ª–∏–Ω–∞) –∏ –º–µ–¥–∏–∞–Ω—ã (–º–Ω–æ–≥–æ n - —Ç–µ—Å—Ç –ú—É–¥–∞, –º–∞–ª–æ n - –ú–∞–Ω–Ω-–í–∏—Ç–Ω–∏) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#–ü–∞—Ä–Ω—ã–π t-–∫—Ä–∏—Ç–µ—Ä–∏–π –°—Ç—å—é–¥–µ–Ω—Ç–∞.  X1—Å—Ä–µ–¥ - –•2—Å—Ä–µ–¥ = –ê , se=((sd1**2/n1)+(sd2**2/n2))**0.5 , df=n1+n2-2\n",
    "#–ü—Ä–∏ t = A/se –∏ df –º–æ–∂–Ω–æ —Ä–∞—Å—Å—á–∏—Ç–∞—Ç—å p –ø—Ä–∏ –∫–æ—Ç–æ—Ä–æ–º M1-M2=0. –¢–æ –µ—Å—Ç—å —Ä–∞–∑–Ω–∏—Ü—ã –º–µ–∂–¥—É –≤—ã–±–æ—Ä–∫–∞–º–∏ –ø–æ—á—Ç–∏ –Ω–µ—Ç\n",
    "#Q-Q Plot –ø–æ–∫–∞–∑—ã–≤–∞–µ—Ç –Ω–∞—Å–∫–æ–ª—å–∫–æ –≤—ã–±–æ—Ä–æ—á–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—Ç –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–Ω—ã–º(–∏–∑ –Ω–æ—Ä–º–∞–ª—å–Ω–æ–≥–æ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω—è)\n",
    "x = inter['DiffCol']\n",
    "y = inter['Black']\n",
    "x.name, y.name = 'DiffCol', 'Black'\n",
    "two_histograms(x, y)\n",
    "\n",
    "#–†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è —É—Å–ª–æ–≤–Ω–æ –Ω–æ—Ä–º–∞–ª—å–Ω—ã. –ü–æ—Å–∫–æ–ª—å–∫—É –≤ –Ω–∞–±–ª—é–¥–µ–Ω–∏—è—Ö —Å–æ–¥–µ—Ä–∂–∞—Ç—Å—è –æ–¥–Ω–∏ –∏ —Ç–µ –∂–µ –ª—é–¥–∏, –≤—ã–±–æ—Ä–∫–∏ —Å–≤—è–∑–Ω—ã–µ (–ø–∞—Ä–Ω—ã–µ)\n",
    "res = stats.ttest_rel(x, y) #–ú–µ—Ç–æ–¥ –¥–ª—è –ø–∞—Ä–Ω—ã—Ö –≤—ã–±–æ—Ä–æ–∫\n",
    "print('p-value: ', res[1])\n",
    "p-value: 0.0162416779538\n",
    "#p-value –Ω–∏–∑–∫–∏–π, –≥–∏–ø–æ—Ç–µ–∑–∞ –Ω–∞ —É—Ä–æ–≤–Ω–µ –∑–Ω–∞—á–∏–º–æ—Å—Ç–∏ 0.05 –±—É–¥–µ—Ç –æ—Ç–≤–µ—Ä–≥–Ω—É—Ç–∞, –Ω–æ –Ω–∞ —É—Ä–æ–≤–Ω–µ 0.01 —É–∂–µ –Ω–µ—Ç. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#U-–∫—Ä–∏—Ç–µ—Ä–∏–π –ú–∞–Ω–Ω–∞-–í–∏—Ç–Ω–∏ –ø–µ—Ä–µ–≤–æ–¥–∏—Ç –∑–Ω–∞—á–µ–Ω–∏—è –≤ —Ä–∞–Ω–≥–æ–≤—É—é (–Ω–µ–ø–∞—Ä–∞–º–µ—Ç—Ä–∏—á–µ—Å–∫—É—é) —à–∫–∞–ª—É –∏ –ø—Ä–æ–≤–µ—Ä—è–µ—Ç –ù–ï —Ä–∞–≤–µ–Ω—Å—Ç–≤–æ –º–µ–¥–∏–∞–Ω. P{X>Y}=P{X<Y}\n",
    "\n",
    "res = stats.mannwhitneyu(x, y)\n",
    "print('p-value:', res[1])\n",
    "#p-value –ø–æ–ª—É—á–∏–ª–æ—Å—å –¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –±–æ–ª—å—à–∏–º, –ø–æ—ç—Ç–æ–º—É —É –Ω–∞—Å –Ω–µ—Ç –æ—Å–Ω–æ–≤–∞–Ω–∏–π –æ—Ç–≤–µ—Ä–≥–Ω—É—Ç—å –≥–∏–ø–æ—Ç–µ–∑—É. –†–∞–∑–Ω–∏—Ü–∞ –º–µ–¥–∏–∞–Ω –≤ –≤—ã–±–æ—Ä–∫–∞—Ö —Å–ª—É—á–∞–π–Ω–∞."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#–ö–æ—Ä—Ä–µ–ª—è—Ü–∏—è. Scatter-plot –∏–ª–∏ –¥–∏–∞–≥—Ä–∞—Ç—Ç–∞ —Ä–∞—Å—Å–µ–∏–≤–∞–Ω–∏—è\n",
    "#–°–∏–ª–∞ –∏ –Ω–∞–ø—Ä–∞–≤–ª–µ–Ω–∏–µ –≤–∑–∞–∏–º–æ—Å–≤—è–∑–∏ –æ–ø—Ä–µ–¥–µ–ª—è–µ—Ç—Å—è –∫–æ–≤–∞—Ä–∏–∞—Ü–∏–µ–π. cov=–°—É–º–º–∞((Xi-X—Å—Ä–µ–¥)*(Yi-Y—Å—Ä–µ–¥))/N-1\n",
    "#–ö–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç –∫–æ—Ä—Ä–µ–ª—è—Ü–∏–∏ –ü–∏—Ä—Å–æ–Ω–∞ –Ω–∞—Ö–æ–¥–∏—Ç—Å—è –≤ –ø—Ä–æ–º–µ–∂—É—Ç–∫–µ [-1; 1] –∏ —Å—á–∏—Ç–∞–µ—Ç—Å—è –∫–∞–∫ Rxy=cov/SDx*SDy\n",
    "#–ö–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç –¥–µ—Ç–µ—Ä–º–∏–Ω–∞—Ü–∏–∏ r**2 –ø–æ–∫–∞–∑—ã–≤–∞–µ—Ç –≤–ª–∏—è–Ω–∏–µ –¥–∏—Å–ø–µ—Ä—Å–∏–∏ –æ–¥–Ω–æ–π –ø–µ—Ä–µ–º–µ–Ω–Ω–æ–π –Ω–∞ –¥—Ä—É–≥—É—é –≤ –ø—Ä–æ–º–µ–∂—É—Ç–∫–µ [0; 1]\n",
    "#–ö–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç –°–ø–∏—Ä–º–µ–Ω–∞ –ø–æ–∑–≤–æ–ª—è–µ—Ç –±–ª–æ–∫–∏—Ä–æ–≤–∞—Ç—å –≤—ã–±—Ä–æ—Å—ã —á–µ—Ä–µ–∑ —Ä–∞–Ω–≥–∏. d=X-Y. Rs=1-6*—Å—É–º–º–∞ d**2/N(N**2-1)\n",
    "#–ß–∞—Å—Ç–æ –∫–æ—Ä—Ä–µ–ª—è—Ü–∏—è –æ–±—É—Å–ª–æ–≤–ª–µ–Ω–∞ —Å–∫—Ä—ã—Ç–æ–π –ø–µ—Ä–µ–º–µ–Ω–Ω–æ–π\n",
    "\n",
    "#–ö–æ—Ä—Ä–µ–ª—è—Ü–∏—è —Ü–µ–Ω—ã –∏ —Ä–∞–∑–º–µ—Ä–∞\n",
    "plt.scatter(albi['PRICE'], albi['SQFT'])\n",
    "\n",
    "res = stats.pearsonr(albi['PRICE'], albi['SQFT']) #–î–æ–ø—É—Å–∫–∞–µ–º —á—Ç–æ –∫–æ—ç—Ñ—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç –∫–æ—Ä—Ä–µ–ª—è—Ü–∏–∏=0, –Ω–æ –≥–∏–ø–æ—Ç–µ–∑–∞ –æ—Ç–≤–µ—Ä–≥–Ω—É—Ç–∞\n",
    "\n",
    "print('Pearson rho: ', res[0])\n",
    "print('p-value: ', res[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#–°—Ç–∞–Ω–¥–∞—Ä—Ç–∏–∑–∞—Ü–∏—è –ø–æ–∑–≤–æ–ª—è–µ—Ç —Å–¥–µ–ª–∞—Ç—å –≤–µ—Å –≤–∞–∂–Ω—ã—Ö –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö —Å–æ–∏–∑–º–µ—Ä–∏–º—ã–º. Min=0(-1), max=1. –ò–õ–ò Z\n",
    "#Z-–°—Ç–∞–Ω–¥–∞—Ä—Ç–∏–∑–∞—Ü–∏—è: –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ –≤ —Ç–∏–ø, –≥–¥–µ –ú=0, sd = 1. –ü—Ä–∞–≤–∏–ª–æ –æ–¥–Ω–æ–π, –¥–≤—É—Ö –∏ —Ç—Ä–µ—Ö \"—Å–∏–≥–º\"\n",
    "#Z=(X–∏–Ω–¥-–ú)/sd –ü—Ä–∏–º–µ—Ä: –ø–æ —Ç–∞–±–ª–∏—Ü–µ Z, –≥–¥–µ –•—Å—Ä–µ–¥=150, sd=8, –ø—Ä–µ–≤—ã—à–∞—Ç—å X–∏–Ω–¥ –±—É–¥–µ—Ç 0.5z –∏–ª–∏ 30%\n",
    "#Z=(X—Å—Ä–µ–¥-M)/se =(18,5-20)/0.5 = -3. –í–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å –ø–æ–ª—É—á–∏—Ç—å —Ç–∞–∫–æ–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç p = 0.0027\n",
    "\n",
    "#–ï—Å–ª–∏ –≤ –ë–î –Ω–µ—Ç –µ–¥–∏–Ω–æ–π –º–µ—Ç—Ä–∏–∫–∏, —Ç–æ —Å—Ç–∞–Ω–¥–∞—Ä—Ç–∏–∑–∏—Ä—É–µ–º –¥–∞–Ω–Ω—ã–µ\n",
    "norm = preprocessing.StandardScaler()\n",
    "norm.fit(df)\n",
    "X = norm.transform(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#–î–∏—Å–ø–µ—Ä—Å–∏–æ–Ω–Ω—ã–π –ê–Ω–∞–ª–∏–∑. –ï—Å–ª–∏ –º–µ–∂–≥—Ä—É–ø–ø–æ–≤–æ–π –ø–æ–∫–∞–∑–∞—Ç–µ–ª—å –∏–∑–º–µ–Ω—á–∏–≤–æ—Å—Ç–∏ —Å–∏–ª—å–Ω–æ –ø—Ä–µ–≤—ã—à–∞–µ—Ç –≤–Ω—É—Ç—Ä–∏–≥—Ä—É–ø–ø–æ–≤–æ–π, —Ç–æ —Å—Ä–µ–¥–Ω–∏–µ —Ä–∞–∑–Ω—è—Ç—Å—è\n",
    "#SST - –æ–±—â–∞—è —Å—É–º–º–∞ –∫–≤–∞–¥—Ä–∞—Ç–æ–≤ –ø–æ–∫–∞–∑—ã–≤–∞–µ—Ç –æ–±—â—É—é –∏–∑–º–µ–Ω—á–∏–≤–æ—Å—Ç—å –¥–∞–Ω–Ω—ã—Ö. –°—É–º–º–∞(X–∏–Ω–¥-X—Å—Ä–µ–¥)**2  SST = SSW+SSB\n",
    "#SSW - —Å—É–º–º–∞ –∫–≤–∞–¥—Ä–∞—Ç–æ–≤ –≤–Ω—É—Ç—Ä–∏–≥—Ä—É–ø–ø–æ–≤–∞—è. –°—É–º–º–∞(X1–∏–Ω–¥-–•1—Å—Ä–µ–¥)**2 + ...(XN–∏–Ω–¥-–•N—Å—Ä–µ–¥)**2\n",
    "#SSB - —Å—É–º–º–∞ –∫–≤–∞–¥—Ä–∞—Ç–æ–≤ –º–µ–∂–≥—Ä—É–ø–ø–æ–≤–∞—è. SSB= n(X1—Å—Ä–µ–¥ - –•—Å—Ä–µ–¥)**2 + ...n(XN—Å—Ä–µ–¥-–•—Å—Ä–µ–¥)**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#–†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –§–∏—à–µ—Ä–∞, F-–∑–Ω–∞—á–µ–Ω–∏–µ. F=(ssb/n-1)/(ssw/N-n). –ü—Ä–∏ –≤–µ—Ä–Ω–æ—Å—Ç–∏ –Ω—É–ª–µ–≤–æ–π –≥–∏–ø–æ—Ç–µ–∑—ã –∑–Ω–∞—á–µ–Ω–∏—è F –æ—á–µ–Ω—å –º–∞–ª–µ–Ω—å–∫–∏–µ\n",
    "#–ü–æ–ø—Ä–∞–≤–∫–∞ –ë–æ–Ω—Ñ–µ—Ä—Ä–æ–Ω–∏ –Ω–∞ –º–Ω–æ–∂–µ—Å—Ç–≤–µ–Ω–Ω—É—é –ø—Ä–æ–≤–µ—Ä–∫—É –≥–∏–ø–æ—Ç–µ–∑. a = ai/n  –ù–û: –º–µ—à–∞–µ—Ç –ø–æ–ª—É—á–∏—Ç—å –∑–Ω–∞—á–∏–º—ã–µ —É—Ä–æ–≤–Ω–∏ —Ä–∞–∑–ª–∏—á–∏—è\n",
    "#FDR –∏–ª–∏ –∫—Ä–∏—Ç–µ—Ä–∏–π –¢—å—é–∫–∏ —Å—á–∏—Ç–∞–µ—Ç p-—É—Ä–æ–≤–µ–Ω—å –¥–ª—è —Å—Ä–∞–≤–Ω–∏–≤–∞–µ–º—ã—Ö –ø–∞—Ä X—Ç—ç=Xa-X–±\n",
    "#–î–≤—É—Ö–∞–∫—Ç–æ—Ä–Ω—ã–π –¥–∏—Å–ø–µ—Ä—Å–∏–æ–Ω–Ω—ã–π –∞–Ω–∞–ª–∏–∑ SStotal=SSW+SSBa +SSBb + SSBa*SSBb\n",
    "#–í–∑–∞–∏–º–æ–¥–µ–π—Å—Ç–≤–∏–µ —Ñ–∞–∫—Ç–æ—Ä–æ–≤ –≤ ANOVA\n",
    "#–î–∏—Å–ø–µ—Ä—Å–∏–æ–Ω–Ω—ã–π –∞–Ω–∞–ª–∏–∑ —Ç—Ä–µ–±—É–µ—Ç –Ω–æ—Ä–º–∞–ª—å–Ω–æ—Å—Ç–∏ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è –∑–∞–≤–∏—Å–∏–º–æ–π –ø–µ—Ä–µ–º–µ–Ω–Ω–æ–π –∏ –≥–æ–º–æ–≥–µ–Ω–Ω–æ—Å—Ç–∏ –¥–∏—Å–ø–µ—Ä—Å–∏–∏(—Ç–µ—Å—Ç –õ–µ–≤–µ–Ω–∞)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#–†–µ–≥—Ä–µ—Å—Å–∏–æ–Ω–Ω–Ω—ã–π –ê–Ω–∞–ª–∏–∑ –ø–æ–∑–≤–æ–ª—è–µ—Ç –∏—Å—Å–ª–µ–¥–æ–≤–∞—Ç—å –≤–∑–∞–∏–º–æ—Å–≤—è–∑–∏ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö –∏ –¥–µ–ª–∞—Ç—å –ª–∏–Ω–∏—é —Ç—Ä–µ–Ω–¥–∞\n",
    "#–ü—Ä–æ—Å—Ç–∞—è –õ–∏–Ω–µ–π–Ω–∞—è –†–µ–≥—Ä–µ—Å—Å–∏—è. –í–∑–∞–∏–º–æ—Å–≤—è–∑—å 2-—Ö –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö. Y-–∑–∞–≤–∏—Å–∏–º–∞—è(–æ—Ç–∫–ª–∏–∫) –•-–Ω–µ–∑–∞–≤–∏—Å–∏–º–∞—è(–ø—Ä–µ–¥–∏–∫—Ç–æ—Ä) \n",
    "#Y=B0(intercept)+B1(slope). –ó–∞—á–µ–Ω–∏–µ Y, –≥–¥–µ –ª–∏–Ω–∏—è –ø–µ—Ä–µ—Å–µ–∫–∞–µ—Ç –æ—Å—å, —É–≥–æ–ª –Ω–∞–∫–ª–æ–Ω–∞ –ª–∏–Ω–∏–∏ –∫ –æ—Å–∏ X\n",
    "#–ú–µ—Ç–æ–¥ –Ω–∞–∏–º–µ–Ω—å—à–∏—Ö –∫–≤–∞–¥—Ä–∞—Ç–æ–≤(–ú–ù–ö) –Ω–∞—Ö–æ–¥–∏—Ç –æ–ø—Ç–∏–º–∞–ª—å–Ω—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã B0 –∏ B1, —á—Ç–æ–±—ã —Å—É–º–º–∞ –∫–≤–∞–¥—Ä–∞—Ç–æ–≤ –æ—Å—Ç–∞—Ç–∫–æ–≤ (SE) –±—ã–ª–∞ –º–∏–Ω–∏–º–∞–ª—å–Ω–∞ MSE\n",
    "#–£—Ä–∞–≤–Ω–µ–Ω–∏–µ —Ä–µ–≥—Ä–µ—Å—Å–∏–∏ Y=B0+B1*X1\n",
    "#B1 = SDy/SDx*Rxy, B0 = (Y—Å—Ä–µ–¥-B1*X—Å—Ä–µ–¥), t = B1/se, df=N-2 –ï—Å–ª–∏ B1 –±–ª–∏–∑–∫–∞ –∫ –Ω—É–ª—é, —Ç–æ –≤–∑–∞–∏–º–æ—Å–≤—è–∑–∏ –ø–æ—á—Ç–∏ –Ω–µ—Ç\n",
    "#–ö–æ—ç—Ñ—Ñ—Ç—Ü—Ç–µ–Ω—Ç –î–µ—Ç–µ—Ä–º–∏–Ω–∞—Ü–∏–∏ (–≤—ã–±–æ—Ä–æ—á–Ω–∞—è –¥–∏—Å–ø–µ—Ä—Å–∏—è) R —É–∫–∞–∑—ã–≤–∞–µ—Ç –∫–∞–∫–æ–π –ø—Ä–æ—Ü–µ–Ω—Ç –≤–∞—Ä–∏–∞—Ü–∏–∏ –æ—Ç–∫–ª–∏–∫–∞ –æ–ø—Ä–µ–¥–µ–ª—è–µ—Ç—Å—è –≤–ª–∏—è–Ω–∏–µ–º –ø—Ä–µ–¥–∏–∫—Ç–æ—Ä–∞\n",
    "#R**2 = 1-(SSres/SStotal) –¥–æ–ª—è –¥–∏—Å–ø–µ—Ä—Å–∏–∏ Y, –æ–±—ä—è—Å–Ω—è–µ–º–∞—è —Ä–µ–≥—Ä–µ—Å—Å–∏–æ–Ω–Ω–æ–π –º–æ–¥–µ–ª—å—é. –ß–µ–º –±–æ–ª—å—à–µ R , —Ç–µ–º –ª—É—á—à–µ\n",
    "#–¢—Ä–µ–±–æ–≤–∞–Ω–∏—è: –ª–∏–Ω–µ–π–Ω–∞—è –≤—Ö–∞–∏–º–æ—Å–≤—è–∑—å X Y, –Ω–æ—Ä–º–∞–ª—å–Ω–æ–µ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –æ—Å—Ç–∞—Ç–∫–æ–≤, –≥–æ–º–æ—Å–∫–µ–¥–∞—Ç–∏—á–Ω–æ—Å—Ç—å(–∏–∑–º–µ–Ω—á–∏–≤–æ—Å—Ç—å) –æ—Å—Ç–∞—Ç–∫–æ–≤\n",
    "#–ò–∑–±–µ–∂–∞—Ç—å –æ—à–∏–±–æ–∫ —Å–ø–µ—Ü–∏—Ñ–∏–∫–∞—Ü–∏–∏ –ø—Ä–∏ –ª–∏–Ω–µ–π–Ω–æ–π —Ä–µ–≥—Ä–µ—Å—Å–∏–∏ –ø–æ–º–æ–≥–∞–µ—Ç –ê–Ω–∞–ª–∏–∑ –û—Å—Ç–∞—Ç–∫–æ–≤. –í—ã—è–≤–ª—è—Ç—å –∫–æ–ª–∏–Ω–µ–∞—Ä–Ω–æ—Å—Ç—å"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "albi = albi.replace(-9999, np.nan)\n",
    "print('Rows in the data frame: {0}'.format(len(albi)))\n",
    "print('Rows without NAN: {0}'.format(len(albi.dropna(how='any'))))\n",
    "\n",
    "#–°–ª–∏—à–∫–æ–º –º–Ω–æ–≥–æ –¥–∞–Ω–Ω—ã—Ö —Å–æ–¥–µ—Ä–∂–∞—Ç —Ö–æ—Ç—è –±—ã –æ–¥–Ω–æ –ø—Ä–æ–ø—É—â–µ–Ω–Ω–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ, —á—Ç–æ–±—ã —É–¥–∞–ª–∏—Ç—å –∏—Ö –≤—Å–µ. –°–º–æ—Ç—Ä–∏–º –∏—Ö —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –ø–æ –∫–æ–ª–æ–Ω–∫–∞–º\n",
    "#–§—É–Ω–∫—Ü–∏—è .apply –¥–ª—è –≤—Å–µ–π –º–∞—Ç—Ä–∏—Ü—ã. 1–π –∞—Ä–≥—É–º–µ–Ω—Ç-–ø—Ä–∏–º–µ–Ω—è–µ–º–∞—è —Ñ—É–Ω–∫—Ü–∏—è, 2–π - –Ω–∞–ø—Ä–∞–≤–ª–µ–Ω–∏–µ –ø—Ä–∏–º–µ–Ω–µ–Ω–∏—è (0 –∫ –∫–æ–ª–æ–Ω–∫–∞–º, 1 –∫–æ —Å—Ç—Ä–æ–∫–∞–º)\n",
    "albi.apply(lambda x: sum(x.isnull()), axis=0)\n",
    "\n",
    "#–ï—Å–ª–∏ –Ω–µ–ø–æ–ø—Ä–∞–≤–∏–º–æ –º–∞–ª–æ –¥–∞–Ω–Ω—ã—Ö, —É–¥–∞–ª—è–µ–º –∫–æ–ª–æ–Ω–∫—É\n",
    "del albi['AGE']\n",
    "del albi['TAX']\n",
    "\n",
    "#–ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º –∫–æ–ª–æ–Ω–∫—É –≥–¥–µ –º–æ–∂–Ω–æ –∑–∞–º–µ–Ω–∏—Ç—å –ø—Ä–æ–ø—É—Å–∫–∏\n",
    "#albi['TAX'].hist()\n",
    "\n",
    "#–ú–µ–Ω—è–µ–º –ø—Ä–æ–ø—É—â–µ–Ω–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è –Ω–∞ —Å—Ä–µ–¥–Ω–µ–µ –∑–Ω–∞—á–µ–Ω–∏–µ –ø–æ –∫–æ–ª–æ–Ω–∫–µ \n",
    "#albi['TAX'] = albi['TAX'].fillna(albi['TAX'].mean())\n",
    "\n",
    "#–°—Ç—Ä–æ–∏–º –º–æ–¥–µ–ª—å –ª–∏–Ω–µ–π–Ω–æ–π —Ä–µ–≥—Ä–µ—Å—Å–∏–∏\n",
    "X = albi.drop('PRICE', axis=1)\n",
    "y = albi['PRICE']\n",
    "model = LinearRegression()\n",
    "model.fit(X, y)\n",
    "\n",
    "#–°—á–∏—Ç–∞–µ–º –∫–∞—á–µ—Å—Ç–≤–æ –º–æ–¥–µ–ª–∏ (–∫–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç  ùëÖ**2 )\n",
    "print('R^2: {0}'.format(model.score(X, y)))\n",
    "\n",
    "#–ü—Ä–æ–º–µ–∂—É—Ç–æ—á–Ω—ã–µ –†–µ–≥—Ä–µ—Å—Å–∏–æ–Ω–Ω—ã–µ –ö–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç—ã –æ—Ç –º–µ—Ç–æ–¥–∞ model.coef_ –∏ —Å–≤–æ–±–æ–¥–Ω—ã–π —á–ª–µ–Ω –æ—Ç –º–µ—Ç–æ–¥–∞ model.intercept_\n",
    "coef = pd.DataFrame(zip(['intercept'] + X.columns.tolist(), [model.intercept_] + model.coef_.tolist()),\n",
    "                    columns=['predictor', 'coef'])\n",
    "\n",
    "#–ú–∞—Ç—Ä–∏—Ü–∞ –ø–æ–∫–∞–∑—ã–≤–∞–µ—Ç –±–∞–∑–æ–≤—É—é —Ü–µ–Ω—É –∏ –≤–µ—Å –∫–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç–æ–≤: 83.17 + 0.29*–ø–ª–æ—â–∞–¥—å SQFT + 12.17*—É–¥–æ–±—Å—Ç–≤–∞ –∏ —Ç.–¥.\n",
    "#–õ–æ–≥–∏–∫–∞ –ø–æ–∫–∞–∑—ã–≤–∞–µ—Ç, —á—Ç–æ —á—Ç–æ-—Ç–æ –Ω–µ —Ç–æ. –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞ –∫–æ–ª–∏–Ω–µ–∞—Ä–Ω–æ—Å—Ç—å\n",
    "albi.corr()\n",
    "\n",
    "#–í–∏–¥–∏–º, —á—Ç–æ –∫–æ–ª–∏–Ω–µ–∞—Ä–µ–Ω TAX. –£–±–∏—Ä–∞–µ–º –∏ —Å–Ω–æ–≤–∞ —Å—á–∏—Ç–∞–µ–º, –≤ —ç—Ç–æ—Ç —Ä–∞–∑ —Å p-–∑–Ω–∞—á–µ–Ω–∏–µ–º\n",
    "regression_coef(model, X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#–ü–æ–ª–∏–Ω–æ–º–∏–∞–ª—å–Ω–∞—è —Ä–µ–≥—Ä–µ—Å—Å–∏—è\n",
    "#–ü—Ä–µ–¥—Å–∫–∞–∑–∞—Ç—å —Ä–µ–∑—É–ª—å—Ç–∞—Ç –Ω–µ —Ç–æ–ª—å–∫–æ —Å –ø–æ–º–æ—â—å—é –ø–µ—Ä–µ–º–µ–Ω–Ω–æ–π (1—è –º–æ–¥–µ–ª—å), –Ω–æ –∏ –µ—ë –∫–≤–∞–¥—Ä–∞—Ç–∞(2—è –º–æ–¥–µ–ª—å) –∏ –∏—Ö –æ–±–µ–∏—Ö (3—è –º–æ–¥–µ–ª—å) \n",
    "#–ö–ª–∞—Å—Å PolynomialFeatures, –º–µ—Ç–æ–¥ fit_transform —Å–≥–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç –∏–∑ –º–Ω–æ–∂–µ—Å—Ç–≤–∞ —Ñ–∏—á –º–Ω–æ–∂–µ—Å—Ç–≤–æ –æ–¥–Ω–æ—á–ª–µ–Ω–æ–≤ –∑–∞–¥–∞–Ω–Ω–æ–π —Å—Ç–µ–ø–µ–Ω–∏ \n",
    "#–ù–∞–ø—Ä–∏–º–µ—Ä, –¥–ª—è —Å—Ç–µ–ø–µ–Ω–∏ 2 –∏ —Ñ–∏—á a, b –±—É–¥—É—Ç —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω—ã —Ñ–∏—á–∏ [a, b, a**2, b**2, ab] \n",
    "#–ø—Ä–∏ —É–∫–∞–∑–∞–Ω–Ω–æ–º –ø–∞—Ä–∞–º–µ—Ç—Ä–µ include_bias=True –µ—â—ë –∏ –≤–µ–∫—Ç–æ—Ä-—Å–≤–æ–±–æ–¥–Ω—ã–π —á–ª–µ–Ω –∏–∑ –µ–¥–∏–Ω–∏—Ü. \n",
    "\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "df = pd.read_csv('diamond.dat', header=None, sep='\\s+', names=['weight', 'price'])\n",
    "\n",
    "poly = PolynomialFeatures(\n",
    "                          # –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–∞—è —Å—Ç–µ–ø–µ–Ω—å\n",
    "                          degree=2,\n",
    "                          # –ù–µ –≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å —Å–≤–æ–±–æ–¥–Ω—ã–π —á–ª–µ–Ω\n",
    "                          include_bias=False)\n",
    "y = df['price']\n",
    "X0 = poly.fit_transform(df[['weight']])\n",
    "X0 = pd.DataFrame(X0, columns=['weight', 'weight**2'])\n",
    "\n",
    "X0 = [\n",
    "    # –û–¥–Ω–∞ –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω–∞—è –ø–µ—Ä–µ–º–µ–Ω–Ω–∞—è weight\n",
    "    X0[['weight']],\n",
    "    # –û–¥–Ω–∞ –ø–µ—Ä–µ–º–µ–Ω–Ω–∞—è weight**2\n",
    "    X0[['weight**2']],\n",
    "    # –î–≤–µ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö weight –∏ weight**2\n",
    "    X0.copy()]\n",
    "models = [LinearRegression() for _ in X0]\n",
    "\n",
    "for X, model in zip(X0, models):\n",
    "    model.fit(X, y)\n",
    "    print(model.score(X, y))\n",
    "    \n",
    "#ùëÖ**2  –≤–æ –≤—Å–µ—Ö –º–æ–¥–µ–ª—è—Ö –æ—á–µ–Ω—å –±–æ–ª—å—à–æ–π –∏ –ø—Ä–∏–º–µ—Ä–Ω–æ –æ–¥–∏–Ω–∞–∫–æ–≤. –ù–æ –Ω–∞ —Å–∞–º–æ–º –¥–µ–ª–µ –º–æ–¥–µ–ª–∏ —Ä–∞–∑–ª–∏—á–Ω—ã. –ü—Ä–æ–≤–µ—Ä–∏–º –∏—Ö –±–æ–ª–µ–µ —Ç—â–∞—Ç–µ–ª—å–Ω–æ\n",
    "\n",
    "regression_coef(models[0], X0[0], y)\n",
    "regression_coef(models[1], X0[1], y)\n",
    "regression_coef(models[2], X0[2], y)\n",
    "\n",
    "#–ö–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç—ã –ø–æ–∫–∞–∑—ã–≤–∞—é—Ç —Å–ø–æ—Ä–Ω—ã–µ –º–æ–º–µ–Ω—Ç—ã –≤ 1 –∏ 3 –º–æ–¥–µ–ª—è—Ö. 3-—è –æ—à–∏–±–∞–µ—Ç—Å—è –∏–∑-–∑–∞ –∫–æ–ª–∏–Ω–µ–∞—Ä–Ω–æ—Å—Ç–∏ (–ª–æ–∂–Ω–æ–π)\n",
    "\n",
    "import statsmodels.api as sm\n",
    "X2 = sm.add_constant(X0[2])\n",
    "est = sm.OLS(y, X2)\n",
    "est2 = est.fit()\n",
    "print(est2.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#–ü—Ä–æ–≥–Ω–æ–∑–∏—Ä–æ–≤–∞–Ω–∏–µ –≤—Ä–µ–º–µ–Ω–Ω—ã—Ö —Ä—è–¥–æ–≤\n",
    "#–õ–∏–Ω–µ–π–Ω–∞—è —Ä–µ–≥—Ä–µ—Å—Å–∏—è –ø–ª–æ—Ö–æ–π –º–µ—Ç–æ–¥, –Ω–æ –±–µ–∑–∞–ª—Ç–µ—Ä–Ω–∞—Ç–∏–≤–µ–Ω –ø—Ä–∏ –∫–æ—Ä–æ—Ç–∫–∏—Ö –≤—Ä–µ–º–µ–Ω–Ω—ã—Ö —Ä—è–¥–∞—Ö –∏–ª–∏ –¥–≤—É—Ö –∏–ª–∏ –±–æ–ª–µ–µ —Ñ–∞–∫—Ç–æ—Ä–∞—Ö —Å–µ–∑–æ–Ω–Ω–æ—Å—Ç–∏\n",
    "df = pd.read_csv('series_g.csv', sep=';')\n",
    "\n",
    "# –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º —Å—Ç—Ä–æ—á–∫–∏ —Å –¥–∞—Ç–∞–º–∏ –≤ –æ–±—ä–µ–∫—Ç datetime\n",
    "df['date'] = pd.to_datetime(df['date'], format='%b %Y') # format –ø–æ–∫–∞–∑—ã–≤–∞–µ—Ç —á—Ç–æ —á–∏—Ç–∞–µ–º: '%b %Y' —Ç—Ä–µ—Ö–±—É–∫–≤–µ–Ω–Ω—ã–π –º–µ—Å—è—Ü, –∑–∞—Ç–µ–º –≥–æ–¥ \n",
    "\n",
    "#–ü–æ—Å—Ç—Ä–æ–∏–º –≥—Ä–∞—Ñ–∏–∫ –ø—Ä–æ–≤–µ—Ä–∏—Ç—å —Ç–∏–ø —Ç—Ä–µ–Ω–¥–∞ (–ª–∏–Ω–µ–π–Ω—ã–π –∏–ª–∏ –Ω–µ—Ç), —Ç–∏–ø —Å–µ–∑–æ–Ω–Ω–æ—Å—Ç–∏ (–∞–¥–¥–∏—Ç–∏–≤–Ω—ã–π –∏–ª–∏ –º—É–ª—å—Ç–∏–ø–ª–∏–∫–∞—Ç–∏–≤–Ω—ã–π), –µ–≥–æ –¥–ª–∏–Ω—É, –≤—ã–±—Ä–æ—Å—ã\n",
    "#–í–∏–¥–∏–º –ª–∏–Ω–µ–π–Ω—ã–π —Ç—Ä–µ–Ω–¥ –∏ –º—É–ª—å—Ç–∏–ø–ª–∏–∫–∞—Ç–∏–≤–Ω—É—é —Å–µ–∑–æ–Ω–Ω–æ—Å—Ç—å. –≠—Ç–æ –ø–æ–¥—Ç–≤–µ—Ä–∂–¥–∞–µ—Ç—Å—è –ø–æ—Å–ª–µ –ª–æ–≥–∏—Ä–∞—Ñ–º–∏—Ä–æ–≤–∞–Ω–∏–µ —Ü–∏–∫–ª–∞ \n",
    "\n",
    "fig = plt.figure(figsize=(12, 4))\n",
    "ax1 = fig.add_subplot(121)\n",
    "df['series_g'].plot(ax=ax1)\n",
    "ax1.set_title(u'–û–±—ä—ë–º –ø–∞—Å—Å–∞–∂–∏—Ä–æ–ø–µ—Ä–µ–≤–æ–∑–æ–∫')\n",
    "ax1.set_ylabel(u'–¢—ã—Å—è—á —á–µ–ª–æ–≤–µ–∫')\n",
    "\n",
    "ax2 = fig.add_subplot(122)\n",
    "pd.Series(np.log10(df['series_g'])).plot(ax=ax2)\n",
    "ax2.set_title(u'log10 –æ—Ç –æ–±—ä—ë–º–∞ –ø–∞—Å—Å–∞–∂–∏—Ä–æ–ø–µ—Ä–µ–≤–æ–∑–æ–∫')\n",
    "ax2.set_ylabel(u'log10 –æ—Ç —Ç—ã—Å—è—á —á–µ–ª–æ–≤–µ–∫')\n",
    "\n",
    "#–í—ã–≤–æ–¥: –±—É–¥–µ–º —Å—Ç—Ä–æ–∏—Ç—å –º–æ–¥–µ–ª—å –ª–∏–Ω–µ–π–Ω–æ–π —Ä–µ–≥—Ä–µ—Å—Å–∏–∏ –¥–ª—è –ø—Ä–∏–±–ª–∏–∂–µ–Ω–∏—è –ª–æ–≥–∞—Ä–∏—Ñ–º–∞ –æ—Ç –æ–±—ä—ë–º–∞ –ø–µ—Ä–µ–≤–æ–∑–æ–∫. \n",
    "# logùë¶ùëñ=ùõΩùë•ùëñ+ùëê(ùë•ùëñ)+ùúÄùëñ, –≥–¥–µ  ùë¶ùëñ –æ–±—ä—ë–º –ø–µ—Ä–µ–≤–æ–∑–æ–∫,  ùë•ùëñ –ø–æ—Ä—è–¥–∫–æ–≤—ã–π –Ω–æ–º–µ—Ä –º–µ—Å—è—Ü–∞,  ùëê(ùë•ùëñ) —Å–µ–∑–æ–Ω–Ω–∞—è —Å–æ—Å—Ç–∞–≤–ª—è—é—â–∞—è,  ùúÄùëñ  —Å–ª—É—á–∞–π–Ω—ã–π —à—É–º\n",
    "#–°–æ–∑–¥–∞–¥–∏–º –Ω–æ–≤—ã–π –æ–±—ä–µ–∫—Ç –∫–ª–∞—Å—Å–∞ DateTimeIndex –¥–ª—è 12 –Ω–æ–≤—ã—Ö –¥–∞—Ç (–º–µ—Å—è—Ü–µ–≤) —Å –ø–æ–º–æ—â—å—é —Ñ—É–Ω–∫—Ü–∏–∏ pd.date_range. \n",
    "# –°–æ–∑–¥–∞—ë–º –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å—Å—Ç—å –º–µ—Å—è—Ü–µ–≤. freq='MS' –æ–∑–Ω–∞—á–∞–µ—Ç –ø–µ—Ä–≤–æ–µ —á–∏—Å–ª–æ –∫–∞–∂–¥–æ–≥–æ –º–µ—Å—è—Ü–∞ –∏–∑ —É–∫–∞–∑–∞–Ω–Ω–æ–≥–æ –¥–∏–∞–ø–∞–∑–æ–Ω–∞ \n",
    "new_dates = pd.date_range('1961-01-01', '1961-12-01', freq='MS')\n",
    "\n",
    "# –ü—Ä–∏–≤–æ–¥–∏–º df['date'] –∫ —Ç–∏–ø—É Index, –æ–±—ä–µ–¥–∏–Ω—è–µ–º —Å 12 –º–µ—Å—è—Ü–∞–º–∏, –ø–æ–ª—É—á–µ–Ω–Ω—ã–º–∏ –Ω–∞ –ø—Ä–µ–¥—ã–¥—É—â–µ–º —à–∞–≥–µ\n",
    "new_dates = pd.Index(df['date']) | new_dates\n",
    "\n",
    "# –°–æ–∑–¥–∞—ë–º –¥–∞—Ç–∞—Ñ—Ä–µ–π–º –∏–∑ –æ–¥–Ω–æ–π –∫–æ–ª–æ–Ω–∫–∏ —Å —Ä–∞—Å—à–∏—Ä–µ–Ω–Ω—ã–º –Ω–∞–±–æ—Ä–æ–º –¥–∞—Ç\n",
    "df2 = pd.DataFrame({'date': new_dates})\n",
    "# –û–±—ä–µ–¥–∏–Ω—è–µ–º –¥–≤–∞ –¥–∞—Ç–∞—Ñ—Ä–µ–π–º–∞ –ø–æ –∫–æ–ª–æ–Ω–∫–µ 'date'.\n",
    "df = pd.merge(df, df2, on='date', how='right') #–°–∫–ª–µ–∏–≤–∞–µ–º –ø–æ —É–∫–∞–∑–∞–Ω–Ω–æ–π –∫–æ–ª–æ–Ω–∫–µ (on) –∏ –ø—Ä–∞–≤–∏–ª—É —Å–∫–ª–µ–π–∫–∏ (how)\n",
    "\n",
    "#–†–µ–≥—Ä–µ—Å—Å–∏–æ–Ω–Ω–∞—è –ø–µ—Ä–µ–º–µ–Ω–Ω–∞—è month_num - –ø–æ—Ä—è–¥–∫–æ–≤—ã–π –Ω–æ–º–µ—Ä –ø–∞—Ä—ã (–º–µ—Å—è—Ü, –≥–æ–¥). –õ–æ–≥–∞—Ä–∏—Ñ–º–∏—Ä—É–µ–º —Ç–∞—Ä–≥–µ—Ç\n",
    "df['month_num'] = range(1, len(df) + 1)\n",
    "df['log_y'] = np.log10(df['series_g'])\n",
    "\n",
    "#–°–æ–∑–¥–∞–¥–µ–º 12 –∫–æ–ª–æ–Ω–æ–∫ season_1.., season_12, –≤ –∫–æ—Ç–æ—Ä—ã–µ –ø–æ–º–µ—Å—Ç–∏–º –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä—ã —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—â–µ–≥–æ –º–µ—Å—è—Ü–∞\n",
    "#–ß—Ç–æ–±—ã –∏–∑–±–µ–∂–∞—Ç—å –∫–æ–ª–∏–Ω–µ–∞—Ä–Ω–æ—Å—Ç–∏, –∏—Å–∫–ª—é—á–∞–µ–º –æ–¥–∏–Ω –∏–∑ –º–µ—Å—è—Ü–µ–≤(—è–Ω–≤–∞—Ä—å) –∏ –¥–µ–ª–∞–µ–º –µ–≥–æ —ç—Ç–∞–ª–æ–Ω–æ–º, —Å –∫–æ—Ç–æ—Ä—ã–º —Å—Ä–∞–≤–Ω–∏–≤–∞–µ–º –≤—Å–µ –æ—Å—Ç–∞–ª—å–Ω—ã–µ\n",
    "#–í–Ω—É—Ç—Ä–∏ —Ü–∏–∫–ª–∞ –ø—Ä–æ–≤–µ—Ä—è–µ–º, —Ä–∞–≤–µ–Ω –ª–∏ –æ—á–µ—Ä–µ–¥–Ω–æ–π –º–µ—Å—è—Ü —Ç–µ–∫—É—â–µ–º—É –∑–Ω–∞—á–µ–Ω–∏—é –∏–∑ —Ü–∏–∫–ª–∞\n",
    "for x in range(1, 13):\n",
    "    df['season_' + str(x)] = df['date'].dt.month == x\n",
    "    \n",
    "# xrange(2, 13) —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É–µ—Ç –≤—Å–µ–º –º–µ—Å—è—Ü–∞–º —Å —Ñ–µ–≤—Ä–∞–ª—è –ø–æ –¥–µ–∫–∞–±—Ä—å\n",
    "season_columns = ['season_' + str(x) for x in range(2, 13)]\n",
    "\n",
    "# –°–æ–∑–¥–∞–¥–∏–º –º–∞—Ç—Ä–∏—Ü—É X –∏ –≤–µ–∫—Ç–æ—Ä y –¥–ª—è –æ–±—É—á–µ–Ω–∏—è –º–æ–¥–µ–ª–∏\n",
    "X = df[['month_num'] + season_columns]\n",
    "y = df['log_y']\n",
    "\n",
    "# –û—Å—Ç–∞–≤–∏–º —Ç–æ–ª—å–∫–æ —Ç–µ —Å—Ç—Ä–æ—á–∫–∏, —É –∫–æ—Ç–æ—Ä—ã—Ö –∏–∑–≤–µ—Å—Ç–Ω—ã –∑–Ω–∞—á–µ–Ω–∏—è y (—Å –Ω–æ–º–µ—Ä–æ–º < 144)\n",
    "X1 = X[X.index < 144]\n",
    "y1 = y[y.index < 144]\n",
    "\n",
    "#–ù–∞—Å—Ç—Ä–æ–∏–º —Ä–µ–≥—Ä–µ—Å—Å–∏–æ–Ω–Ω—É—é –º–æ–¥–µ–ª—å. \"–ü–æ–¥–≥–æ–Ω–∫–∞\" —á–µ—Ä–µ–∑ .fit\n",
    "model = LinearRegression()\n",
    "model.fit(X1, y1)\n",
    "\n",
    "pred = pd.DataFrame({\n",
    "    'pred': model.predict(X1),\n",
    "    'real': y1})\n",
    "pred.plot()\n",
    "\n",
    "#—Å—Ç—Ä–æ–∏–º –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ –¥–ª—è –≤—Å–µ–π –º–∞—Ç—Ä–∏—Ü—ã X, –≤–∫–ª—é—á–∞—è –Ω–µ–∏–∑–≤–µ—Å—Ç–Ω—ã–µ 12 –º–µ—Å—è—Ü–µ–≤\n",
    "pred = pd.DataFrame({\n",
    "    'pred': model.predict(X),\n",
    "    'real': y})\n",
    "pred.plot()\n",
    "\n",
    "#–≠–∫—Å–ø–æ–Ω–∏—Ä—É–µ–º –ø—Ä–æ–≥–Ω–æ–∑, —á—Ç–æ–±—ã –ø–æ–ª—É—á–∏—Ç—å —Ä–µ–∞–ª—å–Ω—ã–µ —á–∏—Å–ª–∞\n",
    "pred['number'] = 10**pred['pred']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#–õ–æ–≥–∏—Å—Ç–∏—á–µ—Å–∫–∞—è —Ä–µ–≥—Ä–µ—Å—Å–∏—è –ø–æ–∑–≤–æ–ª—è–µ—Ç –∏—Å—Å–µ–¥–æ–≤–∞—Ç—å –≤–∑–∞–∏–º–æ—Å–≤—è–∑–∏ –¥–ª—è –∑–∞–≤–∏—Å–∏–º–æ–π –ø–µ—Ä–µ–º–µ–Ω–Ω–æ–π —Å –¥–≤—É–º—è –∑–Ω–∞—á–µ–Ω–∏—è–º–∏ (0,1)\n",
    "#–ú–Ω–æ–∂–µ—Å—Ç–≤–µ–Ω–Ω–∞—è —Ä–µ–≥—Ä–µ—Å—Å–∏—è  Y= B0+B1*X1 + ... + BN*XN   –ú–Ω–æ–≥–æ–º–µ—Ä–Ω—ã–π scatter-plot\n",
    "#–î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–æ —Ç—Ä–µ–±—É–µ—Ç: –º—É–ª—å—Ç–∏–∫–æ–ª–ª–∏–Ω–µ–∞—Ä–Ω–æ—Å—Ç—å(–±–µ–∑ —Å–∏–ª—å–Ω–æ–π –∫–æ—Ä—Ä–µ–ª—è—Ü–∏–∏ –∏–ª–∏ –∏–¥–µ–Ω—Ç–∏—á–Ω–æ—Å—Ç–∏), –Ω–æ—Ä–º–∞–ª—å–Ω–æ–µ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö.\n",
    "#t-–∫—Ä–∏—Ç–µ—Ä–∏–π –ø–æ–∫–∞–∑—ã–≤–∞–µ—Ç –æ–∫–∞–∑—ã–≤–∞–µ–º–æ–µ –≤–ª–∏—è–Ω–∏–µ –∫–∞–∂–¥–æ–≥–æ –ø—Ä–µ–¥–∏–∫—Ç–æ—Ä–∞. –ï—Å–ª–∏ 0, —Ç–æ –≤–ª–∏—è–Ω–∏—è –Ω–µ—Ç\n",
    "#–î–ª—è –º–Ω–æ–∂–µ—Å—Ç–≤–µ–Ω–Ω–æ–π —Ä–µ–≥—Ä–µ—Å—Å–∏–∏ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è \"–ò—Å–ø—Ä–∞–≤–ª–µ–Ω–Ω—ã–π\" R**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#–ó–∞–¥–∞—á–∞ —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏—è –Ω–∞–∏–º–µ–Ω–æ–≤–∞–Ω–∏–π –∏–ª–∏ –ø–æ—Ä—è–¥–∫–æ–≤ —á–µ—Ä–µ–∑ –¥–µ—Ä–µ–≤—å—è –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏. –ò —á–∏—Å–µ–ª —á–µ—Ä–µ–∑ —Ä–µ–≥—Ä–µ—Å—Å–∏—é\n",
    "#–ü–æ–º–∏–º–æ –≤–Ω—É—Ç—Ä–µ–Ω–Ω–∏—Ö –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ (–∑–∞–¥–∞–Ω–Ω—ã—Ö –∏–∑–Ω–∞—á–∞–ª—å–Ω–æ), –µ—Å—Ç—å –µ—â–µ –≤–Ω–µ—à–Ω–∏–µ (–∑–∞–¥–∞–≤–∞–µ–º—ã–µ –∞–Ω–∞–ª–∏—Ç–∏–∫–æ–º)\n",
    "#–í—ã–±–æ—Ä –º–æ–¥–µ–ª–∏ —Å –ø–æ–º–æ—â—å—é –æ–±—É—á–∞—é—â–µ–π/—Ç–µ—Å—Ç–æ–≤–æ–π –≤—ã–±–æ—Ä–æ–∫ —á–µ—Ä–µ–∑ –Ω–∞–∏–º–µ–Ω—å—à—É—é —Å—Ä–µ–¥–Ω—é—é –∫–≤–∞–¥—Ä–∞—Ç–∏—á–Ω—É—é –æ—à–∏–±–∫—É \n",
    "#–ö—Ä–∏—Ç–µ—Ä–∏–π –∫–∞—á–µ—Å—Ç–≤–∞ Q - —Å—É–º–º–∞ –º–æ–¥—É–ª–µ–π –æ—à–∏–±–æ–∫ –∏–ª–∏ —Å—É–º–º–∞ –∫–≤–∞–¥—Ä–∞—Ç–æ–≤ –æ—à–∏–±–æ–∫ –∏–ª–∏ –ø—Ä–æ—Ü–µ–Ω—Ç –æ—à–∏–±–æ–∫ –∏ —Ç.–¥.\n",
    "#–í–∞–ª–∏–¥–∞—Ü–∏—è - –º–µ—Ç–æ–¥ –ø—Ä–æ–≤–µ—Ä–∫–∏ –≤—ã–±—Ä–∞–Ω–Ω–æ–π –º–æ–¥–µ–ª–∏ –Ω–∞ –µ–µ –∞–¥–µ–∫–≤–∞—Ç–Ω–æ—Å—Ç—å\n",
    "#–†–µ–≥—É–ª—è—Ä–∏–∑–∞—Ü–∏—è - –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç –ø—Ä–æ–≤–µ—Ä–∫–∏ –º–æ–¥–µ–ª–µ–π"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CART - Classification and regression trees\n",
    "#–¥–µ–ª–µ–Ω–∏–µ –º–∞—Ç—Ä–∏—Ü—ã –ø—Ä—è–º—ã–º–∏\\–≥–∏–ø–µ—Ä–ø–ª–æ—Å–∫–æ—Å—Ç—è–º–∏, —á—Ç–æ–±—ã –≤ –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–Ω—ã—Ö –æ–±–ª–∞—Å—Ç—è—Ö –¥–æ–º–∏–Ω–∏—Ä–æ–≤–∞–ª–∏ —Å—Ö–æ–∂–∏–µ –æ–±—ä–µ–∫—Ç—ã\n",
    "#–£–∑–µ–ª(node) - –º–Ω–æ–∂–µ—Å—Ç–≤–æ, –∫–æ—Ç–æ—Ä–æ–µ —Ä–∞—Å—â–µ–ø–ª—è–µ—Ç—Å—è. –†–æ–¥–∏—Ç–µ–ª—å—Å–∫–∏–π, –ø–æ—Ç–æ–º–æ–∫, –∫–æ–Ω–µ—á–Ω—ã–π. \n",
    "#–ü–æ—Ä–æ–≥–æ–≤–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ - —ç—Ç–∞–ª–æ–Ω –¥–ª—è —Å—Ä–∞–≤–Ω–µ–Ω–∏—è\n",
    "#–û–≥—Ä–∞–Ω–∏—á–µ–Ω–∏—è –∑–∞–¥–∞—é—Ç—Å—è –æ–ø–µ—Ä–∞—Ç–æ—Ä–æ–º. –ù–∞ –∫–æ–ª-–≤–æ —Å–ª–æ–µ–≤, –Ω–∞ —Å–≤–æ–π—Å—Ç–≤–æ –ø–æ—Ç–æ–º–∫–æ–≤, –Ω–∞ —Ä–æ–¥–∏—Ç–µ–ª—è, –Ω–∞ –ø—Ä–∞–≤–∏–ª–∞ –æ—Å—Ç–∞–Ω–æ–≤–∫–∏ \n",
    "#–ß–∏—Å—Ç–æ—Ç–∞ - –ø–æ—Ä—è–¥–æ–∫ —Ä–∞–∑–¥–µ–ª–µ–Ω–∏—è –≤—ã–±–æ—Ä–∫–∏ –Ω–∞ —á–∞—Å—Ç–∏, –≤ –∫–∞–∂–¥–æ–π –∏–∑ –∫–æ—Ç–æ—Ä—ã—Ö \"–∑–∞–≥—Ä—è–∑–Ω–µ–Ω–∏–µ\" –¥–∞–Ω–Ω—ã—Ö –º–µ–Ω—å—à–µ\n",
    "#–ö—Ä–∏—Ç–µ—Ä–∏–π –∑–∞–≥—Ä–∞–∑–Ω–µ–Ω–Ω–æ—Å—Ç–∏(–≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å –ø—Ä–∏–Ω–∞–¥–ª–µ–∂–∞—Ç—å –∫ –∫–ª–∞—Å—Å—É P) –∏–∑–º–µ—Ä—è–µ—Ç—Å—è –≠–Ω—Ç—Ä–æ–ø–∏–µ–π, –ò–Ω–¥–µ–∫—Å–æ–º –î–∂–∏–Ω–∏ –∏–ª–∏ –û—à–∏–±–∫–æ–π –ö–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏\n",
    "#–≠–Ω—Ç—Ä–æ–ø–∏—è H1 = -–°—É–º–º–∞P*log2P. –ò–Ω–¥–µ–∫—Å –î–∂–∏–Ω–∏ H2 = 1-–°—É–º–º–∞P**2 = –°—É–º–º–∞P*(1-P). –û—à–∏–±–∫–∞ –ö–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏ H3 = 1-maxP\n",
    "#–î–µ–ª—å—Ç–∞ H - –≤–∫–ª–∞–¥ –ø–µ—Ä–µ–º–µ–Ω–Ω–æ–π –≤ –æ—á–∏—â–µ–Ω–∏–µ. –°—á–∏—Ç–∞–µ–º —Å—É–º–º—ã –¥–ª—è –∫–∞–∂–¥–æ–π –∏ –ø–æ–ª—É—á–∞–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ç–∏–≤–Ω–æ—Å—Ç—å –ø–µ—Ä–µ–º–µ–Ω–Ω–æ–π\n",
    "\n",
    "#–ó–∞–¥–∞—á–∞ –∫—Ä–µ–¥–∏—Ç–Ω–æ–≥–æ —Å–∫–æ—Ä–∏–Ω–≥–∞\n",
    "df = pd.read_csv('Credit.csv', sep=';', encoding='cp1251')\n",
    "\n",
    "# –ü—Ä–∞–≤–∏–ª—å–Ω—ã–π –æ—Ç–≤–µ—Ç –∑–∞–ø–∏—Å—ã–≤–∞–µ–º –≤ –≤–µ–∫—Ç–æ—Ä y\n",
    "y = df[u'–∫—Ä–µ–¥–∏—Ç']\n",
    "# –£–¥–∞–ª—è–µ–º –∫–æ–ª–æ–Ω–∫—É —Å –ø—Ä–∞–≤–∏–ª—å–Ω—ã–º –æ—Ç–≤–µ—Ç–æ–º\n",
    "X = df.drop(u'–∫—Ä–µ–¥–∏—Ç', axis=1)\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "#–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º –∏ –æ–±—É—á–∞–µ–º –º–æ–¥–µ–ª—å\n",
    "model = DecisionTreeClassifier(random_state=42,\n",
    "                               # —Ñ—É–Ω–∫—Ü–∏—è –¥–ª—è impurity ('gini' –∏–ª–∏ 'entropy')\n",
    "                               criterion='gini',\n",
    "                               # –º–∞–∫—Å–∏–º–∞–ª—å–Ω–∞—è –≥–ª—É–±–∏–Ω–∞ –¥–µ—Ä–µ–≤–∞\n",
    "                               max_depth=5,\n",
    "                               # –º–∏–Ω–∏–º–∞–ª—å–Ω–æ–µ —á–∏—Å–ª–æ —ç–ª–µ–º–µ–Ω—Ç–æ–≤ –≤ —É–∑–ª–µ –¥–ª—è —Ä–∞–∑–±–∏–µ–Ω–∏—è (–º–æ–∂–µ—Ç –±—ã—Ç—å –¥–æ–ª–µ–π)\n",
    "                               min_samples_split=5,\n",
    "                               # –º–∏–Ω–∏–º–∞–ª—å–Ω–æ–µ —á–∏—Å–ª–æ —ç–ª–µ–º–µ–Ω—Ç–æ–≤ –≤ –ª–∏—Å—Ç–µ (–º–æ–∂–µ—Ç –±—ã—Ç—å –¥–æ–ª–µ–π)\n",
    "                               min_samples_leaf=5,\n",
    "                               # –º–∏–Ω–∏–º–∞–ª—å–Ω–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ –¥–µ–ª—å—Ç—ã impurity\n",
    "                               # min_impurity_decrease=0,\n",
    "                               # –≤–µ—Å–∞ –¥–ª—è –∫–ª–∞—Å—Å–æ–≤ (–º–æ–∂–Ω–æ –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–æ —à—Ç—Ä–∞—Ñ–æ–≤–∞—Ç—å –∑–∞ –æ—à–∏–±–∫—É –≤ –Ω—É–∂–Ω—ã—Ö –∫–ª–∞—Å—Å–∞—Ö).\n",
    "                               # –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç –æ–ø—Ü–∏—é 'balanced'.\n",
    "                               class_weight=None\n",
    "                               \n",
    "                              )\n",
    "\n",
    "model.fit(X, y)\n",
    "\n",
    "#–î–ª—è –∏–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∞—Ü–∏–∏ –ø–æ–ª—É—á–∏–≤—à–µ–π—Å—è –º–æ–¥–µ–ª–∏ –∏–∑–æ–±—Ä–∞–∂–∞–µ–º –µ—ë –≤ –≤–∏–¥–µ –¥–µ—Ä–µ–≤–∞ –ø—Ä–µ–¥–∏–∫–∞—Ç–æ–≤ (—Ä–µ—à–∞—é—â–∏—Ö –ø—Ä–∞–≤–∏–ª)\n",
    "from IPython.display import Image\n",
    "from sklearn.tree import export_graphviz\n",
    "from subprocess import call\n",
    "\n",
    "export_graphviz(model,\n",
    "                out_file='tree.dot',\n",
    "                #–∑–∞–¥–∞—Ç—å –Ω–∞–∑–≤–∞–Ω–∏—è —Ñ–∏—á\n",
    "                #feature_names=X.columns,\n",
    "                class_names=None,\n",
    "                #–ø–æ–∫–∞–∑—ã–≤–∞—Ç—å –Ω–∞–∑–≤–∞–Ω–∏—è –ø–æ–ª–µ–π —É —á–∏—Å–ª–µ–Ω–Ω—ã—Ö –∑–Ω–∞—á–µ–Ω–∏–π –≤–Ω—É—Ç—Ä–∏ —É–∑–ª–∞\n",
    "                label='all',\n",
    "                #—Ä–∞—Å–∫—Ä–∞—à–∏–≤–∞—Ç—å —É–∑–ª—ã –≤ —Ü–≤–µ—Ç –ø—Ä–µ–æ–±–ª–∞–¥–∞—é—â–µ–≥–æ –∫–ª–∞—Å—Å–∞\n",
    "                filled=True,\n",
    "                #–ø–æ–∫–∞–∑—ã–≤–∞—Ç—å –∑–Ω–∞—á–µ–Ω–∏–µ impurity –¥–ª—è –∫–∞–∂–¥–æ–≥–æ —É–∑–ª–∞\n",
    "                impurity=True,\n",
    "                #–ø–æ–∫–∞–∑—ã–≤–∞—Ç—å –Ω–æ–º–µ—Ä–∞ —É–∑–ª–æ–≤\n",
    "                node_ids=True,\n",
    "                #–ü–æ–∫–∞–∑—ã–≤–∞—Ç—å –¥–æ–ª–∏ –∫–∞–∂–¥–æ–≥–æ –∫–ª–∞—Å—Å–∞ –≤ —É–∑–ª–∞—Ö (–∞ –Ω–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ)\n",
    "                proportion=True,\n",
    "                #–ü–æ–≤–µ—Ä–Ω—É—Ç—å –¥–µ—Ä–µ–≤–æ –Ω–∞ 90 –≥—Ä–∞–¥—É—Å–æ–≤ (–≤–µ—Ä—Ç–∏–∫–∞–ª—å–Ω–∞—è –æ—Ä–∏–µ–Ω—Ç–∞—Ü–∏—è)\n",
    "                rotate=True,\n",
    "                #–ß–∏—Å–ª–æ —Ç–æ—á–µ–∫ –ø–æ—Å–ª–µ –∑–∞–ø—è—Ç–æ–π –¥–ª—è –æ—Ç–æ–±—Ä–∞–∂–∞–µ–º—ã—Ö –¥—Ä–æ–±–µ–π\n",
    "                #precision=3\n",
    "               )\n",
    "\n",
    "#–ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º —Ñ–∞–π–ª .dot –≤ .png\n",
    "#node - –Ω–æ–º–µ—Ä —É–∑–ª–∞, X[1]<=1.5 –ø—Ä–∞–≤–∏–ª–æ —Ä–∞—Å—â–µ–ø–ª–µ–Ω–∏—è, gini, samples-–¥–æ–ª—è –Ω–∞–±–ª—é–¥–µ–Ω–∏–π –ø–æ–ø–∞–≤—à–∏—Ö –≤ —É–∑–µ–ª, p-value (p0, pX)\n",
    "(graph,) = pydot.graph_from_dot_file('tree.dot')\n",
    "graph.write_png('tree.png')\n",
    "Image(\"tree.png\")\n",
    "\n",
    "#–ú–æ–¥–µ–ª—å –ø–æ–∑–≤–æ–ª—è–µ—Ç –æ—Ü–µ–Ω–∏—Ç—å —Ü–µ–Ω–Ω–æ—Å—Ç—å (importance) –∏ —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ—Å—Ç—å –∫–∞–∂–¥–æ–π —Ñ–∏—á–∏, —Å—á–∏—Ç–∞—è –¥–ª—è –∫–∞–∂–¥–æ–π –∏–∑ —Å—É–º–º—É –¥–µ–ª—å—Ç—ã H \n",
    "pd.DataFrame({'feature': X.columns,\n",
    "              'importance': model.feature_importances_}).sort_values('importance', \n",
    "            ascending=False\n",
    "            )\n",
    "\n",
    "#–ú–µ—Ç–æ–¥ predict –ø–æ–∑–≤–æ–ª—è–µ—Ç –ø–æ–ª—É—á–∏—Ç—å –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è –∫–ª–∞—Å—Å–æ–≤ –¥–ª—è –≤—Ö–æ–¥–Ω–æ–≥–æ —Å–ø–∏—Å–∫–∞ —ç–ª–µ–º–µ–Ω—Ç–æ–≤ (–ø–æ–¥–∞—ë–º –Ω–∞ –≤—Ö–æ–¥ –º–∞—Ç—Ä–∏—Ü—É)\n",
    "# –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ –∫–ª–∞—Å—Å–∞ –¥–ª—è –Ω–æ–≤—ã—Ö —ç–ª–µ–º–µ–Ω—Ç–æ–≤\n",
    "new_item = [1, 1, 1, 1]\n",
    "model.predict([new_item])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#–†–∞—Å—â–µ–ø–ª–µ–Ω–∏–µ –Ω–∞ –æ–±—É—á–∞—é—â—É—é –∏ —Ç–µ—Å—Ç–æ–≤—ã–µ –≤—ã–±–æ—Ä–∫–∏\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42,\n",
    "                                                    # –¥–æ–ª—è –æ–±—ä—ë–º–∞ —Ç–µ—Å—Ç–æ–≤–æ–≥–æ –º–Ω–æ–∂–µ—Å—Ç–≤–∞\n",
    "                                                    test_size=0.2)\n",
    "#–æ–±—É—á–∞–µ–º –º–æ–¥–µ–ª—å\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "#–°—Ç—Ä–æ–∏–º –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ –º–æ–¥–µ–ª–∏ –Ω–∞ —Ç–µ—Å—Ç–æ–≤–æ–º –º–Ω–æ–∂–µ—Å—Ç–≤–µ\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "#–û—Ü–µ–Ω–∫–∞ –∫–∞—á–µ—Å—Ç–≤–∞ –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ç–æ—Ä–∞: –¥–æ–ª—è —Å–æ–≤–ø–∞–≤—à–∏—Ö –æ—Ç–≤–µ—Ç–æ–≤ –≤ y_pred –∏ y_test, –∏–ª–∏ —Å—á–∏—Ç–∞–µ–º —Ç–æ—á–Ω–æ—Å—Ç—å –∏ –ø–æ–ª–Ω–æ—Ç—É\n",
    "#–ï—Å–ª–∏ –¥–æ–ª—è –≤ –æ–±—É—á–∞—é—â–µ–º –≤—ã—à–µ —Ç–µ—Å—Ç–æ–≤–æ–≥–æ, –æ–∑–Ω–∞—á–∞–µ—Ç –ø–µ—Ä–µ–æ–±—É—á–µ–Ω–Ω–æ—Å—Ç—å –º–æ–¥–µ–ª–∏. –ù—É–∂–Ω–æ —É–ø—Ä–æ—â–∞—Ç—å –º–æ–¥–µ–ª—å\n",
    "#–ú–∞—Ç—Ä–∏—Ü–∞ –æ—à–∏–±–æ–∫  ùê∂=(ùëêùëñ,ùëó) , –≥–¥–µ  ùëêùëñ,ùëó –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —ç–ª–µ–º–µ–Ω—Ç–æ–≤ –∫–ª–∞—Å—Å–∞ ùëñ , –∫–æ—Ç–æ—Ä—ã–º –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ç–æ—Ä –ø—Ä–∏—Å–≤–æ–∏–ª –∫–ª–∞—Å—Å ùëó \n",
    "#–¢–æ—á–Ω–æ—Å—Ç—å(precision) - –¥–æ–ª—è –ø—Ä–∞–≤–∏–ª—å–Ω–æ –∫–ª–∞—Å—Å–∏—Ñ–∏—Ü–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö –æ–±—ä–µ–∫—Ç–æ–≤ –≤ –Ω–∞–π–¥–µ–Ω–Ω—ã—Ö –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ç–æ—Ä–æ–º. \n",
    "#–ü–æ–ª–Ω–æ—Ç–∞(recall) - –¥–æ–ª—è —ç—Ç–∏—Ö –æ–±—ä–µ–∫—Ç–æ–≤ –ù–ê –°–ê–ú–û–ú –î–ï–õ–ï\n",
    "from sklearn import metrics\n",
    "conf_mat = metrics.confusion_matrix(y_test, y_pred)\n",
    "conf_mat = pd.DataFrame(conf_mat, index=model.classes_, columns=model.classes_)\n",
    "conf_mat\n",
    "\n",
    "#–ì–∞—Ä–º–æ–Ω–∏—á–µ—Å–∫–æ–µ —Å—Ä–µ–¥–Ω–µ–µ F1 = 2*—Ç–æ—á–Ω–æ—Å—Ç—å*–ø–æ–ª–Ω–æ—Ç–∞/(—Ç–æ—á–Ω–æ—Å—Ç—å+–ø–æ–ª–Ω–æ—Ç–∞). –°—á–∏—Ç–∞–µ—Ç—Å—è —Å –ø–æ–º–æ—â—å—é classification_report\n",
    "print(metrics.classification_report(y_pred, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#–î–µ—Ä–µ–≤—å—è —Ä–µ—à–µ–Ω–∏–π –¥–ª—è –∑–∞–¥–∞—á —Ä–µ–≥—Ä–µ—Å—Å–∏–∏ (–æ—Ç–∫–ª–∏–∫ –Ω–µ –¥–∏—Å–∫—Ä–µ—Ç–Ω—ã–π, –∞ –Ω–µ–ø—Ä–µ—Ä—ã–≤–Ω—ã–π). –ú–µ—Ç–æ–¥—ã —Å—Ö–æ–∂—ã —Å –¥–µ—Ä–µ–≤–æ–º –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏\n",
    "#–ü—Ä–µ–¥–ø–æ—á—Ç–∏—Ç–µ–ª—å–Ω–∏–∏ –ª–∏–Ω–µ–π–Ω–æ–π —Ä–µ–≥—Ä–µ—Å—Å–∏–∏, –∫–æ–≥–¥–∞ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç—å –Ω–µ –ª–∏–Ω–µ–π–Ω–∞—è :)\n",
    "#–í —ç—Ç–æ–º —Å–ª—É—á–∞ –î–µ–ª—å—Ç–∞ H = —Å—É–º–º–∞ –∫–≤–∞–¥—Ä–∞—Ç–æ–≤ –æ—à–∏–±–æ–∫\n",
    "#Prune (–æ–±—Ä–µ–∑–∞–Ω–∏–µ) - –æ—á–∏—Å—Ç–∫–∞ –æ—Ç —É–∑–ª–æ–≤, –∫–æ—Ç–æ—Ä—ã–µ –Ω–µ –Ω—É–∂–Ω—ã, —á–µ—Ä–µ–∑ –¥–æ–±–∞–≤–ª–µ–Ω–∏–µ —Ç—Ä–µ—Ç—å–µ–π –≤—ã–±–æ—Ä–∫–∏ (–≤–∞–ª–∏–¥–∞—Ü–∏–∏)\n",
    "\n",
    "#–°–ª—É—á–∞–π–Ω—ã–π –ª–µ—Å. –ö–ª—é—á–µ–≤—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã:\n",
    "#ntree - —á–∏—Å–ª–æ –¥–µ—Ä–µ–≤—å–µ–≤(–≤ –Ω–∞—á–∞–ª–µ –º–∞–∫—Å, –ø–æ—Ç–æ–º —Å–æ–∫—Ä–∞—â–∞—Ç—å), mtry - —á–∏—Å–ª–æ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö –≤ –≤—ã–±–æ—Ä–∫–µ (M**0.5)\n",
    "#sampsize - —á–∏—Å–ª–æ –Ω–∞–±–ª—é–¥–µ–Ω–∏–π –≤ –ø–æ–¥–≤—ã–±–æ—Ä–∫–µ(0.632*N –¥–ª—è –¥–µ–∫–æ—Ä—Ä–µ–ª—è—Ü–∏–∏), nodesize - –º–∏–Ω. —á–∏—Å–ª–æ –Ω–∞–±–ª—é–¥–µ–Ω–∏–π –≤ —É–∑–ª–µ (10) \n",
    "#replace - –ø–æ–¥–≤—ã–±–æ—Ä–∫–∞ —Å  –≤–æ–∑–≤—Ä–∞—â–µ–Ω–∏–µ–º –∏–ª–∏ –±–µ–∑\n",
    "#out-of-bag - –Ω–µ–∏—Å–ø–æ–ª—å–∑—É–µ–º–∞—è –ø—Ä–∏ –æ–±—É—á–µ–Ω–∏–∏ —á–∞—Å—Ç—å –≤—ã–±–æ—Ä–∫–∏, –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –≤ –∫–∞—á–µ—Å—Ç–≤–µ –ø—Ä–µ–¥–≤–∞—Ä–∏—Ç–µ–ª—å–Ω–æ–≥–æ —Ç–µ—Å—Ç–∞ –º–æ–¥–µ–ª–∏\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "model = RandomForestClassifier(random_state=42, #–∑–µ—Ä–Ω–æ –¥–∞—Ç—á–∏–∫–∞ —Å–ª—É—á–∞–π–Ω—ã—Ö —á–∏—Å–µ–ª\n",
    "                               #—á–∏—Å–ª–æ –¥–µ—Ä–µ–≤—å–µ–≤ –≤ –ª–µ—Å—É\n",
    "                               n_estimators=30,\n",
    "                               #—Ñ—É–Ω–∫—Ü–∏—è –¥–ª—è –¥–µ–ª—å—Ç–∞ H, impurity ('gini' –∏–ª–∏ 'entropy')\n",
    "                               criterion='gini',\n",
    "                               #–ú–∞–∫—Å —á–∏—Å–ª–æ —Å–ª–æ–µ–≤\n",
    "                               max_depth=5,\n",
    "                               #–í—ã—á–∏—Å–ª—è—Ç—å out-of-bag –æ—à–∏–±–∫—É\n",
    "                               oob_score=True,\n",
    "                               #–∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –ø—Ä–µ–¥—ã–¥—É—â–µ–≥–æ –≤—ã–∑–æ–≤–∞ –∏ –Ω–∞—Ä–∞—Å—Ç–∏—Ç—å –ø—Ä–µ–¥—ã–¥—É—â–∏–π –ª–µ—Å \n",
    "                               warm_start=False,\n",
    "                               #–≤–µ—Å–∞ –∫–ª–∞—Å—Å–æ–≤ –¥–ª—è –±–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∫–∏ –≤—ã–±–æ—Ä–∫–∏ –¥–ª—è –æ–±—É—á–µ–Ω–∏—è\n",
    "                               class_weight=None\n",
    "                               \n",
    "                              )\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "print(metrics.classification_report(y_pred, y_test))\n",
    "\n",
    "print('Out-of-bag score: {0}'.format(model.oob_score_)) \n",
    "\n",
    "pd.DataFrame({'feature': X.columns,\n",
    "              'importance': model.feature_importances_}).sort_values('importance', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#–ü—Ä–∏–µ–º—ã —É–ª—É—á—à–µ–Ω–∏—è –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ç–æ—Ä–æ–≤: stacking, bagging, boosting\n",
    "#Stacking(–ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ –Ω–∞ –±–∞–∑–µ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π)\n",
    "#Bagging(—É—Å—Ä–µ–¥–Ω–µ–Ω–Ω–æ–µ –º–Ω–µ–Ω–∏–µ –≤—Å–µ—Ö –º–æ–¥–µ–ª–µ–π), –æ–Ω –∂–µ —Å–ª—É—á–∞–π–Ω—ã–π –ª–µ—Å. –ß—Ç–æ–±—ã –∏–∑–±–µ–∂–∞—Ç—å –∫–æ–ª–∏–Ω–µ–∞—Ä–Ω–æ—Å—Ç–∏, –≤—ã–±–æ—Ä–∫–∏ —Å–æ–±–∏—Ä–∞—é—Ç—Å—è —Ä–∞–Ω–¥–æ–º–Ω–æ\n",
    "#Boosting - –æ–±—É—á–µ–Ω–∏–µ –Ω–∞ –æ—Å–Ω–æ–≤–µ –æ—à–∏–±–æ–∫ –ø—Ä–µ–¥—ã–¥—É—â–µ–≥–æ –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ç–æ—Ä–∞ (—É–ª—É—á—à–µ–Ω–∏–µ–º —Å–ª–∞–±–æ–≥–æ –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ç–æ—Ä–∞)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#GBM - Gradient Boosting Machine. –û—Å—Ç–∞–Ω–æ–≤–∫–∞ –±—É—Å—Ç–∏–Ω–≥–∞, –∫–æ–≥–¥–∞ –æ—á–µ—Ä–µ–¥–Ω—ã–µ —Ü–∏–∫–ª—ã –ø–µ—Ä—Å—Ç–∞—é—Ç —É–ª—É—á—à–∞—Ç—å –º–æ–¥–µ–ª—å\n",
    "#–°—É–º–º–∞ –∫–≤–∞–¥—Ä–∞—Ç–æ–≤ –æ—à–∏–±–æ–∫ Zi = -2*(Yi - f(Xi))\n",
    "#–ú–µ—Ç–æ–¥ –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–≥–æ –ø—Ä–∞–≤–¥–æ–ø–æ–¥–æ–±–∏—è. –ü—Ä–µ–¥–ø–æ–ª–∞–≥–∞–µ–º –Ω–∞–∏–±–æ–ª–µ–µ –≤–µ—Ä–æ—è—Ç–Ω–æ–µ —Å–æ–±—ã—Ç–∏–µ. –ö—Ä–∏—Ç–µ—Ä–∏–π –∫–∞—á–µ—Å—Ç–≤–∞ = P**A*(1-P)**(n-A)\n",
    "#–ö—Ä–∏—Ç–µ—Ä–∏–∏ –∫–∞—á–µ—Å—Ç–≤–∞ –ì–∞—É—Å—Å–∞ –∏ –õ–∞–ø–ª–∞—Å–∞ —É–Ω–∏–≤–µ—Ä—Å–∞–ª—å–Ω—ã. –î–ª—è –¥–≤—É—Ö –∫–ª–∞—Å—Å–æ–≤ - –±–∏–Ω–æ–º–∏–∞–ª—å–Ω–æ–µ, –¥–ª—è –±–æ–ª—å—à–µ–≥–æ - –º—É–ª—å—Ç–∏–Ω–æ–º–∏–Ω–∞–ª—å–Ω–æ–µ\n",
    "#–ü—Ä–∏ –≤—Ä–µ–º–µ–Ω–Ω–æ–º –ø—Ä–æ–º–µ–∂—É—Ç–∫–µ - —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –ü—É–∞—Å—Å–æ–Ω–∞\n",
    "\n",
    "columns = ['age', 'workclass', 'fnlwgt', 'education', 'education-num',\n",
    "           'marital-status', 'occupation', 'relationship', 'race', 'sex',\n",
    "           'capital-gain', 'capital-loss', 'hours-per-week', 'native-country', 'income']\n",
    "df = pd.read_csv('adult.data', header=None, names=columns, na_values=' ?')\n",
    "\n",
    "# –£–¥–∞–ª—è–µ–º –∫–æ–ª–æ–Ω–∫—É education (–ø–æ—Ç–æ–º—É —á—Ç–æ –µ—Å—Ç—å —É–∂–µ –∑–∞–∫–æ–¥–∏—Ä–æ–≤–∞–Ω–Ω–∞—è –∫–æ–ª–æ–Ω–∫–∞ education-num)\n",
    "df = df.drop('education', axis=1)\n",
    "\n",
    "# –ö–æ–¥–∏—Ä—É–µ–º –æ—Ç–∫–ª–∏–∫ –≤ –±–∏–Ω–∞—Ä–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è\n",
    "df['income'] = df['income'].map({' <=50K': 0, ' >50K': 1})\n",
    "\n",
    "# —É–¥–∞–ª—è–µ–º —Å—Ç—Ä–æ–∫–∏ —Å NA –∑–Ω–∞—á–µ–Ω–∏—è–º–∏\n",
    "df = df.dropna()\n",
    "\n",
    "test = pd.read_csv('adult.test', header=None, names=columns, na_values=' ?', skiprows=1)\n",
    "test = test.drop('education', axis=1)\n",
    "test['income'] = test['income'].map({' <=50K.': 0, ' >50K.': 1})\n",
    "test = test.dropna()\n",
    "\n",
    "#–†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –∫–ª–∞—Å—Å–æ–≤ –≤ –æ—Ç–∫–ª–∏–∫–µ\n",
    "df['income'].value_counts(normalize=True)\n",
    "\n",
    "#–†–∞–∑–±–∏–≤–∞–µ–º –¥–∞—Ç—É. –ë–∏–Ω–∞—Ä–∏–∑—É–µ–º –∫–∞—Ç–µ–≥–æ—Ä–∏–∞–ª—å–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏ (one-hot encoding).\n",
    "X_train = pd.get_dummies(df).drop('income', axis=1)\n",
    "y_train = df['income']\n",
    "\n",
    "X_test = pd.get_dummies(test).drop('income', axis=1)\n",
    "y_test = test['income']\n",
    "\n",
    "#–í —Ç–µ—Å—Ç–æ–≤–æ–π –≤—ã–±–æ—Ä–∫–µ –Ω–µ —Ö–≤–∞—Ç–∞–µ—Ç –æ–¥–Ω–æ–π –∫–æ–ª–æ–Ω–∫–∏ \n",
    "print(len(X_train.columns))\n",
    "print(len(X_test.columns))\n",
    "\n",
    "#–ü—Ä–∏–≤–æ–¥–∏–º –º–Ω–æ–∂–µ—Å—Ç–≤–æ –Ω–∞–∑–≤–∞–Ω–∏–π –∫–æ–ª–æ–Ω–æ–∫ –∫ —Ç–∏–ø—É set, –Ω–∞—Ö–æ–¥–∏–º —Ä–∞–∑–Ω–æ—Å—Ç—å –¥–≤—É—Ö –º–Ω–æ–∂–µ—Å—Ç–≤: –ì–æ–ª–ª–∞–Ω–¥–∏–∏ –Ω–µ—Ç –≤ –∫–æ–ª–æ–Ω–∫–µ native-county \n",
    "print(set(X_train.columns) - set(X_test.columns))\n",
    "print(set(X_test.columns) - set(X_train.columns))\n",
    "\n",
    "#–î–æ–±–∞–≤–ª—è–µ–º –Ω–µ–¥–æ—Å—Ç–∞—é—â—É—é –∫–æ–ª–æ–Ω–∫—É\n",
    "columns = set(X_train.columns) | set(X_test.columns)\n",
    "X_train = X_train.reindex(columns=columns).fillna(0)\n",
    "X_test = X_test.reindex(columns=columns).fillna(0)\n",
    "\n",
    "#–ü—Ä–æ–≤–µ—Ä—è–µ–º —Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ –∫–æ–ª–æ–Ω–æ–∫ (–µ—Å–ª–∏ –¥–∞, —Ç–æ True)\n",
    "all(X_train.columns == X_test.columns)\n",
    "\n",
    "#–û–±—É—á–∞–µ–º –º–æ–¥–µ–ª—å\n",
    "model = GradientBoostingClassifier(random_state=42,\n",
    "                                   # –ß–∏—Å–ª–æ –¥–µ—Ä–µ–≤—å–µ–≤\n",
    "                                   n_estimators=500,\n",
    "                                   #–∑–∞–≥—Ä—è–∑–Ω–µ–Ω–∏–µ –∏–∑–º–µ—Ä—è–µ–º ‚Äúmse‚Äù, ‚Äúmae‚Äù –∏–ª–∏ ‚Äúfriedman_mse‚Äù (mse —Å —É–ª—É—á—à–µ–Ω–∏—è–º–∏)  \n",
    "                                   criterion='friedman_mse', \n",
    "                                   #–ú–∞–∫—Å–∏–º–∞–ª—å–Ω–∞—è –≥–ª—É–±–∏–Ω–∞ –∫–∞–∂–¥–æ–≥–æ –¥–µ—Ä–µ–≤–∞\n",
    "                                   #–∫—Ä–∏—Ç–µ—Ä–∏–π –∫–∞—á–µ—Å—Ç–≤–∞ ‚Äòdeviance‚Äô (–∫—Ä–æ—Å—Å-—ç–Ω—Ç—Ä–æ–ø–∏—è) –∏–ª–∏ ‚Äòexponential‚Äô\n",
    "                                   #‚Äòdeviance‚Äô –¥–ª—è –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏ —Å –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—è–º–∏ –Ω–∞ –≤—ã—Ö–æ–¥–µ\n",
    "                                   loss='deviance', \n",
    "                                   # –º–∏–Ω–∏–º–∞–ª—å–Ω–æ–µ —É–º–µ–Ω—å—à–µ–Ω–∏–µ –∑–∞–≥—Ä—è–∑–Ω–µ–Ω–∏—è \n",
    "                                   min_impurity_decrease=0.0, \n",
    "                                   # –£—Å—Ç–∞—Ä–µ–ª–æ\n",
    "                                   min_impurity_split=None,\n",
    "                                   # —á–∏—Å–ª–æ —É–∑–ª–æ–≤ –≤ –¥–µ—Ä–µ–≤–µ\n",
    "                                   max_depth=5,\n",
    "                                   #–º–∏–Ω–∏–º–∞–ª—å–Ω–æ–µ —á–∏—Å–ª–æ –Ω–∞–±–ª—é–¥–µ–Ω–∏–π –≤ –ø–æ—Ç–æ–º–∫–µ\n",
    "                                   min_samples_leaf=5, \n",
    "                                   #–º–∏–Ω–∏–º–∞–ª—å–Ω–æ–µ —á–∏—Å–ª–æ –Ω–∞–±–ª—é–¥–µ–Ω–∏–π –≤ —Ä–æ–¥–∏—Ç–µ–ª–µ\n",
    "                                   min_samples_split=10,\n",
    "                                   #–ü–∞—Ä–∞–º–µ—Ç—Ä, —É–º–µ–Ω—å—à–∞—é—â–∏–π –ø–µ—Ä–µ–æ–±—É—á–µ–Ω–∏–µ, —è–≤–ª—è—é—â–µ–º—Å—è –≤–µ—Å–æ–º –æ—Ç–¥–µ–ª—å–Ω–æ–≥–æ –¥–µ—Ä–µ–≤–∞ (–º–µ–Ω—å—à–µ –ª—É—á—à–µ)\n",
    "                                   learning_rate=0.01                                   \n",
    "                                   )\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "y_pred_train = model.predict(X_train)\n",
    "print(classification_report(y_train, y_pred_train))\n",
    "\n",
    "from sklearn import metrics\n",
    "conf_mat = metrics.confusion_matrix(y_test, y_pred)\n",
    "conf_mat = pd.DataFrame(conf_mat, index=model.classes_, columns=model.classes_)\n",
    "conf_mat\n",
    "\n",
    "from sklearn import metrics\n",
    "conf_mat = metrics.confusion_matrix(y_train, y_pred_train)\n",
    "conf_mat = pd.DataFrame(conf_mat, index=model.classes_, columns=model.classes_)\n",
    "conf_mat\n",
    "\n",
    "#C–º–æ—Ç—Ä–∏–º –≤–∞–∂–Ω–æ—Å—Ç—å –ø—Ä–∏–∑–Ω–∞–∫–æ–≤\n",
    "fi = pd.DataFrame({'features': X_train.columns, 'importance': model.feature_importances_})\n",
    "fi.sort_values('importance', ascending=False).head(10)\n",
    "\n",
    "#–ö–∞–ª–∏–±—Ä–æ–≤–∫–∞ (–∏–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∞—Ü–∏—è –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–∏)\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "model_sigmoid = CalibratedClassifierCV(model, cv=2, method='sigmoid')\n",
    "# method : ‚Äòsigmoid‚Äô or ‚Äòisotonic‚Äô\n",
    "\n",
    "# Calibrate probabilities\n",
    "model_sigmoid.fit(X_train, y_train)\n",
    "\n",
    "# View calibrated probabilities\n",
    "model_sigmoid.predict_proba(X_test)[0:11, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#–ú–µ—Ç–æ–¥ –≥—Ä–∞–¥–∏–µ–Ω—Ç–Ω–æ–≥–æ —Å–ø—É—Å–∫–∞\n",
    "#–ú–µ—Ç–æ–¥ –æ–±—Ä–∞—Ç–Ω–æ–≥–æ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è E = —Å—É–º–º–∞(Yi-Vi)**2 –ø–æ–∑–≤–æ–ª—è–µ—Ç —á–µ—Ä–µ–∑ MSE –Ω–∞—Ö–æ–¥–∏—Ç—å –æ—à–∏–±–∫—É –∏ –Ω–∞ –µ–µ –æ—Å–Ω–æ–≤–µ –∏—Å–ø—Ä–∞–≤–ª—è—Ç—å –≤–µ—Å–∞"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "12/12 [==============================] - 0s 668us/step - loss: 43.5210 - accuracy: 0.0840\n",
      "Epoch 2/300\n",
      "12/12 [==============================] - 0s 750us/step - loss: 32.8726 - accuracy: 0.0588\n",
      "Epoch 3/300\n",
      "12/12 [==============================] - 0s 665us/step - loss: 22.5263 - accuracy: 0.2017\n",
      "Epoch 4/300\n",
      "12/12 [==============================] - 0s 583us/step - loss: 12.8994 - accuracy: 0.2101\n",
      "Epoch 5/300\n",
      "12/12 [==============================] - 0s 667us/step - loss: 4.7547 - accuracy: 0.2269\n",
      "Epoch 6/300\n",
      "12/12 [==============================] - 0s 750us/step - loss: 1.4066 - accuracy: 0.5462\n",
      "Epoch 7/300\n",
      "12/12 [==============================] - 0s 667us/step - loss: 1.3519 - accuracy: 0.6555\n",
      "Epoch 8/300\n",
      "12/12 [==============================] - 0s 667us/step - loss: 1.0499 - accuracy: 0.6555\n",
      "Epoch 9/300\n",
      "12/12 [==============================] - 0s 583us/step - loss: 1.0295 - accuracy: 0.6807\n",
      "Epoch 10/300\n",
      "12/12 [==============================] - 0s 748us/step - loss: 1.0315 - accuracy: 0.6387\n",
      "Epoch 11/300\n",
      "12/12 [==============================] - 0s 750us/step - loss: 1.0046 - accuracy: 0.6303\n",
      "Epoch 12/300\n",
      "12/12 [==============================] - 0s 667us/step - loss: 0.9712 - accuracy: 0.6723\n",
      "Epoch 13/300\n",
      "12/12 [==============================] - 0s 667us/step - loss: 0.9548 - accuracy: 0.6807\n",
      "Epoch 14/300\n",
      "12/12 [==============================] - 0s 667us/step - loss: 0.9816 - accuracy: 0.6555\n",
      "Epoch 15/300\n",
      "12/12 [==============================] - 0s 669us/step - loss: 0.9543 - accuracy: 0.6555\n",
      "Epoch 16/300\n",
      "12/12 [==============================] - 0s 750us/step - loss: 0.9995 - accuracy: 0.5630\n",
      "Epoch 17/300\n",
      "12/12 [==============================] - 0s 581us/step - loss: 1.0229 - accuracy: 0.6218\n",
      "Epoch 18/300\n",
      "12/12 [==============================] - 0s 667us/step - loss: 0.9765 - accuracy: 0.6555\n",
      "Epoch 19/300\n",
      "12/12 [==============================] - 0s 750us/step - loss: 0.9166 - accuracy: 0.6471\n",
      "Epoch 20/300\n",
      "12/12 [==============================] - 0s 583us/step - loss: 0.9104 - accuracy: 0.6471\n",
      "Epoch 21/300\n",
      "12/12 [==============================] - 0s 667us/step - loss: 0.8671 - accuracy: 0.6639\n",
      "Epoch 22/300\n",
      "12/12 [==============================] - 0s 583us/step - loss: 0.8568 - accuracy: 0.6555\n",
      "Epoch 23/300\n",
      "12/12 [==============================] - 0s 583us/step - loss: 0.9560 - accuracy: 0.6975\n",
      "Epoch 24/300\n",
      "12/12 [==============================] - 0s 669us/step - loss: 0.8876 - accuracy: 0.6639\n",
      "Epoch 25/300\n",
      "12/12 [==============================] - 0s 583us/step - loss: 0.8650 - accuracy: 0.6555\n",
      "Epoch 26/300\n",
      "12/12 [==============================] - 0s 667us/step - loss: 0.8254 - accuracy: 0.6639\n",
      "Epoch 27/300\n",
      "12/12 [==============================] - 0s 750us/step - loss: 0.8491 - accuracy: 0.6891\n",
      "Epoch 28/300\n",
      "12/12 [==============================] - 0s 586us/step - loss: 0.8248 - accuracy: 0.6723\n",
      "Epoch 29/300\n",
      "12/12 [==============================] - 0s 750us/step - loss: 0.8123 - accuracy: 0.6723\n",
      "Epoch 30/300\n",
      "12/12 [==============================] - 0s 667us/step - loss: 0.8030 - accuracy: 0.6975\n",
      "Epoch 31/300\n",
      "12/12 [==============================] - 0s 667us/step - loss: 0.7975 - accuracy: 0.6891\n",
      "Epoch 32/300\n",
      "12/12 [==============================] - 0s 667us/step - loss: 0.8316 - accuracy: 0.6723\n",
      "Epoch 33/300\n",
      "12/12 [==============================] - 0s 666us/step - loss: 0.7688 - accuracy: 0.6723\n",
      "Epoch 34/300\n",
      "12/12 [==============================] - 0s 583us/step - loss: 0.7809 - accuracy: 0.6891\n",
      "Epoch 35/300\n",
      "12/12 [==============================] - 0s 666us/step - loss: 0.7552 - accuracy: 0.6807\n",
      "Epoch 36/300\n",
      "12/12 [==============================] - 0s 583us/step - loss: 0.7542 - accuracy: 0.6723\n",
      "Epoch 37/300\n",
      "12/12 [==============================] - 0s 750us/step - loss: 0.7441 - accuracy: 0.6891\n",
      "Epoch 38/300\n",
      "12/12 [==============================] - 0s 750us/step - loss: 0.7685 - accuracy: 0.6723\n",
      "Epoch 39/300\n",
      "12/12 [==============================] - 0s 667us/step - loss: 0.7670 - accuracy: 0.6975\n",
      "Epoch 40/300\n",
      "12/12 [==============================] - 0s 666us/step - loss: 0.7457 - accuracy: 0.6639\n",
      "Epoch 41/300\n",
      "12/12 [==============================] - 0s 668us/step - loss: 0.7400 - accuracy: 0.6807\n",
      "Epoch 42/300\n",
      "12/12 [==============================] - 0s 583us/step - loss: 0.7256 - accuracy: 0.6723\n",
      "Epoch 43/300\n",
      "12/12 [==============================] - 0s 752us/step - loss: 0.7106 - accuracy: 0.7059\n",
      "Epoch 44/300\n",
      "12/12 [==============================] - 0s 586us/step - loss: 0.7282 - accuracy: 0.6723\n",
      "Epoch 45/300\n",
      "12/12 [==============================] - 0s 667us/step - loss: 0.7207 - accuracy: 0.7143\n",
      "Epoch 46/300\n",
      "12/12 [==============================] - 0s 667us/step - loss: 0.7606 - accuracy: 0.6807\n",
      "Epoch 47/300\n",
      "12/12 [==============================] - 0s 624us/step - loss: 0.7112 - accuracy: 0.6807\n",
      "Epoch 48/300\n",
      "12/12 [==============================] - 0s 712us/step - loss: 0.6864 - accuracy: 0.6891\n",
      "Epoch 49/300\n",
      "12/12 [==============================] - 0s 750us/step - loss: 0.7403 - accuracy: 0.6639\n",
      "Epoch 50/300\n",
      "12/12 [==============================] - 0s 667us/step - loss: 0.7126 - accuracy: 0.6807\n",
      "Epoch 51/300\n",
      "12/12 [==============================] - 0s 747us/step - loss: 0.6919 - accuracy: 0.6891\n",
      "Epoch 52/300\n",
      "12/12 [==============================] - 0s 667us/step - loss: 0.6746 - accuracy: 0.6975\n",
      "Epoch 53/300\n",
      "12/12 [==============================] - 0s 586us/step - loss: 0.6753 - accuracy: 0.7143\n",
      "Epoch 54/300\n",
      "12/12 [==============================] - 0s 666us/step - loss: 0.6613 - accuracy: 0.7059\n",
      "Epoch 55/300\n",
      "12/12 [==============================] - 0s 667us/step - loss: 0.6654 - accuracy: 0.7311\n",
      "Epoch 56/300\n",
      "12/12 [==============================] - 0s 750us/step - loss: 0.6544 - accuracy: 0.7143\n",
      "Epoch 57/300\n",
      "12/12 [==============================] - 0s 750us/step - loss: 0.6776 - accuracy: 0.6807\n",
      "Epoch 58/300\n",
      "12/12 [==============================] - 0s 667us/step - loss: 0.6528 - accuracy: 0.6891\n",
      "Epoch 59/300\n",
      "12/12 [==============================] - 0s 669us/step - loss: 0.6294 - accuracy: 0.6891\n",
      "Epoch 60/300\n",
      "12/12 [==============================] - 0s 664us/step - loss: 0.6470 - accuracy: 0.6723\n",
      "Epoch 61/300\n",
      "12/12 [==============================] - 0s 583us/step - loss: 0.6460 - accuracy: 0.6975\n",
      "Epoch 62/300\n",
      "12/12 [==============================] - 0s 581us/step - loss: 0.6480 - accuracy: 0.6975\n",
      "Epoch 63/300\n",
      "12/12 [==============================] - 0s 583us/step - loss: 0.6441 - accuracy: 0.6723\n",
      "Epoch 64/300\n",
      "12/12 [==============================] - 0s 626us/step - loss: 0.6386 - accuracy: 0.7059\n",
      "Epoch 65/300\n",
      "12/12 [==============================] - 0s 667us/step - loss: 0.6461 - accuracy: 0.6723\n",
      "Epoch 66/300\n",
      "12/12 [==============================] - 0s 626us/step - loss: 0.6165 - accuracy: 0.6723\n",
      "Epoch 67/300\n",
      "12/12 [==============================] - 0s 748us/step - loss: 0.5997 - accuracy: 0.6891\n",
      "Epoch 68/300\n",
      "12/12 [==============================] - 0s 669us/step - loss: 0.6041 - accuracy: 0.7143\n",
      "Epoch 69/300\n",
      "12/12 [==============================] - 0s 665us/step - loss: 0.6102 - accuracy: 0.7227\n",
      "Epoch 70/300\n",
      "12/12 [==============================] - 0s 750us/step - loss: 0.5815 - accuracy: 0.7143\n",
      "Epoch 71/300\n",
      "12/12 [==============================] - 0s 667us/step - loss: 0.5815 - accuracy: 0.7311\n",
      "Epoch 72/300\n",
      "12/12 [==============================] - 0s 667us/step - loss: 0.5799 - accuracy: 0.7143\n",
      "Epoch 73/300\n",
      "12/12 [==============================] - 0s 581us/step - loss: 0.5651 - accuracy: 0.7143\n",
      "Epoch 74/300\n",
      "12/12 [==============================] - 0s 670us/step - loss: 0.5615 - accuracy: 0.7143\n",
      "Epoch 75/300\n",
      "12/12 [==============================] - 0s 750us/step - loss: 0.5897 - accuracy: 0.7227\n",
      "Epoch 76/300\n",
      "12/12 [==============================] - 0s 664us/step - loss: 0.5868 - accuracy: 0.7311\n",
      "Epoch 77/300\n",
      "12/12 [==============================] - 0s 752us/step - loss: 0.6115 - accuracy: 0.7059\n",
      "Epoch 78/300\n",
      "12/12 [==============================] - 0s 711us/step - loss: 0.5641 - accuracy: 0.6975\n",
      "Epoch 79/300\n",
      "12/12 [==============================] - 0s 665us/step - loss: 0.5565 - accuracy: 0.6807\n",
      "Epoch 80/300\n",
      "12/12 [==============================] - 0s 668us/step - loss: 0.5401 - accuracy: 0.6975\n",
      "Epoch 81/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12/12 [==============================] - 0s 664us/step - loss: 0.5951 - accuracy: 0.7311\n",
      "Epoch 82/300\n",
      "12/12 [==============================] - 0s 584us/step - loss: 0.6437 - accuracy: 0.7227\n",
      "Epoch 83/300\n",
      "12/12 [==============================] - 0s 714us/step - loss: 0.5375 - accuracy: 0.7395\n",
      "Epoch 84/300\n",
      "12/12 [==============================] - 0s 750us/step - loss: 0.6066 - accuracy: 0.7227\n",
      "Epoch 85/300\n",
      "12/12 [==============================] - 0s 585us/step - loss: 0.6681 - accuracy: 0.6555\n",
      "Epoch 86/300\n",
      "12/12 [==============================] - 0s 709us/step - loss: 0.6455 - accuracy: 0.7563\n",
      "Epoch 87/300\n",
      "12/12 [==============================] - 0s 664us/step - loss: 0.5379 - accuracy: 0.7311\n",
      "Epoch 88/300\n",
      "12/12 [==============================] - 0s 583us/step - loss: 0.5712 - accuracy: 0.6975\n",
      "Epoch 89/300\n",
      "12/12 [==============================] - 0s 748us/step - loss: 0.5849 - accuracy: 0.7563\n",
      "Epoch 90/300\n",
      "12/12 [==============================] - 0s 583us/step - loss: 0.5072 - accuracy: 0.7143\n",
      "Epoch 91/300\n",
      "12/12 [==============================] - 0s 666us/step - loss: 0.5472 - accuracy: 0.7143\n",
      "Epoch 92/300\n",
      "12/12 [==============================] - 0s 667us/step - loss: 0.5220 - accuracy: 0.7311\n",
      "Epoch 93/300\n",
      "12/12 [==============================] - 0s 583us/step - loss: 0.5065 - accuracy: 0.7143\n",
      "Epoch 94/300\n",
      "12/12 [==============================] - 0s 712us/step - loss: 0.5031 - accuracy: 0.7647\n",
      "Epoch 95/300\n",
      "12/12 [==============================] - 0s 585us/step - loss: 0.4955 - accuracy: 0.7479\n",
      "Epoch 96/300\n",
      "12/12 [==============================] - 0s 586us/step - loss: 0.4884 - accuracy: 0.7479\n",
      "Epoch 97/300\n",
      "12/12 [==============================] - 0s 750us/step - loss: 0.5031 - accuracy: 0.7227\n",
      "Epoch 98/300\n",
      "12/12 [==============================] - 0s 669us/step - loss: 0.4738 - accuracy: 0.7227\n",
      "Epoch 99/300\n",
      "12/12 [==============================] - 0s 667us/step - loss: 0.4879 - accuracy: 0.7395\n",
      "Epoch 100/300\n",
      "12/12 [==============================] - 0s 669us/step - loss: 0.4593 - accuracy: 0.7731\n",
      "Epoch 101/300\n",
      "12/12 [==============================] - 0s 667us/step - loss: 0.4669 - accuracy: 0.7311\n",
      "Epoch 102/300\n",
      "12/12 [==============================] - 0s 667us/step - loss: 0.4887 - accuracy: 0.7479\n",
      "Epoch 103/300\n",
      "12/12 [==============================] - 0s 669us/step - loss: 0.4766 - accuracy: 0.7143\n",
      "Epoch 104/300\n",
      "12/12 [==============================] - 0s 583us/step - loss: 0.4573 - accuracy: 0.7395\n",
      "Epoch 105/300\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.2393 - accuracy: 0.80 - 0s 669us/step - loss: 0.4414 - accuracy: 0.7479\n",
      "Epoch 106/300\n",
      "12/12 [==============================] - 0s 583us/step - loss: 0.4564 - accuracy: 0.7563\n",
      "Epoch 107/300\n",
      "12/12 [==============================] - 0s 664us/step - loss: 0.4713 - accuracy: 0.7731\n",
      "Epoch 108/300\n",
      "12/12 [==============================] - 0s 748us/step - loss: 0.4573 - accuracy: 0.7563\n",
      "Epoch 109/300\n",
      "12/12 [==============================] - 0s 664us/step - loss: 0.4581 - accuracy: 0.7563\n",
      "Epoch 110/300\n",
      "12/12 [==============================] - 0s 667us/step - loss: 0.4646 - accuracy: 0.7815\n",
      "Epoch 111/300\n",
      "12/12 [==============================] - 0s 583us/step - loss: 0.4332 - accuracy: 0.7731\n",
      "Epoch 112/300\n",
      "12/12 [==============================] - 0s 667us/step - loss: 0.4095 - accuracy: 0.7983\n",
      "Epoch 113/300\n",
      "12/12 [==============================] - 0s 752us/step - loss: 0.4155 - accuracy: 0.7731\n",
      "Epoch 114/300\n",
      "12/12 [==============================] - 0s 584us/step - loss: 0.4346 - accuracy: 0.7731\n",
      "Epoch 115/300\n",
      "12/12 [==============================] - 0s 750us/step - loss: 0.4129 - accuracy: 0.8067\n",
      "Epoch 116/300\n",
      "12/12 [==============================] - 0s 665us/step - loss: 0.3946 - accuracy: 0.8067\n",
      "Epoch 117/300\n",
      "12/12 [==============================] - 0s 583us/step - loss: 0.3964 - accuracy: 0.8235\n",
      "Epoch 118/300\n",
      "12/12 [==============================] - 0s 632us/step - loss: 0.3893 - accuracy: 0.8235\n",
      "Epoch 119/300\n",
      "12/12 [==============================] - 0s 667us/step - loss: 0.4044 - accuracy: 0.8151\n",
      "Epoch 120/300\n",
      "12/12 [==============================] - 0s 583us/step - loss: 0.3851 - accuracy: 0.8319\n",
      "Epoch 121/300\n",
      "12/12 [==============================] - 0s 664us/step - loss: 0.3980 - accuracy: 0.8319\n",
      "Epoch 122/300\n",
      "12/12 [==============================] - 0s 583us/step - loss: 0.3911 - accuracy: 0.7983\n",
      "Epoch 123/300\n",
      "12/12 [==============================] - 0s 583us/step - loss: 0.3803 - accuracy: 0.8151\n",
      "Epoch 124/300\n",
      "12/12 [==============================] - 0s 669us/step - loss: 0.3726 - accuracy: 0.8571\n",
      "Epoch 125/300\n",
      "12/12 [==============================] - 0s 583us/step - loss: 0.3575 - accuracy: 0.8824\n",
      "Epoch 126/300\n",
      "12/12 [==============================] - 0s 669us/step - loss: 0.3108 - accuracy: 0.8571\n",
      "Epoch 127/300\n",
      "12/12 [==============================] - 0s 748us/step - loss: 0.3353 - accuracy: 0.8739\n",
      "Epoch 128/300\n",
      "12/12 [==============================] - 0s 585us/step - loss: 0.3791 - accuracy: 0.7983\n",
      "Epoch 129/300\n",
      "12/12 [==============================] - 0s 667us/step - loss: 0.3656 - accuracy: 0.8319\n",
      "Epoch 130/300\n",
      "12/12 [==============================] - 0s 583us/step - loss: 0.3751 - accuracy: 0.8487\n",
      "Epoch 131/300\n",
      "12/12 [==============================] - 0s 583us/step - loss: 0.3026 - accuracy: 0.8908\n",
      "Epoch 132/300\n",
      "12/12 [==============================] - 0s 667us/step - loss: 0.2807 - accuracy: 0.8908\n",
      "Epoch 133/300\n",
      "12/12 [==============================] - 0s 583us/step - loss: 0.2950 - accuracy: 0.8824\n",
      "Epoch 134/300\n",
      "12/12 [==============================] - 0s 669us/step - loss: 0.2829 - accuracy: 0.8992\n",
      "Epoch 135/300\n",
      "12/12 [==============================] - 0s 667us/step - loss: 0.2923 - accuracy: 0.8571\n",
      "Epoch 136/300\n",
      "12/12 [==============================] - 0s 667us/step - loss: 0.2814 - accuracy: 0.9160\n",
      "Epoch 137/300\n",
      "12/12 [==============================] - 0s 667us/step - loss: 0.2802 - accuracy: 0.8487\n",
      "Epoch 138/300\n",
      "12/12 [==============================] - 0s 583us/step - loss: 0.2582 - accuracy: 0.9160\n",
      "Epoch 139/300\n",
      "12/12 [==============================] - 0s 669us/step - loss: 0.3279 - accuracy: 0.8487\n",
      "Epoch 140/300\n",
      "12/12 [==============================] - 0s 669us/step - loss: 0.3051 - accuracy: 0.8908\n",
      "Epoch 141/300\n",
      "12/12 [==============================] - 0s 664us/step - loss: 0.3593 - accuracy: 0.8487\n",
      "Epoch 142/300\n",
      "12/12 [==============================] - 0s 750us/step - loss: 0.3487 - accuracy: 0.8739\n",
      "Epoch 143/300\n",
      "12/12 [==============================] - 0s 667us/step - loss: 0.3167 - accuracy: 0.9076\n",
      "Epoch 144/300\n",
      "12/12 [==============================] - 0s 667us/step - loss: 0.2577 - accuracy: 0.8992\n",
      "Epoch 145/300\n",
      "12/12 [==============================] - 0s 584us/step - loss: 0.2817 - accuracy: 0.8824\n",
      "Epoch 146/300\n",
      "12/12 [==============================] - 0s 583us/step - loss: 0.3039 - accuracy: 0.8908\n",
      "Epoch 147/300\n",
      "12/12 [==============================] - 0s 668us/step - loss: 0.3164 - accuracy: 0.8487\n",
      "Epoch 148/300\n",
      "12/12 [==============================] - 0s 667us/step - loss: 0.3036 - accuracy: 0.8908\n",
      "Epoch 149/300\n",
      "12/12 [==============================] - 0s 667us/step - loss: 0.2301 - accuracy: 0.9412\n",
      "Epoch 150/300\n",
      "12/12 [==============================] - 0s 667us/step - loss: 0.2327 - accuracy: 0.9244\n",
      "Epoch 151/300\n",
      "12/12 [==============================] - 0s 602us/step - loss: 0.2416 - accuracy: 0.9160\n",
      "Epoch 152/300\n",
      "12/12 [==============================] - 0s 666us/step - loss: 0.2484 - accuracy: 0.9244\n",
      "Epoch 153/300\n",
      "12/12 [==============================] - 0s 666us/step - loss: 0.2399 - accuracy: 0.9244\n",
      "Epoch 154/300\n",
      "12/12 [==============================] - 0s 583us/step - loss: 0.2373 - accuracy: 0.8992\n",
      "Epoch 155/300\n",
      "12/12 [==============================] - 0s 708us/step - loss: 0.2451 - accuracy: 0.9412\n",
      "Epoch 156/300\n",
      "12/12 [==============================] - 0s 667us/step - loss: 0.2118 - accuracy: 0.9244\n",
      "Epoch 157/300\n",
      "12/12 [==============================] - 0s 583us/step - loss: 0.2460 - accuracy: 0.9328\n",
      "Epoch 158/300\n",
      "12/12 [==============================] - 0s 667us/step - loss: 0.2178 - accuracy: 0.9160\n",
      "Epoch 159/300\n",
      "12/12 [==============================] - 0s 665us/step - loss: 0.2460 - accuracy: 0.8992\n",
      "Epoch 160/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12/12 [==============================] - 0s 581us/step - loss: 0.2019 - accuracy: 0.9244\n",
      "Epoch 161/300\n",
      "12/12 [==============================] - 0s 583us/step - loss: 0.2219 - accuracy: 0.8992\n",
      "Epoch 162/300\n",
      "12/12 [==============================] - 0s 667us/step - loss: 0.2278 - accuracy: 0.9076\n",
      "Epoch 163/300\n",
      "12/12 [==============================] - 0s 664us/step - loss: 0.2280 - accuracy: 0.9496\n",
      "Epoch 164/300\n",
      "12/12 [==============================] - 0s 667us/step - loss: 0.2400 - accuracy: 0.9328\n",
      "Epoch 165/300\n",
      "12/12 [==============================] - 0s 583us/step - loss: 0.2057 - accuracy: 0.9580\n",
      "Epoch 166/300\n",
      "12/12 [==============================] - 0s 669us/step - loss: 0.2239 - accuracy: 0.9244\n",
      "Epoch 167/300\n",
      "12/12 [==============================] - 0s 581us/step - loss: 0.1897 - accuracy: 0.9412\n",
      "Epoch 168/300\n",
      "12/12 [==============================] - 0s 666us/step - loss: 0.2214 - accuracy: 0.9076\n",
      "Epoch 169/300\n",
      "12/12 [==============================] - 0s 583us/step - loss: 0.2224 - accuracy: 0.9328\n",
      "Epoch 170/300\n",
      "12/12 [==============================] - 0s 502us/step - loss: 0.1954 - accuracy: 0.9328\n",
      "Epoch 171/300\n",
      "12/12 [==============================] - 0s 667us/step - loss: 0.2063 - accuracy: 0.9412\n",
      "Epoch 172/300\n",
      "12/12 [==============================] - 0s 583us/step - loss: 0.2337 - accuracy: 0.9244\n",
      "Epoch 173/300\n",
      "12/12 [==============================] - 0s 668us/step - loss: 0.2346 - accuracy: 0.9076\n",
      "Epoch 174/300\n",
      "12/12 [==============================] - 0s 750us/step - loss: 0.2411 - accuracy: 0.9076\n",
      "Epoch 175/300\n",
      "12/12 [==============================] - 0s 664us/step - loss: 0.2061 - accuracy: 0.9160\n",
      "Epoch 176/300\n",
      "12/12 [==============================] - 0s 630us/step - loss: 0.2476 - accuracy: 0.8824\n",
      "Epoch 177/300\n",
      "12/12 [==============================] - 0s 664us/step - loss: 0.2362 - accuracy: 0.9412\n",
      "Epoch 178/300\n",
      "12/12 [==============================] - 0s 667us/step - loss: 0.1774 - accuracy: 0.9328\n",
      "Epoch 179/300\n",
      "12/12 [==============================] - 0s 752us/step - loss: 0.1843 - accuracy: 0.9412\n",
      "Epoch 180/300\n",
      "12/12 [==============================] - 0s 584us/step - loss: 0.1968 - accuracy: 0.9496\n",
      "Epoch 181/300\n",
      "12/12 [==============================] - 0s 750us/step - loss: 0.1950 - accuracy: 0.9412\n",
      "Epoch 182/300\n",
      "12/12 [==============================] - 0s 750us/step - loss: 0.1680 - accuracy: 0.9496\n",
      "Epoch 183/300\n",
      "12/12 [==============================] - 0s 583us/step - loss: 0.2470 - accuracy: 0.9412\n",
      "Epoch 184/300\n",
      "12/12 [==============================] - 0s 583us/step - loss: 0.3214 - accuracy: 0.8824\n",
      "Epoch 185/300\n",
      "12/12 [==============================] - 0s 680us/step - loss: 0.3271 - accuracy: 0.9160\n",
      "Epoch 186/300\n",
      "12/12 [==============================] - 0s 583us/step - loss: 0.2702 - accuracy: 0.9076\n",
      "Epoch 187/300\n",
      "12/12 [==============================] - 0s 750us/step - loss: 0.2407 - accuracy: 0.8824\n",
      "Epoch 188/300\n",
      "12/12 [==============================] - 0s 583us/step - loss: 0.2033 - accuracy: 0.9412\n",
      "Epoch 189/300\n",
      "12/12 [==============================] - 0s 666us/step - loss: 0.1948 - accuracy: 0.9328\n",
      "Epoch 190/300\n",
      "12/12 [==============================] - 0s 750us/step - loss: 0.2069 - accuracy: 0.8992\n",
      "Epoch 191/300\n",
      "12/12 [==============================] - 0s 583us/step - loss: 0.2487 - accuracy: 0.9160\n",
      "Epoch 192/300\n",
      "12/12 [==============================] - 0s 668us/step - loss: 0.1698 - accuracy: 0.9580\n",
      "Epoch 193/300\n",
      "12/12 [==============================] - 0s 667us/step - loss: 0.1789 - accuracy: 0.9412\n",
      "Epoch 194/300\n",
      "12/12 [==============================] - 0s 666us/step - loss: 0.1805 - accuracy: 0.9496\n",
      "Epoch 195/300\n",
      "12/12 [==============================] - 0s 667us/step - loss: 0.1877 - accuracy: 0.9412\n",
      "Epoch 196/300\n",
      "12/12 [==============================] - 0s 664us/step - loss: 0.1901 - accuracy: 0.9328\n",
      "Epoch 197/300\n",
      "12/12 [==============================] - 0s 667us/step - loss: 0.1733 - accuracy: 0.9412\n",
      "Epoch 198/300\n",
      "12/12 [==============================] - 0s 583us/step - loss: 0.1652 - accuracy: 0.9412\n",
      "Epoch 199/300\n",
      "12/12 [==============================] - 0s 669us/step - loss: 0.1907 - accuracy: 0.9328\n",
      "Epoch 200/300\n",
      "12/12 [==============================] - 0s 750us/step - loss: 0.1805 - accuracy: 0.9580\n",
      "Epoch 201/300\n",
      "12/12 [==============================] - 0s 665us/step - loss: 0.1743 - accuracy: 0.9412\n",
      "Epoch 202/300\n",
      "12/12 [==============================] - 0s 669us/step - loss: 0.1944 - accuracy: 0.9496\n",
      "Epoch 203/300\n",
      "12/12 [==============================] - 0s 667us/step - loss: 0.1866 - accuracy: 0.9328\n",
      "Epoch 204/300\n",
      "12/12 [==============================] - 0s 583us/step - loss: 0.1748 - accuracy: 0.9580\n",
      "Epoch 205/300\n",
      "12/12 [==============================] - 0s 666us/step - loss: 0.1827 - accuracy: 0.9496\n",
      "Epoch 206/300\n",
      "12/12 [==============================] - 0s 667us/step - loss: 0.1486 - accuracy: 0.9496\n",
      "Epoch 207/300\n",
      "12/12 [==============================] - 0s 666us/step - loss: 0.1635 - accuracy: 0.9412\n",
      "Epoch 208/300\n",
      "12/12 [==============================] - 0s 750us/step - loss: 0.1561 - accuracy: 0.9496\n",
      "Epoch 209/300\n",
      "12/12 [==============================] - 0s 667us/step - loss: 0.2185 - accuracy: 0.9076\n",
      "Epoch 210/300\n",
      "12/12 [==============================] - 0s 667us/step - loss: 0.1703 - accuracy: 0.9580\n",
      "Epoch 211/300\n",
      "12/12 [==============================] - 0s 667us/step - loss: 0.2383 - accuracy: 0.9244\n",
      "Epoch 212/300\n",
      "12/12 [==============================] - 0s 581us/step - loss: 0.2061 - accuracy: 0.9412\n",
      "Epoch 213/300\n",
      "12/12 [==============================] - 0s 667us/step - loss: 0.1869 - accuracy: 0.9328\n",
      "Epoch 214/300\n",
      "12/12 [==============================] - 0s 628us/step - loss: 0.2208 - accuracy: 0.9328\n",
      "Epoch 215/300\n",
      "12/12 [==============================] - 0s 666us/step - loss: 0.1560 - accuracy: 0.9580\n",
      "Epoch 216/300\n",
      "12/12 [==============================] - 0s 583us/step - loss: 0.2053 - accuracy: 0.9244\n",
      "Epoch 217/300\n",
      "12/12 [==============================] - 0s 667us/step - loss: 0.1896 - accuracy: 0.9328\n",
      "Epoch 218/300\n",
      "12/12 [==============================] - 0s 626us/step - loss: 0.2132 - accuracy: 0.9160\n",
      "Epoch 219/300\n",
      "12/12 [==============================] - 0s 664us/step - loss: 0.1595 - accuracy: 0.9496\n",
      "Epoch 220/300\n",
      "12/12 [==============================] - 0s 583us/step - loss: 0.1429 - accuracy: 0.9496\n",
      "Epoch 221/300\n",
      "12/12 [==============================] - 0s 750us/step - loss: 0.1467 - accuracy: 0.9496\n",
      "Epoch 222/300\n",
      "12/12 [==============================] - 0s 667us/step - loss: 0.1631 - accuracy: 0.9412\n",
      "Epoch 223/300\n",
      "12/12 [==============================] - 0s 583us/step - loss: 0.1508 - accuracy: 0.9580\n",
      "Epoch 224/300\n",
      "12/12 [==============================] - 0s 667us/step - loss: 0.1398 - accuracy: 0.9496\n",
      "Epoch 225/300\n",
      "12/12 [==============================] - 0s 583us/step - loss: 0.1738 - accuracy: 0.9412\n",
      "Epoch 226/300\n",
      "12/12 [==============================] - 0s 667us/step - loss: 0.1761 - accuracy: 0.9496\n",
      "Epoch 227/300\n",
      "12/12 [==============================] - 0s 667us/step - loss: 0.1715 - accuracy: 0.9160\n",
      "Epoch 228/300\n",
      "12/12 [==============================] - 0s 583us/step - loss: 0.1463 - accuracy: 0.9664\n",
      "Epoch 229/300\n",
      "12/12 [==============================] - 0s 565us/step - loss: 0.1359 - accuracy: 0.9580\n",
      "Epoch 230/300\n",
      "12/12 [==============================] - 0s 586us/step - loss: 0.1358 - accuracy: 0.9580\n",
      "Epoch 231/300\n",
      "12/12 [==============================] - 0s 583us/step - loss: 0.1504 - accuracy: 0.9580\n",
      "Epoch 232/300\n",
      "12/12 [==============================] - 0s 750us/step - loss: 0.1323 - accuracy: 0.9496\n",
      "Epoch 233/300\n",
      "12/12 [==============================] - 0s 582us/step - loss: 0.1714 - accuracy: 0.9496\n",
      "Epoch 234/300\n",
      "12/12 [==============================] - 0s 669us/step - loss: 0.1712 - accuracy: 0.9412\n",
      "Epoch 235/300\n",
      "12/12 [==============================] - 0s 670us/step - loss: 0.2032 - accuracy: 0.8992\n",
      "Epoch 236/300\n",
      "12/12 [==============================] - 0s 583us/step - loss: 0.1853 - accuracy: 0.9412\n",
      "Epoch 237/300\n",
      "12/12 [==============================] - 0s 667us/step - loss: 0.1180 - accuracy: 0.9580\n",
      "Epoch 238/300\n",
      "12/12 [==============================] - 0s 667us/step - loss: 0.1979 - accuracy: 0.9160\n",
      "Epoch 239/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12/12 [==============================] - 0s 586us/step - loss: 0.1203 - accuracy: 0.9664\n",
      "Epoch 240/300\n",
      "12/12 [==============================] - 0s 667us/step - loss: 0.1419 - accuracy: 0.9664\n",
      "Epoch 241/300\n",
      "12/12 [==============================] - 0s 664us/step - loss: 0.1813 - accuracy: 0.9412\n",
      "Epoch 242/300\n",
      "12/12 [==============================] - 0s 667us/step - loss: 0.1371 - accuracy: 0.9664\n",
      "Epoch 243/300\n",
      "12/12 [==============================] - 0s 833us/step - loss: 0.1265 - accuracy: 0.9496\n",
      "Epoch 244/300\n",
      "12/12 [==============================] - 0s 667us/step - loss: 0.1481 - accuracy: 0.9496\n",
      "Epoch 245/300\n",
      "12/12 [==============================] - 0s 585us/step - loss: 0.1319 - accuracy: 0.9580\n",
      "Epoch 246/300\n",
      "12/12 [==============================] - 0s 664us/step - loss: 0.1371 - accuracy: 0.9496\n",
      "Epoch 247/300\n",
      "12/12 [==============================] - 0s 583us/step - loss: 0.1431 - accuracy: 0.9748\n",
      "Epoch 248/300\n",
      "12/12 [==============================] - 0s 583us/step - loss: 0.1341 - accuracy: 0.9412\n",
      "Epoch 249/300\n",
      "12/12 [==============================] - 0s 669us/step - loss: 0.1324 - accuracy: 0.9748\n",
      "Epoch 250/300\n",
      "12/12 [==============================] - 0s 583us/step - loss: 0.1816 - accuracy: 0.9160\n",
      "Epoch 251/300\n",
      "12/12 [==============================] - 0s 750us/step - loss: 0.2262 - accuracy: 0.9244\n",
      "Epoch 252/300\n",
      "12/12 [==============================] - 0s 665us/step - loss: 0.1895 - accuracy: 0.9160\n",
      "Epoch 253/300\n",
      "12/12 [==============================] - 0s 667us/step - loss: 0.1486 - accuracy: 0.9328\n",
      "Epoch 254/300\n",
      "12/12 [==============================] - 0s 665us/step - loss: 0.1700 - accuracy: 0.9328\n",
      "Epoch 255/300\n",
      "12/12 [==============================] - 0s 581us/step - loss: 0.1493 - accuracy: 0.9328\n",
      "Epoch 256/300\n",
      "12/12 [==============================] - 0s 750us/step - loss: 0.1284 - accuracy: 0.9496\n",
      "Epoch 257/300\n",
      "12/12 [==============================] - 0s 667us/step - loss: 0.1335 - accuracy: 0.9580\n",
      "Epoch 258/300\n",
      "12/12 [==============================] - 0s 667us/step - loss: 0.1256 - accuracy: 0.9664\n",
      "Epoch 259/300\n",
      "12/12 [==============================] - 0s 664us/step - loss: 0.1240 - accuracy: 0.9664\n",
      "Epoch 260/300\n",
      "12/12 [==============================] - 0s 583us/step - loss: 0.1365 - accuracy: 0.9496\n",
      "Epoch 261/300\n",
      "12/12 [==============================] - 0s 585us/step - loss: 0.1351 - accuracy: 0.9580\n",
      "Epoch 262/300\n",
      "12/12 [==============================] - 0s 664us/step - loss: 0.1342 - accuracy: 0.9580\n",
      "Epoch 263/300\n",
      "12/12 [==============================] - 0s 669us/step - loss: 0.1578 - accuracy: 0.9412\n",
      "Epoch 264/300\n",
      "12/12 [==============================] - 0s 667us/step - loss: 0.1100 - accuracy: 0.9580\n",
      "Epoch 265/300\n",
      "12/12 [==============================] - 0s 583us/step - loss: 0.1274 - accuracy: 0.9580\n",
      "Epoch 266/300\n",
      "12/12 [==============================] - 0s 667us/step - loss: 0.1353 - accuracy: 0.9496\n",
      "Epoch 267/300\n",
      "12/12 [==============================] - 0s 750us/step - loss: 0.1298 - accuracy: 0.9580\n",
      "Epoch 268/300\n",
      "12/12 [==============================] - 0s 583us/step - loss: 0.1275 - accuracy: 0.9496\n",
      "Epoch 269/300\n",
      "12/12 [==============================] - 0s 748us/step - loss: 0.1187 - accuracy: 0.9664\n",
      "Epoch 270/300\n",
      "12/12 [==============================] - 0s 748us/step - loss: 0.1202 - accuracy: 0.9496\n",
      "Epoch 271/300\n",
      "12/12 [==============================] - 0s 586us/step - loss: 0.1325 - accuracy: 0.9580\n",
      "Epoch 272/300\n",
      "12/12 [==============================] - 0s 667us/step - loss: 0.1239 - accuracy: 0.9580\n",
      "Epoch 273/300\n",
      "12/12 [==============================] - 0s 667us/step - loss: 0.1318 - accuracy: 0.9664\n",
      "Epoch 274/300\n",
      "12/12 [==============================] - 0s 748us/step - loss: 0.1420 - accuracy: 0.9496\n",
      "Epoch 275/300\n",
      "12/12 [==============================] - 0s 752us/step - loss: 0.1303 - accuracy: 0.9580\n",
      "Epoch 276/300\n",
      "12/12 [==============================] - 0s 667us/step - loss: 0.1409 - accuracy: 0.9496\n",
      "Epoch 277/300\n",
      "12/12 [==============================] - 0s 666us/step - loss: 0.1928 - accuracy: 0.9160\n",
      "Epoch 278/300\n",
      "12/12 [==============================] - 0s 667us/step - loss: 0.1419 - accuracy: 0.9412\n",
      "Epoch 279/300\n",
      "12/12 [==============================] - 0s 667us/step - loss: 0.1351 - accuracy: 0.9496\n",
      "Epoch 280/300\n",
      "12/12 [==============================] - 0s 750us/step - loss: 0.1326 - accuracy: 0.9664\n",
      "Epoch 281/300\n",
      "12/12 [==============================] - 0s 667us/step - loss: 0.1157 - accuracy: 0.9580\n",
      "Epoch 282/300\n",
      "12/12 [==============================] - 0s 667us/step - loss: 0.1405 - accuracy: 0.9580\n",
      "Epoch 283/300\n",
      "12/12 [==============================] - 0s 669us/step - loss: 0.1716 - accuracy: 0.9160\n",
      "Epoch 284/300\n",
      "12/12 [==============================] - 0s 583us/step - loss: 0.1179 - accuracy: 0.9580\n",
      "Epoch 285/300\n",
      "12/12 [==============================] - 0s 667us/step - loss: 0.1432 - accuracy: 0.9412\n",
      "Epoch 286/300\n",
      "12/12 [==============================] - 0s 667us/step - loss: 0.1331 - accuracy: 0.9412\n",
      "Epoch 287/300\n",
      "12/12 [==============================] - 0s 668us/step - loss: 0.1548 - accuracy: 0.9496\n",
      "Epoch 288/300\n",
      "12/12 [==============================] - 0s 667us/step - loss: 0.1536 - accuracy: 0.9328\n",
      "Epoch 289/300\n",
      "12/12 [==============================] - 0s 667us/step - loss: 0.2054 - accuracy: 0.9160\n",
      "Epoch 290/300\n",
      "12/12 [==============================] - 0s 667us/step - loss: 0.1211 - accuracy: 0.9580\n",
      "Epoch 291/300\n",
      "12/12 [==============================] - 0s 667us/step - loss: 0.1171 - accuracy: 0.9748\n",
      "Epoch 292/300\n",
      "12/12 [==============================] - 0s 667us/step - loss: 0.1090 - accuracy: 0.9496\n",
      "Epoch 293/300\n",
      "12/12 [==============================] - 0s 669us/step - loss: 0.1069 - accuracy: 0.9664\n",
      "Epoch 294/300\n",
      "12/12 [==============================] - 0s 667us/step - loss: 0.1100 - accuracy: 0.9580\n",
      "Epoch 295/300\n",
      "12/12 [==============================] - 0s 669us/step - loss: 0.1082 - accuracy: 0.9664\n",
      "Epoch 296/300\n",
      "12/12 [==============================] - 0s 669us/step - loss: 0.1249 - accuracy: 0.9580\n",
      "Epoch 297/300\n",
      "12/12 [==============================] - 0s 667us/step - loss: 0.1276 - accuracy: 0.9496\n",
      "Epoch 298/300\n",
      "12/12 [==============================] - 0s 667us/step - loss: 0.1131 - accuracy: 0.9496\n",
      "Epoch 299/300\n",
      "12/12 [==============================] - 0s 750us/step - loss: 0.1362 - accuracy: 0.9496\n",
      "Epoch 300/300\n",
      "12/12 [==============================] - 0s 667us/step - loss: 0.1256 - accuracy: 0.9580\n",
      "Epoch 1/300\n",
      "12/12 [==============================] - 0s 500us/step - loss: 177.2482 - accuracy: 0.4118\n",
      "Epoch 2/300\n",
      "12/12 [==============================] - 0s 586us/step - loss: 1.0871 - accuracy: 0.4118\n",
      "Epoch 3/300\n",
      "12/12 [==============================] - 0s 586us/step - loss: 1.0859 - accuracy: 0.4118\n",
      "Epoch 4/300\n",
      "12/12 [==============================] - 0s 664us/step - loss: 1.0848 - accuracy: 0.4118\n",
      "Epoch 5/300\n",
      "12/12 [==============================] - 0s 581us/step - loss: 1.0847 - accuracy: 0.4118\n",
      "Epoch 6/300\n",
      "12/12 [==============================] - 0s 583us/step - loss: 1.0839 - accuracy: 0.4118\n",
      "Epoch 7/300\n",
      "12/12 [==============================] - 0s 666us/step - loss: 1.0855 - accuracy: 0.4118\n",
      "Epoch 8/300\n",
      "12/12 [==============================] - 0s 584us/step - loss: 1.0876 - accuracy: 0.4118\n",
      "Epoch 9/300\n",
      "12/12 [==============================] - 0s 583us/step - loss: 1.0845 - accuracy: 0.4118\n",
      "Epoch 10/300\n",
      "12/12 [==============================] - 0s 583us/step - loss: 1.0856 - accuracy: 0.4118\n",
      "Epoch 11/300\n",
      "12/12 [==============================] - 0s 669us/step - loss: 1.0848 - accuracy: 0.4118\n",
      "Epoch 12/300\n",
      "12/12 [==============================] - 0s 583us/step - loss: 1.0847 - accuracy: 0.4118\n",
      "Epoch 13/300\n",
      "12/12 [==============================] - 0s 666us/step - loss: 1.0858 - accuracy: 0.4118\n",
      "Epoch 14/300\n",
      "12/12 [==============================] - 0s 584us/step - loss: 1.0853 - accuracy: 0.4118\n",
      "Epoch 15/300\n",
      "12/12 [==============================] - 0s 500us/step - loss: 1.0848 - accuracy: 0.4118\n",
      "Epoch 16/300\n",
      "12/12 [==============================] - 0s 583us/step - loss: 1.0855 - accuracy: 0.4118\n",
      "Epoch 17/300\n",
      "12/12 [==============================] - 0s 581us/step - loss: 1.0845 - accuracy: 0.4118\n",
      "Epoch 18/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12/12 [==============================] - 0s 666us/step - loss: 1.0858 - accuracy: 0.4118\n",
      "Epoch 19/300\n",
      "12/12 [==============================] - 0s 583us/step - loss: 1.0851 - accuracy: 0.4118\n",
      "Epoch 20/300\n",
      "12/12 [==============================] - 0s 500us/step - loss: 1.0854 - accuracy: 0.4118\n",
      "Epoch 21/300\n",
      "12/12 [==============================] - 0s 583us/step - loss: 1.0843 - accuracy: 0.4118\n",
      "Epoch 22/300\n",
      "12/12 [==============================] - 0s 581us/step - loss: 1.0867 - accuracy: 0.4118\n",
      "Epoch 23/300\n",
      "12/12 [==============================] - 0s 583us/step - loss: 1.0849 - accuracy: 0.4118\n",
      "Epoch 24/300\n",
      "12/12 [==============================] - 0s 581us/step - loss: 1.0841 - accuracy: 0.4118\n",
      "Epoch 25/300\n",
      "12/12 [==============================] - 0s 585us/step - loss: 1.0853 - accuracy: 0.4118\n",
      "Epoch 26/300\n",
      "12/12 [==============================] - 0s 583us/step - loss: 1.0854 - accuracy: 0.4118\n",
      "Epoch 27/300\n",
      "12/12 [==============================] - 0s 583us/step - loss: 1.0842 - accuracy: 0.4118\n",
      "Epoch 28/300\n",
      "12/12 [==============================] - 0s 661us/step - loss: 1.0851 - accuracy: 0.4118\n",
      "Epoch 29/300\n",
      "12/12 [==============================] - 0s 582us/step - loss: 1.0843 - accuracy: 0.4118\n",
      "Epoch 30/300\n",
      "12/12 [==============================] - 0s 647us/step - loss: 1.0852 - accuracy: 0.4118\n",
      "Epoch 31/300\n",
      "12/12 [==============================] - 0s 636us/step - loss: 1.0858 - accuracy: 0.4118\n",
      "Epoch 32/300\n",
      "12/12 [==============================] - 0s 583us/step - loss: 1.0849 - accuracy: 0.4118\n",
      "Epoch 33/300\n",
      "12/12 [==============================] - 0s 584us/step - loss: 1.0850 - accuracy: 0.4118\n",
      "Epoch 34/300\n",
      "12/12 [==============================] - 0s 583us/step - loss: 1.0860 - accuracy: 0.4118\n",
      "Epoch 35/300\n",
      "12/12 [==============================] - 0s 667us/step - loss: 1.0841 - accuracy: 0.4118\n",
      "Epoch 36/300\n",
      "12/12 [==============================] - 0s 750us/step - loss: 1.0854 - accuracy: 0.4118\n",
      "Epoch 37/300\n",
      "12/12 [==============================] - 0s 583us/step - loss: 1.0846 - accuracy: 0.4118\n",
      "Epoch 38/300\n",
      "12/12 [==============================] - 0s 583us/step - loss: 1.0840 - accuracy: 0.4118\n",
      "Epoch 39/300\n",
      "12/12 [==============================] - 0s 750us/step - loss: 1.0845 - accuracy: 0.4118\n",
      "Epoch 40/300\n",
      "12/12 [==============================] - 0s 500us/step - loss: 1.0862 - accuracy: 0.4118\n",
      "Epoch 41/300\n",
      "12/12 [==============================] - 0s 667us/step - loss: 1.0845 - accuracy: 0.4118\n",
      "Epoch 42/300\n",
      "12/12 [==============================] - 0s 585us/step - loss: 1.0849 - accuracy: 0.4118\n",
      "Epoch 43/300\n",
      "12/12 [==============================] - 0s 584us/step - loss: 1.0839 - accuracy: 0.4118\n",
      "Epoch 44/300\n",
      "12/12 [==============================] - 0s 667us/step - loss: 1.0847 - accuracy: 0.4118\n",
      "Epoch 45/300\n",
      "12/12 [==============================] - 0s 667us/step - loss: 1.0850 - accuracy: 0.4118\n",
      "Epoch 46/300\n",
      "12/12 [==============================] - 0s 583us/step - loss: 1.0838 - accuracy: 0.4118\n",
      "Epoch 47/300\n",
      "12/12 [==============================] - 0s 726us/step - loss: 1.0855 - accuracy: 0.4118\n",
      "Epoch 48/300\n",
      "12/12 [==============================] - 0s 583us/step - loss: 1.0843 - accuracy: 0.4118\n",
      "Epoch 49/300\n",
      "12/12 [==============================] - 0s 667us/step - loss: 1.0841 - accuracy: 0.4118\n",
      "Epoch 50/300\n",
      "12/12 [==============================] - 0s 581us/step - loss: 1.0857 - accuracy: 0.4118\n",
      "Epoch 51/300\n",
      "12/12 [==============================] - 0s 583us/step - loss: 1.0844 - accuracy: 0.4118\n",
      "Epoch 52/300\n",
      "12/12 [==============================] - 0s 665us/step - loss: 1.0853 - accuracy: 0.4118\n",
      "Epoch 53/300\n",
      "12/12 [==============================] - 0s 667us/step - loss: 1.0858 - accuracy: 0.4118\n",
      "Epoch 54/300\n",
      "12/12 [==============================] - 0s 667us/step - loss: 1.0863 - accuracy: 0.4118\n",
      "Epoch 55/300\n",
      "12/12 [==============================] - 0s 583us/step - loss: 1.0842 - accuracy: 0.4118\n",
      "Epoch 56/300\n",
      "12/12 [==============================] - 0s 583us/step - loss: 1.0850 - accuracy: 0.4118\n",
      "Epoch 57/300\n",
      "12/12 [==============================] - 0s 664us/step - loss: 1.0848 - accuracy: 0.4118\n",
      "Epoch 58/300\n",
      "12/12 [==============================] - 0s 643us/step - loss: 1.0857 - accuracy: 0.4118\n",
      "Epoch 59/300\n",
      "12/12 [==============================] - 0s 583us/step - loss: 1.0850 - accuracy: 0.4118\n",
      "Epoch 60/300\n",
      "12/12 [==============================] - 0s 502us/step - loss: 1.0837 - accuracy: 0.4118\n",
      "Epoch 61/300\n",
      "12/12 [==============================] - 0s 583us/step - loss: 1.0848 - accuracy: 0.4118\n",
      "Epoch 62/300\n",
      "12/12 [==============================] - 0s 582us/step - loss: 1.0856 - accuracy: 0.4118\n",
      "Epoch 63/300\n",
      "12/12 [==============================] - 0s 667us/step - loss: 1.0868 - accuracy: 0.4118\n",
      "Epoch 64/300\n",
      "12/12 [==============================] - 0s 584us/step - loss: 1.0857 - accuracy: 0.4118\n",
      "Epoch 65/300\n",
      "12/12 [==============================] - 0s 502us/step - loss: 1.0855 - accuracy: 0.4118\n",
      "Epoch 66/300\n",
      "12/12 [==============================] - 0s 603us/step - loss: 1.0855 - accuracy: 0.4118\n",
      "Epoch 67/300\n",
      "12/12 [==============================] - 0s 583us/step - loss: 1.0848 - accuracy: 0.4118\n",
      "Epoch 68/300\n",
      "12/12 [==============================] - 0s 667us/step - loss: 1.0859 - accuracy: 0.4118\n",
      "Epoch 69/300\n",
      "12/12 [==============================] - 0s 667us/step - loss: 1.0842 - accuracy: 0.4118\n",
      "Epoch 70/300\n",
      "12/12 [==============================] - 0s 583us/step - loss: 1.0856 - accuracy: 0.4118\n",
      "Epoch 71/300\n",
      "12/12 [==============================] - 0s 583us/step - loss: 1.0847 - accuracy: 0.4118\n",
      "Epoch 72/300\n",
      "12/12 [==============================] - 0s 500us/step - loss: 1.0843 - accuracy: 0.4118\n",
      "Epoch 73/300\n",
      "12/12 [==============================] - 0s 668us/step - loss: 1.0849 - accuracy: 0.4118\n",
      "Epoch 74/300\n",
      "12/12 [==============================] - 0s 583us/step - loss: 1.0845 - accuracy: 0.4118\n",
      "Epoch 75/300\n",
      "12/12 [==============================] - 0s 585us/step - loss: 1.0852 - accuracy: 0.4118\n",
      "Epoch 76/300\n",
      "12/12 [==============================] - 0s 583us/step - loss: 1.0843 - accuracy: 0.4118\n",
      "Epoch 77/300\n",
      "12/12 [==============================] - 0s 580us/step - loss: 1.0861 - accuracy: 0.4118\n",
      "Epoch 78/300\n",
      "12/12 [==============================] - 0s 664us/step - loss: 1.0858 - accuracy: 0.4118\n",
      "Epoch 79/300\n",
      "12/12 [==============================] - 0s 673us/step - loss: 1.0853 - accuracy: 0.4118\n",
      "Epoch 80/300\n",
      "12/12 [==============================] - 0s 583us/step - loss: 1.0842 - accuracy: 0.4118\n",
      "Epoch 81/300\n",
      "12/12 [==============================] - 0s 581us/step - loss: 1.0840 - accuracy: 0.4118\n",
      "Epoch 82/300\n",
      "12/12 [==============================] - ETA: 0s - loss: 1.0913 - accuracy: 0.40 - 0s 583us/step - loss: 1.0854 - accuracy: 0.4118\n",
      "Epoch 83/300\n",
      "12/12 [==============================] - 0s 629us/step - loss: 1.0846 - accuracy: 0.4118\n",
      "Epoch 84/300\n",
      "12/12 [==============================] - 0s 585us/step - loss: 1.0841 - accuracy: 0.4118\n",
      "Epoch 85/300\n",
      "12/12 [==============================] - 0s 666us/step - loss: 1.0851 - accuracy: 0.4118\n",
      "Epoch 86/300\n",
      "12/12 [==============================] - 0s 666us/step - loss: 1.0851 - accuracy: 0.4118\n",
      "Epoch 87/300\n",
      "12/12 [==============================] - 0s 585us/step - loss: 1.0848 - accuracy: 0.4118\n",
      "Epoch 88/300\n",
      "12/12 [==============================] - 0s 667us/step - loss: 1.0851 - accuracy: 0.4118\n",
      "Epoch 89/300\n",
      "12/12 [==============================] - 0s 581us/step - loss: 1.0860 - accuracy: 0.4118\n",
      "Epoch 90/300\n",
      "12/12 [==============================] - 0s 583us/step - loss: 1.0852 - accuracy: 0.4118\n",
      "Epoch 91/300\n",
      "12/12 [==============================] - 0s 667us/step - loss: 1.0839 - accuracy: 0.4118\n",
      "Epoch 92/300\n",
      "12/12 [==============================] - 0s 583us/step - loss: 1.0848 - accuracy: 0.4118\n",
      "Epoch 93/300\n",
      "12/12 [==============================] - 0s 665us/step - loss: 1.0843 - accuracy: 0.4118\n",
      "Epoch 94/300\n",
      "12/12 [==============================] - 0s 600us/step - loss: 1.0841 - accuracy: 0.4118\n",
      "Epoch 95/300\n",
      "12/12 [==============================] - 0s 584us/step - loss: 1.0845 - accuracy: 0.4118\n",
      "Epoch 96/300\n",
      "12/12 [==============================] - 0s 667us/step - loss: 1.0842 - accuracy: 0.4118\n",
      "Epoch 97/300\n",
      "12/12 [==============================] - 0s 500us/step - loss: 1.0862 - accuracy: 0.4118\n",
      "Epoch 98/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12/12 [==============================] - 0s 584us/step - loss: 1.0847 - accuracy: 0.4118\n",
      "Epoch 99/300\n",
      "12/12 [==============================] - 0s 583us/step - loss: 1.0845 - accuracy: 0.4118\n",
      "Epoch 100/300\n",
      "12/12 [==============================] - 0s 582us/step - loss: 1.0858 - accuracy: 0.4118\n",
      "Epoch 101/300\n",
      "12/12 [==============================] - 0s 583us/step - loss: 1.0840 - accuracy: 0.4118\n",
      "Epoch 102/300\n",
      "12/12 [==============================] - 0s 583us/step - loss: 1.0844 - accuracy: 0.4118\n",
      "Epoch 103/300\n",
      "12/12 [==============================] - 0s 583us/step - loss: 1.0842 - accuracy: 0.4118\n",
      "Epoch 104/300\n",
      "12/12 [==============================] - 0s 581us/step - loss: 1.0844 - accuracy: 0.4118\n",
      "Epoch 105/300\n",
      "12/12 [==============================] - 0s 586us/step - loss: 1.0843 - accuracy: 0.4118\n",
      "Epoch 106/300\n",
      "12/12 [==============================] - 0s 584us/step - loss: 1.0847 - accuracy: 0.4118\n",
      "Epoch 107/300\n",
      "12/12 [==============================] - 0s 583us/step - loss: 1.0873 - accuracy: 0.4118\n",
      "Epoch 108/300\n",
      "12/12 [==============================] - 0s 664us/step - loss: 1.0862 - accuracy: 0.4118\n",
      "Epoch 109/300\n",
      "12/12 [==============================] - 0s 500us/step - loss: 1.0847 - accuracy: 0.4118\n",
      "Epoch 110/300\n",
      "12/12 [==============================] - 0s 585us/step - loss: 1.0853 - accuracy: 0.4118\n",
      "Epoch 111/300\n",
      "12/12 [==============================] - 0s 583us/step - loss: 1.0852 - accuracy: 0.4118\n",
      "Epoch 112/300\n",
      "12/12 [==============================] - 0s 667us/step - loss: 1.0844 - accuracy: 0.4118\n",
      "Epoch 113/300\n",
      "12/12 [==============================] - 0s 667us/step - loss: 1.0849 - accuracy: 0.4118\n",
      "Epoch 114/300\n",
      "12/12 [==============================] - 0s 500us/step - loss: 1.0841 - accuracy: 0.4118\n",
      "Epoch 115/300\n",
      "12/12 [==============================] - 0s 664us/step - loss: 1.0848 - accuracy: 0.4118\n",
      "Epoch 116/300\n",
      "12/12 [==============================] - 0s 500us/step - loss: 1.0849 - accuracy: 0.4118\n",
      "Epoch 117/300\n",
      "12/12 [==============================] - 0s 667us/step - loss: 1.0852 - accuracy: 0.4118\n",
      "Epoch 118/300\n",
      "12/12 [==============================] - 0s 582us/step - loss: 1.0844 - accuracy: 0.4118\n",
      "Epoch 119/300\n",
      "12/12 [==============================] - 0s 586us/step - loss: 1.0849 - accuracy: 0.4118\n",
      "Epoch 120/300\n",
      "12/12 [==============================] - 0s 583us/step - loss: 1.0848 - accuracy: 0.4118\n",
      "Epoch 121/300\n",
      "12/12 [==============================] - 0s 583us/step - loss: 1.0862 - accuracy: 0.4118\n",
      "Epoch 122/300\n",
      "12/12 [==============================] - 0s 583us/step - loss: 1.0846 - accuracy: 0.4118\n",
      "Epoch 123/300\n",
      "12/12 [==============================] - 0s 583us/step - loss: 1.0845 - accuracy: 0.4118\n",
      "Epoch 124/300\n",
      "12/12 [==============================] - 0s 583us/step - loss: 1.0856 - accuracy: 0.4118\n",
      "Epoch 125/300\n",
      "12/12 [==============================] - 0s 583us/step - loss: 1.0845 - accuracy: 0.4118\n",
      "Epoch 126/300\n",
      "12/12 [==============================] - 0s 583us/step - loss: 1.0845 - accuracy: 0.4118\n",
      "Epoch 127/300\n",
      "12/12 [==============================] - 0s 585us/step - loss: 1.0857 - accuracy: 0.4118\n",
      "Epoch 128/300\n",
      "12/12 [==============================] - 0s 502us/step - loss: 1.0838 - accuracy: 0.4118\n",
      "Epoch 129/300\n",
      "12/12 [==============================] - 0s 667us/step - loss: 1.0861 - accuracy: 0.4118\n",
      "Epoch 130/300\n",
      "12/12 [==============================] - 0s 665us/step - loss: 1.0847 - accuracy: 0.4118\n",
      "Epoch 131/300\n",
      "12/12 [==============================] - 0s 669us/step - loss: 1.0847 - accuracy: 0.4118\n",
      "Epoch 132/300\n",
      "12/12 [==============================] - 0s 581us/step - loss: 1.0857 - accuracy: 0.4118\n",
      "Epoch 133/300\n",
      "12/12 [==============================] - 0s 669us/step - loss: 1.0843 - accuracy: 0.4118\n",
      "Epoch 134/300\n",
      "12/12 [==============================] - 0s 583us/step - loss: 1.0839 - accuracy: 0.4118\n",
      "Epoch 135/300\n",
      "12/12 [==============================] - 0s 581us/step - loss: 1.0840 - accuracy: 0.4118\n",
      "Epoch 136/300\n",
      "12/12 [==============================] - 0s 666us/step - loss: 1.0848 - accuracy: 0.4118\n",
      "Epoch 137/300\n",
      "12/12 [==============================] - 0s 667us/step - loss: 1.0846 - accuracy: 0.4118\n",
      "Epoch 138/300\n",
      "12/12 [==============================] - 0s 583us/step - loss: 1.0855 - accuracy: 0.4118\n",
      "Epoch 139/300\n",
      "12/12 [==============================] - 0s 667us/step - loss: 1.0851 - accuracy: 0.4118\n",
      "Epoch 140/300\n",
      "12/12 [==============================] - 0s 503us/step - loss: 1.0843 - accuracy: 0.4118\n",
      "Epoch 141/300\n",
      "12/12 [==============================] - 0s 666us/step - loss: 1.0867 - accuracy: 0.4118\n",
      "Epoch 142/300\n",
      "12/12 [==============================] - 0s 582us/step - loss: 1.0871 - accuracy: 0.4118\n",
      "Epoch 143/300\n",
      "12/12 [==============================] - 0s 667us/step - loss: 1.0847 - accuracy: 0.4118\n",
      "Epoch 144/300\n",
      "12/12 [==============================] - 0s 586us/step - loss: 1.0845 - accuracy: 0.4118\n",
      "Epoch 145/300\n",
      "12/12 [==============================] - 0s 583us/step - loss: 1.0864 - accuracy: 0.4118\n",
      "Epoch 146/300\n",
      "12/12 [==============================] - ETA: 0s - loss: 1.0788 - accuracy: 0.50 - 0s 667us/step - loss: 1.0854 - accuracy: 0.4118\n",
      "Epoch 147/300\n",
      "12/12 [==============================] - 0s 583us/step - loss: 1.0857 - accuracy: 0.4118\n",
      "Epoch 148/300\n",
      "12/12 [==============================] - 0s 626us/step - loss: 1.0836 - accuracy: 0.4118\n",
      "Epoch 149/300\n",
      "12/12 [==============================] - 0s 612us/step - loss: 1.0850 - accuracy: 0.4118\n",
      "Epoch 150/300\n",
      "12/12 [==============================] - 0s 667us/step - loss: 1.0845 - accuracy: 0.4118\n",
      "Epoch 151/300\n",
      "12/12 [==============================] - 0s 664us/step - loss: 1.0849 - accuracy: 0.4118\n",
      "Epoch 152/300\n",
      "12/12 [==============================] - 0s 583us/step - loss: 1.0845 - accuracy: 0.4118\n",
      "Epoch 153/300\n",
      "12/12 [==============================] - 0s 586us/step - loss: 1.0844 - accuracy: 0.4118\n",
      "Epoch 154/300\n",
      "12/12 [==============================] - 0s 664us/step - loss: 1.0844 - accuracy: 0.4118\n",
      "Epoch 155/300\n",
      "12/12 [==============================] - 0s 583us/step - loss: 1.0846 - accuracy: 0.4118\n",
      "Epoch 156/300\n",
      "12/12 [==============================] - 0s 627us/step - loss: 1.0852 - accuracy: 0.4118\n",
      "Epoch 157/300\n",
      "12/12 [==============================] - 0s 502us/step - loss: 1.0854 - accuracy: 0.4118\n",
      "Epoch 158/300\n",
      "12/12 [==============================] - 0s 667us/step - loss: 1.0853 - accuracy: 0.4118\n",
      "Epoch 159/300\n",
      "12/12 [==============================] - 0s 583us/step - loss: 1.0844 - accuracy: 0.4118\n",
      "Epoch 160/300\n",
      "12/12 [==============================] - 0s 583us/step - loss: 1.0846 - accuracy: 0.4118\n",
      "Epoch 161/300\n",
      "12/12 [==============================] - 0s 627us/step - loss: 1.0848 - accuracy: 0.4118\n",
      "Epoch 162/300\n",
      "12/12 [==============================] - 0s 582us/step - loss: 1.0848 - accuracy: 0.4118\n",
      "Epoch 163/300\n",
      "12/12 [==============================] - 0s 665us/step - loss: 1.0884 - accuracy: 0.4118\n",
      "Epoch 164/300\n",
      "12/12 [==============================] - 0s 585us/step - loss: 1.0872 - accuracy: 0.4118\n",
      "Epoch 165/300\n",
      "12/12 [==============================] - 0s 667us/step - loss: 1.0843 - accuracy: 0.4118\n",
      "Epoch 166/300\n",
      "12/12 [==============================] - 0s 667us/step - loss: 1.0845 - accuracy: 0.4118\n",
      "Epoch 167/300\n",
      "12/12 [==============================] - 0s 583us/step - loss: 1.0859 - accuracy: 0.4118\n",
      "Epoch 168/300\n",
      "12/12 [==============================] - 0s 667us/step - loss: 1.0853 - accuracy: 0.4118\n",
      "Epoch 169/300\n",
      "12/12 [==============================] - 0s 583us/step - loss: 1.0848 - accuracy: 0.4118\n",
      "Epoch 170/300\n",
      "12/12 [==============================] - 0s 583us/step - loss: 1.0847 - accuracy: 0.4118\n",
      "Epoch 171/300\n",
      "12/12 [==============================] - 0s 581us/step - loss: 1.0849 - accuracy: 0.4118\n",
      "Epoch 172/300\n",
      "12/12 [==============================] - 0s 667us/step - loss: 1.0841 - accuracy: 0.4118\n",
      "Epoch 173/300\n",
      "12/12 [==============================] - 0s 667us/step - loss: 1.0847 - accuracy: 0.4118\n",
      "Epoch 174/300\n",
      "12/12 [==============================] - 0s 583us/step - loss: 1.0851 - accuracy: 0.4118\n",
      "Epoch 175/300\n",
      "12/12 [==============================] - 0s 583us/step - loss: 1.0848 - accuracy: 0.4118\n",
      "Epoch 176/300\n",
      "12/12 [==============================] - 0s 583us/step - loss: 1.0850 - accuracy: 0.4118\n",
      "Epoch 177/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12/12 [==============================] - 0s 667us/step - loss: 1.0840 - accuracy: 0.4118\n",
      "Epoch 178/300\n",
      "12/12 [==============================] - 0s 583us/step - loss: 1.0849 - accuracy: 0.4118\n",
      "Epoch 179/300\n",
      "12/12 [==============================] - 0s 667us/step - loss: 1.0843 - accuracy: 0.4118\n",
      "Epoch 180/300\n",
      "12/12 [==============================] - 0s 667us/step - loss: 1.0847 - accuracy: 0.4118\n",
      "Epoch 181/300\n",
      "12/12 [==============================] - 0s 581us/step - loss: 1.0859 - accuracy: 0.4118\n",
      "Epoch 182/300\n",
      "12/12 [==============================] - 0s 624us/step - loss: 1.0849 - accuracy: 0.4118\n",
      "Epoch 183/300\n",
      "12/12 [==============================] - 0s 665us/step - loss: 1.0860 - accuracy: 0.4118\n",
      "Epoch 184/300\n",
      "12/12 [==============================] - 0s 586us/step - loss: 1.0853 - accuracy: 0.4118\n",
      "Epoch 185/300\n",
      "12/12 [==============================] - 0s 583us/step - loss: 1.0854 - accuracy: 0.4118\n",
      "Epoch 186/300\n",
      "12/12 [==============================] - 0s 583us/step - loss: 1.0857 - accuracy: 0.4118\n",
      "Epoch 187/300\n",
      "12/12 [==============================] - 0s 667us/step - loss: 1.0843 - accuracy: 0.4118\n",
      "Epoch 188/300\n",
      "12/12 [==============================] - 0s 581us/step - loss: 1.0854 - accuracy: 0.4118\n",
      "Epoch 189/300\n",
      "12/12 [==============================] - 0s 583us/step - loss: 1.0850 - accuracy: 0.4118\n",
      "Epoch 190/300\n",
      "12/12 [==============================] - 0s 583us/step - loss: 1.0842 - accuracy: 0.4118\n",
      "Epoch 191/300\n",
      "12/12 [==============================] - 0s 585us/step - loss: 1.0852 - accuracy: 0.4118\n",
      "Epoch 192/300\n",
      "12/12 [==============================] - 0s 750us/step - loss: 1.0839 - accuracy: 0.4118\n",
      "Epoch 193/300\n",
      "12/12 [==============================] - 0s 580us/step - loss: 1.0849 - accuracy: 0.4118\n",
      "Epoch 194/300\n",
      "12/12 [==============================] - 0s 586us/step - loss: 1.0841 - accuracy: 0.4118\n",
      "Epoch 195/300\n",
      "12/12 [==============================] - 0s 583us/step - loss: 1.0846 - accuracy: 0.4118\n",
      "Epoch 196/300\n",
      "12/12 [==============================] - 0s 664us/step - loss: 1.0850 - accuracy: 0.4118\n",
      "Epoch 197/300\n",
      "12/12 [==============================] - 0s 664us/step - loss: 1.0842 - accuracy: 0.4118\n",
      "Epoch 198/300\n",
      "12/12 [==============================] - 0s 583us/step - loss: 1.0843 - accuracy: 0.4118\n",
      "Epoch 199/300\n",
      "12/12 [==============================] - 0s 665us/step - loss: 1.0858 - accuracy: 0.4118\n",
      "Epoch 200/300\n",
      "12/12 [==============================] - 0s 500us/step - loss: 1.0851 - accuracy: 0.4118\n",
      "Epoch 201/300\n",
      "12/12 [==============================] - 0s 668us/step - loss: 1.0841 - accuracy: 0.4118\n",
      "Epoch 202/300\n",
      "12/12 [==============================] - 0s 583us/step - loss: 1.0846 - accuracy: 0.4118\n",
      "Epoch 203/300\n",
      "12/12 [==============================] - 0s 586us/step - loss: 1.0846 - accuracy: 0.4118\n",
      "Epoch 204/300\n",
      "12/12 [==============================] - 0s 583us/step - loss: 1.0844 - accuracy: 0.4118\n",
      "Epoch 205/300\n",
      "12/12 [==============================] - 0s 585us/step - loss: 1.0857 - accuracy: 0.4118\n",
      "Epoch 206/300\n",
      "12/12 [==============================] - 0s 583us/step - loss: 1.0844 - accuracy: 0.4118\n",
      "Epoch 207/300\n",
      "12/12 [==============================] - 0s 584us/step - loss: 1.0846 - accuracy: 0.4118\n",
      "Epoch 208/300\n",
      "12/12 [==============================] - 0s 667us/step - loss: 1.0870 - accuracy: 0.4118\n",
      "Epoch 209/300\n",
      "12/12 [==============================] - 0s 583us/step - loss: 1.0862 - accuracy: 0.4118\n",
      "Epoch 210/300\n",
      "12/12 [==============================] - 0s 585us/step - loss: 1.0849 - accuracy: 0.4118\n",
      "Epoch 211/300\n",
      "12/12 [==============================] - 0s 665us/step - loss: 1.0846 - accuracy: 0.4118\n",
      "Epoch 212/300\n",
      "12/12 [==============================] - 0s 583us/step - loss: 1.0847 - accuracy: 0.4118\n",
      "Epoch 213/300\n",
      "12/12 [==============================] - 0s 750us/step - loss: 1.0857 - accuracy: 0.4118\n",
      "Epoch 214/300\n",
      "12/12 [==============================] - 0s 500us/step - loss: 1.0851 - accuracy: 0.4118\n",
      "Epoch 215/300\n",
      "12/12 [==============================] - 0s 581us/step - loss: 1.0847 - accuracy: 0.4118\n",
      "Epoch 216/300\n",
      "12/12 [==============================] - 0s 583us/step - loss: 1.0857 - accuracy: 0.4118\n",
      "Epoch 217/300\n",
      "12/12 [==============================] - 0s 586us/step - loss: 1.0844 - accuracy: 0.4118\n",
      "Epoch 218/300\n",
      "12/12 [==============================] - 0s 583us/step - loss: 1.0853 - accuracy: 0.4118\n",
      "Epoch 219/300\n",
      "12/12 [==============================] - 0s 583us/step - loss: 1.0852 - accuracy: 0.4118\n",
      "Epoch 220/300\n",
      "12/12 [==============================] - 0s 581us/step - loss: 1.0853 - accuracy: 0.4118\n",
      "Epoch 221/300\n",
      "12/12 [==============================] - 0s 665us/step - loss: 1.0845 - accuracy: 0.4118\n",
      "Epoch 222/300\n",
      "12/12 [==============================] - 0s 669us/step - loss: 1.0851 - accuracy: 0.4118\n",
      "Epoch 223/300\n",
      "12/12 [==============================] - 0s 667us/step - loss: 1.0871 - accuracy: 0.4118\n",
      "Epoch 224/300\n",
      "12/12 [==============================] - 0s 583us/step - loss: 1.0846 - accuracy: 0.4118\n",
      "Epoch 225/300\n",
      "12/12 [==============================] - 0s 667us/step - loss: 1.0841 - accuracy: 0.4118\n",
      "Epoch 226/300\n",
      "12/12 [==============================] - 0s 581us/step - loss: 1.0838 - accuracy: 0.4118\n",
      "Epoch 227/300\n",
      "12/12 [==============================] - 0s 664us/step - loss: 1.0848 - accuracy: 0.4118\n",
      "Epoch 228/300\n",
      "12/12 [==============================] - 0s 581us/step - loss: 1.0850 - accuracy: 0.4118\n",
      "Epoch 229/300\n",
      "12/12 [==============================] - 0s 583us/step - loss: 1.0844 - accuracy: 0.4118\n",
      "Epoch 230/300\n",
      "12/12 [==============================] - 0s 666us/step - loss: 1.0857 - accuracy: 0.4118\n",
      "Epoch 231/300\n",
      "12/12 [==============================] - 0s 583us/step - loss: 1.0850 - accuracy: 0.4118\n",
      "Epoch 232/300\n",
      "12/12 [==============================] - 0s 665us/step - loss: 1.0858 - accuracy: 0.4118\n",
      "Epoch 233/300\n",
      "12/12 [==============================] - 0s 583us/step - loss: 1.0855 - accuracy: 0.4118\n",
      "Epoch 234/300\n",
      "12/12 [==============================] - 0s 584us/step - loss: 1.0863 - accuracy: 0.4118\n",
      "Epoch 235/300\n",
      "12/12 [==============================] - 0s 667us/step - loss: 1.0841 - accuracy: 0.4118\n",
      "Epoch 236/300\n",
      "12/12 [==============================] - 0s 586us/step - loss: 1.0865 - accuracy: 0.4118\n",
      "Epoch 237/300\n",
      "12/12 [==============================] - 0s 583us/step - loss: 1.0857 - accuracy: 0.4118\n",
      "Epoch 238/300\n",
      "12/12 [==============================] - 0s 583us/step - loss: 1.0840 - accuracy: 0.4118\n",
      "Epoch 239/300\n",
      "12/12 [==============================] - 0s 665us/step - loss: 1.0851 - accuracy: 0.4118\n",
      "Epoch 240/300\n",
      "12/12 [==============================] - 0s 665us/step - loss: 1.0841 - accuracy: 0.4118\n",
      "Epoch 241/300\n",
      "12/12 [==============================] - 0s 581us/step - loss: 1.0840 - accuracy: 0.4118\n",
      "Epoch 242/300\n",
      "12/12 [==============================] - 0s 606us/step - loss: 1.0861 - accuracy: 0.4118\n",
      "Epoch 243/300\n",
      "12/12 [==============================] - 0s 582us/step - loss: 1.0841 - accuracy: 0.4118\n",
      "Epoch 244/300\n",
      "12/12 [==============================] - 0s 583us/step - loss: 1.0855 - accuracy: 0.4118\n",
      "Epoch 245/300\n",
      "12/12 [==============================] - 0s 580us/step - loss: 1.0845 - accuracy: 0.4118\n",
      "Epoch 246/300\n",
      "12/12 [==============================] - 0s 669us/step - loss: 1.0859 - accuracy: 0.4118\n",
      "Epoch 247/300\n",
      "12/12 [==============================] - 0s 583us/step - loss: 1.0860 - accuracy: 0.4118\n",
      "Epoch 248/300\n",
      "12/12 [==============================] - 0s 583us/step - loss: 1.0839 - accuracy: 0.4118\n",
      "Epoch 249/300\n",
      "12/12 [==============================] - 0s 583us/step - loss: 1.0846 - accuracy: 0.4118\n",
      "Epoch 250/300\n",
      "12/12 [==============================] - 0s 583us/step - loss: 1.0850 - accuracy: 0.4118\n",
      "Epoch 251/300\n",
      "12/12 [==============================] - 0s 586us/step - loss: 1.0862 - accuracy: 0.4118\n",
      "Epoch 252/300\n",
      "12/12 [==============================] - 0s 584us/step - loss: 1.0846 - accuracy: 0.4118\n",
      "Epoch 253/300\n",
      "12/12 [==============================] - 0s 586us/step - loss: 1.0847 - accuracy: 0.4118\n",
      "Epoch 254/300\n",
      "12/12 [==============================] - 0s 664us/step - loss: 1.0843 - accuracy: 0.4118\n",
      "Epoch 255/300\n",
      "12/12 [==============================] - 0s 584us/step - loss: 1.0849 - accuracy: 0.4118\n",
      "Epoch 256/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12/12 [==============================] - 0s 667us/step - loss: 1.0841 - accuracy: 0.4118\n",
      "Epoch 257/300\n",
      "12/12 [==============================] - 0s 583us/step - loss: 1.0854 - accuracy: 0.4118\n",
      "Epoch 258/300\n",
      "12/12 [==============================] - 0s 583us/step - loss: 1.0850 - accuracy: 0.4118\n",
      "Epoch 259/300\n",
      "12/12 [==============================] - 0s 667us/step - loss: 1.0850 - accuracy: 0.4118\n",
      "Epoch 260/300\n",
      "12/12 [==============================] - 0s 583us/step - loss: 1.0850 - accuracy: 0.4118\n",
      "Epoch 261/300\n",
      "12/12 [==============================] - 0s 585us/step - loss: 1.0857 - accuracy: 0.4118\n",
      "Epoch 262/300\n",
      "12/12 [==============================] - 0s 667us/step - loss: 1.0862 - accuracy: 0.4118\n",
      "Epoch 263/300\n",
      "12/12 [==============================] - 0s 583us/step - loss: 1.0839 - accuracy: 0.4118\n",
      "Epoch 264/300\n",
      "12/12 [==============================] - 0s 583us/step - loss: 1.0851 - accuracy: 0.4118\n",
      "Epoch 265/300\n",
      "12/12 [==============================] - 0s 499us/step - loss: 1.0848 - accuracy: 0.4118\n",
      "Epoch 266/300\n",
      "12/12 [==============================] - 0s 592us/step - loss: 1.0847 - accuracy: 0.4118\n",
      "Epoch 267/300\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 1.0846 - accuracy: 0.4118\n",
      "Epoch 268/300\n",
      "12/12 [==============================] - 0s 667us/step - loss: 1.0840 - accuracy: 0.4118\n",
      "Epoch 269/300\n",
      "12/12 [==============================] - 0s 667us/step - loss: 1.0859 - accuracy: 0.4118\n",
      "Epoch 270/300\n",
      "12/12 [==============================] - 0s 666us/step - loss: 1.0846 - accuracy: 0.4118\n",
      "Epoch 271/300\n",
      "12/12 [==============================] - 0s 583us/step - loss: 1.0850 - accuracy: 0.4118\n",
      "Epoch 272/300\n",
      "12/12 [==============================] - 0s 586us/step - loss: 1.0845 - accuracy: 0.4118\n",
      "Epoch 273/300\n",
      "12/12 [==============================] - 0s 500us/step - loss: 1.0858 - accuracy: 0.4118\n",
      "Epoch 274/300\n",
      "12/12 [==============================] - 0s 667us/step - loss: 1.0871 - accuracy: 0.4118\n",
      "Epoch 275/300\n",
      "12/12 [==============================] - 0s 586us/step - loss: 1.0841 - accuracy: 0.4118\n",
      "Epoch 276/300\n",
      "12/12 [==============================] - 0s 581us/step - loss: 1.0844 - accuracy: 0.4118\n",
      "Epoch 277/300\n",
      "12/12 [==============================] - 0s 667us/step - loss: 1.0845 - accuracy: 0.4118\n",
      "Epoch 278/300\n",
      "12/12 [==============================] - 0s 500us/step - loss: 1.0843 - accuracy: 0.4118\n",
      "Epoch 279/300\n",
      "12/12 [==============================] - 0s 586us/step - loss: 1.0857 - accuracy: 0.4118\n",
      "Epoch 280/300\n",
      "12/12 [==============================] - 0s 583us/step - loss: 1.0860 - accuracy: 0.4118\n",
      "Epoch 281/300\n",
      "12/12 [==============================] - 0s 585us/step - loss: 1.0848 - accuracy: 0.4118\n",
      "Epoch 282/300\n",
      "12/12 [==============================] - 0s 664us/step - loss: 1.0850 - accuracy: 0.4118\n",
      "Epoch 283/300\n",
      "12/12 [==============================] - 0s 500us/step - loss: 1.0851 - accuracy: 0.4118\n",
      "Epoch 284/300\n",
      "12/12 [==============================] - 0s 669us/step - loss: 1.0843 - accuracy: 0.4118\n",
      "Epoch 285/300\n",
      "12/12 [==============================] - 0s 581us/step - loss: 1.0844 - accuracy: 0.4118\n",
      "Epoch 286/300\n",
      "12/12 [==============================] - 0s 586us/step - loss: 1.0839 - accuracy: 0.4118\n",
      "Epoch 287/300\n",
      "12/12 [==============================] - 0s 585us/step - loss: 1.0840 - accuracy: 0.4118\n",
      "Epoch 288/300\n",
      "12/12 [==============================] - 0s 583us/step - loss: 1.0855 - accuracy: 0.4118\n",
      "Epoch 289/300\n",
      "12/12 [==============================] - 0s 664us/step - loss: 1.0845 - accuracy: 0.4118\n",
      "Epoch 290/300\n",
      "12/12 [==============================] - 0s 581us/step - loss: 1.0863 - accuracy: 0.4118\n",
      "Epoch 291/300\n",
      "12/12 [==============================] - 0s 667us/step - loss: 1.0844 - accuracy: 0.4118\n",
      "Epoch 292/300\n",
      "12/12 [==============================] - 0s 586us/step - loss: 1.0837 - accuracy: 0.4118\n",
      "Epoch 293/300\n",
      "12/12 [==============================] - 0s 583us/step - loss: 1.0852 - accuracy: 0.4118\n",
      "Epoch 294/300\n",
      "12/12 [==============================] - 0s 667us/step - loss: 1.0844 - accuracy: 0.4118\n",
      "Epoch 295/300\n",
      "12/12 [==============================] - 0s 585us/step - loss: 1.0838 - accuracy: 0.4118\n",
      "Epoch 296/300\n",
      "12/12 [==============================] - 0s 664us/step - loss: 1.0847 - accuracy: 0.4118\n",
      "Epoch 297/300\n",
      "12/12 [==============================] - 0s 583us/step - loss: 1.0850 - accuracy: 0.4118\n",
      "Epoch 298/300\n",
      "12/12 [==============================] - 0s 583us/step - loss: 1.0856 - accuracy: 0.4118\n",
      "Epoch 299/300\n",
      "12/12 [==============================] - 0s 669us/step - loss: 1.0862 - accuracy: 0.4118\n",
      "Epoch 300/300\n",
      "12/12 [==============================] - 0s 584us/step - loss: 1.0841 - accuracy: 0.4118\n",
      "Epoch 1/300\n",
      "12/12 [==============================] - 0s 583us/step - loss: 1.1132 - accuracy: 0.3697\n",
      "Epoch 2/300\n",
      "12/12 [==============================] - 0s 583us/step - loss: 1.0909 - accuracy: 0.4118\n",
      "Epoch 3/300\n",
      "12/12 [==============================] - 0s 585us/step - loss: 1.0850 - accuracy: 0.4118\n",
      "Epoch 4/300\n",
      "12/12 [==============================] - 0s 583us/step - loss: 1.0842 - accuracy: 0.4118\n",
      "Epoch 5/300\n",
      "12/12 [==============================] - 0s 564us/step - loss: 1.0859 - accuracy: 0.4118\n",
      "Epoch 6/300\n",
      "12/12 [==============================] - 0s 581us/step - loss: 1.0863 - accuracy: 0.4118\n",
      "Epoch 7/300\n",
      "12/12 [==============================] - 0s 586us/step - loss: 1.0857 - accuracy: 0.4118\n",
      "Epoch 8/300\n",
      "12/12 [==============================] - 0s 583us/step - loss: 1.0840 - accuracy: 0.4118\n",
      "Epoch 9/300\n",
      "12/12 [==============================] - 0s 583us/step - loss: 1.0862 - accuracy: 0.4118\n",
      "Epoch 10/300\n",
      "12/12 [==============================] - 0s 583us/step - loss: 1.0863 - accuracy: 0.4118\n",
      "Epoch 11/300\n",
      "12/12 [==============================] - 0s 583us/step - loss: 1.0874 - accuracy: 0.4118\n",
      "Epoch 12/300\n",
      "12/12 [==============================] - 0s 667us/step - loss: 1.0856 - accuracy: 0.4118\n",
      "Epoch 13/300\n",
      "12/12 [==============================] - 0s 667us/step - loss: 1.0854 - accuracy: 0.4118\n",
      "Epoch 14/300\n",
      "12/12 [==============================] - 0s 583us/step - loss: 1.0840 - accuracy: 0.4118\n",
      "Epoch 15/300\n",
      "12/12 [==============================] - 0s 583us/step - loss: 1.0849 - accuracy: 0.4118\n",
      "Epoch 16/300\n",
      "12/12 [==============================] - 0s 583us/step - loss: 1.0849 - accuracy: 0.4118\n",
      "Epoch 17/300\n",
      "12/12 [==============================] - 0s 583us/step - loss: 1.0873 - accuracy: 0.4118\n",
      "Epoch 18/300\n",
      "12/12 [==============================] - 0s 583us/step - loss: 1.0875 - accuracy: 0.4118\n",
      "Epoch 19/300\n",
      "12/12 [==============================] - 0s 583us/step - loss: 1.0859 - accuracy: 0.4118\n",
      "Epoch 20/300\n",
      "12/12 [==============================] - 0s 583us/step - loss: 1.0872 - accuracy: 0.4118\n",
      "Epoch 21/300\n",
      "12/12 [==============================] - 0s 667us/step - loss: 1.0865 - accuracy: 0.4118\n",
      "Epoch 22/300\n",
      "12/12 [==============================] - 0s 667us/step - loss: 1.0843 - accuracy: 0.4118\n",
      "Epoch 23/300\n",
      "12/12 [==============================] - 0s 583us/step - loss: 1.0841 - accuracy: 0.4118\n",
      "Epoch 24/300\n",
      "12/12 [==============================] - 0s 585us/step - loss: 1.0868 - accuracy: 0.4118\n",
      "Epoch 25/300\n",
      "12/12 [==============================] - 0s 599us/step - loss: 1.0860 - accuracy: 0.4118\n",
      "Epoch 26/300\n",
      "12/12 [==============================] - 0s 585us/step - loss: 1.0853 - accuracy: 0.4118\n",
      "Epoch 27/300\n",
      "12/12 [==============================] - 0s 582us/step - loss: 1.0860 - accuracy: 0.4118\n",
      "Epoch 28/300\n",
      "12/12 [==============================] - 0s 502us/step - loss: 1.0869 - accuracy: 0.4118\n",
      "Epoch 29/300\n",
      "12/12 [==============================] - 0s 584us/step - loss: 1.0848 - accuracy: 0.4118\n",
      "Epoch 30/300\n",
      "12/12 [==============================] - 0s 583us/step - loss: 1.0842 - accuracy: 0.4118\n",
      "Epoch 31/300\n",
      "12/12 [==============================] - 0s 586us/step - loss: 1.0844 - accuracy: 0.4118\n",
      "Epoch 32/300\n",
      "12/12 [==============================] - 0s 583us/step - loss: 1.0840 - accuracy: 0.4118\n",
      "Epoch 33/300\n",
      "12/12 [==============================] - 0s 586us/step - loss: 1.0854 - accuracy: 0.4118\n",
      "Epoch 34/300\n",
      "12/12 [==============================] - 0s 667us/step - loss: 1.0849 - accuracy: 0.4118\n",
      "Epoch 35/300\n",
      "12/12 [==============================] - 0s 583us/step - loss: 1.0846 - accuracy: 0.4118\n",
      "Epoch 36/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12/12 [==============================] - 0s 667us/step - loss: 1.0843 - accuracy: 0.4118\n",
      "Epoch 37/300\n",
      "12/12 [==============================] - 0s 583us/step - loss: 1.0840 - accuracy: 0.4118\n",
      "Epoch 38/300\n",
      "12/12 [==============================] - 0s 583us/step - loss: 1.0849 - accuracy: 0.4118\n",
      "Epoch 39/300\n",
      "12/12 [==============================] - 0s 626us/step - loss: 1.0863 - accuracy: 0.4118\n",
      "Epoch 40/300\n",
      "12/12 [==============================] - 0s 583us/step - loss: 1.0840 - accuracy: 0.4118\n",
      "Epoch 41/300\n",
      "12/12 [==============================] - 0s 583us/step - loss: 1.0854 - accuracy: 0.4118\n",
      "Epoch 42/300\n",
      "12/12 [==============================] - 0s 583us/step - loss: 1.0847 - accuracy: 0.4118\n",
      "Epoch 43/300\n",
      "12/12 [==============================] - 0s 666us/step - loss: 1.0854 - accuracy: 0.4118\n",
      "Epoch 44/300\n",
      "12/12 [==============================] - 0s 583us/step - loss: 1.0844 - accuracy: 0.4118\n",
      "Epoch 45/300\n",
      "12/12 [==============================] - 0s 583us/step - loss: 1.0866 - accuracy: 0.4118\n",
      "Epoch 46/300\n",
      "12/12 [==============================] - 0s 750us/step - loss: 1.0840 - accuracy: 0.4118\n",
      "Epoch 47/300\n",
      "12/12 [==============================] - 0s 500us/step - loss: 1.0867 - accuracy: 0.4118\n",
      "Epoch 48/300\n",
      "12/12 [==============================] - 0s 583us/step - loss: 1.0847 - accuracy: 0.4118\n",
      "Epoch 49/300\n",
      "12/12 [==============================] - 0s 581us/step - loss: 1.0882 - accuracy: 0.4118\n",
      "Epoch 50/300\n",
      "12/12 [==============================] - 0s 583us/step - loss: 1.0847 - accuracy: 0.4118\n",
      "Epoch 51/300\n",
      "12/12 [==============================] - 0s 586us/step - loss: 1.0847 - accuracy: 0.4118\n",
      "Epoch 52/300\n",
      "12/12 [==============================] - 0s 586us/step - loss: 1.0847 - accuracy: 0.4118\n",
      "Epoch 53/300\n",
      "12/12 [==============================] - 0s 583us/step - loss: 1.0847 - accuracy: 0.4118\n",
      "Epoch 54/300\n",
      "12/12 [==============================] - 0s 583us/step - loss: 1.0846 - accuracy: 0.4118\n",
      "Epoch 55/300\n",
      "12/12 [==============================] - 0s 531us/step - loss: 1.0870 - accuracy: 0.4118\n",
      "Epoch 56/300\n",
      "12/12 [==============================] - 0s 581us/step - loss: 1.0859 - accuracy: 0.4118\n",
      "Epoch 57/300\n",
      "12/12 [==============================] - 0s 585us/step - loss: 1.0860 - accuracy: 0.4118\n",
      "Epoch 58/300\n",
      "12/12 [==============================] - 0s 665us/step - loss: 1.0862 - accuracy: 0.4118\n",
      "Epoch 59/300\n",
      "12/12 [==============================] - 0s 583us/step - loss: 1.0873 - accuracy: 0.4118\n",
      "Epoch 60/300\n",
      "12/12 [==============================] - 0s 585us/step - loss: 1.0858 - accuracy: 0.4118\n",
      "Epoch 61/300\n",
      "12/12 [==============================] - 0s 583us/step - loss: 1.0856 - accuracy: 0.4118\n",
      "Epoch 62/300\n",
      "12/12 [==============================] - 0s 583us/step - loss: 1.0882 - accuracy: 0.4118\n",
      "Epoch 63/300\n",
      "12/12 [==============================] - 0s 585us/step - loss: 1.0840 - accuracy: 0.4118\n",
      "Epoch 64/300\n",
      "12/12 [==============================] - 0s 583us/step - loss: 1.0853 - accuracy: 0.4118\n",
      "Epoch 65/300\n",
      "12/12 [==============================] - 0s 583us/step - loss: 1.0846 - accuracy: 0.4118\n",
      "Epoch 66/300\n",
      "12/12 [==============================] - 0s 498us/step - loss: 1.0864 - accuracy: 0.4118\n",
      "Epoch 67/300\n",
      "12/12 [==============================] - 0s 585us/step - loss: 1.0852 - accuracy: 0.4118\n",
      "Epoch 68/300\n",
      "12/12 [==============================] - 0s 581us/step - loss: 1.0852 - accuracy: 0.4118\n",
      "Epoch 69/300\n",
      "12/12 [==============================] - 0s 664us/step - loss: 1.0855 - accuracy: 0.4118\n",
      "Epoch 70/300\n",
      "12/12 [==============================] - 0s 583us/step - loss: 1.0858 - accuracy: 0.4118\n",
      "Epoch 71/300\n",
      "12/12 [==============================] - 0s 497us/step - loss: 1.0842 - accuracy: 0.4118\n",
      "Epoch 72/300\n",
      "12/12 [==============================] - 0s 582us/step - loss: 1.0849 - accuracy: 0.4118\n",
      "Epoch 73/300\n",
      "12/12 [==============================] - 0s 665us/step - loss: 1.0848 - accuracy: 0.4118\n",
      "Epoch 74/300\n",
      "12/12 [==============================] - 0s 665us/step - loss: 1.0847 - accuracy: 0.4118\n",
      "Epoch 75/300\n",
      "12/12 [==============================] - 0s 583us/step - loss: 1.0842 - accuracy: 0.4118\n",
      "Epoch 76/300\n",
      "12/12 [==============================] - 0s 583us/step - loss: 1.0855 - accuracy: 0.4118\n",
      "Epoch 77/300\n",
      "12/12 [==============================] - 0s 500us/step - loss: 1.0862 - accuracy: 0.4118\n",
      "Epoch 78/300\n",
      "12/12 [==============================] - 0s 583us/step - loss: 1.0863 - accuracy: 0.4118\n",
      "Epoch 79/300\n",
      "12/12 [==============================] - 0s 667us/step - loss: 1.0855 - accuracy: 0.4118\n",
      "Epoch 80/300\n",
      "12/12 [==============================] - 0s 583us/step - loss: 1.0868 - accuracy: 0.4118\n",
      "Epoch 81/300\n",
      "12/12 [==============================] - 0s 585us/step - loss: 1.0865 - accuracy: 0.4118\n",
      "Epoch 82/300\n",
      "12/12 [==============================] - 0s 500us/step - loss: 1.0862 - accuracy: 0.4118\n",
      "Epoch 83/300\n",
      "12/12 [==============================] - 0s 585us/step - loss: 1.0873 - accuracy: 0.4118\n",
      "Epoch 84/300\n",
      "12/12 [==============================] - 0s 583us/step - loss: 1.0860 - accuracy: 0.4118\n",
      "Epoch 85/300\n",
      "12/12 [==============================] - 0s 585us/step - loss: 1.0854 - accuracy: 0.4118\n",
      "Epoch 86/300\n",
      "12/12 [==============================] - 0s 667us/step - loss: 1.0850 - accuracy: 0.4118\n",
      "Epoch 87/300\n",
      "12/12 [==============================] - 0s 500us/step - loss: 1.0859 - accuracy: 0.4118\n",
      "Epoch 88/300\n",
      "12/12 [==============================] - 0s 586us/step - loss: 1.0864 - accuracy: 0.4118\n",
      "Epoch 89/300\n",
      "12/12 [==============================] - 0s 583us/step - loss: 1.0859 - accuracy: 0.4118\n",
      "Epoch 90/300\n",
      "12/12 [==============================] - 0s 667us/step - loss: 1.0904 - accuracy: 0.4118\n",
      "Epoch 91/300\n",
      "12/12 [==============================] - 0s 583us/step - loss: 1.0846 - accuracy: 0.4118\n",
      "Epoch 92/300\n",
      "12/12 [==============================] - 0s 585us/step - loss: 1.0846 - accuracy: 0.4118\n",
      "Epoch 93/300\n",
      "12/12 [==============================] - 0s 667us/step - loss: 1.0854 - accuracy: 0.4118\n",
      "Epoch 94/300\n",
      "12/12 [==============================] - 0s 583us/step - loss: 1.0843 - accuracy: 0.4118\n",
      "Epoch 95/300\n",
      "12/12 [==============================] - 0s 583us/step - loss: 1.0858 - accuracy: 0.4118\n",
      "Epoch 96/300\n",
      "12/12 [==============================] - 0s 627us/step - loss: 1.0864 - accuracy: 0.4118\n",
      "Epoch 97/300\n",
      "12/12 [==============================] - 0s 667us/step - loss: 1.0849 - accuracy: 0.4118\n",
      "Epoch 98/300\n",
      "12/12 [==============================] - 0s 583us/step - loss: 1.0853 - accuracy: 0.4118\n",
      "Epoch 99/300\n",
      "12/12 [==============================] - 0s 586us/step - loss: 1.0872 - accuracy: 0.4118\n",
      "Epoch 100/300\n",
      "12/12 [==============================] - 0s 669us/step - loss: 1.0853 - accuracy: 0.4118\n",
      "Epoch 101/300\n",
      "12/12 [==============================] - 0s 584us/step - loss: 1.0866 - accuracy: 0.4118\n",
      "Epoch 102/300\n",
      "12/12 [==============================] - 0s 583us/step - loss: 1.0853 - accuracy: 0.4118\n",
      "Epoch 103/300\n",
      "12/12 [==============================] - 0s 665us/step - loss: 1.0847 - accuracy: 0.4118\n",
      "Epoch 104/300\n",
      "12/12 [==============================] - 0s 586us/step - loss: 1.0887 - accuracy: 0.4118\n",
      "Epoch 105/300\n",
      "12/12 [==============================] - 0s 666us/step - loss: 1.0835 - accuracy: 0.4118\n",
      "Epoch 106/300\n",
      "12/12 [==============================] - 0s 585us/step - loss: 1.0858 - accuracy: 0.4118\n",
      "Epoch 107/300\n",
      "12/12 [==============================] - 0s 667us/step - loss: 1.0854 - accuracy: 0.4118\n",
      "Epoch 108/300\n",
      "12/12 [==============================] - 0s 581us/step - loss: 1.0851 - accuracy: 0.4118\n",
      "Epoch 109/300\n",
      "12/12 [==============================] - 0s 665us/step - loss: 1.0860 - accuracy: 0.4118\n",
      "Epoch 110/300\n",
      "12/12 [==============================] - 0s 584us/step - loss: 1.0837 - accuracy: 0.4118\n",
      "Epoch 111/300\n",
      "12/12 [==============================] - 0s 583us/step - loss: 1.0864 - accuracy: 0.4118\n",
      "Epoch 112/300\n",
      "12/12 [==============================] - 0s 583us/step - loss: 1.0865 - accuracy: 0.4118\n",
      "Epoch 113/300\n",
      "12/12 [==============================] - 0s 583us/step - loss: 1.0847 - accuracy: 0.4118\n",
      "Epoch 114/300\n",
      "12/12 [==============================] - 0s 583us/step - loss: 1.0856 - accuracy: 0.4118\n",
      "Epoch 115/300\n",
      "12/12 [==============================] - 0s 581us/step - loss: 1.0863 - accuracy: 0.4118\n",
      "Epoch 116/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12/12 [==============================] - 0s 664us/step - loss: 1.0848 - accuracy: 0.4118\n",
      "Epoch 117/300\n",
      "12/12 [==============================] - 0s 583us/step - loss: 1.0852 - accuracy: 0.4118\n",
      "Epoch 118/300\n",
      "12/12 [==============================] - 0s 667us/step - loss: 1.0853 - accuracy: 0.4118\n",
      "Epoch 119/300\n",
      "12/12 [==============================] - 0s 667us/step - loss: 1.0844 - accuracy: 0.4118\n",
      "Epoch 120/300\n",
      "12/12 [==============================] - 0s 581us/step - loss: 1.0857 - accuracy: 0.4118\n",
      "Epoch 121/300\n",
      "12/12 [==============================] - 0s 583us/step - loss: 1.0846 - accuracy: 0.4118\n",
      "Epoch 122/300\n",
      "12/12 [==============================] - 0s 667us/step - loss: 1.0864 - accuracy: 0.4118\n",
      "Epoch 123/300\n",
      "12/12 [==============================] - 0s 500us/step - loss: 1.0843 - accuracy: 0.4118\n",
      "Epoch 124/300\n",
      "12/12 [==============================] - 0s 669us/step - loss: 1.0856 - accuracy: 0.4118\n",
      "Epoch 125/300\n",
      "12/12 [==============================] - 0s 583us/step - loss: 1.0842 - accuracy: 0.4118\n",
      "Epoch 126/300\n",
      "12/12 [==============================] - 0s 583us/step - loss: 1.0864 - accuracy: 0.4118\n",
      "Epoch 127/300\n",
      "12/12 [==============================] - 0s 583us/step - loss: 1.0841 - accuracy: 0.4118\n",
      "Epoch 128/300\n",
      "12/12 [==============================] - 0s 583us/step - loss: 1.0853 - accuracy: 0.4118\n",
      "Epoch 129/300\n",
      "12/12 [==============================] - 0s 750us/step - loss: 1.0852 - accuracy: 0.4118\n",
      "Epoch 130/300\n",
      "12/12 [==============================] - 0s 500us/step - loss: 1.0852 - accuracy: 0.4118\n",
      "Epoch 131/300\n",
      "12/12 [==============================] - 0s 583us/step - loss: 1.0850 - accuracy: 0.4118\n",
      "Epoch 132/300\n",
      "12/12 [==============================] - 0s 583us/step - loss: 1.0859 - accuracy: 0.4118\n",
      "Epoch 133/300\n",
      "12/12 [==============================] - 0s 669us/step - loss: 1.0837 - accuracy: 0.4118\n",
      "Epoch 134/300\n",
      "12/12 [==============================] - 0s 585us/step - loss: 1.0879 - accuracy: 0.4118\n",
      "Epoch 135/300\n",
      "12/12 [==============================] - 0s 581us/step - loss: 1.0886 - accuracy: 0.4118\n",
      "Epoch 136/300\n",
      "12/12 [==============================] - 0s 500us/step - loss: 1.0854 - accuracy: 0.4118\n",
      "Epoch 137/300\n",
      "12/12 [==============================] - 0s 583us/step - loss: 1.0859 - accuracy: 0.4118\n",
      "Epoch 138/300\n",
      "12/12 [==============================] - 0s 629us/step - loss: 1.0851 - accuracy: 0.4118\n",
      "Epoch 139/300\n",
      "12/12 [==============================] - 0s 667us/step - loss: 1.0844 - accuracy: 0.4118\n",
      "Epoch 140/300\n",
      "12/12 [==============================] - 0s 583us/step - loss: 1.0855 - accuracy: 0.4118\n",
      "Epoch 141/300\n",
      "12/12 [==============================] - 0s 585us/step - loss: 1.0856 - accuracy: 0.4118\n",
      "Epoch 142/300\n",
      "12/12 [==============================] - 0s 581us/step - loss: 1.0844 - accuracy: 0.4118\n",
      "Epoch 143/300\n",
      "12/12 [==============================] - 0s 502us/step - loss: 1.0861 - accuracy: 0.4118\n",
      "Epoch 144/300\n",
      "12/12 [==============================] - 0s 584us/step - loss: 1.0853 - accuracy: 0.4118\n",
      "Epoch 145/300\n",
      "12/12 [==============================] - 0s 585us/step - loss: 1.0855 - accuracy: 0.4118\n",
      "Epoch 146/300\n",
      "12/12 [==============================] - 0s 583us/step - loss: 1.0853 - accuracy: 0.4118\n",
      "Epoch 147/300\n",
      "12/12 [==============================] - 0s 667us/step - loss: 1.0861 - accuracy: 0.4118\n",
      "Epoch 148/300\n",
      "12/12 [==============================] - 0s 748us/step - loss: 1.0857 - accuracy: 0.4118\n",
      "Epoch 149/300\n",
      "12/12 [==============================] - 0s 500us/step - loss: 1.0866 - accuracy: 0.4118\n",
      "Epoch 150/300\n",
      "12/12 [==============================] - 0s 583us/step - loss: 1.0849 - accuracy: 0.4118\n",
      "Epoch 151/300\n",
      "12/12 [==============================] - 0s 667us/step - loss: 1.0845 - accuracy: 0.4118\n",
      "Epoch 152/300\n",
      "12/12 [==============================] - 0s 667us/step - loss: 1.0842 - accuracy: 0.4118\n",
      "Epoch 153/300\n",
      "12/12 [==============================] - 0s 583us/step - loss: 1.0853 - accuracy: 0.4118\n",
      "Epoch 154/300\n",
      "12/12 [==============================] - 0s 502us/step - loss: 1.0856 - accuracy: 0.4118\n",
      "Epoch 155/300\n",
      "12/12 [==============================] - 0s 567us/step - loss: 1.0854 - accuracy: 0.4118\n",
      "Epoch 156/300\n",
      "12/12 [==============================] - 0s 583us/step - loss: 1.0847 - accuracy: 0.4118\n",
      "Epoch 157/300\n",
      "12/12 [==============================] - 0s 667us/step - loss: 1.0881 - accuracy: 0.4118\n",
      "Epoch 158/300\n",
      "12/12 [==============================] - 0s 586us/step - loss: 1.0908 - accuracy: 0.4118\n",
      "Epoch 159/300\n",
      "12/12 [==============================] - 0s 583us/step - loss: 1.0863 - accuracy: 0.4118\n",
      "Epoch 160/300\n",
      "12/12 [==============================] - 0s 583us/step - loss: 1.0851 - accuracy: 0.4118\n",
      "Epoch 161/300\n",
      "12/12 [==============================] - 0s 583us/step - loss: 1.0864 - accuracy: 0.4118\n",
      "Epoch 162/300\n",
      "12/12 [==============================] - 0s 585us/step - loss: 1.0874 - accuracy: 0.4118\n",
      "Epoch 163/300\n",
      "12/12 [==============================] - 0s 581us/step - loss: 1.0842 - accuracy: 0.4118\n",
      "Epoch 164/300\n",
      "12/12 [==============================] - 0s 585us/step - loss: 1.0841 - accuracy: 0.4118\n",
      "Epoch 165/300\n",
      "12/12 [==============================] - 0s 585us/step - loss: 1.0854 - accuracy: 0.4118\n",
      "Epoch 166/300\n",
      "12/12 [==============================] - 0s 583us/step - loss: 1.0862 - accuracy: 0.4118\n",
      "Epoch 167/300\n",
      "12/12 [==============================] - 0s 667us/step - loss: 1.0853 - accuracy: 0.4118\n",
      "Epoch 168/300\n",
      "12/12 [==============================] - 0s 583us/step - loss: 1.0853 - accuracy: 0.4118\n",
      "Epoch 169/300\n",
      "12/12 [==============================] - 0s 581us/step - loss: 1.0848 - accuracy: 0.4118\n",
      "Epoch 170/300\n",
      "12/12 [==============================] - 0s 581us/step - loss: 1.0892 - accuracy: 0.4118\n",
      "Epoch 171/300\n",
      "12/12 [==============================] - 0s 643us/step - loss: 1.0846 - accuracy: 0.4118\n",
      "Epoch 172/300\n",
      "12/12 [==============================] - 0s 583us/step - loss: 1.0863 - accuracy: 0.4118\n",
      "Epoch 173/300\n",
      "12/12 [==============================] - 0s 584us/step - loss: 1.0849 - accuracy: 0.4118\n",
      "Epoch 174/300\n",
      "12/12 [==============================] - 0s 586us/step - loss: 1.0841 - accuracy: 0.4118\n",
      "Epoch 175/300\n",
      "12/12 [==============================] - 0s 583us/step - loss: 1.0854 - accuracy: 0.4118\n",
      "Epoch 176/300\n",
      "12/12 [==============================] - 0s 583us/step - loss: 1.0861 - accuracy: 0.4118\n",
      "Epoch 177/300\n",
      "12/12 [==============================] - 0s 586us/step - loss: 1.0847 - accuracy: 0.4118\n",
      "Epoch 178/300\n",
      "12/12 [==============================] - 0s 668us/step - loss: 1.0870 - accuracy: 0.4118\n",
      "Epoch 179/300\n",
      "12/12 [==============================] - 0s 667us/step - loss: 1.0849 - accuracy: 0.4118\n",
      "Epoch 180/300\n",
      "12/12 [==============================] - 0s 583us/step - loss: 1.0852 - accuracy: 0.4118\n",
      "Epoch 181/300\n",
      "12/12 [==============================] - 0s 586us/step - loss: 1.0854 - accuracy: 0.4118\n",
      "Epoch 182/300\n",
      "12/12 [==============================] - 0s 583us/step - loss: 1.0895 - accuracy: 0.4118\n",
      "Epoch 183/300\n",
      "12/12 [==============================] - 0s 583us/step - loss: 1.0845 - accuracy: 0.4118\n",
      "Epoch 184/300\n",
      "12/12 [==============================] - 0s 665us/step - loss: 1.0841 - accuracy: 0.4118\n",
      "Epoch 185/300\n",
      "12/12 [==============================] - 0s 583us/step - loss: 1.0857 - accuracy: 0.4118\n",
      "Epoch 186/300\n",
      "12/12 [==============================] - 0s 583us/step - loss: 1.0844 - accuracy: 0.4118\n",
      "Epoch 187/300\n",
      "12/12 [==============================] - 0s 667us/step - loss: 1.0845 - accuracy: 0.4118\n",
      "Epoch 188/300\n",
      "12/12 [==============================] - 0s 585us/step - loss: 1.0852 - accuracy: 0.4118\n",
      "Epoch 189/300\n",
      "12/12 [==============================] - 0s 581us/step - loss: 1.0854 - accuracy: 0.4118\n",
      "Epoch 190/300\n",
      "12/12 [==============================] - 0s 583us/step - loss: 1.0836 - accuracy: 0.4118\n",
      "Epoch 191/300\n",
      "12/12 [==============================] - 0s 667us/step - loss: 1.0858 - accuracy: 0.4118\n",
      "Epoch 192/300\n",
      "12/12 [==============================] - 0s 500us/step - loss: 1.0861 - accuracy: 0.4118\n",
      "Epoch 193/300\n",
      "12/12 [==============================] - 0s 669us/step - loss: 1.0881 - accuracy: 0.4118\n",
      "Epoch 194/300\n",
      "12/12 [==============================] - 0s 584us/step - loss: 1.0858 - accuracy: 0.4118\n",
      "Epoch 195/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12/12 [==============================] - 0s 583us/step - loss: 1.0853 - accuracy: 0.4118\n",
      "Epoch 196/300\n",
      "12/12 [==============================] - 0s 583us/step - loss: 1.0846 - accuracy: 0.4118\n",
      "Epoch 197/300\n",
      "12/12 [==============================] - 0s 585us/step - loss: 1.0859 - accuracy: 0.4118\n",
      "Epoch 198/300\n",
      "12/12 [==============================] - 0s 583us/step - loss: 1.0853 - accuracy: 0.4118\n",
      "Epoch 199/300\n",
      "12/12 [==============================] - 0s 639us/step - loss: 1.0857 - accuracy: 0.4118\n",
      "Epoch 200/300\n",
      "12/12 [==============================] - 0s 500us/step - loss: 1.0872 - accuracy: 0.4118\n",
      "Epoch 201/300\n",
      "12/12 [==============================] - 0s 665us/step - loss: 1.0895 - accuracy: 0.4118\n",
      "Epoch 202/300\n",
      "12/12 [==============================] - 0s 581us/step - loss: 1.0840 - accuracy: 0.4118\n",
      "Epoch 203/300\n",
      "12/12 [==============================] - 0s 586us/step - loss: 1.0862 - accuracy: 0.4118\n",
      "Epoch 204/300\n",
      "12/12 [==============================] - 0s 583us/step - loss: 1.0888 - accuracy: 0.4118\n",
      "Epoch 205/300\n",
      "12/12 [==============================] - 0s 582us/step - loss: 1.0864 - accuracy: 0.4118\n",
      "Epoch 206/300\n",
      "12/12 [==============================] - 0s 583us/step - loss: 1.0852 - accuracy: 0.4118\n",
      "Epoch 207/300\n",
      "12/12 [==============================] - 0s 583us/step - loss: 1.0850 - accuracy: 0.4118\n",
      "Epoch 208/300\n",
      "12/12 [==============================] - 0s 665us/step - loss: 1.0864 - accuracy: 0.4118\n",
      "Epoch 209/300\n",
      "12/12 [==============================] - 0s 583us/step - loss: 1.0854 - accuracy: 0.4118\n",
      "Epoch 210/300\n",
      "12/12 [==============================] - 0s 748us/step - loss: 1.0858 - accuracy: 0.4118\n",
      "Epoch 211/300\n",
      "12/12 [==============================] - ETA: 0s - loss: 1.0564 - accuracy: 0.40 - 0s 583us/step - loss: 1.0855 - accuracy: 0.4118\n",
      "Epoch 212/300\n",
      "12/12 [==============================] - 0s 643us/step - loss: 1.0863 - accuracy: 0.4118\n",
      "Epoch 213/300\n",
      "12/12 [==============================] - 0s 582us/step - loss: 1.0853 - accuracy: 0.4118\n",
      "Epoch 214/300\n",
      "12/12 [==============================] - 0s 583us/step - loss: 1.0858 - accuracy: 0.4118\n",
      "Epoch 215/300\n",
      "12/12 [==============================] - 0s 583us/step - loss: 1.0844 - accuracy: 0.4118\n",
      "Epoch 216/300\n",
      "12/12 [==============================] - 0s 667us/step - loss: 1.0841 - accuracy: 0.4118\n",
      "Epoch 217/300\n",
      "12/12 [==============================] - 0s 669us/step - loss: 1.0862 - accuracy: 0.4118\n",
      "Epoch 218/300\n",
      "12/12 [==============================] - 0s 667us/step - loss: 1.0875 - accuracy: 0.4118\n",
      "Epoch 219/300\n",
      "12/12 [==============================] - 0s 583us/step - loss: 1.0871 - accuracy: 0.4118\n",
      "Epoch 220/300\n",
      "12/12 [==============================] - 0s 585us/step - loss: 1.0844 - accuracy: 0.4118\n",
      "Epoch 221/300\n",
      "12/12 [==============================] - 0s 583us/step - loss: 1.0839 - accuracy: 0.4118\n",
      "Epoch 222/300\n",
      "12/12 [==============================] - 0s 583us/step - loss: 1.0856 - accuracy: 0.4118\n",
      "Epoch 223/300\n",
      "12/12 [==============================] - 0s 667us/step - loss: 1.0855 - accuracy: 0.4118\n",
      "Epoch 224/300\n",
      "12/12 [==============================] - 0s 667us/step - loss: 1.0854 - accuracy: 0.4118\n",
      "Epoch 225/300\n",
      "12/12 [==============================] - 0s 583us/step - loss: 1.0838 - accuracy: 0.4118\n",
      "Epoch 226/300\n",
      "12/12 [==============================] - 0s 583us/step - loss: 1.0849 - accuracy: 0.4118\n",
      "Epoch 227/300\n",
      "12/12 [==============================] - 0s 583us/step - loss: 1.0846 - accuracy: 0.4118\n",
      "Epoch 228/300\n",
      "12/12 [==============================] - 0s 585us/step - loss: 1.0854 - accuracy: 0.4118\n",
      "Epoch 229/300\n",
      "12/12 [==============================] - 0s 750us/step - loss: 1.0853 - accuracy: 0.4118\n",
      "Epoch 230/300\n",
      "12/12 [==============================] - 0s 585us/step - loss: 1.0872 - accuracy: 0.4118\n",
      "Epoch 231/300\n",
      "12/12 [==============================] - 0s 583us/step - loss: 1.0861 - accuracy: 0.4118\n",
      "Epoch 232/300\n",
      "12/12 [==============================] - 0s 667us/step - loss: 1.0840 - accuracy: 0.4118\n",
      "Epoch 233/300\n",
      "12/12 [==============================] - 0s 502us/step - loss: 1.0873 - accuracy: 0.4118\n",
      "Epoch 234/300\n",
      "12/12 [==============================] - 0s 583us/step - loss: 1.0862 - accuracy: 0.4118\n",
      "Epoch 235/300\n",
      "12/12 [==============================] - 0s 750us/step - loss: 1.0854 - accuracy: 0.4118\n",
      "Epoch 236/300\n",
      "12/12 [==============================] - 0s 583us/step - loss: 1.0846 - accuracy: 0.4118\n",
      "Epoch 237/300\n",
      "12/12 [==============================] - 0s 584us/step - loss: 1.0861 - accuracy: 0.4118\n",
      "Epoch 238/300\n",
      "12/12 [==============================] - 0s 633us/step - loss: 1.0848 - accuracy: 0.4118\n",
      "Epoch 239/300\n",
      "12/12 [==============================] - 0s 583us/step - loss: 1.0849 - accuracy: 0.4118\n",
      "Epoch 240/300\n",
      "12/12 [==============================] - 0s 667us/step - loss: 1.0880 - accuracy: 0.4118\n",
      "Epoch 241/300\n",
      "12/12 [==============================] - 0s 583us/step - loss: 1.0859 - accuracy: 0.4118\n",
      "Epoch 242/300\n",
      "12/12 [==============================] - 0s 665us/step - loss: 1.0864 - accuracy: 0.4118\n",
      "Epoch 243/300\n",
      "12/12 [==============================] - 0s 585us/step - loss: 1.0854 - accuracy: 0.4118\n",
      "Epoch 244/300\n",
      "12/12 [==============================] - 0s 583us/step - loss: 1.0855 - accuracy: 0.4118\n",
      "Epoch 245/300\n",
      "12/12 [==============================] - 0s 664us/step - loss: 1.0846 - accuracy: 0.4118\n",
      "Epoch 246/300\n",
      "12/12 [==============================] - 0s 583us/step - loss: 1.0873 - accuracy: 0.4118\n",
      "Epoch 247/300\n",
      "12/12 [==============================] - 0s 583us/step - loss: 1.0860 - accuracy: 0.4118\n",
      "Epoch 248/300\n",
      "12/12 [==============================] - 0s 583us/step - loss: 1.0854 - accuracy: 0.4118\n",
      "Epoch 249/300\n",
      "12/12 [==============================] - 0s 585us/step - loss: 1.0851 - accuracy: 0.4118\n",
      "Epoch 250/300\n",
      "12/12 [==============================] - 0s 664us/step - loss: 1.0843 - accuracy: 0.4118\n",
      "Epoch 251/300\n",
      "12/12 [==============================] - 0s 583us/step - loss: 1.0859 - accuracy: 0.4118\n",
      "Epoch 252/300\n",
      "12/12 [==============================] - 0s 583us/step - loss: 1.0887 - accuracy: 0.4118\n",
      "Epoch 253/300\n",
      "12/12 [==============================] - 0s 586us/step - loss: 1.0842 - accuracy: 0.4118\n",
      "Epoch 254/300\n",
      "12/12 [==============================] - 0s 583us/step - loss: 1.0869 - accuracy: 0.4118\n",
      "Epoch 255/300\n",
      "12/12 [==============================] - 0s 583us/step - loss: 1.0896 - accuracy: 0.4118\n",
      "Epoch 256/300\n",
      "12/12 [==============================] - 0s 664us/step - loss: 1.0885 - accuracy: 0.4118\n",
      "Epoch 257/300\n",
      "12/12 [==============================] - 0s 664us/step - loss: 1.0849 - accuracy: 0.4118\n",
      "Epoch 258/300\n",
      "12/12 [==============================] - 0s 585us/step - loss: 1.0852 - accuracy: 0.4118\n",
      "Epoch 259/300\n",
      "12/12 [==============================] - 0s 667us/step - loss: 1.0851 - accuracy: 0.4118\n",
      "Epoch 260/300\n",
      "12/12 [==============================] - 0s 583us/step - loss: 1.0845 - accuracy: 0.4118\n",
      "Epoch 261/300\n",
      "12/12 [==============================] - 0s 667us/step - loss: 1.0875 - accuracy: 0.4118\n",
      "Epoch 262/300\n",
      "12/12 [==============================] - 0s 583us/step - loss: 1.0839 - accuracy: 0.4118\n",
      "Epoch 263/300\n",
      "12/12 [==============================] - 0s 581us/step - loss: 1.0864 - accuracy: 0.4118\n",
      "Epoch 264/300\n",
      "12/12 [==============================] - 0s 583us/step - loss: 1.0838 - accuracy: 0.4118\n",
      "Epoch 265/300\n",
      "12/12 [==============================] - 0s 583us/step - loss: 1.0864 - accuracy: 0.4118\n",
      "Epoch 266/300\n",
      "12/12 [==============================] - 0s 583us/step - loss: 1.0842 - accuracy: 0.4118\n",
      "Epoch 267/300\n",
      "12/12 [==============================] - 0s 586us/step - loss: 1.0895 - accuracy: 0.4118\n",
      "Epoch 268/300\n",
      "12/12 [==============================] - 0s 583us/step - loss: 1.0868 - accuracy: 0.4118\n",
      "Epoch 269/300\n",
      "12/12 [==============================] - 0s 667us/step - loss: 1.0859 - accuracy: 0.4118\n",
      "Epoch 270/300\n",
      "12/12 [==============================] - 0s 585us/step - loss: 1.0854 - accuracy: 0.4118\n",
      "Epoch 271/300\n",
      "12/12 [==============================] - 0s 502us/step - loss: 1.0852 - accuracy: 0.4118\n",
      "Epoch 272/300\n",
      "12/12 [==============================] - 0s 664us/step - loss: 1.0849 - accuracy: 0.4118\n",
      "Epoch 273/300\n",
      "12/12 [==============================] - 0s 667us/step - loss: 1.0844 - accuracy: 0.4118\n",
      "Epoch 274/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12/12 [==============================] - 0s 583us/step - loss: 1.0837 - accuracy: 0.4118\n",
      "Epoch 275/300\n",
      "12/12 [==============================] - 0s 583us/step - loss: 1.0852 - accuracy: 0.4118\n",
      "Epoch 276/300\n",
      "12/12 [==============================] - 0s 586us/step - loss: 1.0846 - accuracy: 0.4118\n",
      "Epoch 277/300\n",
      "12/12 [==============================] - 0s 583us/step - loss: 1.0857 - accuracy: 0.4118\n",
      "Epoch 278/300\n",
      "12/12 [==============================] - 0s 500us/step - loss: 1.0863 - accuracy: 0.4118\n",
      "Epoch 279/300\n",
      "12/12 [==============================] - 0s 747us/step - loss: 1.0883 - accuracy: 0.4118\n",
      "Epoch 280/300\n",
      "12/12 [==============================] - 0s 581us/step - loss: 1.0852 - accuracy: 0.4118\n",
      "Epoch 281/300\n",
      "12/12 [==============================] - 0s 621us/step - loss: 1.0848 - accuracy: 0.4118\n",
      "Epoch 282/300\n",
      "12/12 [==============================] - 0s 665us/step - loss: 1.0857 - accuracy: 0.4118\n",
      "Epoch 283/300\n",
      "12/12 [==============================] - 0s 583us/step - loss: 1.0854 - accuracy: 0.4118\n",
      "Epoch 284/300\n",
      "12/12 [==============================] - 0s 752us/step - loss: 1.0848 - accuracy: 0.4118\n",
      "Epoch 285/300\n",
      "12/12 [==============================] - 0s 584us/step - loss: 1.0843 - accuracy: 0.4118\n",
      "Epoch 286/300\n",
      "12/12 [==============================] - 0s 666us/step - loss: 1.0853 - accuracy: 0.4118\n",
      "Epoch 287/300\n",
      "12/12 [==============================] - 0s 667us/step - loss: 1.0836 - accuracy: 0.4118\n",
      "Epoch 288/300\n",
      "12/12 [==============================] - 0s 583us/step - loss: 1.0855 - accuracy: 0.4118\n",
      "Epoch 289/300\n",
      "12/12 [==============================] - 0s 593us/step - loss: 1.0843 - accuracy: 0.4118\n",
      "Epoch 290/300\n",
      "12/12 [==============================] - 0s 750us/step - loss: 1.0868 - accuracy: 0.4118\n",
      "Epoch 291/300\n",
      "12/12 [==============================] - 0s 583us/step - loss: 1.0851 - accuracy: 0.4118\n",
      "Epoch 292/300\n",
      "12/12 [==============================] - 0s 665us/step - loss: 1.0883 - accuracy: 0.4118\n",
      "Epoch 293/300\n",
      "12/12 [==============================] - 0s 582us/step - loss: 1.0866 - accuracy: 0.4118\n",
      "Epoch 294/300\n",
      "12/12 [==============================] - 0s 585us/step - loss: 1.0843 - accuracy: 0.4118\n",
      "Epoch 295/300\n",
      "12/12 [==============================] - 0s 667us/step - loss: 1.0841 - accuracy: 0.4118\n",
      "Epoch 296/300\n",
      "12/12 [==============================] - 0s 502us/step - loss: 1.0864 - accuracy: 0.4118\n",
      "Epoch 297/300\n",
      "12/12 [==============================] - 0s 586us/step - loss: 1.0845 - accuracy: 0.4118\n",
      "Epoch 298/300\n",
      "12/12 [==============================] - 0s 583us/step - loss: 1.0862 - accuracy: 0.4118\n",
      "Epoch 299/300\n",
      "12/12 [==============================] - 0s 669us/step - loss: 1.0854 - accuracy: 0.4118\n",
      "Epoch 300/300\n",
      "12/12 [==============================] - 0s 750us/step - loss: 1.0874 - accuracy: 0.4118\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x000002904F44C1F0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "2/2 [==============================] - 0s 499us/step - loss: 0.3737 - accuracy: 0.8644\n",
      "\n",
      "Accuracy: 86.44%\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x0000029051C7A310> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "2/2 [==============================] - 0s 1ms/step - loss: 1.0932 - accuracy: 0.3729\n",
      "\n",
      "Accuracy2: 37.29%\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x00000290533BC4C0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "2/2 [==============================] - 0s 487us/step - loss: 1.0937 - accuracy: 0.3729\n",
      "\n",
      "Accuracy3: 37.29%\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x000002905371B670> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x000002905371B550> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x0000029051C7A0D0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "[[2.61392500e-02 1.84928195e-03 9.72011507e-01]\n",
      " [1.06049076e-01 1.44709542e-01 7.49241352e-01]\n",
      " [1.14454573e-03 9.98456717e-01 3.98764183e-04]\n",
      " [9.43152189e-01 6.51249569e-03 5.03352508e-02]\n",
      " [1.76165413e-05 9.99579728e-01 4.02613223e-04]]\n",
      "[[0.32000455 0.26878783 0.41120762]\n",
      " [0.32000455 0.26878783 0.41120762]\n",
      " [0.32000455 0.26878783 0.41120762]\n",
      " [0.32000455 0.26878783 0.41120762]\n",
      " [0.32000455 0.26878783 0.41120762]]\n",
      "[[0.3223921  0.26088637 0.41672155]\n",
      " [0.3223921  0.26088637 0.41672155]\n",
      " [0.3223921  0.26088637 0.41672155]\n",
      " [0.3223921  0.26088637 0.41672155]\n",
      " [0.3223921  0.26088637 0.41672155]]\n"
     ]
    }
   ],
   "source": [
    "#–ù–µ–π—Ä–æ–Ω–Ω—ã–µ —Å–µ—Ç–∏. Deep Learning\n",
    "#–ê–∫—Ç–∏–≤–∞—Ü–∏–æ–Ω–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è = —Å—É–º–º–∞(Wi*Xi) –æ—Ç —á–∏—Å–ª–∞ –≤—Ö–æ–¥–æ–≤ –Ω–µ–π—Ä–æ–Ω–∞. \n",
    "#–õ–æ–≥–∏—Å—Ç–∏—á–µ—Å–∫–∞—è —Ñ—É–Ω–∫—Ü–∏—è f(x)=e**x/(1+e**x) –∏–ª–∏ –≥–∏–ø–µ—Ä–±–æ–ª–∏—á–µ—Å–∫–∏–π —Ç–∞–Ω–≥–µ–Ω—Å\n",
    "#ReLU —Ñ—É–Ω–∫—Ü–∏—è f(x) = max(0, X) –ø—Ä–æ—â–µ, –Ω–æ —á—É—Ç—å –º–µ–Ω–µ–µ —Ç–æ—á–Ω–∞—è –∏ —Å–ª–æ–∂–Ω–µ–µ –≤ –¥–æ–±–∞–≤–ª–µ–Ω–∏–∏ –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤\n",
    "#–ü–æ–¥–±–æ—Ä –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—ã –ù–° –ø–æ–∑–≤–æ–ª—è–µ—Ç –æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞—Ç—å —á–∏—Å–ª–æ –Ω–µ–π—Ä–æ–Ω–æ–≤, –Ω–∞—Å—Ç—Ä–æ–∏–≤ –≤—Ö–æ–¥–Ω–æ–π, —Å–∫—Ä—ã—Ç—ã–µ, –≤—ã—Ö–æ–¥–Ω–æ–π —Å–ª–æ–∏. \n",
    "#–°–µ—Ç–∏ –ø—Ä—è–º–æ–≥–æ —Ä–∞—Å–ø—Ä–æ—Å—Ç—Ä–∞–Ω–µ–Ω–∏—è: –≤ –ø—Ä–µ–¥–µ–ª–∞—Ö —Å–ª–æ—è –Ω–µ–π—Ä–æ–Ω—ã –Ω–µ —Å–≤—è–∑–∞–Ω—ã, –ø–µ—Ä–µ–¥–∞—é—Ç —Ç–æ–ª—å–∫–æ –≤ —Å–ª–µ–¥. —Å–ª–æ–π, –ø–µ—Ä–µ–ø—Ä—ã–≥–∏–≤–∞—Ç—å –Ω–µ–ª—å–∑—è\n",
    "#–û–±—É—á–µ–Ω–∏–µ –ù–° = –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –∑–Ω–∞—á–µ–Ω–∏–π –í–ï–°–û–í (–≤–Ω—É—Ç—Ä–µ–Ω–Ω–∏—Ö –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤)  –∫–∞–∂–¥–æ–≥–æ —Å–æ–µ–¥–∏–Ω–µ–Ω–∏—è. –û—Å—Ç–∞–ª—å–Ω–æ–µ –∑–∞–¥–∞–µ—Ç—Å—è –∞–Ω–∞–ª–∏—Ç–∏–∫–æ–º –∑–∞—Ä–∞–Ω–µ–µ\n",
    "#Keras –º–æ–¥—É–ª–∏: –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞, –≤—Ö–æ–¥–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è, —É—Å–ª–æ–≤–∏—è –æ–±—É—á–µ–Ω–∏—è, –æ—Ü–µ–Ω–∫–∞ –∫–∞—á–µ—Å—Ç–≤–∞\n",
    "\n",
    "wine['Desired1(3)'].value_counts(normalize=True)\n",
    "\n",
    "#–ò–º–µ–Ω—É–µ–º –ø—Ä–µ–¥–∏–∫—Ç–æ—Ä—ã –∏ –æ—Ç–∫–ª–∏–∫\n",
    "y = wine['Desired1(3)']\n",
    "X = wine.drop('Desired1(3)', axis=1)\n",
    "\n",
    "#—Ä–∞—Å—â–µ–ø–ª–µ–Ω–∏–µ –Ω–∞ –≤—ã–±–æ—Ä–∫–∏ —Å —É–∫–∞–∑–∞–Ω–∏–µ–º –æ–±—ä—ë–º–∞ —Ç–µ—Å—Ç–æ–≤–æ–≥–æ –º–Ω–æ–∂–µ—Å—Ç–≤–∞\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=12345, test_size=0.33)\n",
    "\n",
    "#–ü—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ –≤ np.array –¥–ª—è Keras\n",
    "X_train = X_train.values\n",
    "X_test = X_test.values\n",
    "y_train = y_train.values\n",
    "y_test = y_test.values\n",
    "\n",
    "#–ü–æ—Å–∫–æ–ª—å–∫—É –±–æ–ª—å—à–µ –¥–≤—É—Ö –∫–ª–∞—Å—Å–æ–≤ –∏ –æ–Ω–∏ –Ω–µ —É–ø–æ—Ä—è–¥–æ—á–µ–Ω—ã, —Ç–æ —Ä–∞–∑–±–∏–≤–∞–µ–º –∫–æ–ª–æ–Ω–∫—É \"y\" –Ω–∞ —Ç—Ä–∏, —Å –±–∏–Ω–∞—Ä–Ω—ã–º–∏ –∑–Ω–∞—á–µ–Ω–∏—è–º–∏\n",
    "y_train_bin = np_utils.to_categorical(y_train)\n",
    "y_test_bin = np_utils.to_categorical(y_test)\n",
    "y_train_bin[0:5]\n",
    "\n",
    "#–ú–µ—Ç–æ–¥ —Å–∫–æ—Ä–µ–π—à–µ–≥–æ(–≥—Ä–∞–¥–∏–µ–Ω—Ç–Ω–æ–≥–æ) —Å–ø—É—Å–∫–∞ SGD. –£–ª—É—á—à–µ–Ω–∏–µ –º–µ—Ç–æ–¥–∞: Momentum, Nesterov momentum, Adam –∏ –¥—Ä.\n",
    "#Argmin, –ø—Ä–∞–≤–∏–ª–æ –æ—Å—Ç–∞–Ω–æ–≤–∫–∏: —á–∏—Å–ª–æ –∏—Ç–µ—Ä–∞—Ü–∏–π –∏–ª–∏ –º–∞–ª–æ–µ —É–º–µ–Ω—å—à–µ–Ω–∏–µ —Ñ—É–Ω–∫—Ü–∏–∏\n",
    "#–ù–∞—á–∞–ª—å–Ω–∞—è —Ç–æ—á–∫–∞(–∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è). –ù–∞—á–∞–ª—å–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏–µ –¥.–±. –º–∏–Ω–∏–º–∞–ª—å–Ω—ã–º, –±–ª–∏–∂–µ –∫ –Ω—É–ª—é (–∫—Ä–æ–º–µ —Å–≤–æ–±–æ–¥–Ω—ã—Ö —Å–ª–∞–≥–∞–µ–º—ã—Ö)\n",
    "#–ì—Ä–∞—Ñ–∏–∫ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –∫—Ä–∏—Ç–µ—Ä–∏—è –∫–∞–∞—á-–≤–∞ Q –æ—Ç –Ω–æ–º–µ—Ä–∞ –∏—Ç–µ—Ä–∞—Ü–∏–∏. –ú–∞–ª–∞—è —Å–∫–æ—Ä–æ—Å—Ç—å –æ–±—É—á–µ–Ω–∏—è(0.001 –∏ —Ç.–¥.) –¥–∞–µ—Ç –∫–∞—á–µ—Å—Ç–≤–æ, –Ω–æ –∏–¥–µ—Ç –¥–æ–ª—å—à–µ\n",
    "#–í—Ö–æ–¥–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è —Ä–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è —Å—Ç–∞–Ω–¥–∞—Ä—Ç–∏–∑–æ–≤–∞—Ç—å(—Å–Ω–∏–∂–∞–µ—Ç —Ä–∏—Å–∫ –Ω–∞—Å—ã—â–µ–Ω–∏—è) (Xi-Xmin)/(Xmax-Xmin)\n",
    "#Batch - –∫–æ—Ä—Ä–µ–∫—Ü–∏—è –≤–µ—Å–æ–≤ –ø–æ—Å–ª–µ –∫–∞–∂–¥–æ–π —ç–ø–æ—Ö–∏. –ù–∞—Å—ã—â–µ–Ω–∏–µ - –æ—Ç—Å—É—Ç—Å—Ç–≤–∏–µ –∫–æ—Ä—Ä–µ–∫—Ü–∏–π. Gradient clipping - –±–ª–æ–∫ –æ—Ç –±–æ–ª—å—à–∏—Ö –ø–æ–ø—Ä–∞–≤–æ–∫\n",
    "\n",
    "#–°–æ–∑–¥–∞–µ–º –º–æ–¥–µ–ª–∏. –î–ª—è –Ω–µ–±–æ–ª—å—à–∏—Ö –¥–∞–Ω–Ω—ã—Ö –º–æ–∂–Ω–æ –≤—Å–µ–≥–æ –ø–∞—Ä—É —Å–ª–æ–µ–≤ –≤ 5-7 –Ω–µ–π—Ä–æ–Ω–æ–≤\n",
    "#–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è. –ü—Ä–∏—Å–≤–æ–µ–Ω–∏–µ —Å—Ç–∞—Ä—Ç–æ–≤—ã—Ö –≤–µ—Å–æ–≤\n",
    "init = initializers.RandomNormal(mean=0.0, stddev=0.05, seed=None) #–ó–µ—Ä–Ω–æ –Ω–µ —É–∫–∞–∑–∞–Ω–æ, –∫–æ–Ω—Ç—Ä–æ–ª—è –Ω–∞–¥ –æ–±—É—á–µ–Ω–∏–µ–º –º–µ–Ω—å—à–µ\n",
    "init_2 = initializers.TruncatedNormal(mean=0.0, stddev=0.05, seed=12345) #–£—Å–µ—á–µ–Ω–Ω–æ–µ –Ω–æ—Ä–º–∞–ª—å–Ω–æ–µ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ. –ò–Ω–∏—Ü–∏–∞—Ü–∏—è –≤–µ—Å–æ–≤\n",
    "init_3 = initializers.Constant(value = 1e-3) #–ò–Ω–∏—Ü–∏–∞—Ü–∏—è —Å–≤–æ–±–æ–¥–Ω—ã—Ö —á–ª–µ–Ω–æ–≤\n",
    "\n",
    "model = Sequential() #–£–∫–∞–∑—ã–≤–∞–µ–º –Ω–∞ —Ç–∏–ø –º–æ–¥–µ–ª–∏ (—Å–µ—Ç—å –ø—Ä—è–º–æ–≥–æ —Ä–∞—Å–ø—Ä–æ—Å—Ç—Ä–∞–Ω–µ–Ω–∏—è)\n",
    "model.add(Dense(9, input_dim=13, activation='relu')) #–ü–µ—Ä–≤—ã–π —Å–ª–æ–π, 9 –Ω–µ–π—Ä–æ–Ω–æ–≤, –≤—Ö–æ–¥–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è (13 –ø—Ä–µ–¥–∏–∫—Ç–æ—Ä–æ–≤)\n",
    "model.add(Dense(10, activation='relu', )) #–í—Ç–æ–æ–π —Å–ª–æ–π, 10 –Ω–µ–π—Ä–æ–Ω–æ–≤\n",
    "model.add(Dense(3, activation='softmax')) #–¢—Ä–µ—Ç–∏–π —Å–ª–æ–π, —Ä–∞–Ω–∂–∏—Ä–æ–≤–∫–∞ —Å–æ—Ñ—Ç–º–∞–∫—Å–æ–º –¥–ª—è —Å—Ç–∞–Ω–¥–∞—Ä—Ç–∏–∑–∞—Ü–∏–∏ –∏ –∞–∫—Ç–∏–≤–∞—Ü–∏–∏. –¢—Ä–∏ –≤—ã—Ö–æ–¥–∞\n",
    "\n",
    "model2 = Sequential()\n",
    "model2.add(Dense(9, input_dim=13, activation='relu'))\n",
    "model2.add(Dense(10, activation='relu' ))\n",
    "model2.add(Dense(3, activation='softmax'))\n",
    "\n",
    "model3 = Sequential()\n",
    "model3.add(Dense(9, input_dim=13, activation='relu', kernel_initializer=init_2, bias_initializer=init_3))\n",
    "model3.add(Dense(10, activation='relu', kernel_initializer=init_2, bias_initializer=init_3 ))\n",
    "model3.add(Dense(3, activation='softmax', kernel_initializer=init_2, bias_initializer=init_3))\n",
    "\n",
    "#Categorical crossentropy (CC) –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –¥–ª—è –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–∏ –ø—Ä–∏–Ω–∞–¥–ª–µ–∂–Ω–æ—Å—Ç–∏ –æ–±—ä–µ–∫—Ç–∞ –∫ –∫–ª–∞—Å—Å—É (—É–ø–æ—Ä—è–¥–æ—á–Ω–æ–º—É)\n",
    "\n",
    "#–ö–æ–º–ø–∏–ª–∏—Ä—É–µ–º: optimizer(rmsprop –∏–ª–∏ adam), loss function(categorical_crossentropy(–∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è) –∏–ª–∏ mse(—Ä–µ–≥—Ä–µ—Å—Å–∏—è)). –¢–æ—á–Ω–æ—Å—Ç—å\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "sgd2 = optimizers.SGD(lr=0.02, decay=1e-6, momentum=0.8, nesterov=True)\n",
    "model2.compile(loss='categorical_crossentropy', optimizer=sgd2, metrics=['accuracy'])\n",
    "\n",
    "sgd3 = optimizers.SGD(lr=0.02, decay=1e-7, momentum=0.9, nesterov=True)\n",
    "model3.compile(loss='categorical_crossentropy', optimizer=sgd3, metrics=['accuracy'])\n",
    "\n",
    "#–û–±—É—á–∞–µ–º –º–æ–¥–µ–ª—å: 300 —ç–ø–æ—Ö, –ø—Ä–æ–ø—É—Å–∫ 10 —ç–ª–µ–º–µ–Ω—Ç–æ–≤ –¥–æ —Å–º–µ–Ω—ã –≤–µ—Å–æ–≤\n",
    "model.fit(X_train, y_train_bin, epochs=300, batch_size=10)\n",
    "model2.fit(X_train, y_train_bin, epochs=300, batch_size=10)\n",
    "model3.fit(X_train, y_train_bin, epochs=300, batch_size=10)\n",
    "\n",
    "#–ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞ —Ç–µ—Å—Ç–æ–≤–æ–º –º–Ω–æ–∂–µ—Å—Ç–≤–µ\n",
    "scores = model.evaluate(X_test, y_test_bin)\n",
    "print(\"\\nAccuracy: %.2f%%\" % (scores[1]*100))\n",
    "\n",
    "scores2 = model2.evaluate(X_test, y_test_bin)\n",
    "print(\"\\nAccuracy2: %.2f%%\" % (scores2[1]*100))\n",
    "\n",
    "scores3 = model3.evaluate(X_test, y_test_bin)\n",
    "print(\"\\nAccuracy3: %.2f%%\" % (scores3[1]*100))\n",
    "\n",
    "\n",
    "#–†–∞—Å—Å—á–∏—Ç—ã–≤–∞–µ–º –ø—Ä–µ–¥–∏–∫—Ç–æ—Ä—ã\n",
    "predictions = model.predict(X_test)\n",
    "predictions2 = model2.predict(X_test)\n",
    "predictions3 = model3.predict(X_test)\n",
    "#round predictions\n",
    "#rounded = [round(x[0]) for x in predictions]\n",
    "#print(rounded)\n",
    "print(predictions[0:5])\n",
    "print(predictions2[0:5])\n",
    "print(predictions3[0:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "3/3 [==============================] - 0s 1000us/step - loss: 82332072.0000 - mean_absolute_percentage_error: 57.6390\n",
      "Epoch 2/300\n",
      "3/3 [==============================] - 0s 999us/step - loss: 67629448.0000 - mean_absolute_percentage_error: 50.6311\n",
      "Epoch 3/300\n",
      "3/3 [==============================] - 0s 666us/step - loss: 57471532.0000 - mean_absolute_percentage_error: 45.3311\n",
      "Epoch 4/300\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 47555856.0000 - mean_absolute_percentage_error: 40.1855\n",
      "Epoch 5/300\n",
      "3/3 [==============================] - 0s 667us/step - loss: 41630244.0000 - mean_absolute_percentage_error: 37.1666\n",
      "Epoch 6/300\n",
      "3/3 [==============================] - 0s 666us/step - loss: 37347452.0000 - mean_absolute_percentage_error: 35.6267\n",
      "Epoch 7/300\n",
      "3/3 [==============================] - 0s 1000us/step - loss: 34635620.0000 - mean_absolute_percentage_error: 34.6937\n",
      "Epoch 8/300\n",
      "3/3 [==============================] - 0s 667us/step - loss: 33117012.0000 - mean_absolute_percentage_error: 34.0659\n",
      "Epoch 9/300\n",
      "3/3 [==============================] - 0s 599us/step - loss: 31804642.0000 - mean_absolute_percentage_error: 33.6313\n",
      "Epoch 10/300\n",
      "3/3 [==============================] - 0s 666us/step - loss: 30793902.0000 - mean_absolute_percentage_error: 33.0751\n",
      "Epoch 11/300\n",
      "3/3 [==============================] - 0s 1000us/step - loss: 29634014.0000 - mean_absolute_percentage_error: 32.4574\n",
      "Epoch 12/300\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 28487156.0000 - mean_absolute_percentage_error: 31.8054\n",
      "Epoch 13/300\n",
      "3/3 [==============================] - 0s 667us/step - loss: 27214432.0000 - mean_absolute_percentage_error: 31.0344\n",
      "Epoch 14/300\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 25797904.0000 - mean_absolute_percentage_error: 30.1561\n",
      "Epoch 15/300\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 24459014.0000 - mean_absolute_percentage_error: 29.2398\n",
      "Epoch 16/300\n",
      "3/3 [==============================] - 0s 666us/step - loss: 23089922.0000 - mean_absolute_percentage_error: 28.3581\n",
      "Epoch 17/300\n",
      "3/3 [==============================] - 0s 333us/step - loss: 21706870.0000 - mean_absolute_percentage_error: 27.3799\n",
      "Epoch 18/300\n",
      "3/3 [==============================] - 0s 666us/step - loss: 20496622.0000 - mean_absolute_percentage_error: 26.4872\n",
      "Epoch 19/300\n",
      "3/3 [==============================] - 0s 667us/step - loss: 19249098.0000 - mean_absolute_percentage_error: 25.6127\n",
      "Epoch 20/300\n",
      "3/3 [==============================] - 0s 666us/step - loss: 18273020.0000 - mean_absolute_percentage_error: 24.7872\n",
      "Epoch 21/300\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 17403414.0000 - mean_absolute_percentage_error: 24.1591\n",
      "Epoch 22/300\n",
      "3/3 [==============================] - 0s 721us/step - loss: 16622757.0000 - mean_absolute_percentage_error: 23.5413\n",
      "Epoch 23/300\n",
      "3/3 [==============================] - 0s 667us/step - loss: 15986988.0000 - mean_absolute_percentage_error: 23.0447\n",
      "Epoch 24/300\n",
      "3/3 [==============================] - 0s 667us/step - loss: 15441784.0000 - mean_absolute_percentage_error: 22.6628\n",
      "Epoch 25/300\n",
      "3/3 [==============================] - 0s 1000us/step - loss: 15051925.0000 - mean_absolute_percentage_error: 22.4022\n",
      "Epoch 26/300\n",
      "3/3 [==============================] - 0s 1000us/step - loss: 14756794.0000 - mean_absolute_percentage_error: 22.1846\n",
      "Epoch 27/300\n",
      "3/3 [==============================] - 0s 666us/step - loss: 14455240.0000 - mean_absolute_percentage_error: 22.0193\n",
      "Epoch 28/300\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 14290380.0000 - mean_absolute_percentage_error: 21.9529\n",
      "Epoch 29/300\n",
      "3/3 [==============================] - 0s 667us/step - loss: 14122922.0000 - mean_absolute_percentage_error: 21.8318\n",
      "Epoch 30/300\n",
      "3/3 [==============================] - 0s 666us/step - loss: 13971597.0000 - mean_absolute_percentage_error: 21.7426\n",
      "Epoch 31/300\n",
      "3/3 [==============================] - 0s 667us/step - loss: 13851150.0000 - mean_absolute_percentage_error: 21.6712\n",
      "Epoch 32/300\n",
      "3/3 [==============================] - 0s 667us/step - loss: 13751735.0000 - mean_absolute_percentage_error: 21.6231\n",
      "Epoch 33/300\n",
      "3/3 [==============================] - 0s 667us/step - loss: 13643939.0000 - mean_absolute_percentage_error: 21.5931\n",
      "Epoch 34/300\n",
      "3/3 [==============================] - 0s 667us/step - loss: 13543951.0000 - mean_absolute_percentage_error: 21.5416\n",
      "Epoch 35/300\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 13466306.0000 - mean_absolute_percentage_error: 21.5022\n",
      "Epoch 36/300\n",
      "3/3 [==============================] - 0s 667us/step - loss: 13374065.0000 - mean_absolute_percentage_error: 21.4480\n",
      "Epoch 37/300\n",
      "3/3 [==============================] - 0s 1000us/step - loss: 13303307.0000 - mean_absolute_percentage_error: 21.3927\n",
      "Epoch 38/300\n",
      "3/3 [==============================] - 0s 667us/step - loss: 13217799.0000 - mean_absolute_percentage_error: 21.3420\n",
      "Epoch 39/300\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 13127250.0000 - mean_absolute_percentage_error: 21.2710\n",
      "Epoch 40/300\n",
      "3/3 [==============================] - 0s 667us/step - loss: 13051734.0000 - mean_absolute_percentage_error: 21.2032\n",
      "Epoch 41/300\n",
      "3/3 [==============================] - 0s 667us/step - loss: 12959096.0000 - mean_absolute_percentage_error: 21.1156\n",
      "Epoch 42/300\n",
      "3/3 [==============================] - 0s 667us/step - loss: 12890015.0000 - mean_absolute_percentage_error: 21.0503\n",
      "Epoch 43/300\n",
      "3/3 [==============================] - 0s 666us/step - loss: 12800007.0000 - mean_absolute_percentage_error: 20.9752\n",
      "Epoch 44/300\n",
      "3/3 [==============================] - 0s 1000us/step - loss: 12728753.0000 - mean_absolute_percentage_error: 20.9117\n",
      "Epoch 45/300\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 12660040.0000 - mean_absolute_percentage_error: 20.8497\n",
      "Epoch 46/300\n",
      "3/3 [==============================] - 0s 667us/step - loss: 12583151.0000 - mean_absolute_percentage_error: 20.7900\n",
      "Epoch 47/300\n",
      "3/3 [==============================] - 0s 666us/step - loss: 12513851.0000 - mean_absolute_percentage_error: 20.7349\n",
      "Epoch 48/300\n",
      "3/3 [==============================] - 0s 667us/step - loss: 12441224.0000 - mean_absolute_percentage_error: 20.6694\n",
      "Epoch 49/300\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 12359179.0000 - mean_absolute_percentage_error: 20.6037\n",
      "Epoch 50/300\n",
      "3/3 [==============================] - 0s 676us/step - loss: 12292009.0000 - mean_absolute_percentage_error: 20.5573\n",
      "Epoch 51/300\n",
      "3/3 [==============================] - 0s 667us/step - loss: 12220121.0000 - mean_absolute_percentage_error: 20.5017\n",
      "Epoch 52/300\n",
      "3/3 [==============================] - 0s 1000us/step - loss: 12147452.0000 - mean_absolute_percentage_error: 20.4491\n",
      "Epoch 53/300\n",
      "3/3 [==============================] - 0s 667us/step - loss: 12075540.0000 - mean_absolute_percentage_error: 20.3897\n",
      "Epoch 54/300\n",
      "3/3 [==============================] - 0s 1000us/step - loss: 12005057.0000 - mean_absolute_percentage_error: 20.3317\n",
      "Epoch 55/300\n",
      "3/3 [==============================] - 0s 991us/step - loss: 11938642.0000 - mean_absolute_percentage_error: 20.2847\n",
      "Epoch 56/300\n",
      "3/3 [==============================] - 0s 666us/step - loss: 11860504.0000 - mean_absolute_percentage_error: 20.2211\n",
      "Epoch 57/300\n",
      "3/3 [==============================] - 0s 1000us/step - loss: 11786222.0000 - mean_absolute_percentage_error: 20.1486\n",
      "Epoch 58/300\n",
      "3/3 [==============================] - 0s 667us/step - loss: 11716106.0000 - mean_absolute_percentage_error: 20.0899\n",
      "Epoch 59/300\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 11651730.0000 - mean_absolute_percentage_error: 20.0326\n",
      "Epoch 60/300\n",
      "3/3 [==============================] - 0s 666us/step - loss: 11575895.0000 - mean_absolute_percentage_error: 19.9765\n",
      "Epoch 61/300\n",
      "3/3 [==============================] - 0s 667us/step - loss: 11502676.0000 - mean_absolute_percentage_error: 19.9103\n",
      "Epoch 62/300\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 11431769.0000 - mean_absolute_percentage_error: 19.8490\n",
      "Epoch 63/300\n",
      "3/3 [==============================] - 0s 667us/step - loss: 11363926.0000 - mean_absolute_percentage_error: 19.7920\n",
      "Epoch 64/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 1000us/step - loss: 11290487.0000 - mean_absolute_percentage_error: 19.7325\n",
      "Epoch 65/300\n",
      "3/3 [==============================] - 0s 666us/step - loss: 11221243.0000 - mean_absolute_percentage_error: 19.6685\n",
      "Epoch 66/300\n",
      "3/3 [==============================] - 0s 666us/step - loss: 11148555.0000 - mean_absolute_percentage_error: 19.6006\n",
      "Epoch 67/300\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 11078321.0000 - mean_absolute_percentage_error: 19.5381\n",
      "Epoch 68/300\n",
      "3/3 [==============================] - 0s 667us/step - loss: 11013134.0000 - mean_absolute_percentage_error: 19.4793\n",
      "Epoch 69/300\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 10941378.0000 - mean_absolute_percentage_error: 19.4090\n",
      "Epoch 70/300\n",
      "3/3 [==============================] - 0s 667us/step - loss: 10880294.0000 - mean_absolute_percentage_error: 19.3533\n",
      "Epoch 71/300\n",
      "3/3 [==============================] - 0s 667us/step - loss: 10803645.0000 - mean_absolute_percentage_error: 19.2949\n",
      "Epoch 72/300\n",
      "3/3 [==============================] - 0s 666us/step - loss: 10744814.0000 - mean_absolute_percentage_error: 19.2439\n",
      "Epoch 73/300\n",
      "3/3 [==============================] - 0s 1000us/step - loss: 10670396.0000 - mean_absolute_percentage_error: 19.1798\n",
      "Epoch 74/300\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 10605793.0000 - mean_absolute_percentage_error: 19.1188\n",
      "Epoch 75/300\n",
      "3/3 [==============================] - 0s 667us/step - loss: 10540136.0000 - mean_absolute_percentage_error: 19.0598\n",
      "Epoch 76/300\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 10475716.0000 - mean_absolute_percentage_error: 18.9937\n",
      "Epoch 77/300\n",
      "3/3 [==============================] - 0s 838us/step - loss: 10408051.0000 - mean_absolute_percentage_error: 18.9407\n",
      "Epoch 78/300\n",
      "3/3 [==============================] - 0s 667us/step - loss: 10340337.0000 - mean_absolute_percentage_error: 18.8831\n",
      "Epoch 79/300\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 10278390.0000 - mean_absolute_percentage_error: 18.8232\n",
      "Epoch 80/300\n",
      "3/3 [==============================] - 0s 837us/step - loss: 10210463.0000 - mean_absolute_percentage_error: 18.7615\n",
      "Epoch 81/300\n",
      "3/3 [==============================] - 0s 667us/step - loss: 10145764.0000 - mean_absolute_percentage_error: 18.7017\n",
      "Epoch 82/300\n",
      "3/3 [==============================] - 0s 666us/step - loss: 10080408.0000 - mean_absolute_percentage_error: 18.6461\n",
      "Epoch 83/300\n",
      "3/3 [==============================] - 0s 1000us/step - loss: 10015909.0000 - mean_absolute_percentage_error: 18.5858\n",
      "Epoch 84/300\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 9948082.0000 - mean_absolute_percentage_error: 18.5168\n",
      "Epoch 85/300\n",
      "3/3 [==============================] - 0s 666us/step - loss: 9887455.0000 - mean_absolute_percentage_error: 18.4575\n",
      "Epoch 86/300\n",
      "3/3 [==============================] - 0s 927us/step - loss: 9825253.0000 - mean_absolute_percentage_error: 18.3987\n",
      "Epoch 87/300\n",
      "3/3 [==============================] - 0s 1000us/step - loss: 9763038.0000 - mean_absolute_percentage_error: 18.3379\n",
      "Epoch 88/300\n",
      "3/3 [==============================] - 0s 667us/step - loss: 9697106.0000 - mean_absolute_percentage_error: 18.2734\n",
      "Epoch 89/300\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 9634892.0000 - mean_absolute_percentage_error: 18.2167\n",
      "Epoch 90/300\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 9578400.0000 - mean_absolute_percentage_error: 18.1649\n",
      "Epoch 91/300\n",
      "3/3 [==============================] - 0s 666us/step - loss: 9508766.0000 - mean_absolute_percentage_error: 18.0927\n",
      "Epoch 92/300\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 9445677.0000 - mean_absolute_percentage_error: 18.0386\n",
      "Epoch 93/300\n",
      "3/3 [==============================] - 0s 666us/step - loss: 9391186.0000 - mean_absolute_percentage_error: 17.9926\n",
      "Epoch 94/300\n",
      "3/3 [==============================] - 0s 667us/step - loss: 9336295.0000 - mean_absolute_percentage_error: 17.9449\n",
      "Epoch 95/300\n",
      "3/3 [==============================] - 0s 667us/step - loss: 9268376.0000 - mean_absolute_percentage_error: 17.8813\n",
      "Epoch 96/300\n",
      "3/3 [==============================] - 0s 667us/step - loss: 9201573.0000 - mean_absolute_percentage_error: 17.8054\n",
      "Epoch 97/300\n",
      "3/3 [==============================] - 0s 667us/step - loss: 9143520.0000 - mean_absolute_percentage_error: 17.7475\n",
      "Epoch 98/300\n",
      "3/3 [==============================] - 0s 667us/step - loss: 9085322.0000 - mean_absolute_percentage_error: 17.6918\n",
      "Epoch 99/300\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 9029850.0000 - mean_absolute_percentage_error: 17.6336\n",
      "Epoch 100/300\n",
      "3/3 [==============================] - 0s 668us/step - loss: 8972787.0000 - mean_absolute_percentage_error: 17.5759\n",
      "Epoch 101/300\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 8905867.0000 - mean_absolute_percentage_error: 17.5090\n",
      "Epoch 102/300\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 8860955.0000 - mean_absolute_percentage_error: 17.4518\n",
      "Epoch 103/300\n",
      "3/3 [==============================] - 0s 667us/step - loss: 8788709.0000 - mean_absolute_percentage_error: 17.3859\n",
      "Epoch 104/300\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 8735007.0000 - mean_absolute_percentage_error: 17.3370\n",
      "Epoch 105/300\n",
      "3/3 [==============================] - 0s 666us/step - loss: 8684150.0000 - mean_absolute_percentage_error: 17.2775\n",
      "Epoch 106/300\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 8629554.0000 - mean_absolute_percentage_error: 17.2306\n",
      "Epoch 107/300\n",
      "3/3 [==============================] - 0s 667us/step - loss: 8565503.0000 - mean_absolute_percentage_error: 17.1700\n",
      "Epoch 108/300\n",
      "3/3 [==============================] - 0s 658us/step - loss: 8509511.0000 - mean_absolute_percentage_error: 17.1107\n",
      "Epoch 109/300\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 8451867.0000 - mean_absolute_percentage_error: 17.0500\n",
      "Epoch 110/300\n",
      "3/3 [==============================] - 0s 667us/step - loss: 8397021.0000 - mean_absolute_percentage_error: 16.9954\n",
      "Epoch 111/300\n",
      "3/3 [==============================] - 0s 999us/step - loss: 8336787.5000 - mean_absolute_percentage_error: 16.9362\n",
      "Epoch 112/300\n",
      "3/3 [==============================] - 0s 334us/step - loss: 8289211.0000 - mean_absolute_percentage_error: 16.8869\n",
      "Epoch 113/300\n",
      "3/3 [==============================] - 0s 666us/step - loss: 8229886.5000 - mean_absolute_percentage_error: 16.8217\n",
      "Epoch 114/300\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 8175472.5000 - mean_absolute_percentage_error: 16.7645\n",
      "Epoch 115/300\n",
      "3/3 [==============================] - 0s 667us/step - loss: 8121916.5000 - mean_absolute_percentage_error: 16.7074\n",
      "Epoch 116/300\n",
      "3/3 [==============================] - 0s 666us/step - loss: 8067638.0000 - mean_absolute_percentage_error: 16.6501\n",
      "Epoch 117/300\n",
      "3/3 [==============================] - 0s 682us/step - loss: 8015893.0000 - mean_absolute_percentage_error: 16.5925\n",
      "Epoch 118/300\n",
      "3/3 [==============================] - 0s 667us/step - loss: 7971719.0000 - mean_absolute_percentage_error: 16.5403\n",
      "Epoch 119/300\n",
      "3/3 [==============================] - 0s 667us/step - loss: 7915624.0000 - mean_absolute_percentage_error: 16.4741\n",
      "Epoch 120/300\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 7860048.0000 - mean_absolute_percentage_error: 16.4192\n",
      "Epoch 121/300\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 7808495.0000 - mean_absolute_percentage_error: 16.3647\n",
      "Epoch 122/300\n",
      "3/3 [==============================] - 0s 666us/step - loss: 7758988.5000 - mean_absolute_percentage_error: 16.3132\n",
      "Epoch 123/300\n",
      "3/3 [==============================] - 0s 667us/step - loss: 7711336.0000 - mean_absolute_percentage_error: 16.2618\n",
      "Epoch 124/300\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 7656822.0000 - mean_absolute_percentage_error: 16.1975\n",
      "Epoch 125/300\n",
      "3/3 [==============================] - 0s 667us/step - loss: 7611127.0000 - mean_absolute_percentage_error: 16.1472\n",
      "Epoch 126/300\n",
      "3/3 [==============================] - 0s 667us/step - loss: 7556267.5000 - mean_absolute_percentage_error: 16.0889\n",
      "Epoch 127/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 1ms/step - loss: 7519749.5000 - mean_absolute_percentage_error: 16.0444\n",
      "Epoch 128/300\n",
      "3/3 [==============================] - 0s 667us/step - loss: 7466271.0000 - mean_absolute_percentage_error: 15.9859\n",
      "Epoch 129/300\n",
      "3/3 [==============================] - 0s 667us/step - loss: 7409750.5000 - mean_absolute_percentage_error: 15.9228\n",
      "Epoch 130/300\n",
      "3/3 [==============================] - 0s 667us/step - loss: 7362217.0000 - mean_absolute_percentage_error: 15.8692\n",
      "Epoch 131/300\n",
      "3/3 [==============================] - 0s 667us/step - loss: 7318487.0000 - mean_absolute_percentage_error: 15.8203\n",
      "Epoch 132/300\n",
      "3/3 [==============================] - 0s 666us/step - loss: 7265914.5000 - mean_absolute_percentage_error: 15.7522\n",
      "Epoch 133/300\n",
      "3/3 [==============================] - 0s 666us/step - loss: 7222526.5000 - mean_absolute_percentage_error: 15.7043\n",
      "Epoch 134/300\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 7170160.0000 - mean_absolute_percentage_error: 15.6433\n",
      "Epoch 135/300\n",
      "3/3 [==============================] - 0s 667us/step - loss: 7125248.0000 - mean_absolute_percentage_error: 15.5918\n",
      "Epoch 136/300\n",
      "3/3 [==============================] - 0s 667us/step - loss: 7081887.0000 - mean_absolute_percentage_error: 15.5390\n",
      "Epoch 137/300\n",
      "3/3 [==============================] - 0s 667us/step - loss: 7041366.0000 - mean_absolute_percentage_error: 15.4910\n",
      "Epoch 138/300\n",
      "3/3 [==============================] - 0s 667us/step - loss: 6994280.0000 - mean_absolute_percentage_error: 15.4324\n",
      "Epoch 139/300\n",
      "3/3 [==============================] - 0s 667us/step - loss: 6941119.5000 - mean_absolute_percentage_error: 15.3676\n",
      "Epoch 140/300\n",
      "3/3 [==============================] - ETA: 0s - loss: 6324799.0000 - mean_absolute_percentage_error: 13.777 - 0s 667us/step - loss: 6900215.5000 - mean_absolute_percentage_error: 15.3145\n",
      "Epoch 141/300\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 6857938.5000 - mean_absolute_percentage_error: 15.2551\n",
      "Epoch 142/300\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 6813054.5000 - mean_absolute_percentage_error: 15.2048\n",
      "Epoch 143/300\n",
      "3/3 [==============================] - 0s 999us/step - loss: 6771819.0000 - mean_absolute_percentage_error: 15.1451\n",
      "Epoch 144/300\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 6725822.5000 - mean_absolute_percentage_error: 15.0977\n",
      "Epoch 145/300\n",
      "3/3 [==============================] - 0s 667us/step - loss: 6687914.0000 - mean_absolute_percentage_error: 15.0504\n",
      "Epoch 146/300\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 6648792.5000 - mean_absolute_percentage_error: 15.0013\n",
      "Epoch 147/300\n",
      "3/3 [==============================] - 0s 667us/step - loss: 6599754.0000 - mean_absolute_percentage_error: 14.9443\n",
      "Epoch 148/300\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 6557511.5000 - mean_absolute_percentage_error: 14.8937\n",
      "Epoch 149/300\n",
      "3/3 [==============================] - 0s 666us/step - loss: 6515253.5000 - mean_absolute_percentage_error: 14.8409\n",
      "Epoch 150/300\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 6477661.5000 - mean_absolute_percentage_error: 14.7883\n",
      "Epoch 151/300\n",
      "3/3 [==============================] - 0s 666us/step - loss: 6434610.0000 - mean_absolute_percentage_error: 14.7390\n",
      "Epoch 152/300\n",
      "3/3 [==============================] - 0s 667us/step - loss: 6395569.0000 - mean_absolute_percentage_error: 14.6921\n",
      "Epoch 153/300\n",
      "3/3 [==============================] - 0s 667us/step - loss: 6356263.5000 - mean_absolute_percentage_error: 14.6445\n",
      "Epoch 154/300\n",
      "3/3 [==============================] - 0s 667us/step - loss: 6316819.0000 - mean_absolute_percentage_error: 14.5930\n",
      "Epoch 155/300\n",
      "3/3 [==============================] - 0s 666us/step - loss: 6274944.5000 - mean_absolute_percentage_error: 14.5502\n",
      "Epoch 156/300\n",
      "3/3 [==============================] - 0s 992us/step - loss: 6237320.5000 - mean_absolute_percentage_error: 14.5086\n",
      "Epoch 157/300\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 6200731.5000 - mean_absolute_percentage_error: 14.4638\n",
      "Epoch 158/300\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 6159765.0000 - mean_absolute_percentage_error: 14.4150\n",
      "Epoch 159/300\n",
      "3/3 [==============================] - 0s 663us/step - loss: 6123679.0000 - mean_absolute_percentage_error: 14.3676\n",
      "Epoch 160/300\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 6103823.0000 - mean_absolute_percentage_error: 14.3411\n",
      "Epoch 161/300\n",
      "3/3 [==============================] - 0s 667us/step - loss: 6047957.0000 - mean_absolute_percentage_error: 14.2777\n",
      "Epoch 162/300\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 6016697.0000 - mean_absolute_percentage_error: 14.2345\n",
      "Epoch 163/300\n",
      "3/3 [==============================] - 0s 667us/step - loss: 5976211.5000 - mean_absolute_percentage_error: 14.1877\n",
      "Epoch 164/300\n",
      "3/3 [==============================] - 0s 667us/step - loss: 5942305.0000 - mean_absolute_percentage_error: 14.1437\n",
      "Epoch 165/300\n",
      "3/3 [==============================] - 0s 667us/step - loss: 5901593.5000 - mean_absolute_percentage_error: 14.0949\n",
      "Epoch 166/300\n",
      "3/3 [==============================] - 0s 667us/step - loss: 5869926.0000 - mean_absolute_percentage_error: 14.0481\n",
      "Epoch 167/300\n",
      "3/3 [==============================] - 0s 676us/step - loss: 5832790.0000 - mean_absolute_percentage_error: 14.0020\n",
      "Epoch 168/300\n",
      "3/3 [==============================] - 0s 333us/step - loss: 5805727.5000 - mean_absolute_percentage_error: 13.9690\n",
      "Epoch 169/300\n",
      "3/3 [==============================] - 0s 667us/step - loss: 5771484.5000 - mean_absolute_percentage_error: 13.9194\n",
      "Epoch 170/300\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 5731857.0000 - mean_absolute_percentage_error: 13.8698\n",
      "Epoch 171/300\n",
      "3/3 [==============================] - 0s 667us/step - loss: 5715265.0000 - mean_absolute_percentage_error: 13.8452\n",
      "Epoch 172/300\n",
      "3/3 [==============================] - 0s 667us/step - loss: 5665859.5000 - mean_absolute_percentage_error: 13.7842\n",
      "Epoch 173/300\n",
      "3/3 [==============================] - 0s 837us/step - loss: 5635281.0000 - mean_absolute_percentage_error: 13.7401\n",
      "Epoch 174/300\n",
      "3/3 [==============================] - 0s 675us/step - loss: 5599204.0000 - mean_absolute_percentage_error: 13.6959\n",
      "Epoch 175/300\n",
      "3/3 [==============================] - 0s 667us/step - loss: 5566848.0000 - mean_absolute_percentage_error: 13.6503\n",
      "Epoch 176/300\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 5536239.0000 - mean_absolute_percentage_error: 13.6087\n",
      "Epoch 177/300\n",
      "3/3 [==============================] - 0s 998us/step - loss: 5506757.5000 - mean_absolute_percentage_error: 13.5701\n",
      "Epoch 178/300\n",
      "3/3 [==============================] - 0s 667us/step - loss: 5475532.5000 - mean_absolute_percentage_error: 13.5217\n",
      "Epoch 179/300\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 5440535.0000 - mean_absolute_percentage_error: 13.4741\n",
      "Epoch 180/300\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 5413110.0000 - mean_absolute_percentage_error: 13.4366\n",
      "Epoch 181/300\n",
      "3/3 [==============================] - 0s 667us/step - loss: 5385664.5000 - mean_absolute_percentage_error: 13.3991\n",
      "Epoch 182/300\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 5351527.5000 - mean_absolute_percentage_error: 13.3483\n",
      "Epoch 183/300\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 5321524.0000 - mean_absolute_percentage_error: 13.3084\n",
      "Epoch 184/300\n",
      "3/3 [==============================] - 0s 666us/step - loss: 5290274.0000 - mean_absolute_percentage_error: 13.2668\n",
      "Epoch 185/300\n",
      "3/3 [==============================] - 0s 999us/step - loss: 5263153.0000 - mean_absolute_percentage_error: 13.2298\n",
      "Epoch 186/300\n",
      "3/3 [==============================] - 0s 667us/step - loss: 5234519.0000 - mean_absolute_percentage_error: 13.1920\n",
      "Epoch 187/300\n",
      "3/3 [==============================] - 0s 667us/step - loss: 5208259.0000 - mean_absolute_percentage_error: 13.1549\n",
      "Epoch 188/300\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 5179492.5000 - mean_absolute_percentage_error: 13.1170\n",
      "Epoch 189/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 666us/step - loss: 5151939.0000 - mean_absolute_percentage_error: 13.0822\n",
      "Epoch 190/300\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 5121201.0000 - mean_absolute_percentage_error: 13.0381\n",
      "Epoch 191/300\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 5095197.5000 - mean_absolute_percentage_error: 12.9939\n",
      "Epoch 192/300\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 5067539.5000 - mean_absolute_percentage_error: 12.9535\n",
      "Epoch 193/300\n",
      "3/3 [==============================] - 0s 667us/step - loss: 5052824.5000 - mean_absolute_percentage_error: 12.9234\n",
      "Epoch 194/300\n",
      "3/3 [==============================] - 0s 667us/step - loss: 5013452.5000 - mean_absolute_percentage_error: 12.8704\n",
      "Epoch 195/300\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 4986039.0000 - mean_absolute_percentage_error: 12.8419\n",
      "Epoch 196/300\n",
      "3/3 [==============================] - 0s 1000us/step - loss: 4960609.5000 - mean_absolute_percentage_error: 12.8062\n",
      "Epoch 197/300\n",
      "3/3 [==============================] - 0s 666us/step - loss: 4942370.0000 - mean_absolute_percentage_error: 12.7862\n",
      "Epoch 198/300\n",
      "3/3 [==============================] - 0s 667us/step - loss: 4911218.5000 - mean_absolute_percentage_error: 12.7439\n",
      "Epoch 199/300\n",
      "3/3 [==============================] - 0s 666us/step - loss: 4888162.0000 - mean_absolute_percentage_error: 12.7110\n",
      "Epoch 200/300\n",
      "3/3 [==============================] - 0s 667us/step - loss: 4864839.5000 - mean_absolute_percentage_error: 12.6726\n",
      "Epoch 201/300\n",
      "3/3 [==============================] - 0s 667us/step - loss: 4832176.0000 - mean_absolute_percentage_error: 12.6153\n",
      "Epoch 202/300\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 4812186.0000 - mean_absolute_percentage_error: 12.5848\n",
      "Epoch 203/300\n",
      "3/3 [==============================] - 0s 667us/step - loss: 4787764.0000 - mean_absolute_percentage_error: 12.5425\n",
      "Epoch 204/300\n",
      "3/3 [==============================] - 0s 667us/step - loss: 4765418.5000 - mean_absolute_percentage_error: 12.5175\n",
      "Epoch 205/300\n",
      "3/3 [==============================] - 0s 666us/step - loss: 4738073.5000 - mean_absolute_percentage_error: 12.4761\n",
      "Epoch 206/300\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 4717124.0000 - mean_absolute_percentage_error: 12.4433\n",
      "Epoch 207/300\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 4697225.0000 - mean_absolute_percentage_error: 12.4131\n",
      "Epoch 208/300\n",
      "3/3 [==============================] - 0s 667us/step - loss: 4672163.5000 - mean_absolute_percentage_error: 12.3800\n",
      "Epoch 209/300\n",
      "3/3 [==============================] - 0s 666us/step - loss: 4647913.0000 - mean_absolute_percentage_error: 12.3529\n",
      "Epoch 210/300\n",
      "3/3 [==============================] - 0s 666us/step - loss: 4630770.5000 - mean_absolute_percentage_error: 12.3252\n",
      "Epoch 211/300\n",
      "3/3 [==============================] - 0s 667us/step - loss: 4603812.0000 - mean_absolute_percentage_error: 12.2839\n",
      "Epoch 212/300\n",
      "3/3 [==============================] - 0s 667us/step - loss: 4584352.5000 - mean_absolute_percentage_error: 12.2629\n",
      "Epoch 213/300\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 4562662.5000 - mean_absolute_percentage_error: 12.2399\n",
      "Epoch 214/300\n",
      "3/3 [==============================] - 0s 837us/step - loss: 4541213.0000 - mean_absolute_percentage_error: 12.2213\n",
      "Epoch 215/300\n",
      "3/3 [==============================] - 0s 666us/step - loss: 4521778.5000 - mean_absolute_percentage_error: 12.1964\n",
      "Epoch 216/300\n",
      "3/3 [==============================] - 0s 667us/step - loss: 4500311.5000 - mean_absolute_percentage_error: 12.1577\n",
      "Epoch 217/300\n",
      "3/3 [==============================] - 0s 666us/step - loss: 4480480.5000 - mean_absolute_percentage_error: 12.1273\n",
      "Epoch 218/300\n",
      "3/3 [==============================] - 0s 995us/step - loss: 4457227.5000 - mean_absolute_percentage_error: 12.0791\n",
      "Epoch 219/300\n",
      "3/3 [==============================] - 0s 667us/step - loss: 4438330.0000 - mean_absolute_percentage_error: 12.0393\n",
      "Epoch 220/300\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 4421835.5000 - mean_absolute_percentage_error: 11.9993\n",
      "Epoch 221/300\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 4403141.0000 - mean_absolute_percentage_error: 11.9593\n",
      "Epoch 222/300\n",
      "3/3 [==============================] - 0s 666us/step - loss: 4382367.0000 - mean_absolute_percentage_error: 11.9294\n",
      "Epoch 223/300\n",
      "3/3 [==============================] - 0s 667us/step - loss: 4371372.5000 - mean_absolute_percentage_error: 11.9087\n",
      "Epoch 224/300\n",
      "3/3 [==============================] - 0s 674us/step - loss: 4345582.5000 - mean_absolute_percentage_error: 11.8715\n",
      "Epoch 225/300\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 4323834.5000 - mean_absolute_percentage_error: 11.8552\n",
      "Epoch 226/300\n",
      "3/3 [==============================] - 0s 334us/step - loss: 4319551.5000 - mean_absolute_percentage_error: 11.8638\n",
      "Epoch 227/300\n",
      "3/3 [==============================] - 0s 667us/step - loss: 4290578.5000 - mean_absolute_percentage_error: 11.8311\n",
      "Epoch 228/300\n",
      "3/3 [==============================] - 0s 668us/step - loss: 4272020.5000 - mean_absolute_percentage_error: 11.7968\n",
      "Epoch 229/300\n",
      "3/3 [==============================] - 0s 666us/step - loss: 4254519.0000 - mean_absolute_percentage_error: 11.7660\n",
      "Epoch 230/300\n",
      "3/3 [==============================] - 0s 667us/step - loss: 4236803.0000 - mean_absolute_percentage_error: 11.7287\n",
      "Epoch 231/300\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 4223127.0000 - mean_absolute_percentage_error: 11.6944\n",
      "Epoch 232/300\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 4205003.5000 - mean_absolute_percentage_error: 11.6655\n",
      "Epoch 233/300\n",
      "3/3 [==============================] - 0s 667us/step - loss: 4186484.7500 - mean_absolute_percentage_error: 11.6398\n",
      "Epoch 234/300\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 4174309.7500 - mean_absolute_percentage_error: 11.6038\n",
      "Epoch 235/300\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 4153728.7500 - mean_absolute_percentage_error: 11.5666\n",
      "Epoch 236/300\n",
      "3/3 [==============================] - 0s 666us/step - loss: 4143759.5000 - mean_absolute_percentage_error: 11.5514\n",
      "Epoch 237/300\n",
      "3/3 [==============================] - 0s 674us/step - loss: 4124933.2500 - mean_absolute_percentage_error: 11.5292\n",
      "Epoch 238/300\n",
      "3/3 [==============================] - 0s 667us/step - loss: 4106206.2500 - mean_absolute_percentage_error: 11.4998\n",
      "Epoch 239/300\n",
      "3/3 [==============================] - 0s 667us/step - loss: 4089408.7500 - mean_absolute_percentage_error: 11.4680\n",
      "Epoch 240/300\n",
      "3/3 [==============================] - 0s 667us/step - loss: 4075593.5000 - mean_absolute_percentage_error: 11.4353\n",
      "Epoch 241/300\n",
      "3/3 [==============================] - 0s 667us/step - loss: 4058858.5000 - mean_absolute_percentage_error: 11.4013\n",
      "Epoch 242/300\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 4047420.5000 - mean_absolute_percentage_error: 11.3777\n",
      "Epoch 243/300\n",
      "3/3 [==============================] - 0s 666us/step - loss: 4030776.2500 - mean_absolute_percentage_error: 11.3494\n",
      "Epoch 244/300\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 4018042.2500 - mean_absolute_percentage_error: 11.3283\n",
      "Epoch 245/300\n",
      "3/3 [==============================] - 0s 667us/step - loss: 4003485.5000 - mean_absolute_percentage_error: 11.3164\n",
      "Epoch 246/300\n",
      "3/3 [==============================] - 0s 1000us/step - loss: 3989985.5000 - mean_absolute_percentage_error: 11.2957\n",
      "Epoch 247/300\n",
      "3/3 [==============================] - 0s 667us/step - loss: 3975714.5000 - mean_absolute_percentage_error: 11.2788\n",
      "Epoch 248/300\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 3961666.0000 - mean_absolute_percentage_error: 11.2506\n",
      "Epoch 249/300\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 3948774.0000 - mean_absolute_percentage_error: 11.2274\n",
      "Epoch 250/300\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 3934534.7500 - mean_absolute_percentage_error: 11.1999\n",
      "Epoch 251/300\n",
      "3/3 [==============================] - 0s 667us/step - loss: 3921588.0000 - mean_absolute_percentage_error: 11.1774\n",
      "Epoch 252/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 667us/step - loss: 3913987.5000 - mean_absolute_percentage_error: 11.1665\n",
      "Epoch 253/300\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 3896949.5000 - mean_absolute_percentage_error: 11.1422\n",
      "Epoch 254/300\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 3882766.0000 - mean_absolute_percentage_error: 11.1007\n",
      "Epoch 255/300\n",
      "3/3 [==============================] - 0s 667us/step - loss: 3870155.5000 - mean_absolute_percentage_error: 11.0715\n",
      "Epoch 256/300\n",
      "3/3 [==============================] - 0s 667us/step - loss: 3857847.5000 - mean_absolute_percentage_error: 11.0578\n",
      "Epoch 257/300\n",
      "3/3 [==============================] - 0s 1000us/step - loss: 3844594.0000 - mean_absolute_percentage_error: 11.0491\n",
      "Epoch 258/300\n",
      "3/3 [==============================] - 0s 666us/step - loss: 3831598.5000 - mean_absolute_percentage_error: 11.0373\n",
      "Epoch 259/300\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 3819849.7500 - mean_absolute_percentage_error: 11.0224\n",
      "Epoch 260/300\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 3809088.7500 - mean_absolute_percentage_error: 11.0051\n",
      "Epoch 261/300\n",
      "3/3 [==============================] - 0s 333us/step - loss: 3799628.2500 - mean_absolute_percentage_error: 11.0010\n",
      "Epoch 262/300\n",
      "3/3 [==============================] - 0s 667us/step - loss: 3793117.5000 - mean_absolute_percentage_error: 11.0019\n",
      "Epoch 263/300\n",
      "3/3 [==============================] - 0s 667us/step - loss: 3778538.2500 - mean_absolute_percentage_error: 10.9813\n",
      "Epoch 264/300\n",
      "3/3 [==============================] - 0s 666us/step - loss: 3762262.2500 - mean_absolute_percentage_error: 10.9529\n",
      "Epoch 265/300\n",
      "3/3 [==============================] - 0s 667us/step - loss: 3754792.0000 - mean_absolute_percentage_error: 10.9378\n",
      "Epoch 266/300\n",
      "3/3 [==============================] - 0s 696us/step - loss: 3741527.2500 - mean_absolute_percentage_error: 10.9140\n",
      "Epoch 267/300\n",
      "3/3 [==============================] - 0s 995us/step - loss: 3731821.7500 - mean_absolute_percentage_error: 10.8898\n",
      "Epoch 268/300\n",
      "3/3 [==============================] - 0s 667us/step - loss: 3718831.5000 - mean_absolute_percentage_error: 10.8601\n",
      "Epoch 269/300\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 3710553.7500 - mean_absolute_percentage_error: 10.8397\n",
      "Epoch 270/300\n",
      "3/3 [==============================] - 0s 666us/step - loss: 3701209.2500 - mean_absolute_percentage_error: 10.8159\n",
      "Epoch 271/300\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 3692428.7500 - mean_absolute_percentage_error: 10.8017\n",
      "Epoch 272/300\n",
      "3/3 [==============================] - 0s 999us/step - loss: 3681625.2500 - mean_absolute_percentage_error: 10.7839\n",
      "Epoch 273/300\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 3671238.7500 - mean_absolute_percentage_error: 10.7778\n",
      "Epoch 274/300\n",
      "3/3 [==============================] - 0s 666us/step - loss: 3660500.0000 - mean_absolute_percentage_error: 10.7768\n",
      "Epoch 275/300\n",
      "3/3 [==============================] - 0s 667us/step - loss: 3649646.5000 - mean_absolute_percentage_error: 10.7689\n",
      "Epoch 276/300\n",
      "3/3 [==============================] - 0s 667us/step - loss: 3640750.5000 - mean_absolute_percentage_error: 10.7687\n",
      "Epoch 277/300\n",
      "3/3 [==============================] - 0s 666us/step - loss: 3635818.2500 - mean_absolute_percentage_error: 10.7639\n",
      "Epoch 278/300\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 3625356.0000 - mean_absolute_percentage_error: 10.7592\n",
      "Epoch 279/300\n",
      "3/3 [==============================] - 0s 556us/step - loss: 3619506.7500 - mean_absolute_percentage_error: 10.7512\n",
      "Epoch 280/300\n",
      "3/3 [==============================] - 0s 666us/step - loss: 3609513.2500 - mean_absolute_percentage_error: 10.7359\n",
      "Epoch 281/300\n",
      "3/3 [==============================] - 0s 667us/step - loss: 3597647.7500 - mean_absolute_percentage_error: 10.7149\n",
      "Epoch 282/300\n",
      "3/3 [==============================] - 0s 666us/step - loss: 3585596.5000 - mean_absolute_percentage_error: 10.6637\n",
      "Epoch 283/300\n",
      "3/3 [==============================] - 0s 667us/step - loss: 3581398.2500 - mean_absolute_percentage_error: 10.6460\n",
      "Epoch 284/300\n",
      "3/3 [==============================] - 0s 667us/step - loss: 3573647.7500 - mean_absolute_percentage_error: 10.6246\n",
      "Epoch 285/300\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 3572590.5000 - mean_absolute_percentage_error: 10.6221\n",
      "Epoch 286/300\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 3557017.2500 - mean_absolute_percentage_error: 10.5930\n",
      "Epoch 287/300\n",
      "3/3 [==============================] - 0s 673us/step - loss: 3547341.7500 - mean_absolute_percentage_error: 10.5927\n",
      "Epoch 288/300\n",
      "3/3 [==============================] - 0s 667us/step - loss: 3539719.0000 - mean_absolute_percentage_error: 10.5979\n",
      "Epoch 289/300\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 3531563.2500 - mean_absolute_percentage_error: 10.6043\n",
      "Epoch 290/300\n",
      "3/3 [==============================] - 0s 1000us/step - loss: 3523897.7500 - mean_absolute_percentage_error: 10.5932\n",
      "Epoch 291/300\n",
      "3/3 [==============================] - 0s 667us/step - loss: 3529744.2500 - mean_absolute_percentage_error: 10.5747\n",
      "Epoch 292/300\n",
      "3/3 [==============================] - 0s 1000us/step - loss: 3507610.0000 - mean_absolute_percentage_error: 10.5579\n",
      "Epoch 293/300\n",
      "3/3 [==============================] - 0s 1000us/step - loss: 3501010.7500 - mean_absolute_percentage_error: 10.5501\n",
      "Epoch 294/300\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 3493939.7500 - mean_absolute_percentage_error: 10.5431\n",
      "Epoch 295/300\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 3490102.7500 - mean_absolute_percentage_error: 10.5401\n",
      "Epoch 296/300\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 3484192.2500 - mean_absolute_percentage_error: 10.5310\n",
      "Epoch 297/300\n",
      "3/3 [==============================] - 0s 667us/step - loss: 3471127.2500 - mean_absolute_percentage_error: 10.5077\n",
      "Epoch 298/300\n",
      "3/3 [==============================] - 0s 1000us/step - loss: 3465624.2500 - mean_absolute_percentage_error: 10.4983\n",
      "Epoch 299/300\n",
      "3/3 [==============================] - 0s 667us/step - loss: 3460873.5000 - mean_absolute_percentage_error: 10.4899\n",
      "Epoch 300/300\n",
      "3/3 [==============================] - 0s 999us/step - loss: 3451681.5000 - mean_absolute_percentage_error: 10.4673\n",
      "WARNING:tensorflow:9 out of the last 12 calls to <function Model.make_test_function.<locals>.test_function at 0x0000029053649280> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 0s 0s/step - loss: 9479204.0000 - mean_absolute_percentage_error: 15.7532\n",
      "\n",
      "MAPE: 15.75%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x290521c3f40>]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#–ù–µ–π—Ä–æ–Ω–Ω—ã–µ —Å–µ—Ç–∏: –ü—Ä–æ–≥–Ω–æ–∑–∏—Ä–æ–≤–∞–Ω–∏–µ\n",
    "#–£–º–µ–Ω—å—à–µ–Ω–∏–µ –Ω–∞–∫–∞–ø–ª–∏–≤–∞–µ–º–æ—Å—Ç–∏ –æ—à–∏–±–∫–∏ –º.–±. —Ç–æ–ª—å–∫–æ —Å –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω—ã–º –æ–±—É—á–µ–Ω–∏–µ–º –Ω–µ—Å–∫–æ–ª—å–∫–∏—Ö —Å–µ—Ç–µ–π (–∏ —Å–æ —Å–Ω–∏–∂–µ–Ω–∏–µ–º –∫–∞—á–µ—Å—Ç–≤–∞ –≤ —Ü–µ–ª–æ–º)\n",
    "#–ù–∞–∏–±–æ–ª–µ–µ –≤–∞–∂–Ω—ã —Å–∞–º—ã–µ –Ω–µ–¥–∞–≤–Ω–∏–µ (–∏–ª–∏ —Å–∞–º—ã–µ –≤—ã—Å–æ–∫–æ—Ä–∞–Ω–∂–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ) –Ω–∞–±–ª—é–¥–µ–Ω–∏—è. –ò—Ö –æ–ø—Ç–∏–º–∞–ª—å–Ω–æ —Å—Ç–∞–≤–∏—Ç—å –≤ —Ç–µ—Å—Ç–æ–≤—É—é\n",
    "#MSE, MAE –∏–ª–∏ Mean absolute percentage error (MAPE) - –ø–æ–∫–∞–∑—ã–≤–∞—é—Ç –æ—Ç–Ω–æ—Å–∏—Ç–µ–ª—å–Ω—É—é –æ—à–∏–±–∫—É –≤ —Ä–µ–≥—Ä–µ—Å—Å–∏–∏\n",
    "#MAPE = 1/n *—Å—É–º–º–∞(Yi-Y–ø—Ä–æ–≥–Ω–æ–∑)/Yi*100%\n",
    "\n",
    "\n",
    "sales = pd.read_csv('monthly-car-sales-in-quebec-1960.csv', sep=';', header=0, parse_dates=[0])\n",
    "\n",
    "#–ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º –¥–∞–Ω–Ω—ã–µ\n",
    "sales_2 = pd.DataFrame()\n",
    "\n",
    "for i in range(12,0,-1):\n",
    "    sales_2['t-'+str(i)] = sales.iloc[:,1].shift(i) #–ù–æ–≤—ã–µ –∫–æ–ª–æ–Ω–∫–∏, –≥–¥–µ –∑–Ω–∞—á–µ–Ω–∏—è —Å–¥–≤–∏–Ω—É—Ç—ã —Å –æ–±—Ä–∞—Ç–Ω—ã–º –≤—Ä–µ–º–µ–Ω–Ω—ã–º —à–∞–≥–æ–º(–ø–æ–º–µ—Å—è—á–Ω–æ)\n",
    "\n",
    "sales_2['t'] = sales.iloc[:,1].values #–î—É–±–ª–∏—Ä—É–µ–º –ø–µ—Ä–≤–æ–Ω–∞—á–∞–ª—å–Ω—É—é –∫–æ–ª–æ–Ω–∫—É\n",
    "sales_4 = sales_2[12:] #–û—Ç—Ä–µ–∑–∞–µ–º –ø–µ—Ä–≤—ã–µ 12 —Å—Ç—Ä–æ–∫\n",
    "\n",
    "#–ó–∞–¥–∞–µ–º –ø—Ä–µ–¥–∏–∫—Ç–æ—Ä—ã –∏ –æ—Ç–∫–ª–∏–∫\n",
    "y = sales_4['t']\n",
    "X = sales_4.drop('t', axis=1)\n",
    "\n",
    "#–†–∞–∑–¥–µ–ª—è–µ–º –Ω–∞ –æ–±—É—á–∞—é—â—É—é –∏ —Ç–µ—Å—Ç–æ–≤—É—é. –¢–µ—Å—Ç–æ–≤–∞—è - –ø–æ—Å–ª–µ–¥–Ω–∏–µ –Ω–∞–±–ª—é–¥–µ–Ω–∏—è\n",
    "X_train = X[:91]\n",
    "y_train = y[:91]\n",
    "X_test  = X[91:]\n",
    "y_test  = y[91:]\n",
    "\n",
    "#–ü—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ –≤ np.array\n",
    "X_train = X_train.values\n",
    "X_test = X_test.values\n",
    "y_train = y_train.values\n",
    "y_test = y_test.values\n",
    "\n",
    "#–°–æ–∑–¥–∞–µ–º, –∫–æ–º–ø–∏–ª–∏—Ä—É–µ–º –∏ –æ–±—É—á–∞–µ–º –º–æ–¥–µ–ª—å\n",
    "model = Sequential()\n",
    "model.add(Dense(8, input_dim=12, activation='relu'))\n",
    "model.add(Dense(1, activation='linear'))\n",
    "model.compile(loss='mean_squared_error', optimizer='adam', metrics=['mean_absolute_percentage_error'])\n",
    "model.fit(X_train, y_train, epochs=300, batch_size=None)\n",
    "\n",
    "#–æ—Ü–µ–Ω–∫–∞ –∫–∞—á–µ—Å—Ç–≤–∞ –º–æ–¥–µ–ª–∏ –Ω–∞ —Ç–µ—Å—Ç–æ–≤–æ–º –º–Ω–æ–∂–µ—Å—Ç–≤–µ\n",
    "scores = model.evaluate(X_test, y_test)\n",
    "print(\"\\nMAPE: %.2f%%\" % (scores[1]))\n",
    "\n",
    "# –í—ã—á–∏—Å–ª—è–µ–º –ø—Ä–æ–≥–Ω–æ–∑\n",
    "predictions = model.predict(X_test)\n",
    "\n",
    "# –í—ã—á–∏—Å–ª—è–µ–º –ø–æ–¥–≥–æ–Ω–∫—É\n",
    "predictions_train = model.predict(X_train)\n",
    "\n",
    "#–ì—Ä–∞—Ñ–∏–∫ —Å —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º–∏ numpy.arange(start, stop, step, dtype=None)\n",
    "x2 = np.arange(0, 91, 1)\n",
    "x3 = np.arange(91, 96, 1)\n",
    "\n",
    "plt.plot(x2, y_train, color='blue')\n",
    "plt.plot(x2, predictions_train, color='green')\n",
    "plt.plot(x3, y_test, color='blue')\n",
    "plt.plot(x3, predictions, color='red') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#–í—ã—á–∏—Å–ª–µ–Ω–∏–µ —Å—Ç–∞—Ç–∏—Å—Ç–∏—á–µ—Å–∫–æ–π –ø–æ–≥—Ä–µ—à–Ω–æ—Å—Ç–∏ –¥–ª—è —Å–ª—É—á–∞–π–Ω–æ–π –≤—ã–±–æ—Ä–∫–∏\n",
    "\n",
    "#–†–∞—Å—á–µ—Ç –æ–±—ä–µ–º–∞ –≤—ã–±–æ—Ä–∫–∏\n",
    "N = 40000 #–ì–µ–Ω–µ—Ä–∞–ª—å–Ω–∞—è —Å–æ–≤–æ–∫—É–ø–Ω–æ—Å—Ç—å\n",
    "P = 0.95 #–î–æ–≤–µ—Ä–∏—Ç–µ–ª—å–Ω—ã–π —É—Ä–æ–≤–µ–Ω—å –≤ 95% \n",
    "Z = 1.96 #–∫–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç –¥–æ–≤–µ—Ä–∏—Ç–µ–ª—å–Ω–æ–≥–æ —É—Ä–æ–≤–Ω—è (p = 95%, Z=1,96)(p=99%,   Z=2,58)\n",
    "p = 0.5 #–¥–æ–ª—è —Ä–µ—Å–ø–æ–Ω–¥–µ–Ω—Ç–æ–≤ —Å  –Ω–∞–ª–∏—á–∏–µ–º –∏—Å—Å–ª–µ–¥—É–µ–º–æ–≥–æ –ø—Ä–∏–∑–Ω–∞–∫–∞,\n",
    "q = (1 - p) #–¥–æ–ª—è —Ä–µ—Å–ø–æ–Ω–¥–µ–Ω—Ç–æ–≤, —É –∫–æ—Ç–æ—Ä—ã—Ö –∏—Å—Å–ª–µ–¥—É–µ–º—ã–π –ø—Ä–∏–∑–Ω–∞–∫ –æ—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç,\n",
    "delta = 0.05 #–ó–∞–¥–∞–≤–∞–µ–º–∞—è –ø—Ä–µ–¥–µ–ª—å–Ω–∞—è –æ—à–∏–±–∫–∞ –≤—ã–±–æ—Ä–∫–∏.\n",
    "n = (Z**2)*p*q/delta**2 #–æ–±—ä–µ–º –≤—ã–±–æ—Ä–∫–∏\n",
    "\n",
    "print(\"–†–µ–∫–æ–º–µ–Ω–¥—É–µ–º—ã–π –æ–±—ä–µ–º –≤—ã–±–æ—Ä–∫–∏ –¥–ª—è –¥–∞–Ω–Ω–æ–π –∞—É–¥–∏—Ç–æ—Ä–∏–∏:\", int(n), \"—á–µ–ª–æ–≤–µ–∫\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#–†–∞—Å—á–µ—Ç –æ—à–∏–±–∫–∏ –≤—ã–±–æ–∫–∏ –¥–ª—è –¥–æ–ª–∏ –ø—Ä–∏–∑–Ω–∞–∫–∞\n",
    "#–°–ª—É—á–∞–π 1. –ì–µ–Ω–µ—Ä–∞–ª—å–Ω–∞—è —Å–æ–≤–æ–∫—É–ø–Ω–æ—Å—Ç—å –∑–Ω–∞—á–∏—Ç–µ–ª—å–Ω–æ –±–æ–ª—å—à–µ –≤—ã–±–æ—Ä–∫–∏\n",
    "n = 384 #–û–±—ä–µ–º –≤—ã–±–æ—Ä–∫–∏\n",
    "m = 276 #–ß–∏—Å–ª–æ –æ–±—ä–µ–∫—Ç–æ–≤ –≤—ã–±–æ—Ä–∫–∏ —Å –Ω—É–∂–Ω—ã–º–∏ –ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º–∏ (True)\n",
    "p = m/n #–í–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å –Ω–∞ –æ—Å–Ω–æ–≤–µ –ø—Ä–∞–∫—Ç–∏—á–µ—Å–∫–∏—Ö –¥–∞–Ω–Ω—ã—Ö\n",
    "sigma = n/2*((p*(1-p)/n*(1-n/N)))**0.5 \n",
    "print('–†–µ–∑—É–ª—å—Ç–∞—Ç –≤—ã–±–æ—Ä–∫–∏ –æ–¥–∏–Ω —Å–æ—Å—Ç–∞–≤–∏—Ç: ', \\\n",
    "      float(\"{0:.1f}\".format(p*100)), \"¬±\", float(\"{0:.1f}\".format(sigma)), \"%\")\n",
    "\n",
    "#–°–ª—É—á–∞–π 2. –ì–µ–Ω–µ—Ä–∞–ª—å–Ω–∞—è —Å–æ–≤–æ–∫—É–ø–Ω–æ—Å—Ç—å —Å–æ–ø–æ—Å—Ç–∞–≤–∏–º–∞ —Å –æ–±—ä–µ–º–æ–º –≤—ã–±–æ—Ä–∫–∏\n",
    "N = 2500\n",
    "delta = Z*((p*q/n)*((N-n)/(N-1)))**0.5 \n",
    "print(\"–¢–æ—á–Ω–æ—Å—Ç—å —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –≤—ã–±–æ—Ä–∫–∏ –¥–≤–∞ —Å–æ—Å—Ç–∞–≤–∏—Ç: \", \"¬±\", float(\"{0:.1f}\".format(delta*100)), \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#–†–∞—Å—Å—á–µ—Ç –¥–æ–≤–µ—Ä–∏—Ç–µ–ª—å–Ω–æ–≥–æ –∏–Ω—Ç–µ—Ä–≤–∞–ª–∞\n",
    "P = 0.99 #–î–æ–≤–µ—Ä–∏—Ç–µ–ª—å–Ω—ã–π —É—Ä–æ–≤–µ–Ω—å –≤ 99% \n",
    "Z = 2.58 #–∫–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç –¥–æ–≤–µ—Ä–∏—Ç–µ–ª—å–Ω–æ–≥–æ —É—Ä–æ–≤–Ω—è \n",
    "p = 0.2 #–¥–æ–ª—è —Ä–µ—Å–ø–æ–Ω–¥–µ–Ω—Ç–æ–≤ —Å –Ω–∞–ª–∏—á–∏–µ–º –∏—Å—Å–ª–µ–¥—É–µ–º–æ–≥–æ –ø—Ä–∏–∑–Ω–∞–∫–∞,\n",
    "q = (1 - p) #–¥–æ–ª—è —Ä–µ—Å–ø–æ–Ω–¥–µ–Ω—Ç–æ–≤, —É –∫–æ—Ç–æ—Ä—ã—Ö –∏—Å—Å–ª–µ–¥—É–µ–º—ã–π –ø—Ä–∏–∑–Ω–∞–∫ –æ—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç,\n",
    "n = 1000 #–û–±—ä–µ–º –≤—ã–±–æ—Ä–∫–∏\n",
    "\n",
    "sigma = Z*(p*q/n)**0.5 #–ü–æ–≥—Ä–µ—à–Ω–æ—Å—Ç—å –æ—Ü–µ–Ω–∫–∏\n",
    "\n",
    "print('–¢–æ—á–Ω–æ—Å—Ç—å —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–π –≤—ã–±–æ—Ä–∫–∏ —Å–æ—Å—Ç–∞–≤–∏—Ç: ¬±', float(\"{0:.2f}\".format(sigma*100)), \"%\")\n",
    "print('–î–æ–≤–µ—Ä–∏—Ç–µ–ª—å–Ω—ã–π –∏–Ω—Ç–µ—Ä–≤–∞–ª —Å–æ—Å—Ç–∞–≤–∏—Ç:', float(\"{0:.2f}\".format((p - sigma)*100)), \"% ;\", \\\n",
    "                                            float(\"{0:.2f}\".format((p + sigma)*100)), \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#–ù–µ–Ω–æ—Ä–º–∞–ª—å–Ω—ã–µ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è\n",
    "#–°–≥–ª–∞–¥–∏—Ç—å —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ, —É–º–µ–Ω—å—à–∏–≤ —à–∫–∞–ª—É –Ω–∞ –æ—Å–Ω–æ–≤–∞–Ω–∏–∏ –ø–æ–ª–µ–∑–Ω–æ—Å—Ç–∏ –¥–∞–Ω–Ω—ã—Ö, —É–¥–∞–ª–∏–≤ –∞–Ω–æ–º–∞–ª–∏–∏\n",
    "#–õ–æ–≥–∞—Ä–∏—Ñ–º–∏—Ä–æ–≤–∞—Ç—å –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ (–Ω–µ –∑–∞–±—ã–≤–∞–µ–º –ø—Ä–æ –Ω–æ–ª—å –≤ –∏—Å—Ö–æ–¥–Ω–æ–π –ø–µ—Ä–µ–º–µ–Ω–Ω–æ–π). –°—Ö–ª–æ–ø—ã–≤–∞–µ—Ç —ç–∫—Å—Ç—Ä–µ–º–∞–ª—å–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è\n",
    "#–õ–æ–≥–∞—Ä–∏—Ñ–º–∏—Ä–æ–≤–∞–Ω–∏–µ –æ—Ç–ª–∏—á–Ω–æ —Ä–∞–±–æ—Ç–∞–µ—Ç —Å –∞—Å—Å–∏–º–µ—Ç—Ä–∏—á–Ω—ã–º–∏ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è–º–∏\n",
    "#–ï—Å–ª–∏ –ª–æ–≥–∞—Ä–∏—Ñ–º—ã –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö –∑–∞–≤–∏—Å–∏–º—ã –ª–∏–Ω–µ–π–Ω–æ, —Ç–æ –∑–Ω–∞—á–∏—Ç —Å–∞–º–∏ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –∑–∞–≤–∏—Å—è—Ç –Ω–µ–ª–∏–Ω–µ–π–Ω–æ \n",
    "#–ü—Ä–∏–º–µ–Ω–∏—Ç—å –Ω–µ–ø–∞—Ä–∞–º–µ—Ç—Ä–∏—á–µ—Å–∫–∏–π –∫—Ä–∏—Ç–µ—Ä–∏–π (—Ä–∞–Ω–≥–æ–≤–æ–µ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ)\n",
    "#–ü—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ –ë–æ–∫—Å–∞-–ö–æ–∫—Å–∞ –ø–æ–¥–±–∏—Ä–∞–µ—Ç –æ–ø—Ç–∏–º–∞–ª—å–Ω—É—é —Å—Ç–µ–ø–µ–Ω—å –¥–ª—è –≤–æ–∑–≤–µ–¥–µ–Ω–∏—è –≤ –Ω–µ–µ mathworks.com/help/finance/boxcox.html \n",
    "#Bootstrap –∏ –º–µ—Ç–æ–¥ –ú–æ–Ω—Ç–µ-–ö–∞—Ä–ª–æ. –°—Ä–∞–≤–Ω–∏–≤–∞—Ç—å –º–µ–¥–∏–∞–Ω—É, –º–∏–Ω, –º–∞–∫—Å, 13-–ø—Ä–æ—Ü–µ–Ω—Ç–∏–ª—å, —Å—Ä–µ–¥–Ω–µ–µ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* –ü—Ä–æ–≤–µ—Ä–∫–∞ –≥–∏–ø–æ—Ç–µ–∑—ã –æ –Ω–æ—Ä–º–∞–ª—å–Ω–æ—Å—Ç–∏ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è.<br>\n",
    "H0: $X \\sim N(\\cdot, \\cdot)$<br>\n",
    "H1: $X \\nsim N(\\cdot, \\cdot)$<br>\n",
    "–ö—Ä–∏—Ç–µ—Ä–∏–π –®–∞–ø–∏—Ä–æ-–£–∏–ª–∫–∞ [scipy.stats.shapiro](https://docs.scipy.org/doc/scipy-0.14.0/reference/generated/scipy.stats.shapiro.html).<br>\n",
    "\n",
    "\n",
    "* –ö—Ä–∏—Ç–µ—Ä–∏–π —Å–æ–≥–ª–∞—Å–∏—è –°—Ç—å—é–¥–µ–Ω—Ç–∞.<br>\n",
    "H0: $\\mu = M$<br>\n",
    "H1: $\\mu \\ne M$<br>\n",
    "[scipy.stats.ttest_1samp](https://docs.scipy.org/doc/scipy-0.14.0/reference/generated/scipy.stats.ttest_1samp.html).<br>\n",
    "\n",
    "\n",
    "* –ü—Ä–æ–≤–µ—Ä–∫–∞ –≥–∏–ø–æ—Ç–µ–∑—ã –æ —Ä–∞–≤–µ–Ω—Å—Ç–≤–µ —Å—Ä–µ–¥–Ω–∏—Ö –∑–Ω–∞—á–µ–Ω–∏–π.<br>\n",
    "H0: $\\mu_1 = \\mu_2$<br>\n",
    "H1: $\\mu_1 \\ne \\mu_2$<br>\n",
    "–†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –≤—ã–±–æ—Ä–æ–∫ –¥–æ–ª–∂–Ω–æ –±—ã—Ç—å –±–ª–∏–∑–∫–æ –∫ –Ω–æ—Ä–º–∞–ª—å–Ω–æ–º—É.<br>\n",
    "  * –î–ª—è –Ω–µ—Å–≤—è–∑–Ω—ã—Ö –≤—ã–±–æ—Ä–æ–∫: [scipy.stats.ttest_ind](https://docs.scipy.org/doc/scipy-0.14.0/reference/generated/scipy.stats.ttest_ind.html).<br>\n",
    "  * –î–ª—è —Å–≤—è–∑–Ω—ã—Ö –≤—ã–±–æ—Ä–æ–∫: [scipy.stats.ttest_rel](https://docs.scipy.org/doc/scipy-0.14.0/reference/generated/scipy.stats.ttest_rel.html).<br>\n",
    "  \n",
    "\n",
    "* –ü—Ä–æ–≤–µ—Ä–∫–∞ –≥–∏–ø–æ—Ç–µ–∑—ã –æ —Ä–∞–≤–µ–Ω—Å—Ç–≤–µ –º–µ–¥–∏–∞–Ω.<br>\n",
    "  * –î–ª—è –Ω–µ—Å–≤—è–∑–Ω—ã—Ö –≤—ã–±–æ—Ä–æ–∫: –∫—Ä–∏—Ç–µ—Ä–∏–π –ú–∞–Ω–Ω–∞-–£–∏—Ç–Ω–∏ [scipy.stats.mannwhitneyu](https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.mannwhitneyu.html).<br>\n",
    "  * –î–ª—è —Å–≤—è–∑–Ω—ã—Ö –≤—ã–±–æ—Ä–æ–∫: –∫—Ä–∏—Ç–µ—Ä–∏–π –£–∏–ª–∫–æ–∫—Å–æ–Ω–∞ [scipy.stats.wilcoxon](https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.wilcoxon.html).<br>\n",
    "  * –ö—Ä–∏—Ç–µ—Ä–∏–π –ú—É–¥–∞ [scipy.stats.median_test](https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.median_test.html).<br>\n",
    "\n",
    "\n",
    "* –ü—Ä–æ–≤–µ—Ä–∫–∞ –≥–∏–ø–æ—Ç–µ–∑—ã –æ —Ä–∞–≤–µ–Ω—Å—Ç–≤–µ –¥–∏—Å–ø–µ—Ä—Å–∏–π.<br>\n",
    "H0: $\\sigma_1 = \\sigma_2$<br>\n",
    "H1: $\\sigma_1 \\neq \\sigma_2$<br>\n",
    "–ö—Ä–∏—Ç–µ—Ä–∏–π –§–ª–∏–Ω–≥–µ—Ä–∞-–ö–∏–ª–∏–Ω–∞ [scipy.stats.fligner](https://docs.scipy.org/doc/scipy-0.17.0/reference/generated/scipy.stats.fligner.html).<br>\n",
    "\n",
    "\n",
    "* –ü—Ä–æ–≤–µ—Ä–∫–∞ –≥–∏–ø–æ—Ç–µ–∑—ã –æ —Ä–∞–≤–µ–Ω—Å—Ç–≤–µ –¥–æ–ª–µ–π –∫–∞—Ç–µ–≥–æ—Ä–∏–∞–ª—å–Ω–æ–≥–æ –ø—Ä–∏–∑–Ω–∞–∫–∞.<br>\n",
    "H0: $p_1 = p_2$<br>\n",
    "H1: $p_1 \\ne p_2$<br>\n",
    "–ö—Ä–∏—Ç–µ—Ä–∏–π —Ö–∏-–∫–≤–∞–¥—Ä–∞—Ç [scipy.stats.chi2_contingency](https://docs.scipy.org/doc/scipy-0.17.0/reference/generated/scipy.stats.chi2_contingency.html).<br>\n",
    "\n",
    "\n",
    "* –ü—Ä–æ–≤–µ—Ä–∫–∞ –≥–∏–ø–æ—Ç–µ–∑—ã –æ –Ω–µ–∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ (–∫–æ—Ä—Ä–µ–ª—è—Ü–∏—è).<br>\n",
    "H0: X –∏ Y –Ω–µ–∑–∞–≤–∏—Å–∏–º—ã<br>\n",
    "H1: X –∏ Y –∑–∞–≤–∏—Å–∏–º—ã<br>\n",
    "  * –î–ª—è –Ω–µ–ø—Ä–µ—Ä—ã–Ω—ã—Ö –≤–µ–ª–∏—á–∏–Ω: –∫–æ—Ä—Ä–µ–ª—è—Ü–∏—è –ü–∏—Ä—Å–æ–Ω–∞ [scipy.stats.pearsonr](https://docs.scipy.org/doc/scipy-0.14.0/reference/generated/scipy.stats.pearsonr.html),<br>\n",
    "  * –î–ª—è –¥–∏—Å–∫—Ä–µ—Ç–Ω—ã—Ö –≤–µ–ª–∏—á–∏–Ω: –∫–æ—Ä—Ä–µ–ª—è—Ü–∏—è –°–ø–∏—Ä–º—ç–Ω–∞ [scipy.stats.kendalltau](https://docs.scipy.org/doc/scipy-0.14.0/reference/generated/scipy.stats.kendalltau.html).<br>\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
