{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://python.ivan-shamaev.ru/python-data-wrangling-tutorial-for-cryptocurrency/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import reduce\n",
    "import pandas as pd\n",
    "\n",
    "pd.options.display.float_format = '{:,.2f}'.format\n",
    "pd.options.display.max_rows = 200\n",
    "pd.options.display.max_columns = 100\n",
    "\n",
    "df = pd.read_csv('BNC2_sample.csv',\n",
    "                 names=['Code', 'Date', 'Open', 'High', 'Low', \n",
    "                        'Close', 'Volume', 'VWAP', 'TWAP'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Эквивалентность в гранулярности —  например, 10 строк данных. Но не 11-ю аггрегацией по среднему или сумме\n",
    "#Эквивалентность в единицах — 10 строк с ценами в USD, не должно быть еще 10 строк в евро\n",
    "#Для расчета returns путем смещения набора данных нужно отсортировать их по дате, не иметь пропущенных дат (!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Проверка уникальных значений в колонке\n",
    "print( df.Code.unique() )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Фильтр фрейма, оставить только строки с опредленным значением в одной из колонок\n",
    "print( 'Before:', len(df) )\n",
    "gwa_codes = [code for code in df.Code.unique() if 'GWA_' in code]\n",
    "df = df[df.Code.isin(gwa_codes)]\n",
    "print( 'After:', len(df) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#повернем набор данных, оставив только один ценовой столбец VWAP (средневзвешенная цена)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pivot dataset\n",
    "pivoted_df = df.pivot(index='Date', columns='Code', values='VWAP')\n",
    " \n",
    "# Display examples from pivoted dataset\n",
    "pivoted_df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Чтобы легко рассчитать returns за предыдущие 7, 14, 21 и 28 дней, используем метод shift из Pandas\n",
    "#функция сдвигает индекс dataframe на указанное количество периодов. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(pivoted_df.tail(3))\n",
    "print(pivoted_df.tail(3).shift(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#для расчета доходности за 7 дней понадобится prices_today / prices_7_days_ago - 1.0, что означает:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculate returns over 7 days prior\n",
    "delta_7 = pivoted_df / pivoted_df.shift(7) - 1.0\n",
    "\n",
    "#display examples\n",
    "delta_7.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Calculate returns over each window and store them in dictionary\n",
    "delta_dict = {}\n",
    "for offset in [7, 14, 21, 28]:\n",
    "    delta_dict['delta_{}'.format(offset)] = pivoted_df / pivoted_df.shift(offset) - 1.0\n",
    "# Display result \"delta_dict\"\n",
    "delta_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Чтобы расплавить данные требуется:\n",
    "#reset_index(), чтобы вызывать столбцы по имени;\n",
    "#метод melt();\n",
    "#Передайте столбец (столбцы), чтобы сохранить в аргумент id_vars=;\n",
    "#Назовите растопленный столбец (melted column), используя аргумент value_name=."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Melt delta_7 returns\n",
    "melted_7 = delta_7.reset_index().melt(id_vars=['Date'], value_name='delta_7')\n",
    " \n",
    "# Melted dataframe examples\n",
    "melted_7.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Melt all the delta dataframes and store in list\n",
    "melted_dfs = []\n",
    "for key, delta_df in delta_dict.items():\n",
    "    melted_dfs.append( delta_df.reset_index().melt(id_vars=['Date'], value_name=key) )\n",
    "melted_dfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#расплавленный фрейм данных, который содержит прогнозные 7-дневные возвраты будет «целевой переменной» для оценки\n",
    "#Просто сдвинуть сводный набор данных на — 7, чтобы получить «будущие» цены"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate 7-day returns after the date\n",
    "return_df = pivoted_df.shift(-7) / pivoted_df - 1.0\n",
    " \n",
    "# Melt the return dataset and append to list\n",
    "melted_dfs.append( return_df.reset_index().melt(id_vars=['Date'], value_name='return_7') )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Объединить расплавленные DataFrames в единую аналитическую базовую таблицу"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge two dataframes\n",
    "pd.merge(melted_dfs[0], melted_dfs[1], on=['Date', 'Code']).tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#список feature_dfs содержит базовые элементы из исходного набора данных плюс расплавленные наборы данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grab features from original dataset\n",
    "base_df = df[['Date', 'Code', 'Volume', 'VWAP']]\n",
    " \n",
    "# Create a list with all the feature dataframes\n",
    "feature_dfs = [base_df] + melted_dfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reduce применяет функцию двух аргументов кумулятивно к объектам в последовательности (например, список)\n",
    "#reduce(lambda x,y: x+y, [1,2,3,4,5]) = ((((1+2)+3)+4)+5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reduce-merge features into analytical base table\n",
    "abt = reduce(lambda left,right: pd.merge(left, right, on=['Date', 'Code']), feature_dfs)\n",
    " \n",
    "# Display examples from the ABT\n",
    "abt.tail(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#если  хотим выбрать монету, которая имела наибольший импульс 1 сентября 2017, \n",
    "#просто выбираем строки для этой даты и смотрим на 7, 14, 21 и 28-дневный возврат:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data from Sept 1st, 2017\n",
    "abt[abt.Date == '2017-09-01']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#выбрать криптовалюту (пару для торгов) с наибольшим импульсом (например, за предыдущие 28 дней)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_momentum_id = abt[abt.Date == '2017-09-01'].delta_28.idxmax()\n",
    "abt.loc[max_momentum_id, ['Code','return_7']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# если хотим сохранить только первые дни каждого месяца: группирование с последующей агрегацией\n",
    "#новая функцию ‘month’ из первых 7 символов строк Date.\n",
    "#группируем наблюдения по «Коду» и «месяцу». \n",
    "#в каждой группе возьмите .first() и сбросьте индекс."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create 'month' feature\n",
    "abt['month'] = abt.Date.apply(lambda x: x[:7])\n",
    " \n",
    "# Group by 'Code' and 'month' and keep first date\n",
    "gb_df = abt.groupby(['Code', 'month']).first().reset_index()\n",
    " \n",
    "# Display examples\n",
    "gb_df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ИТОГ0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Import libraries and dataset\n",
    "import pandas as pd\n",
    "pd.options.display.float_format = '{:,.2f}'.format\n",
    "pd.options.display.max_rows = 200\n",
    "pd.options.display.max_columns = 100\n",
    " \n",
    "df = pd.read_csv('BNC2_sample.csv',\n",
    "                 names=['Code', 'Date', 'Open', 'High', 'Low', \n",
    "                        'Close', 'Volume', 'VWAP', 'TWAP'])\n",
    " \n",
    "# 4. Filter unwanted observations\n",
    "gwa_codes = [code for code in df.Code.unique() if 'GWA_' in code]\n",
    "df = df[df.Code.isin(gwa_codes)]\n",
    " \n",
    "# 5. Pivot the dataset\n",
    "pivoted_df = df.pivot(index='Date', columns='Code', values='VWAP')\n",
    " \n",
    "# 6. Shift the pivoted dataset\n",
    "delta_dict = {}\n",
    "for offset in [7, 14, 21, 28]:\n",
    "    delta_dict['delta_{}'.format(offset)] = pivoted_df / pivoted_df.shift(offset) - 1\n",
    "    \n",
    "# 7. Melt the shifted dataset\n",
    "melted_dfs = []\n",
    "for key, delta_df in delta_dict.items():\n",
    "    melted_dfs.append( delta_df.reset_index().melt(id_vars=['Date'], value_name=key) )\n",
    " \n",
    "return_df = pivoted_df.shift(-7) / pivoted_df - 1.0\n",
    "melted_dfs.append( return_df.reset_index().melt(id_vars=['Date'], value_name='return_7') )\n",
    " \n",
    "# 8. Reduce-merge the melted data\n",
    "from functools import reduce\n",
    " \n",
    "base_df = df[['Date', 'Code', 'Volume', 'VWAP']]\n",
    "feature_dfs = [base_df] + melted_dfs\n",
    " \n",
    "abt = reduce(lambda left,right: pd.merge(left,right,on=['Date', 'Code']), feature_dfs)\n",
    " \n",
    "# 9. Aggregate with group-by.\n",
    "abt['month'] = abt.Date.apply(lambda x: x[:7])\n",
    "gb_df = abt.groupby(['Code', 'month']).first().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
