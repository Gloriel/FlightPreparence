{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Согласованность, Точность, Уникальность, Полнота, Своевременность, Доступность и т.д.\n",
    "\n",
    "Range Constraints: числа или даты должны попадать в определенный диапазон с использованием одной единицы измерения\n",
    "Mandatory Constraints: некоторые столбцы не могут быть пустыми\n",
    "Шаблоны регулярных выражений: текстовые поля, которые должны быть в определенном шаблоне. Например (999) 999–9999.\n",
    "Consistency: степень соответствия данных в одном или нескольких БД"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib \n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "from pylab import plot,show,hist\n",
    "from scipy.stats.kde import gaussian_kde\n",
    "from scipy.stats import norm, chi2_contingency\n",
    "\n",
    "from sklearn import preprocessing\n",
    "#%config InlineBackend.figure_format = 'svg' для большей четкости графиков\n",
    "matplotlib.style.use('ggplot')\n",
    "%matplotlib inline\n",
    "\n",
    "#df = pd.read_csv('AmesHousing.txt', sep=\"\\t\", header = 0, encoding='cp1251', index_col=False)\n",
    "#df = pd.read_csv('beverage_r.csv', sep=\";\", decimal=',', parse_dates=[0], index_col='numb.obs')\n",
    "#df = pd.read_csv('diamond.dat', header=None, sep='\\s+', names=['weight', 'price'])\n",
    "#df = pd.read_csv('adult.test', header=None, names=columns, na_values=' ?', skiprows=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Удаляем столбцы, где данные непрочитались\n",
    "df = df.filter(regex='^(?!.*Unnamed).*$')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Смотрим коэффициенты корелляций. Мало больших значений - плохо для факторного анализа\n",
    "df.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Сортировка числовых колонок\n",
    "df['data'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Чистка от пустых значений\n",
    "df = df.replace(-9999, np.nan)\n",
    "print('Rows in the data frame: {0}'.format(len(df)))\n",
    "print('Rows without NAN: {0}'.format(len(df.dropna(how='any'))))\n",
    "\n",
    "#Слишком много данных содержат хотя бы одно пропущенное значение, чтобы удалить их все. Смотрим их распределение по колонкам\n",
    "#Функция .apply для всей матрицы. 1й аргумент-применяемая функция, 2й - направление применения (0 к колонкам, 1 ко строкам)\n",
    "df.apply(lambda x: sum(x.isnull()), axis=0)\n",
    "\n",
    "#Если непоправимо мало данных, удаляем колонку\n",
    "del df['data']\n",
    "\n",
    "#Анализируем колонку где можно заменить пропуски\n",
    "df['data'].hist()\n",
    "\n",
    "#Меняем пропущенные значения на среднее значение по колонке \n",
    "df['data'] = df['data'].fillna(df['data'].mean())\n",
    "\n",
    "#Удалим самые пустые колонки полностью и выбросим строчки с пропущенными значениями в тех где нужно\n",
    "df = df.drop(['data', 'data'], axis=1)\n",
    "df = df[(df['data'] != 'unknown') & (df['data'] != 'unknown')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Преобразуем бинарные столбцы в численные. Колонку y тоже\n",
    "df['data'] = df['data'].map({'predict1': 0, 'predict2': 1, 'predict3': 2})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Категориальные колонки не имеют естественного порядка, поэтому преобразуем их с помощью one-hot encoding\n",
    "features = ['predict1', 'predict2', 'predict3']\n",
    "df = pd.get_dummies(df, columns=features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Преобразуем строчки с датами в объект datetime\n",
    "df['date'] = pd.to_datetime(df['date'], format='%b %Y') # format показывает что читаем: '%b %Y' трехбуквенный месяц, затем год \n",
    "\n",
    "#Построим график проверить тип тренда (линейный или нет), тип сезонности (аддитивный или мультипликативный), его длину, выбросы\n",
    "#Видим линейный тренд и мультипликативную сезонность. Это подтверждается после логирафмирование цикла \n",
    "\n",
    "fig = plt.figure(figsize=(12, 4))\n",
    "ax1 = fig.add_subplot(121)\n",
    "df['date'].plot(ax=ax1)\n",
    "ax1.set_title(u'коммент')\n",
    "ax1.set_ylabel(u'коммент')\n",
    "\n",
    "ax2 = fig.add_subplot(122)\n",
    "pd.Series(np.log10(df['date'])).plot(ax=ax2)\n",
    "ax2.set_title(u'коммент')\n",
    "ax2.set_ylabel(u'коммент')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Если несколько классов, но хочется сделать классификацию строго бинарной, то разбиваем на группы ДА и НЕТ\n",
    "df['date'] = df['date'].replace(0, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Вероятностная гистограмма \n",
    "df['data'].hist(density=True, bins=60)\n",
    "#Сравнение гистограмм\n",
    "df.groupby('data')['data'].plot.hist(alpha=.6)\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#В случае очевидного смешения двух нормальных распределений, можно оценить их более подробно\n",
    "df.groupby('data')['data'].plot.hist(alpha=0.6)\n",
    "df.groupby('data')['data'].plot.hist(density=True) #Нормализованный вариант\n",
    "plt.legend(loc='upper left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Shapiro-Wilk позволяют проверить выборку на принадлежность к ГС и нормальность распредеелния\n",
    "df = df.set_index(u'номер')\n",
    "plt.hist(np.log10(df[u'номер']), bins=50) #Применяем критерий Шапиро-Вилка после логарифмирования\n",
    "res = stats.shapiro(np.log10(df[u'номер']))\n",
    "print('p-value: ', res[1]) #Если p маленькое, гипотезу о нормальности отвергаем"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Работа с выбросами\n",
    "town_2 = df.iloc[2:1004] #Обрезать аномалии\n",
    "\n",
    "x = np.log10(df[u'номер']) #Логарифмировать переменную (для лог-нормального распределения)\n",
    "pd.Series(x).hist(bins=45)\n",
    "\n",
    "exclude = int(len(df)/100*2.5) #Усеченное среднее (Среднее -2,5% самых малых и -2,5% наибольших)\n",
    "redacted_town = df[exclude:len(df)-exclude]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Матрица диаграмм рассеивания: комплексное сравнение по нескольким переменным. Диагональ - ядерная оценка плотности\n",
    "colors = {'genuine': 'green', 'counterfeit': 'red'}\n",
    "scatter_matrix(df,               \n",
    "               figsize=(6, 6), #размер картинки\n",
    "               diagonal='kde', #плотность вместо гистограммы на диагонали\n",
    "               c=df['data'].replace(colors),  #цвета классов\n",
    "               alpha=0.2 #степень прозрачности точек\n",
    "              )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Корреляция двух переменных\n",
    "plt.scatter(df['data'], df['data'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Исправление опечаток\n",
    "df['data'].map({'m': 'male', fem.': 'female', ...})\n",
    "re.sub (r \"\\ ^ m \\ $\", ' Male ', ' male ', flags = re. IGNORECASE )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Заполнить пробелы Средним значением\n",
    "rand = np.random.randint(average_age - 2*std_age, average_age + 2*std_age, size = count_nan_age) \n",
    "df[\"data\"][np.isnan(df[\"data\"])] = rand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Строим R матрицу корелляций. Много выбросов, есть бимодальности. Но сильной корелляции увы нет\n",
    "scatter_matrix(df); #Добавление \";\" позволяет показать только график, без цифр"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Приводим множество названий колонок к типу set, находим разность двух множеств: Голландии нет в колонке native-county \n",
    "print(set(X_train.columns) - set(X_test.columns))\n",
    "print(set(X_test.columns) - set(X_train.columns))\n",
    "\n",
    "#Добавляем недостающую колонку. Смотрим, стоит ли склеивать отдельные переменные в более крупные классы\n",
    "columns = set(X_train.columns) | set(X_test.columns)\n",
    "X_train = X_train.reindex(columns=columns).fillna(0)\n",
    "X_test = X_test.reindex(columns=columns).fillna(0)\n",
    "\n",
    "#Проверяем совпадение колонок (если да, то True)\n",
    "all(X_train.columns == X_test.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Если в БД нет единой метрики, то стандартизируем данные\n",
    "import math\n",
    "from sklearn import preprocessing\n",
    "from sklearn.decomposition import FactorAnalysis\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "norm = preprocessing.StandardScaler()\n",
    "norm.fit(df)\n",
    "X = norm.transform(df)\n",
    "\n",
    "#Cтандартизируем переменные 2\n",
    "df_scaled = preprocessing.scale(df)\n",
    "\n",
    "#Методом поиска главных компонентов проецируем данные на двумерную плоскость и получаем ранжирование компонентов по важности \n",
    "pca = PCA(n_components=5).fit(df_scaled) #Уточняем число компонент и источник данных \n",
    "\n",
    "#Доля разброса в данных, объясняемая главными компонентами\n",
    "print('Влияние компонентов на общий разброс данных: ', pca.explained_variance_ratio_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.options.display.float_format = '{:,.2f}'.format\n",
    "pd.set_option('display.width', 85)\n",
    "pd.set_option('display.max_columns', 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
